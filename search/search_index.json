{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-aiperf-documentation","title":"Welcome to AIPerf Documentation","text":"<p>AIPerf is a package for performance testing of AI models.</p>"},{"location":"#overview","title":"Overview","text":"<ul> <li>Explore the documentation using the navigation menu.</li> <li>See the Development page for contributing and setup instructions.</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li>Install dependencies</li> <li>Run the CLI or use the Python API</li> </ol> <p>For more details, see the rest of the documentation.</p>"},{"location":"Development/","title":"Development","text":""},{"location":"Development/#developers-guide","title":"Developers Guide","text":"<p>Execute the following commands to set up your development environment for <code>aiperf</code>. Make sure you are in the root directory of the <code>aiperf</code> repository.</p>"},{"location":"Development/#development-environment","title":"Development Environment","text":"<ul> <li>Install uv https://docs.astral.sh/uv/getting-started/installation/</li> </ul> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> <ul> <li>Create virtual env</li> </ul> <pre><code>uv venv\n</code></pre> <ul> <li>Activate venv</li> </ul> <pre><code>source .venv/bin/activate\n</code></pre> <ul> <li>Install <code>aiperf</code> package in editable development mode</li> </ul> <pre><code>uv pip install -e \".[dev]\"\n</code></pre> <ul> <li>Run <code>aiperf</code> in asyncio mode (current default)</li> </ul> <pre><code>aiperf --run-type async\n</code></pre> <p>Press <code>Ctrl-C</code> to stop the process</p> <ul> <li>Run <code>aiperf</code> in multiprocessing mode</li> </ul> <pre><code>aiperf --run-type process\n</code></pre> <p>Press <code>Ctrl-C</code> to stop the process</p> <ul> <li>Run <code>aiperf</code> with <code>--help</code> to see available commands</li> </ul> <pre><code>aiperf --help\n</code></pre>"},{"location":"Development/#code-overview","title":"Code Overview","text":""},{"location":"Development/#project-structure","title":"Project Structure","text":"<pre><code>aiperf/\n\u251c\u2500\u2500 aiperf/              # Main python package\n\u2502   \u251c\u2500\u2500 app/                 # Application components\n\u2502   \u251c\u2500\u2500 cli.py               # Command line interface\n\u2502   \u251c\u2500\u2500 common/              # Shared utilities and models\n\u2502   \u2502   \u251c\u2500\u2500 config/             # Configuration management\n\u2502   \u2502   \u251c\u2500\u2500 enums.py            # Enum definitions\n\u2502   \u2502   \u251c\u2500\u2500 exceptions/         # Custom exceptions\n\u2502   \u2502   \u251c\u2500\u2500 models/             # Pydantic data models\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 messages.py         # Message definitions\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 service.py          # Service related model definitions\n\u2502   \u2502   \u2514\u2500\u2500 service.py          # Base service implementation\n\u2502   \u2514\u2500\u2500 services/            # System services\n\u2502       \u251c\u2500\u2500 dataset_manager/        # Handles dataset operations\n\u2502       \u251c\u2500\u2500 post_processor_manager/ # Processes results\n\u2502       \u251c\u2500\u2500 records_manager/        # Manages test records\n\u2502       \u251c\u2500\u2500 system_controller/      # Controls system operation\n\u2502       \u251c\u2500\u2500 timing_manager/         # Handles timing and credits\n\u2502       \u251c\u2500\u2500 worker/                 # Executes benchmarks\n\u2502       \u2514\u2500\u2500 worker_manager/         # Manages worker processes\n\u251c\u2500\u2500 docs/                # Documentation\n\u251c\u2500\u2500 tests/               # Test suite\n\u251c\u2500\u2500 pyproject.toml       # Project configuration\n\u251c\u2500\u2500 Makefile             # Build and automation scripts\n\u2514\u2500\u2500 README.md            # Project readme\n</code></pre>"},{"location":"Development/#core-components","title":"Core Components","text":"<p>This comes from the AIPerf Design Document</p> <p>AIPerf implements a distributed microservices architecture with the following key components:</p> <ul> <li>System Controller: Primary responsibility is to orchestrate the system. It will ensure all blocks are ready and healthy. It will also help orchestrating graceful shutdowns. This is the component that will contain the methods users can interact with.</li> <li> <p>Dataset Manager: Primary responsibility is to manage the data: generation or acquisition. For  synthetic generation, it contains the code to generate the prompts or tokens. It will have an API for dataset acquisition of a dataset if available in a remote repository or database.</p> </li> <li> <p>Worker Manager: Primary responsibility is to pull data from the dataset manager after receiving the timing credit from the timing manager. It will then push the request data to the worker to issue to the request.</p> </li> <li> <p>Worker: Primarily responsible for converting the data into the appropriate format for the interface being used by the server. Also responsible for managing the conversation between turns.</p> </li> <li> <p>Timing Manager: Primary responsibility is to generate the schedule and issuing timing credits for requests.</p> </li> <li> <p>Records Manager: Primarily responsible for holding the results returned from the workers.</p> </li> <li> <p>Post-Processor Manager: Primarily responsible for iterating over the records to generate metrics and other conclusions from the records.</p> </li> </ul>"},{"location":"Development/#communication-system","title":"Communication System","text":"<p>Services communicate using a message-based system with the following components:</p> <ul> <li>Topics: Categorized channels for message distribution (commands, status, data, etc.)</li> <li>Messages: Strongly-typed data structures for inter-service communication</li> <li>Service States: Lifecycle states that services transition through (initializing, running, stopping, etc.)</li> </ul>"},{"location":"Development/#command-line-interface","title":"Command Line Interface","text":"<p>The CLI (<code>aiperf/cli.py</code>) provides the entry point to the system</p>"},{"location":"Development/#message-processing","title":"Message Processing","text":"<p>To handle messages:</p> <ol> <li>Subscribe to relevant topics using <code>_subscribe_to_topic(Topic)</code></li> <li>Implement message processing logic in <code>_process_message(topic, message)</code></li> <li>Send messages using <code>_publish_message(topic, message)</code></li> </ol>"},{"location":"Development/#service-inheritance-model","title":"Service Inheritance Model","text":"<p>AIPerf uses an inheritance-based architecture where all system services inherit from a common <code>ServiceBase</code> abstract class. This approach provides a consistent interface and shared functionality across services.</p>"},{"location":"Development/#base-service-responsibilities","title":"Base Service Responsibilities","text":"<p>The <code>ServiceBase</code> class (<code>aiperf/common/service.py</code>) provides automatically for all services:</p> <ul> <li>Lifecycle Management: Standard initialize/run/stop/cleanup methods</li> <li>State Transitions: Manages service state changes (INITIALIZING \u2192 RUNNING \u2192 STOPPING \u2192 STOPPED)</li> <li>Communication: Methods for publishing messages and subscribing to topics</li> <li>Heartbeat: Automatic heartbeat generation for service health monitoring</li> </ul>"},{"location":"Development/#service-implementation-requirements","title":"Service Implementation Requirements","text":"<p>When implementing a new service that inherits from <code>ServiceBase</code>, you must:</p> <ol> <li>Implement Abstract Methods:</li> <li><code>_initialize()</code>: Set up service-specific resources</li> <li><code>_on_start()</code>: Main service logic</li> <li><code>_on_stop()</code>: Handle graceful shutdown</li> <li><code>_cleanup()</code>: Release resources</li> <li> <p><code>_process_message()</code>: Handle incoming messages</p> </li> <li> <p>Configuration:</p> </li> <li>Define service-specific configuration needs</li> <li>Pass configuration to the base class constructor</li> </ol>"},{"location":"Development/#example-service-implementation","title":"Example Service Implementation","text":"<p>Here's a simplified example of a service implementation:</p> <pre><code>from aiperf.common.service.base_service import BaseService\nfrom aiperf.common.config.service_config import ServiceConfig\nfrom aiperf.common.enums import Topic, ClientType\nfrom aiperf.common.models import Message\n\n\nclass ExampleService(BaseService):\n    def __init__(self, config: ServiceConfig) -&gt; None:\n        super().__init__(service_type=\"example_service\", service_config=config)\n        self.my_resource = None\n\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize service-specific resources.\"\"\"\n        self.logger.debug(\"Initializing Example Service\")\n        # Subscribe to required topics\n        # TODO: Fix this documentation\n        await self._subscribe_to_topic(ClientType.CONTROLLER_SUB, Topic.COMMAND)\n        await self._subscribe_to_topic(ClientType.INFERENCE_REQUEST_SUB, Topic.DATA)\n        # Initialize resources\n        self.my_resource = SomeResource()\n\n    async def _on_start(self) -&gt; None:\n        \"\"\"Main service logic.\"\"\"\n        self.logger.debug(\"Running Example Service\")\n        # Implement your service's main logic here\n        # This method should typically set up ongoing tasks or loops\n\n    async def _on_stop(self) -&gt; None:\n        \"\"\"Handle graceful shutdown.\"\"\"\n        self.logger.debug(\"Stopping Example Service\")\n        # Cancel any ongoing tasks\n        # Prepare for cleanup\n\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Release resources.\"\"\"\n        self.logger.debug(\"Cleaning up Example Service\")\n        # Release any resources\n        if self.my_resource:\n            await self.my_resource.close()\n\n    async def _process_message(self, topic: Topic, message: Message) -&gt; None:\n        \"\"\"Handle incoming messages.\"\"\"\n        self.logger.debug(f\"Processing response: {topic}, {message}\")\n        if topic == Topic.COMMAND:\n            # Handle command messages\n            await self._handle_command(message)\n        elif topic == Topic.DATA:\n            # Handle data messages\n            await self._handle_data(message)\n\n    async def _handle_command(self, message: Message) -&gt; None:\n        \"\"\"Handle command messages.\"\"\"\n        # Implement command handling logic\n\n    async def _handle_data(self, message: Message) -&gt; None:\n        \"\"\"Handle data messages.\"\"\"\n        # Implement data handling logic\n</code></pre>"},{"location":"Development/#using-the-service","title":"Using the Service","text":"<p>To instantiate and run a service:</p> <pre><code>def main() -&gt; None:\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(ExampleService)\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n</code></pre> <p>The <code>bootstrap_and_run_service</code> function handles: 1. Setting up the event loop (using uvloop) 2. Creating an instance of your service 3. Running the service's lifecycle methods 4. Handling graceful shutdown</p> <p>This inheritance model ensures consistent behavior across all services while allowing for service-specific customization.</p>"},{"location":"api/","title":"API Reference","text":"<p>This page contains the API documentation for all Python modules in the codebase (excluding init.py files).</p>"},{"location":"api/#aiperfcli","title":"aiperf.cli","text":""},{"location":"api/#aiperf.cli.main","title":"<code>main()</code>","text":"<p>Main entry point for the AIPerf system.</p> Source code in <code>aiperf/cli.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the AIPerf system.\"\"\"\n    parser = ArgumentParser(description=\"AIPerf Benchmarking System\")\n    parser.add_argument(\"--config\", type=str, help=\"Path to configuration file\")\n    parser.add_argument(\n        \"--log-level\",\n        type=str,\n        default=\"INFO\",\n        choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"],\n        help=\"Set the logging level\",\n    )\n    parser.add_argument(\n        \"--run-type\",\n        type=str,\n        default=\"process\",\n        choices=[\"process\", \"k8s\"],\n        help=\"Process manager backend to use \"\n        \"(multiprocessing: 'process', or kubernetes: 'k8s')\",\n    )\n    args = parser.parse_args()\n\n    # Set logging level for the root logger (affects all loggers)\n    logging.root.setLevel(getattr(logging, args.log_level))\n\n    # Set up logging to use Rich\n    handler = RichHandler(\n        rich_tracebacks=True,\n        show_path=True,\n        console=Console(),\n        tracebacks_show_locals=True,\n    )\n    logging.root.addHandler(handler)\n\n    # Load configuration\n    config = ServiceConfig(\n        service_run_type=args.run_type,\n    )\n\n    if args.config:\n        # In a real implementation, this would load from the specified file\n        logger.debug(\"Loading configuration from %s\", args.config)\n        # config.load_from_file(args.config)\n\n    # Create and start the system controller\n\n    logger.info(\"Starting AIPerf System\")\n    bootstrap_and_run_service(SystemController, service_config=config)\n    logger.info(\"AIPerf System exited\")\n</code></pre>"},{"location":"api/#aiperfcommonbootstrap","title":"aiperf.common.bootstrap","text":""},{"location":"api/#aiperf.common.bootstrap.bootstrap_and_run_service","title":"<code>bootstrap_and_run_service(service_class, service_config=None)</code>","text":"<p>Bootstrap the service and run it.</p> <p>This function will load the service configuration, create an instance of the service, and run it.</p> <p>Parameters:</p> Name Type Description Default <code>service_class</code> <code>type[BaseService]</code> <p>The service class of the service to run</p> required <code>service_config</code> <code>ServiceConfig | None</code> <p>The service configuration to use, if not provided, the service configuration will be loaded from the config file</p> <code>None</code> Source code in <code>aiperf/common/bootstrap.py</code> <pre><code>def bootstrap_and_run_service(\n    service_class: type[BaseService], service_config: ServiceConfig | None = None\n):\n    \"\"\"Bootstrap the service and run it.\n\n    This function will load the service configuration,\n    create an instance of the service, and run it.\n\n    Args:\n        service_class: The service class of the service to run\n        service_config: The service configuration to use, if not provided, the service\n            configuration will be loaded from the config file\n\n    \"\"\"\n    import uvloop\n\n    # Load the service configuration\n    if service_config is None:\n        from aiperf.common.config.loader import load_service_config\n\n        service_config = load_service_config()\n\n    # Create the service instance and run it\n    service = service_class(service_config=service_config)\n    uvloop.run(service.run_forever())\n</code></pre>"},{"location":"api/#aiperfcommoncommsbase","title":"aiperf.common.comms.base","text":""},{"location":"api/#aiperf.common.comms.base.BaseCommunication","title":"<code>BaseCommunication</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for specifying the base communication layer for AIPerf components.</p> Source code in <code>aiperf/common/comms/base.py</code> <pre><code>class BaseCommunication(ABC):\n    \"\"\"Base class for specifying the base communication layer for AIPerf components.\"\"\"\n\n    @abstractmethod\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize communication channels.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def is_initialized(self) -&gt; bool:\n        \"\"\"Check if communication channels are initialized.\n\n        Returns:\n            True if communication channels are initialized, False otherwise\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def is_shutdown(self) -&gt; bool:\n        \"\"\"Check if communication channels are shutdown.\n\n        Returns:\n            True if communication channels are shutdown, False otherwise\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def shutdown(self) -&gt; None:\n        \"\"\"Gracefully shutdown communication channels.\"\"\"\n        pass\n\n    @abstractmethod\n    async def create_clients(self, *client_types: ClientType) -&gt; None:\n        \"\"\"Create the communication clients.\n\n        Args:\n            *client_types: The client types to create\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def publish(self, topic: TopicType, message: Message) -&gt; None:\n        \"\"\"Publish a response to a topic.\n\n        Args:\n            topic: Topic to publish to\n            message: Message to publish\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def subscribe(\n        self,\n        topic: TopicType,\n        callback: Callable[[Message], Coroutine[Any, Any, None]],\n    ) -&gt; None:\n        \"\"\"Subscribe to a topic.\n\n        Args:\n            topic: Topic to subscribe to\n            callback: Function to call when a response is received\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def request(\n        self,\n        target: str,\n        request_data: Message,\n        timeout: float = 5.0,\n    ) -&gt; Message:\n        \"\"\"Send a request and wait for a response.\n\n        Args:\n            target: Target component to send request to\n            request_data: Request data\n            timeout: Timeout in seconds\n\n        Returns:\n            Response message if successful\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def respond(self, target: str, response: Message) -&gt; None:\n        \"\"\"Send a response to a request.\n\n        Args:\n            target: Target component to send response to\n            response: Response message\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def push(self, topic: TopicType, message: Message) -&gt; None:\n        \"\"\"Push data to a target.\n\n        Args:\n            topic: Topic to push to\n            message: Message to be pushed\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def pull(\n        self,\n        topic: TopicType,\n        callback: Callable[[Message], Coroutine[Any, Any, None]],\n    ) -&gt; None:\n        \"\"\"Pull data from a source.\n\n        Args:\n            topic: Topic to pull from\n            callback: function to call when data is received.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.is_initialized","title":"<code>is_initialized</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Check if communication channels are initialized.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if communication channels are initialized, False otherwise</p>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.is_shutdown","title":"<code>is_shutdown</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Check if communication channels are shutdown.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if communication channels are shutdown, False otherwise</p>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.create_clients","title":"<code>create_clients(*client_types)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Create the communication clients.</p> <p>Parameters:</p> Name Type Description Default <code>*client_types</code> <code>ClientType</code> <p>The client types to create</p> <code>()</code> Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def create_clients(self, *client_types: ClientType) -&gt; None:\n    \"\"\"Create the communication clients.\n\n    Args:\n        *client_types: The client types to create\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.initialize","title":"<code>initialize()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Initialize communication channels.</p> Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def initialize(self) -&gt; None:\n    \"\"\"Initialize communication channels.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.publish","title":"<code>publish(topic, message)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Publish a response to a topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>Topic to publish to</p> required <code>message</code> <code>Message</code> <p>Message to publish</p> required Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def publish(self, topic: TopicType, message: Message) -&gt; None:\n    \"\"\"Publish a response to a topic.\n\n    Args:\n        topic: Topic to publish to\n        message: Message to publish\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.pull","title":"<code>pull(topic, callback)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Pull data from a source.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>Topic to pull from</p> required <code>callback</code> <code>Callable[[Message], Coroutine[Any, Any, None]]</code> <p>function to call when data is received.</p> required Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def pull(\n    self,\n    topic: TopicType,\n    callback: Callable[[Message], Coroutine[Any, Any, None]],\n) -&gt; None:\n    \"\"\"Pull data from a source.\n\n    Args:\n        topic: Topic to pull from\n        callback: function to call when data is received.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.push","title":"<code>push(topic, message)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Push data to a target.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>Topic to push to</p> required <code>message</code> <code>Message</code> <p>Message to be pushed</p> required Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def push(self, topic: TopicType, message: Message) -&gt; None:\n    \"\"\"Push data to a target.\n\n    Args:\n        topic: Topic to push to\n        message: Message to be pushed\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.request","title":"<code>request(target, request_data, timeout=5.0)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Send a request and wait for a response.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>Target component to send request to</p> required <code>request_data</code> <code>Message</code> <p>Request data</p> required <code>timeout</code> <code>float</code> <p>Timeout in seconds</p> <code>5.0</code> <p>Returns:</p> Type Description <code>Message</code> <p>Response message if successful</p> Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def request(\n    self,\n    target: str,\n    request_data: Message,\n    timeout: float = 5.0,\n) -&gt; Message:\n    \"\"\"Send a request and wait for a response.\n\n    Args:\n        target: Target component to send request to\n        request_data: Request data\n        timeout: Timeout in seconds\n\n    Returns:\n        Response message if successful\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.respond","title":"<code>respond(target, response)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Send a response to a request.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>Target component to send response to</p> required <code>response</code> <code>Message</code> <p>Response message</p> required Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def respond(self, target: str, response: Message) -&gt; None:\n    \"\"\"Send a response to a request.\n\n    Args:\n        target: Target component to send response to\n        response: Response message\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.shutdown","title":"<code>shutdown()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Gracefully shutdown communication channels.</p> Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def shutdown(self) -&gt; None:\n    \"\"\"Gracefully shutdown communication channels.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.subscribe","title":"<code>subscribe(topic, callback)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Subscribe to a topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>Topic to subscribe to</p> required <code>callback</code> <code>Callable[[Message], Coroutine[Any, Any, None]]</code> <p>Function to call when a response is received</p> required Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def subscribe(\n    self,\n    topic: TopicType,\n    callback: Callable[[Message], Coroutine[Any, Any, None]],\n) -&gt; None:\n    \"\"\"Subscribe to a topic.\n\n    Args:\n        topic: Topic to subscribe to\n        callback: Function to call when a response is received\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperfcommoncommsclient_enums","title":"aiperf.common.comms.client_enums","text":""},{"location":"api/#aiperf.common.comms.client_enums.ClientType","title":"<code>ClientType = Union[PubClientType, SubClientType, PushClientType, PullClientType, ReqClientType, RepClientType]</code>  <code>module-attribute</code>","text":"<p>Union of all client types.</p>"},{"location":"api/#aiperf.common.comms.client_enums.PubClientType","title":"<code>PubClientType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum for specifying the client type for publishing messages. Includes a helper method for retrieving the appropriate client type based on the topic.</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>class PubClientType(StrEnum):\n    \"\"\"\n    Enum for specifying the client type for publishing messages. Includes a helper method\n    for retrieving the appropriate client type based on the topic.\n    \"\"\"\n\n    CONTROLLER = \"controller_pub\"\n    COMPONENT = \"component_pub\"\n\n    @classmethod\n    def from_topic(cls, topic: TopicType) -&gt; \"PubClientType\":\n        \"\"\"Determine the appropriate ClientType based on topic.\n\n        Args:\n            topic: The topic to communicate on\n\n        Returns:\n            The appropriate ClientType for the given topic\n        \"\"\"\n        match topic:\n            case Topic.HEARTBEAT | Topic.REGISTRATION | Topic.STATUS | Topic.RESPONSE:\n                return cls.COMPONENT\n            case Topic.COMMAND:\n                return cls.CONTROLLER\n            case _:\n                raise CommunicationClientNotFoundError(\n                    f\"No client type found for topic {topic}\"\n                )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.PubClientType.from_topic","title":"<code>from_topic(topic)</code>  <code>classmethod</code>","text":"<p>Determine the appropriate ClientType based on topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>The topic to communicate on</p> required <p>Returns:</p> Type Description <code>PubClientType</code> <p>The appropriate ClientType for the given topic</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>@classmethod\ndef from_topic(cls, topic: TopicType) -&gt; \"PubClientType\":\n    \"\"\"Determine the appropriate ClientType based on topic.\n\n    Args:\n        topic: The topic to communicate on\n\n    Returns:\n        The appropriate ClientType for the given topic\n    \"\"\"\n    match topic:\n        case Topic.HEARTBEAT | Topic.REGISTRATION | Topic.STATUS | Topic.RESPONSE:\n            return cls.COMPONENT\n        case Topic.COMMAND:\n            return cls.CONTROLLER\n        case _:\n            raise CommunicationClientNotFoundError(\n                f\"No client type found for topic {topic}\"\n            )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.PullClientType","title":"<code>PullClientType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum for specifying the client type for pulling messages. Includes a helper method for retrieving the appropriate client type based on the topic.</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>class PullClientType(StrEnum):\n    \"\"\"\n    Enum for specifying the client type for pulling messages. Includes a helper method\n    for retrieving the appropriate client type based on the topic.\n    \"\"\"\n\n    RECORDS = \"records_pull\"\n    INFERENCE_RESULTS = \"inference_results_pull\"\n    CREDIT_DROP = \"credit_drop_pull\"\n    CREDIT_RETURN = \"credit_return_pull\"\n\n    @classmethod\n    def from_topic(cls, topic: TopicType) -&gt; \"PullClientType\":\n        \"\"\"Determine the appropriate ClientType based on topic.\n\n        Args:\n            topic: The topic to communicate on\n\n        Returns:\n            The appropriate ClientType for the given topic\n        \"\"\"\n        match topic:\n            case Topic.CREDIT_DROP:\n                return cls.CREDIT_DROP\n            case Topic.CREDIT_RETURN:\n                return cls.CREDIT_RETURN\n            case DataTopic.RECORDS:\n                return cls.RECORDS\n            case DataTopic.RESULTS:\n                return cls.INFERENCE_RESULTS\n            case _:\n                raise CommunicationClientNotFoundError(\n                    f\"No client type found for topic {topic}\"\n                )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.PullClientType.from_topic","title":"<code>from_topic(topic)</code>  <code>classmethod</code>","text":"<p>Determine the appropriate ClientType based on topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>The topic to communicate on</p> required <p>Returns:</p> Type Description <code>PullClientType</code> <p>The appropriate ClientType for the given topic</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>@classmethod\ndef from_topic(cls, topic: TopicType) -&gt; \"PullClientType\":\n    \"\"\"Determine the appropriate ClientType based on topic.\n\n    Args:\n        topic: The topic to communicate on\n\n    Returns:\n        The appropriate ClientType for the given topic\n    \"\"\"\n    match topic:\n        case Topic.CREDIT_DROP:\n            return cls.CREDIT_DROP\n        case Topic.CREDIT_RETURN:\n            return cls.CREDIT_RETURN\n        case DataTopic.RECORDS:\n            return cls.RECORDS\n        case DataTopic.RESULTS:\n            return cls.INFERENCE_RESULTS\n        case _:\n            raise CommunicationClientNotFoundError(\n                f\"No client type found for topic {topic}\"\n            )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.PushClientType","title":"<code>PushClientType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum for specifying the client type for pushing messages. Includes a helper method for retrieving the appropriate client type based on the topic.</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>class PushClientType(StrEnum):\n    \"\"\"\n    Enum for specifying the client type for pushing messages. Includes a helper method\n    for retrieving the appropriate client type based on the topic.\n    \"\"\"\n\n    RECORDS = \"records_push\"\n    INFERENCE_RESULTS = \"inference_results_push\"\n    CREDIT_DROP = \"credit_drop_push\"\n    CREDIT_RETURN = \"credit_return_push\"\n\n    @classmethod\n    def from_topic(cls, topic: TopicType) -&gt; \"PushClientType\":\n        \"\"\"Determine the appropriate ClientType based on communication type and topic.\n\n        Args:\n            topic: The topic to communicate on\n\n        Returns:\n            The appropriate ClientType for the given topic\n        \"\"\"\n        match topic:\n            case Topic.CREDIT_DROP:\n                return cls.CREDIT_DROP\n            case Topic.CREDIT_RETURN:\n                return cls.CREDIT_RETURN\n            case DataTopic.RECORDS:\n                return cls.RECORDS\n            case DataTopic.RESULTS:\n                return cls.INFERENCE_RESULTS\n            case _:\n                raise CommunicationClientNotFoundError(\n                    f\"No client type found for topic {topic}\"\n                )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.PushClientType.from_topic","title":"<code>from_topic(topic)</code>  <code>classmethod</code>","text":"<p>Determine the appropriate ClientType based on communication type and topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>The topic to communicate on</p> required <p>Returns:</p> Type Description <code>PushClientType</code> <p>The appropriate ClientType for the given topic</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>@classmethod\ndef from_topic(cls, topic: TopicType) -&gt; \"PushClientType\":\n    \"\"\"Determine the appropriate ClientType based on communication type and topic.\n\n    Args:\n        topic: The topic to communicate on\n\n    Returns:\n        The appropriate ClientType for the given topic\n    \"\"\"\n    match topic:\n        case Topic.CREDIT_DROP:\n            return cls.CREDIT_DROP\n        case Topic.CREDIT_RETURN:\n            return cls.CREDIT_RETURN\n        case DataTopic.RECORDS:\n            return cls.RECORDS\n        case DataTopic.RESULTS:\n            return cls.INFERENCE_RESULTS\n        case _:\n            raise CommunicationClientNotFoundError(\n                f\"No client type found for topic {topic}\"\n            )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.RepClientType","title":"<code>RepClientType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum for specifying the client type for responding to messages. Includes a helper method for retrieving the appropriate client type based on the topic.</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>class RepClientType(StrEnum):\n    \"\"\"\n    Enum for specifying the client type for responding to messages. Includes a helper method\n    for retrieving the appropriate client type based on the topic.\n    \"\"\"\n\n    CONVERSATION_DATA = \"conversation_data_rep\"\n\n    @classmethod\n    def from_topic(cls, topic: TopicType) -&gt; \"RepClientType\":\n        \"\"\"Determine the appropriate ClientType based on topic.\n\n        Args:\n            topic: The topic to communicate on\n\n        Returns:\n            The appropriate ClientType for the given topic\n        \"\"\"\n        match topic:\n            case DataTopic.CONVERSATION:\n                return cls.CONVERSATION_DATA\n            case _:\n                raise CommunicationClientNotFoundError(\n                    f\"No client type found for topic {topic}\"\n                )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.RepClientType.from_topic","title":"<code>from_topic(topic)</code>  <code>classmethod</code>","text":"<p>Determine the appropriate ClientType based on topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>The topic to communicate on</p> required <p>Returns:</p> Type Description <code>RepClientType</code> <p>The appropriate ClientType for the given topic</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>@classmethod\ndef from_topic(cls, topic: TopicType) -&gt; \"RepClientType\":\n    \"\"\"Determine the appropriate ClientType based on topic.\n\n    Args:\n        topic: The topic to communicate on\n\n    Returns:\n        The appropriate ClientType for the given topic\n    \"\"\"\n    match topic:\n        case DataTopic.CONVERSATION:\n            return cls.CONVERSATION_DATA\n        case _:\n            raise CommunicationClientNotFoundError(\n                f\"No client type found for topic {topic}\"\n            )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.ReqClientType","title":"<code>ReqClientType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum for specifying the client type for requesting messages. Includes a helper method for retrieving the appropriate client type based on the topic.</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>class ReqClientType(StrEnum):\n    \"\"\"\n    Enum for specifying the client type for requesting messages. Includes a helper method\n    for retrieving the appropriate client type based on the topic.\n    \"\"\"\n\n    CONVERSATION_DATA = \"conversation_data_req\"\n\n    @classmethod\n    def from_topic(cls, topic: TopicType) -&gt; \"ReqClientType\":\n        \"\"\"Determine the appropriate ClientType based on topic.\n\n        Args:\n            topic: The topic to communicate on\n\n        Returns:\n            The appropriate ClientType for the given topic\n        \"\"\"\n        match topic:\n            case DataTopic.CONVERSATION:\n                return cls.CONVERSATION_DATA\n            case _:\n                raise CommunicationClientNotFoundError(\n                    f\"No client type found for topic {topic}\"\n                )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.ReqClientType.from_topic","title":"<code>from_topic(topic)</code>  <code>classmethod</code>","text":"<p>Determine the appropriate ClientType based on topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>The topic to communicate on</p> required <p>Returns:</p> Type Description <code>ReqClientType</code> <p>The appropriate ClientType for the given topic</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>@classmethod\ndef from_topic(cls, topic: TopicType) -&gt; \"ReqClientType\":\n    \"\"\"Determine the appropriate ClientType based on topic.\n\n    Args:\n        topic: The topic to communicate on\n\n    Returns:\n        The appropriate ClientType for the given topic\n    \"\"\"\n    match topic:\n        case DataTopic.CONVERSATION:\n            return cls.CONVERSATION_DATA\n        case _:\n            raise CommunicationClientNotFoundError(\n                f\"No client type found for topic {topic}\"\n            )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.SubClientType","title":"<code>SubClientType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum for specifying the client type for subscribing to messages. Includes a helper method for retrieving the appropriate client type based on the topic.</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>class SubClientType(StrEnum):\n    \"\"\"\n    Enum for specifying the client type for subscribing to messages. Includes a helper method\n    for retrieving the appropriate client type based on the topic.\n    \"\"\"\n\n    CONTROLLER = \"controller_sub\"\n    COMPONENT = \"component_sub\"\n\n    @classmethod\n    def from_topic(cls, topic: TopicType) -&gt; \"SubClientType\":\n        \"\"\"Determine the appropriate ClientType based on topic.\n\n        Args:\n            topic: The topic to communicate on\n\n        Returns:\n            The appropriate ClientType for the given topic\n        \"\"\"\n        match topic:\n            case Topic.HEARTBEAT | Topic.REGISTRATION | Topic.STATUS | Topic.RESPONSE:\n                return cls.COMPONENT\n            case Topic.COMMAND:\n                return cls.CONTROLLER\n            case _:\n                raise CommunicationClientNotFoundError(\n                    f\"No client type found for topic {topic}\"\n                )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.SubClientType.from_topic","title":"<code>from_topic(topic)</code>  <code>classmethod</code>","text":"<p>Determine the appropriate ClientType based on topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>The topic to communicate on</p> required <p>Returns:</p> Type Description <code>SubClientType</code> <p>The appropriate ClientType for the given topic</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>@classmethod\ndef from_topic(cls, topic: TopicType) -&gt; \"SubClientType\":\n    \"\"\"Determine the appropriate ClientType based on topic.\n\n    Args:\n        topic: The topic to communicate on\n\n    Returns:\n        The appropriate ClientType for the given topic\n    \"\"\"\n    match topic:\n        case Topic.HEARTBEAT | Topic.REGISTRATION | Topic.STATUS | Topic.RESPONSE:\n            return cls.COMPONENT\n        case Topic.COMMAND:\n            return cls.CONTROLLER\n        case _:\n            raise CommunicationClientNotFoundError(\n                f\"No client type found for topic {topic}\"\n            )\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientsbase","title":"aiperf.common.comms.zmq.clients.base","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient","title":"<code>BaseZMQClient</code>","text":"<p>               Bases: <code>AIPerfTaskMixin</code></p> <p>Base class for all ZMQ clients.</p> <p>This class provides a common interface for all ZMQ clients in the AIPerf framework. It inherits from the :class:<code>AIPerfTaskMixin</code>, allowing derived classes to implement specific hooks.</p> Source code in <code>aiperf/common/comms/zmq/clients/base.py</code> <pre><code>@supports_hooks(\n    AIPerfHook.ON_INIT,\n    AIPerfHook.ON_STOP,\n    AIPerfHook.ON_CLEANUP,\n    AIPerfHook.AIPERF_TASK,\n)\nclass BaseZMQClient(AIPerfTaskMixin):\n    \"\"\"Base class for all ZMQ clients.\n\n    This class provides a common interface for all ZMQ clients in the AIPerf\n    framework. It inherits from the :class:`AIPerfTaskMixin`, allowing derived\n    classes to implement specific hooks.\n    \"\"\"\n\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        socket_type: SocketType,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Base class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_type (SocketType): The type of ZMQ socket (PUB or SUB).\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        self.logger = logging.getLogger(__name__)\n        self.stop_event: asyncio.Event = asyncio.Event()\n        self.initialized_event: asyncio.Event = asyncio.Event()\n        self.context: zmq.asyncio.Context = context\n        self.address: str = address\n        self.bind: bool = bind\n        self.socket_type: SocketType = socket_type\n        self._socket: zmq.asyncio.Socket | None = None\n        self.socket_ops: dict = socket_ops or {}\n        self.client_id: str = f\"{self.socket_type.name}_client_{uuid.uuid4().hex[:8]}\"\n        super().__init__()\n\n    @property\n    def is_initialized(self) -&gt; bool:\n        \"\"\"Check if the client is initialized.\"\"\"\n        return self.initialized_event.is_set()\n\n    @property\n    def is_shutdown(self) -&gt; bool:\n        \"\"\"Check if the client is shutdown.\"\"\"\n        return self.stop_event.is_set()\n\n    @property\n    def socket_type_name(self) -&gt; str:\n        \"\"\"Get the name of the socket type.\"\"\"\n        return self.socket_type.name\n\n    @property\n    def socket(self) -&gt; zmq.asyncio.Socket:\n        \"\"\"Get the zmq socket for the client.\n\n        Raises:\n            CommunicationNotInitializedError: If the client is not initialized\n        \"\"\"\n        if not self._socket:\n            raise CommunicationNotInitializedError()\n        return self._socket\n\n    def _ensure_initialized(self) -&gt; None:\n        \"\"\"Ensure the communication channels are initialized and not shutdown.\n\n        Raises:\n            CommunicationNotInitializedError: If the communication channels are not initialized.\n            CommunicationShutdownError: If the communication channels are shutdown.\n        \"\"\"\n        if not self.is_initialized:\n            raise CommunicationNotInitializedError()\n        if self.is_shutdown:\n            raise CommunicationShutdownError()\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize the communication.\n\n        This method will:\n        - Create the zmq socket\n        - Bind or connect the socket to the address\n        - Set the socket options\n        - Run the AIPerfHook.ON_INIT hooks\n        \"\"\"\n        try:\n            self._socket = self.context.socket(self.socket_type)\n            if self.bind:\n                self.logger.debug(\n                    \"ZMQ %s socket initialized and bound to %s (%s)\",\n                    self.socket_type_name,\n                    self.address,\n                    self.client_id,\n                )\n                self.socket.bind(self.address)\n            else:\n                self.logger.debug(\n                    \"ZMQ %s socket initialized and connected to %s (%s)\",\n                    self.socket_type_name,\n                    self.address,\n                    self.client_id,\n                )\n                self.socket.connect(self.address)\n\n            # Set safe timeouts for send and receive operations\n            self._socket.setsockopt(zmq.RCVTIMEO, 30 * 1000)\n            self._socket.setsockopt(zmq.SNDTIMEO, 30 * 1000)\n\n            # Set additional socket options requested by the caller\n            for key, val in self.socket_ops.items():\n                self._socket.setsockopt(key, val)\n\n            await self.run_hooks(AIPerfHook.ON_INIT)\n\n            self.initialized_event.set()\n            self.logger.debug(\n                \"ZMQ %s socket initialized and connected to %s (%s)\",\n                self.socket_type_name,\n                self.address,\n                self.client_id,\n            )\n\n        except Exception as e:\n            self.logger.error(\"Exception initializing ZMQ socket: %s\", e)\n            raise CommunicationInitializationError from e\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Shutdown the communication.\n\n        This method will:\n        - Close the zmq socket\n        - Run the AIPerfHook.ON_CLEANUP hooks\n        \"\"\"\n        if self.is_shutdown:\n            return\n\n        if not self.stop_event.is_set():\n            self.stop_event.set()\n\n        try:\n            if self._socket:\n                self.socket.close()\n                self.logger.debug(\n                    \"ZMQ %s socket closed (%s)\", self.socket_type_name, self.client_id\n                )\n\n        except Exception as e:\n            self.logger.error(\n                \"Exception shutting down ZMQ socket: %s (%s)\", e, self.client_id\n            )\n            raise CommunicationShutdownError(\"Failed to shutdown ZMQ socket\") from e\n\n        finally:\n            self._socket = None\n\n        try:\n            await self.run_hooks(AIPerfHook.ON_STOP)\n            await self.run_hooks(AIPerfHook.ON_CLEANUP)\n\n        except Exception as e:\n            self.logger.error(\n                \"Exception cleaning up ZMQ socket: %s (%s)\", e, self.client_id\n            )\n            raise CommunicationError(\"Failed to cleanup ZMQ socket\") from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.is_initialized","title":"<code>is_initialized</code>  <code>property</code>","text":"<p>Check if the client is initialized.</p>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.is_shutdown","title":"<code>is_shutdown</code>  <code>property</code>","text":"<p>Check if the client is shutdown.</p>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.socket","title":"<code>socket</code>  <code>property</code>","text":"<p>Get the zmq socket for the client.</p> <p>Raises:</p> Type Description <code>CommunicationNotInitializedError</code> <p>If the client is not initialized</p>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.socket_type_name","title":"<code>socket_type_name</code>  <code>property</code>","text":"<p>Get the name of the socket type.</p>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.__init__","title":"<code>__init__(context, socket_type, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Base class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_type</code> <code>SocketType</code> <p>The type of ZMQ socket (PUB or SUB).</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/base.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    socket_type: SocketType,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Base class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_type (SocketType): The type of ZMQ socket (PUB or SUB).\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    self.logger = logging.getLogger(__name__)\n    self.stop_event: asyncio.Event = asyncio.Event()\n    self.initialized_event: asyncio.Event = asyncio.Event()\n    self.context: zmq.asyncio.Context = context\n    self.address: str = address\n    self.bind: bool = bind\n    self.socket_type: SocketType = socket_type\n    self._socket: zmq.asyncio.Socket | None = None\n    self.socket_ops: dict = socket_ops or {}\n    self.client_id: str = f\"{self.socket_type.name}_client_{uuid.uuid4().hex[:8]}\"\n    super().__init__()\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.initialize","title":"<code>initialize()</code>  <code>async</code>","text":"<p>Initialize the communication.</p> <p>This method will: - Create the zmq socket - Bind or connect the socket to the address - Set the socket options - Run the AIPerfHook.ON_INIT hooks</p> Source code in <code>aiperf/common/comms/zmq/clients/base.py</code> <pre><code>async def initialize(self) -&gt; None:\n    \"\"\"Initialize the communication.\n\n    This method will:\n    - Create the zmq socket\n    - Bind or connect the socket to the address\n    - Set the socket options\n    - Run the AIPerfHook.ON_INIT hooks\n    \"\"\"\n    try:\n        self._socket = self.context.socket(self.socket_type)\n        if self.bind:\n            self.logger.debug(\n                \"ZMQ %s socket initialized and bound to %s (%s)\",\n                self.socket_type_name,\n                self.address,\n                self.client_id,\n            )\n            self.socket.bind(self.address)\n        else:\n            self.logger.debug(\n                \"ZMQ %s socket initialized and connected to %s (%s)\",\n                self.socket_type_name,\n                self.address,\n                self.client_id,\n            )\n            self.socket.connect(self.address)\n\n        # Set safe timeouts for send and receive operations\n        self._socket.setsockopt(zmq.RCVTIMEO, 30 * 1000)\n        self._socket.setsockopt(zmq.SNDTIMEO, 30 * 1000)\n\n        # Set additional socket options requested by the caller\n        for key, val in self.socket_ops.items():\n            self._socket.setsockopt(key, val)\n\n        await self.run_hooks(AIPerfHook.ON_INIT)\n\n        self.initialized_event.set()\n        self.logger.debug(\n            \"ZMQ %s socket initialized and connected to %s (%s)\",\n            self.socket_type_name,\n            self.address,\n            self.client_id,\n        )\n\n    except Exception as e:\n        self.logger.error(\"Exception initializing ZMQ socket: %s\", e)\n        raise CommunicationInitializationError from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.shutdown","title":"<code>shutdown()</code>  <code>async</code>","text":"<p>Shutdown the communication.</p> <p>This method will: - Close the zmq socket - Run the AIPerfHook.ON_CLEANUP hooks</p> Source code in <code>aiperf/common/comms/zmq/clients/base.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Shutdown the communication.\n\n    This method will:\n    - Close the zmq socket\n    - Run the AIPerfHook.ON_CLEANUP hooks\n    \"\"\"\n    if self.is_shutdown:\n        return\n\n    if not self.stop_event.is_set():\n        self.stop_event.set()\n\n    try:\n        if self._socket:\n            self.socket.close()\n            self.logger.debug(\n                \"ZMQ %s socket closed (%s)\", self.socket_type_name, self.client_id\n            )\n\n    except Exception as e:\n        self.logger.error(\n            \"Exception shutting down ZMQ socket: %s (%s)\", e, self.client_id\n        )\n        raise CommunicationShutdownError(\"Failed to shutdown ZMQ socket\") from e\n\n    finally:\n        self._socket = None\n\n    try:\n        await self.run_hooks(AIPerfHook.ON_STOP)\n        await self.run_hooks(AIPerfHook.ON_CLEANUP)\n\n    except Exception as e:\n        self.logger.error(\n            \"Exception cleaning up ZMQ socket: %s (%s)\", e, self.client_id\n        )\n        raise CommunicationError(\"Failed to cleanup ZMQ socket\") from e\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientspub","title":"aiperf.common.comms.zmq.clients.pub","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.pub.ZMQPubClient","title":"<code>ZMQPubClient</code>","text":"<p>               Bases: <code>BaseZMQClient</code></p> Source code in <code>aiperf/common/comms/zmq/clients/pub.py</code> <pre><code>class ZMQPubClient(BaseZMQClient):\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Publisher class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        super().__init__(context, SocketType.PUB, address, bind, socket_ops)\n\n    async def publish(self, topic: str, message: Message) -&gt; None:\n        \"\"\"Publish a message to a topic.\n\n        Args:\n            topic: Topic to publish to\n            message: Message to publish (must be a Pydantic model)\n\n        Raises:\n            CommunicationNotInitializedError: If the client is not initialized\n            CommunicationPublishError: If the message was not published successfully\n        \"\"\"\n        self._ensure_initialized()\n\n        try:\n            # Serialize message using Pydantic's built-in method\n            message_json = message.model_dump_json()\n\n            # Publish message\n            await self.socket.send_multipart([topic.encode(), message_json.encode()])\n\n        except Exception as e:\n            logger.error(\"Exception publishing message to topic %s: %s\", topic, e)\n            raise CommunicationPublishError(\n                \"Failed to publish message to topic %s\", topic\n            ) from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.pub.ZMQPubClient.__init__","title":"<code>__init__(context, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Publisher class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/pub.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Publisher class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    super().__init__(context, SocketType.PUB, address, bind, socket_ops)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.pub.ZMQPubClient.publish","title":"<code>publish(topic, message)</code>  <code>async</code>","text":"<p>Publish a message to a topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>str</code> <p>Topic to publish to</p> required <code>message</code> <code>Message</code> <p>Message to publish (must be a Pydantic model)</p> required <p>Raises:</p> Type Description <code>CommunicationNotInitializedError</code> <p>If the client is not initialized</p> <code>CommunicationPublishError</code> <p>If the message was not published successfully</p> Source code in <code>aiperf/common/comms/zmq/clients/pub.py</code> <pre><code>async def publish(self, topic: str, message: Message) -&gt; None:\n    \"\"\"Publish a message to a topic.\n\n    Args:\n        topic: Topic to publish to\n        message: Message to publish (must be a Pydantic model)\n\n    Raises:\n        CommunicationNotInitializedError: If the client is not initialized\n        CommunicationPublishError: If the message was not published successfully\n    \"\"\"\n    self._ensure_initialized()\n\n    try:\n        # Serialize message using Pydantic's built-in method\n        message_json = message.model_dump_json()\n\n        # Publish message\n        await self.socket.send_multipart([topic.encode(), message_json.encode()])\n\n    except Exception as e:\n        logger.error(\"Exception publishing message to topic %s: %s\", topic, e)\n        raise CommunicationPublishError(\n            \"Failed to publish message to topic %s\", topic\n        ) from e\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientspull","title":"aiperf.common.comms.zmq.clients.pull","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.pull.ZMQPullClient","title":"<code>ZMQPullClient</code>","text":"<p>               Bases: <code>BaseZMQClient</code></p> Source code in <code>aiperf/common/comms/zmq/clients/pull.py</code> <pre><code>class ZMQPullClient(BaseZMQClient):\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Puller class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        super().__init__(context, SocketType.PULL, address, bind, socket_ops)\n        self._pull_callbacks: dict[str, list[Callable[[Message], None]]] = {}\n\n    @aiperf_task\n    async def _pull_receiver(self) -&gt; None:\n        \"\"\"Background task for receiving data from the pull socket.\n\n        This method is a coroutine that will run indefinitely until the client is\n        shutdown. It will wait for messages from the socket and handle them.\n        \"\"\"\n        while not self.is_shutdown:\n            try:\n                if not self.is_initialized:\n                    await self.initialized_event.wait()\n\n                # Receive data\n                message_bytes = await self.socket.recv()\n                message_json = message_bytes.decode()\n\n                # Parse JSON into a BaseMessage object\n                message = BaseMessage.model_validate_json(message_json)\n                topic = message.payload.message_type\n\n                # Call callbacks with BaseMessage object\n                if topic in self._pull_callbacks:\n                    await call_all_functions(self._pull_callbacks[topic], message)\n\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(f\"Exception receiving data from pull socket: {e}\")\n                await asyncio.sleep(0.1)\n\n    async def pull(\n        self,\n        topic: str,\n        callback: Callable[[Message], None],\n    ) -&gt; None:\n        \"\"\"Register a ZMQ Pull data callback from a source (topic).\n\n        Args:\n            topic: Topic (source) to pull data from\n            callback: function to call when data is received.\n\n        Raises:\n            CommunicationNotInitializedError: If the client is not initialized\n            CommunicationPullError: If an exception occurred registering the pull callback\n        \"\"\"\n        self._ensure_initialized()\n\n        # Register callback\n        if topic not in self._pull_callbacks:\n            self._pull_callbacks[topic] = []\n        self._pull_callbacks[topic].append(callback)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.pull.ZMQPullClient.__init__","title":"<code>__init__(context, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Puller class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/pull.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Puller class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    super().__init__(context, SocketType.PULL, address, bind, socket_ops)\n    self._pull_callbacks: dict[str, list[Callable[[Message], None]]] = {}\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.pull.ZMQPullClient.pull","title":"<code>pull(topic, callback)</code>  <code>async</code>","text":"<p>Register a ZMQ Pull data callback from a source (topic).</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>str</code> <p>Topic (source) to pull data from</p> required <code>callback</code> <code>Callable[[Message], None]</code> <p>function to call when data is received.</p> required <p>Raises:</p> Type Description <code>CommunicationNotInitializedError</code> <p>If the client is not initialized</p> <code>CommunicationPullError</code> <p>If an exception occurred registering the pull callback</p> Source code in <code>aiperf/common/comms/zmq/clients/pull.py</code> <pre><code>async def pull(\n    self,\n    topic: str,\n    callback: Callable[[Message], None],\n) -&gt; None:\n    \"\"\"Register a ZMQ Pull data callback from a source (topic).\n\n    Args:\n        topic: Topic (source) to pull data from\n        callback: function to call when data is received.\n\n    Raises:\n        CommunicationNotInitializedError: If the client is not initialized\n        CommunicationPullError: If an exception occurred registering the pull callback\n    \"\"\"\n    self._ensure_initialized()\n\n    # Register callback\n    if topic not in self._pull_callbacks:\n        self._pull_callbacks[topic] = []\n    self._pull_callbacks[topic].append(callback)\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientspush","title":"aiperf.common.comms.zmq.clients.push","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.push.ZMQPushClient","title":"<code>ZMQPushClient</code>","text":"<p>               Bases: <code>BaseZMQClient</code></p> Source code in <code>aiperf/common/comms/zmq/clients/push.py</code> <pre><code>class ZMQPushClient(BaseZMQClient):\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Pusher class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        super().__init__(context, SocketType.PUSH, address, bind, socket_ops)\n\n    async def push(self, message: Message) -&gt; None:\n        \"\"\"Push data to a target.\n\n        Args:\n            message: Message to be sent must be a Message object\n\n        Raises:\n            CommunicationNotInitializedError: If the client is not initialized\n            CommunicationPushError: If the data was not pushed successfully\n        \"\"\"\n        self._ensure_initialized()\n\n        try:\n            # Serialize data directly using Pydantic's built-in method\n            data_json = message.model_dump_json()\n\n            # Send data\n            await self.socket.send_string(data_json)\n            logger.debug(\"Pushed json data: %s\", data_json)\n        except Exception as e:\n            logger.error(f\"Exception pushing data: {e} {type(e)}\")\n            raise CommunicationPushError from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.push.ZMQPushClient.__init__","title":"<code>__init__(context, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Pusher class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/push.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Pusher class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    super().__init__(context, SocketType.PUSH, address, bind, socket_ops)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.push.ZMQPushClient.push","title":"<code>push(message)</code>  <code>async</code>","text":"<p>Push data to a target.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>Message to be sent must be a Message object</p> required <p>Raises:</p> Type Description <code>CommunicationNotInitializedError</code> <p>If the client is not initialized</p> <code>CommunicationPushError</code> <p>If the data was not pushed successfully</p> Source code in <code>aiperf/common/comms/zmq/clients/push.py</code> <pre><code>async def push(self, message: Message) -&gt; None:\n    \"\"\"Push data to a target.\n\n    Args:\n        message: Message to be sent must be a Message object\n\n    Raises:\n        CommunicationNotInitializedError: If the client is not initialized\n        CommunicationPushError: If the data was not pushed successfully\n    \"\"\"\n    self._ensure_initialized()\n\n    try:\n        # Serialize data directly using Pydantic's built-in method\n        data_json = message.model_dump_json()\n\n        # Send data\n        await self.socket.send_string(data_json)\n        logger.debug(\"Pushed json data: %s\", data_json)\n    except Exception as e:\n        logger.error(f\"Exception pushing data: {e} {type(e)}\")\n        raise CommunicationPushError from e\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientsrep","title":"aiperf.common.comms.zmq.clients.rep","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.rep.ZMQRepClient","title":"<code>ZMQRepClient</code>","text":"<p>               Bases: <code>BaseZMQClient</code></p> Source code in <code>aiperf/common/comms/zmq/clients/rep.py</code> <pre><code>class ZMQRepClient(BaseZMQClient):\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ REP class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        super().__init__(context, SocketType.REP, address, bind, socket_ops)\n\n        self._response_futures = {}\n        self._response_data = {}\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up any pending futures.\"\"\"\n        # Resolve any pending futures with errors\n        for _, future in self._response_futures.items():\n            if not future.done():\n                future.set_exception(ConnectionError(\"Socket was shut down\"))\n\n        self._response_futures.clear()\n        self._response_data.clear()\n\n    async def wait_for_request(self, timeout: float | None = None) -&gt; Message:\n        \"\"\"Wait for a request to arrive.\n\n        Args:\n            timeout: Timeout in seconds or None for no timeout\n\n        Returns:\n            Message or Exception if request was not received successfully\n\n        Raises:\n            CommunicationNotInitializedError: If the client is not initialized\n            CommunicationResponseError: If the request was not received successfully\n        \"\"\"\n        self._ensure_initialized()\n\n        try:\n            # Create a future for the next request\n            request_id = \"next_request\"  # Special ID for the next request\n            future = asyncio.Future()\n            self._response_futures[request_id] = future\n\n            try:\n                # Wait for the request with optional timeout\n                if timeout is not None:\n                    request_json = await asyncio.wait_for(future, timeout)\n                else:\n                    request_json = await future\n\n                # Parse the request\n                request = BaseMessage.model_validate_json(request_json)\n                return request\n\n            except asyncio.TimeoutError as e:\n                logger.debug(\"Timeout waiting for request\")\n                raise CommunicationResponseError(\"Timeout waiting for request\") from e\n\n            except Exception as e:\n                logger.error(f\"Exception waiting for request: {e}\")\n                raise CommunicationResponseError(\"Exception waiting for request\") from e\n\n            finally:\n                # Clean up future\n                self._response_futures.pop(request_id, None)\n\n        except Exception as e:\n            logger.error(f\"Exception waiting for request: {e}\")\n            raise CommunicationResponseError(\"Exception waiting for request\") from e\n\n    async def respond(self, target: str, response: Message) -&gt; None:\n        \"\"\"Send a response to a request.\n\n        Args:\n            target: Target component to send response to\n            response: Response message (must be a Message instance)\n\n        Raises:\n            CommunicationNotInitializedError: If the client is not initialized\n            CommunicationResponseError: If the response was not sent successfully\n        \"\"\"\n        self._ensure_initialized()\n\n        try:\n            # Serialize response using Pydantic's built-in method\n            response_json = response.model_dump_json()\n\n            # Send response\n            await self.socket.send_string(response_json)\n\n        except Exception as e:\n            logger.error(f\"Exception sending response to {target}: {e}\")\n            raise CommunicationResponseError(\n                f\"Exception sending response to {target}\"\n            ) from e\n\n    @aiperf_task\n    async def _rep_receiver(self) -&gt; None:\n        \"\"\"Background task for receiving requests and sending responses.\n\n        This method is a coroutine that will run indefinitely until the client is\n        shutdown. It will wait for requests from the socket and send responses.\n        \"\"\"\n        while not self.is_shutdown:\n            try:\n                if not self.is_initialized:\n                    await self.initialized_event.wait()\n\n                # Receive request\n                request_json = await self.socket.recv_string()\n\n                # Parse JSON to create RequestData object\n                request = BaseMessage.model_validate_json(request_json)\n                request_id = request.request_id\n\n                # Store request data\n                self._response_data[request_id] = request\n\n                # Check for special \"next_request\" future\n                if \"next_request\" in self._response_futures:\n                    future = self._response_futures.pop(\"next_request\")\n                    if not future.done():\n                        future.set_result(request_json)\n                # Resolve future if it exists for the specific request ID\n                elif request_id in self._response_futures:\n                    future = self._response_futures[request_id]\n                    if not future.done():\n                        future.set_result(request_json)\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(f\"Exception receiving request: {e}\")\n                await asyncio.sleep(0.1)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.rep.ZMQRepClient.__init__","title":"<code>__init__(context, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ REP class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/rep.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ REP class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    super().__init__(context, SocketType.REP, address, bind, socket_ops)\n\n    self._response_futures = {}\n    self._response_data = {}\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.rep.ZMQRepClient.respond","title":"<code>respond(target, response)</code>  <code>async</code>","text":"<p>Send a response to a request.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>Target component to send response to</p> required <code>response</code> <code>Message</code> <p>Response message (must be a Message instance)</p> required <p>Raises:</p> Type Description <code>CommunicationNotInitializedError</code> <p>If the client is not initialized</p> <code>CommunicationResponseError</code> <p>If the response was not sent successfully</p> Source code in <code>aiperf/common/comms/zmq/clients/rep.py</code> <pre><code>async def respond(self, target: str, response: Message) -&gt; None:\n    \"\"\"Send a response to a request.\n\n    Args:\n        target: Target component to send response to\n        response: Response message (must be a Message instance)\n\n    Raises:\n        CommunicationNotInitializedError: If the client is not initialized\n        CommunicationResponseError: If the response was not sent successfully\n    \"\"\"\n    self._ensure_initialized()\n\n    try:\n        # Serialize response using Pydantic's built-in method\n        response_json = response.model_dump_json()\n\n        # Send response\n        await self.socket.send_string(response_json)\n\n    except Exception as e:\n        logger.error(f\"Exception sending response to {target}: {e}\")\n        raise CommunicationResponseError(\n            f\"Exception sending response to {target}\"\n        ) from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.rep.ZMQRepClient.wait_for_request","title":"<code>wait_for_request(timeout=None)</code>  <code>async</code>","text":"<p>Wait for a request to arrive.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float | None</code> <p>Timeout in seconds or None for no timeout</p> <code>None</code> <p>Returns:</p> Type Description <code>Message</code> <p>Message or Exception if request was not received successfully</p> <p>Raises:</p> Type Description <code>CommunicationNotInitializedError</code> <p>If the client is not initialized</p> <code>CommunicationResponseError</code> <p>If the request was not received successfully</p> Source code in <code>aiperf/common/comms/zmq/clients/rep.py</code> <pre><code>async def wait_for_request(self, timeout: float | None = None) -&gt; Message:\n    \"\"\"Wait for a request to arrive.\n\n    Args:\n        timeout: Timeout in seconds or None for no timeout\n\n    Returns:\n        Message or Exception if request was not received successfully\n\n    Raises:\n        CommunicationNotInitializedError: If the client is not initialized\n        CommunicationResponseError: If the request was not received successfully\n    \"\"\"\n    self._ensure_initialized()\n\n    try:\n        # Create a future for the next request\n        request_id = \"next_request\"  # Special ID for the next request\n        future = asyncio.Future()\n        self._response_futures[request_id] = future\n\n        try:\n            # Wait for the request with optional timeout\n            if timeout is not None:\n                request_json = await asyncio.wait_for(future, timeout)\n            else:\n                request_json = await future\n\n            # Parse the request\n            request = BaseMessage.model_validate_json(request_json)\n            return request\n\n        except asyncio.TimeoutError as e:\n            logger.debug(\"Timeout waiting for request\")\n            raise CommunicationResponseError(\"Timeout waiting for request\") from e\n\n        except Exception as e:\n            logger.error(f\"Exception waiting for request: {e}\")\n            raise CommunicationResponseError(\"Exception waiting for request\") from e\n\n        finally:\n            # Clean up future\n            self._response_futures.pop(request_id, None)\n\n    except Exception as e:\n        logger.error(f\"Exception waiting for request: {e}\")\n        raise CommunicationResponseError(\"Exception waiting for request\") from e\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientsreq","title":"aiperf.common.comms.zmq.clients.req","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.req.ZMQReqClient","title":"<code>ZMQReqClient</code>","text":"<p>               Bases: <code>BaseZMQClient</code></p> Source code in <code>aiperf/common/comms/zmq/clients/req.py</code> <pre><code>class ZMQReqClient(BaseZMQClient):\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Req class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        super().__init__(context, SocketType.REQ, address, bind, socket_ops)\n        self._response_futures = {}\n\n    @aiperf_task\n    async def _process_messages(self) -&gt; None:\n        \"\"\"Process incoming response messages in the background.\n\n        This method is a coroutine that will run indefinitely until the client is\n        shutdown. It will wait for messages from the socket and handle them.\n        \"\"\"\n        while not self.is_shutdown:\n            try:\n                if not self.is_initialized:\n                    await self.initialized_event.wait()\n\n                response_json = await self.socket.recv_string()\n                await self._handle_response(response_json)\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(f\"Exception processing messages: {e}\")\n                await asyncio.sleep(0.1)\n\n    async def _handle_response(self, response_json: str) -&gt; None:\n        \"\"\"Handle a response message.\n\n        Args:\n            response_json: The JSON response string\n        \"\"\"\n        try:\n            response = BaseMessage.model_validate_json(response_json)\n            request_id = response.request_id\n\n            if request_id in self._response_futures:\n                future = self._response_futures[request_id]\n                if not future.done():\n                    future.set_result(response_json)\n            else:\n                logger.warning(\n                    f\"Received response for unknown request ID: {request_id}\"\n                )\n        except Exception as e:\n            logger.error(f\"Exception handling response: {e}\")\n            raise CommunicationRequestError(\"Exception handling response\") from e\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up any pending futures.\"\"\"\n        # Resolve any pending futures with errors\n        for request_id, future in self._response_futures.items():\n            if not future.done():\n                error_response = BaseMessage(\n                    request_id=request_id,\n                    payload=ErrorPayload(\n                        error_message=\"Socket was shut down\",\n                    ),\n                )\n                future.set_result(error_response.model_dump_json())\n\n        self._response_futures.clear()\n\n    async def request(\n        self,\n        target: str,\n        request_data: Message,\n        timeout: float = 5.0,\n    ) -&gt; Message:\n        \"\"\"Send a request and wait for a response.\n\n        Args:\n            target: Target component to send request to\n            request_data: Request data (must be a RequestData instance)\n            timeout: Timeout in seconds\n\n        Returns:\n            ResponseData object\n        \"\"\"\n        self._ensure_initialized()\n\n        try:\n            # Set target if not already set\n            if not request_data.target:\n                request_data.target = target\n\n            # Ensure client_id is set\n            if not request_data.client_id:\n                request_data.client_id = self.client_id\n\n            # Generate request ID if not provided\n            if not request_data.request_id:\n                request_data.request_id = uuid.uuid4().hex\n\n            # Serialize request\n            request_json = request_data.model_dump_json()\n\n            # Create future for response\n            future = asyncio.Future()\n            self._response_futures[request_data.request_id] = future\n\n            # Send request\n            await self.socket.send_string(request_json)\n\n            # Wait for response with timeout\n            try:\n                response_json = await asyncio.wait_for(future, timeout)\n                response = BaseMessage.model_validate_json(response_json)\n                return response\n\n            except asyncio.TimeoutError as e:\n                logger.error(\n                    f\"Timeout waiting for response to request {request_data.request_id}\"\n                )\n                raise CommunicationRequestError(\n                    f\"Timeout waiting for response to request {request_data.request_id}\"\n                ) from e\n\n            finally:\n                # Clean up future\n                self._response_futures.pop(request_data.request_id, None)\n\n        except Exception as e:\n            logger.error(f\"Exception sending request to {target}: {e}\")\n            raise CommunicationRequestError(\n                f\"Exception sending request to {target}: {e}\"\n            ) from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.req.ZMQReqClient.__init__","title":"<code>__init__(context, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Req class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/req.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Req class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    super().__init__(context, SocketType.REQ, address, bind, socket_ops)\n    self._response_futures = {}\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.req.ZMQReqClient.request","title":"<code>request(target, request_data, timeout=5.0)</code>  <code>async</code>","text":"<p>Send a request and wait for a response.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>Target component to send request to</p> required <code>request_data</code> <code>Message</code> <p>Request data (must be a RequestData instance)</p> required <code>timeout</code> <code>float</code> <p>Timeout in seconds</p> <code>5.0</code> <p>Returns:</p> Type Description <code>Message</code> <p>ResponseData object</p> Source code in <code>aiperf/common/comms/zmq/clients/req.py</code> <pre><code>async def request(\n    self,\n    target: str,\n    request_data: Message,\n    timeout: float = 5.0,\n) -&gt; Message:\n    \"\"\"Send a request and wait for a response.\n\n    Args:\n        target: Target component to send request to\n        request_data: Request data (must be a RequestData instance)\n        timeout: Timeout in seconds\n\n    Returns:\n        ResponseData object\n    \"\"\"\n    self._ensure_initialized()\n\n    try:\n        # Set target if not already set\n        if not request_data.target:\n            request_data.target = target\n\n        # Ensure client_id is set\n        if not request_data.client_id:\n            request_data.client_id = self.client_id\n\n        # Generate request ID if not provided\n        if not request_data.request_id:\n            request_data.request_id = uuid.uuid4().hex\n\n        # Serialize request\n        request_json = request_data.model_dump_json()\n\n        # Create future for response\n        future = asyncio.Future()\n        self._response_futures[request_data.request_id] = future\n\n        # Send request\n        await self.socket.send_string(request_json)\n\n        # Wait for response with timeout\n        try:\n            response_json = await asyncio.wait_for(future, timeout)\n            response = BaseMessage.model_validate_json(response_json)\n            return response\n\n        except asyncio.TimeoutError as e:\n            logger.error(\n                f\"Timeout waiting for response to request {request_data.request_id}\"\n            )\n            raise CommunicationRequestError(\n                f\"Timeout waiting for response to request {request_data.request_id}\"\n            ) from e\n\n        finally:\n            # Clean up future\n            self._response_futures.pop(request_data.request_id, None)\n\n    except Exception as e:\n        logger.error(f\"Exception sending request to {target}: {e}\")\n        raise CommunicationRequestError(\n            f\"Exception sending request to {target}: {e}\"\n        ) from e\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientssub","title":"aiperf.common.comms.zmq.clients.sub","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.sub.ZMQSubClient","title":"<code>ZMQSubClient</code>","text":"<p>               Bases: <code>BaseZMQClient</code></p> Source code in <code>aiperf/common/comms/zmq/clients/sub.py</code> <pre><code>class ZMQSubClient(BaseZMQClient):\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Subscriber class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        super().__init__(context, SocketType.SUB, address, bind, socket_ops)\n        self._subscribers: dict[str, list[Callable[[Message], Any]]] = {}\n\n    async def subscribe(self, topic: str, callback: Callable[[Message], Any]) -&gt; None:\n        \"\"\"Subscribe to a topic.\n\n        Args:\n            topic: Topic to subscribe to\n            callback: Function to call when a response is received (receives Message object)\n\n        Raises:\n            Exception if subscription was not successful, None otherwise\n        \"\"\"\n        self._ensure_initialized()\n\n        try:\n            # Subscribe to topic\n            self.socket.subscribe(topic.encode())\n\n            # Register callback\n            if topic not in self._subscribers:\n                self._subscribers[topic] = []\n            self._subscribers[topic].append(callback)\n\n            logger.debug(\"Subscribed to topic: %s, %s\", topic, self._subscribers[topic])\n\n        except Exception as e:\n            logger.error(\"Exception subscribing to topic %s: %s\", topic, e)\n            raise CommunicationSubscribeError from e\n\n    @aiperf_task\n    async def _sub_receiver(self) -&gt; None:\n        \"\"\"Background task for receiving messages from subscribed topics.\n\n        This method is a coroutine that will run indefinitely until the client is\n        shutdown. It will wait for messages from the socket and handle them.\n        \"\"\"\n        while not self.is_shutdown:\n            try:\n                if not self.is_initialized:\n                    logger.debug(\n                        \"Sub client %s waiting for initialization\", self.client_id\n                    )\n                    await self.initialized_event.wait()\n                    logger.debug(\"Sub client %s initialized\", self.client_id)\n\n                # Receive response\n                (\n                    topic_bytes,\n                    message_bytes,\n                ) = await self.socket.recv_multipart()\n                topic = topic_bytes.decode()\n                message_json = message_bytes.decode()\n                logger.debug(\n                    \"Client %s received message from topic: '%s', message: %s\",\n                    self.client_id,\n                    topic,\n                    message_json,\n                )\n\n                message = BaseMessage.model_validate_json(message_json)\n\n                # Call callbacks with the parsed response object\n                if topic in self._subscribers:\n                    await call_all_functions(self._subscribers[topic], message)\n\n            except asyncio.CancelledError:\n                break\n            except zmq.Again:\n                # Handle ZMQ timeout or interruption\n                logger.debug(\n                    \"ZMQ recv timeout due to no messages. trying again @ %s\",\n                    self.address,\n                )\n                await asyncio.sleep(0.001)\n            except Exception as e:\n                logger.error(\n                    \"Exception receiving response from subscription: %s, %s\",\n                    e,\n                    type(e),\n                )\n                await asyncio.sleep(0.1)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.sub.ZMQSubClient.__init__","title":"<code>__init__(context, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Subscriber class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/sub.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Subscriber class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    super().__init__(context, SocketType.SUB, address, bind, socket_ops)\n    self._subscribers: dict[str, list[Callable[[Message], Any]]] = {}\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.sub.ZMQSubClient.subscribe","title":"<code>subscribe(topic, callback)</code>  <code>async</code>","text":"<p>Subscribe to a topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>str</code> <p>Topic to subscribe to</p> required <code>callback</code> <code>Callable[[Message], Any]</code> <p>Function to call when a response is received (receives Message object)</p> required Source code in <code>aiperf/common/comms/zmq/clients/sub.py</code> <pre><code>async def subscribe(self, topic: str, callback: Callable[[Message], Any]) -&gt; None:\n    \"\"\"Subscribe to a topic.\n\n    Args:\n        topic: Topic to subscribe to\n        callback: Function to call when a response is received (receives Message object)\n\n    Raises:\n        Exception if subscription was not successful, None otherwise\n    \"\"\"\n    self._ensure_initialized()\n\n    try:\n        # Subscribe to topic\n        self.socket.subscribe(topic.encode())\n\n        # Register callback\n        if topic not in self._subscribers:\n            self._subscribers[topic] = []\n        self._subscribers[topic].append(callback)\n\n        logger.debug(\"Subscribed to topic: %s, %s\", topic, self._subscribers[topic])\n\n    except Exception as e:\n        logger.error(\"Exception subscribing to topic %s: %s\", topic, e)\n        raise CommunicationSubscribeError from e\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqzmq_comms","title":"aiperf.common.comms.zmq.zmq_comms","text":""},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication","title":"<code>ZMQCommunication</code>","text":"<p>               Bases: <code>BaseCommunication</code></p> <p>ZeroMQ-based implementation of the Communication interface.</p> <p>Uses ZeroMQ for publish/subscribe and request/reply patterns to facilitate communication between AIPerf components.</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>@CommunicationFactory.register(CommunicationBackend.ZMQ_TCP)\nclass ZMQCommunication(BaseCommunication):\n    \"\"\"ZeroMQ-based implementation of the Communication interface.\n\n    Uses ZeroMQ for publish/subscribe and request/reply patterns to\n    facilitate communication between AIPerf components.\n    \"\"\"\n\n    def __init__(\n        self,\n        config: ZMQCommunicationConfig | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize ZMQ communication.\n\n        Args:\n            config: ZMQCommunicationConfig object with configuration parameters\n        \"\"\"\n        self.stop_event: asyncio.Event = asyncio.Event()\n        self.initialized_event: asyncio.Event = asyncio.Event()\n        self.config = config or ZMQCommunicationConfig()\n\n        # Generate client_id if not provided\n        if not self.config.client_id:\n            self.config.client_id = f\"client_{uuid.uuid4().hex[:8]}\"\n\n        self._context: zmq.asyncio.Context | None = None\n        self.clients: dict[ClientType, ZMQClient] = {}\n\n        logger.debug(\n            \"ZMQ communication using protocol: %s with client ID: %s\",\n            type(self.config.protocol_config).__name__,\n            self.config.client_id,\n        )\n\n    @property\n    def context(self) -&gt; zmq.asyncio.Context:\n        \"\"\"Get the ZeroMQ context.\n\n        Returns:\n            ZeroMQ context\n        \"\"\"\n        if not self._context:\n            raise CommunicationNotInitializedError()\n        return self._context\n\n    @property\n    def is_initialized(self) -&gt; bool:\n        \"\"\"Check if communication channels are initialized.\n\n        Returns:\n            True if communication channels are initialized, False otherwise\n        \"\"\"\n        return self.initialized_event.is_set()\n\n    @property\n    def is_shutdown(self) -&gt; bool:\n        \"\"\"Check if communication channels are shutdown.\n\n        Returns:\n            True if communication channels are shutdown, False otherwise\n        \"\"\"\n        return self.stop_event.is_set()\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize communication channels.\n\n        Returns:\n            True if initialization was successful, False otherwise\n        \"\"\"\n        if self.is_initialized:\n            return\n\n        self._context = zmq.asyncio.Context()\n        self.initialized_event.set()\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Gracefully shutdown communication channels.\n\n        This method will wait for all clients to shutdown before shutting down\n        the context.\n\n        Returns:\n            True if shutdown was successful, False otherwise\n        \"\"\"\n        if self.is_shutdown:\n            logger.debug(\"ZMQ communication already shutdown\")\n            return\n\n        try:\n            if not self.stop_event.is_set():\n                self.stop_event.set()\n\n            logger.debug(\n                f\"Shutting down ZMQ communication for client {self.config.client_id}\"\n            )\n            await asyncio.gather(\n                *(client.shutdown() for client in self.clients.values())\n            )\n\n            if self.context:\n                self.context.term()\n\n            self._context = None\n            logger.debug(\"ZMQ communication shutdown successfully\")\n\n        except Exception as e:\n            logger.error(f\"Exception shutting down ZMQ communication: {e}\")\n            raise CommunicationShutdownError(\n                \"Failed to shutdown ZMQ communication\"\n            ) from e\n\n        finally:\n            self.clients = {}\n            self._context = None\n\n    def _ensure_initialized(self) -&gt; None:\n        \"\"\"Ensure the communication channels are initialized.\n\n        Raises:\n            CommunicationNotInitializedError: If the communication channels are not\n                initialized\n            CommunicationShutdownError: If the communication channels are shutdown\n        \"\"\"\n        if not self.is_initialized:\n            raise CommunicationNotInitializedError()\n        if self.is_shutdown:\n            raise CommunicationShutdownError()\n\n    def _create_pub_client(self, client_type: PubClientType) -&gt; ZMQPubClient:\n        \"\"\"Create a ZMQ publisher client based on the client type.\n\n        Args:\n            client_type: The type of client to create\n\n        Returns:\n            ZMQPubClient instance\n\n        Raises:\n            CommunicationClientCreationError: If the client type is invalid\n        \"\"\"\n        match client_type:\n            case PubClientType.CONTROLLER:\n                return ZMQPubClient(\n                    self.context,\n                    self.config.controller_pub_sub_address,\n                    bind=True,\n                )\n\n            case PubClientType.COMPONENT:\n                return ZMQPubClient(\n                    self.context,\n                    self.config.component_pub_sub_address,\n                    bind=False,\n                )\n\n            case _:\n                raise CommunicationClientCreationError(\n                    f\"Invalid client type: {client_type}\"\n                )\n\n    def _create_sub_client(self, client_type: SubClientType) -&gt; ZMQSubClient:\n        \"\"\"Create a ZMQ subscriber client based on the client type.\n\n        Args:\n            client_type: The type of client to create\n\n        Returns:\n            ZMQSubClient instance\n\n        Raises:\n            CommunicationClientCreationError: If the client type is invalid\n        \"\"\"\n        match client_type:\n            case SubClientType.CONTROLLER:\n                return ZMQSubClient(\n                    self.context,\n                    self.config.controller_pub_sub_address,\n                    bind=False,\n                )\n\n            case SubClientType.COMPONENT:\n                return ZMQSubClient(\n                    self.context,\n                    self.config.component_pub_sub_address,\n                    bind=True,\n                )\n\n            case _:\n                raise CommunicationClientCreationError(\n                    f\"Invalid client type: {client_type}\"\n                )\n\n    def _create_push_client(self, client_type: PushClientType) -&gt; ZMQPushClient:\n        \"\"\"Create a ZMQ push client based on the client type.\n\n        Args:\n            client_type: The type of client to create\n\n        Returns:\n            ZMQPushClient instance\n\n        Raises:\n            CommunicationClientCreationError: If the client type is invalid\n        \"\"\"\n        match client_type:\n            case PushClientType.INFERENCE_RESULTS:\n                return ZMQPushClient(\n                    self.context,\n                    self.config.inference_push_pull_address,\n                    bind=False,  # Workers are the pushers\n                )\n\n            case PushClientType.CREDIT_DROP:\n                return ZMQPushClient(\n                    self.context,\n                    self.config.credit_drop_address,\n                    bind=True,\n                )\n\n            case PushClientType.CREDIT_RETURN:\n                return ZMQPushClient(\n                    self.context,\n                    self.config.credit_return_address,\n                    bind=False,\n                )\n\n            case PushClientType.RECORDS:\n                return ZMQPushClient(\n                    self.context,\n                    self.config.records_address,\n                    bind=False,\n                )\n\n            case _:\n                raise CommunicationClientCreationError(\n                    f\"Invalid client type: {client_type}\"\n                )\n\n    def _create_pull_client(self, client_type: PullClientType) -&gt; ZMQPullClient:\n        \"\"\"Create a ZMQ pull client based on the client type.\n\n        Args:\n            client_type: The type of client to create\n\n        Returns:\n            ZMQPullClient instance\n\n        Raises:\n            CommunicationClientCreationError: If the client type is invalid\n        \"\"\"\n        match client_type:\n            case PullClientType.INFERENCE_RESULTS:\n                return ZMQPullClient(\n                    self.context,\n                    self.config.inference_push_pull_address,\n                    bind=True,  # Records manager is the pull\n                )\n\n            case PullClientType.CREDIT_DROP:\n                return ZMQPullClient(\n                    self.context,\n                    self.config.credit_drop_address,\n                    bind=False,\n                )\n\n            case PullClientType.CREDIT_RETURN:\n                return ZMQPullClient(\n                    self.context,\n                    self.config.credit_return_address,\n                    bind=True,\n                )\n\n            case PushClientType.RECORDS:\n                return ZMQPullClient(\n                    self.context,\n                    self.config.records_address,\n                    bind=True,\n                )\n\n            case _:\n                raise CommunicationClientCreationError(\n                    f\"Invalid client type: {client_type}\"\n                )\n\n    def _create_req_client(self, client_type: ReqClientType) -&gt; ZMQReqClient:\n        \"\"\"Create a ZMQ request client based on the client type.\n\n        Args:\n            client_type: The type of client to create\n\n        Returns:\n            ZMQReqClient instance\n\n        Raises:\n            CommunicationClientCreationError: If the client type is invalid\n        \"\"\"\n        match client_type:\n            case ReqClientType.CONVERSATION_DATA:\n                return ZMQReqClient(\n                    self.context,\n                    self.config.conversation_data_address,\n                    bind=False,  # Worker manager is the request\n                )\n            case _:\n                raise CommunicationClientCreationError(\n                    f\"Invalid client type: {client_type}\"\n                )\n\n    def _create_rep_client(self, client_type: RepClientType) -&gt; ZMQRepClient:\n        \"\"\"Create a ZMQ reply client based on the client type.\n\n        Args:\n            client_type: The type of client to create\n\n        Returns:\n            ZMQRepClient instance\n\n        Raises:\n            CommunicationClientCreationError: If the client type is invalid\n        \"\"\"\n        match client_type:\n            case RepClientType.CONVERSATION_DATA:\n                return ZMQRepClient(\n                    self.context,\n                    self.config.conversation_data_address,\n                    bind=True,  # Data manager is the reply\n                )\n\n            case _:\n                raise CommunicationClientCreationError(\n                    f\"Invalid client type: {client_type}\"\n                )\n\n    async def create_clients(self, *types: ClientType) -&gt; None:\n        \"\"\"Create and initialize ZMQ clients based on the client types.\n\n        Args:\n            types: List of ClientType enums indicating the types of clients to\n            create and initialize\n\n        Raises:\n            CommunicationClientCreationError: If the clients were not created\n                successfully\n        \"\"\"\n\n        for client_type in types:\n            if client_type in self.clients:\n                continue\n\n            if isinstance(client_type, PubClientType):\n                client = self._create_pub_client(client_type)\n\n            elif isinstance(client_type, SubClientType):\n                client = self._create_sub_client(client_type)\n\n            elif isinstance(client_type, PushClientType):\n                client = self._create_push_client(client_type)\n\n            elif isinstance(client_type, PullClientType):\n                client = self._create_pull_client(client_type)\n\n            elif isinstance(client_type, ReqClientType):\n                client = self._create_req_client(client_type)\n\n            elif isinstance(client_type, RepClientType):\n                client = self._create_rep_client(client_type)\n\n            else:\n                raise CommunicationClientCreationError(\n                    f\"Invalid client type: {client_type}\"\n                )\n\n            await client.initialize()\n\n            self.clients[client_type] = client\n\n    async def publish(self, topic: TopicType, message: Message) -&gt; None:\n        \"\"\"Publish a message to a topic. If the client type is not found, it will\n        be created.\n\n        Args:\n            topic: The topic to publish the message to\n            message: The message to publish\n\n        Raises:\n            CommunicationPublishError: If the message was not published successfully\n        \"\"\"\n\n        self._ensure_initialized()\n        client_type = PubClientType.from_topic(topic)\n\n        if client_type not in self.clients:\n            logger.warning(\n                \"Client type %s not found for pub topic %s, creating client\",\n                client_type,\n                topic,\n            )\n            await self.create_clients(client_type)\n\n        try:\n            await self.clients[client_type].publish(topic, message)\n        except Exception as e:\n            logger.error(\n                \"Exception publishing message to topic: %s, message: %s, error: %s\",\n                topic,\n                message,\n                e,\n            )\n            raise CommunicationPublishError() from e\n\n    async def subscribe(\n        self,\n        topic: TopicType,\n        callback: Callable[[Message], Coroutine[Any, Any, None]],\n    ) -&gt; None:\n        \"\"\"Subscribe to a topic. If the proper ZMQ client type is not found, it\n        will be created.\n\n        Args:\n            topic: The topic to subscribe to\n            callback: The callback to call when a message is received\n\n        Raises:\n            CommunicationSubscribeError: If there was an error subscribing to the\n                topic\n            CommunicationNotInitializedError: If the communication channels are not\n                initialized\n            CommunicationShutdownError: If the communication channels are shutdown\n        \"\"\"\n\n        self._ensure_initialized()\n\n        client_type = SubClientType.from_topic(topic)\n\n        if client_type not in self.clients:\n            logger.debug(\n                \"Client type %s not found for sub topic %s, creating client\",\n                client_type,\n                topic,\n            )\n            await self.create_clients(client_type)\n\n        try:\n            await self.clients[client_type].subscribe(topic, callback)\n        except Exception as e:\n            logger.error(f\"Exception subscribing to topic: {e}\")\n            raise CommunicationSubscribeError() from e\n\n    async def request(\n        self,\n        target: str,\n        request_data: Message,\n        timeout: float = 5.0,\n    ) -&gt; Message:\n        \"\"\"Request a message from a target. If the proper ZMQ client type is not\n        found, it will be created.\n\n        Args:\n            target: The target to request from\n            request_data: The data to request\n            timeout: The timeout for the request\n\n        Returns:\n            The response from the target\n\n        Raises:\n            CommunicationRequestError: If there was an error requesting from the\n                target\n            CommunicationNotInitializedError: If the communication channels are not\n                initialized\n            CommunicationShutdownError: If the communication channels are shutdown\n        \"\"\"\n\n        self._ensure_initialized()\n\n        client_type = ReqClientType.from_topic(target)\n\n        if client_type not in self.clients:\n            logger.warning(\n                \"Client type %s not found for req topic %s, creating client\",\n                client_type,\n                target,\n            )\n            await self.create_clients(client_type)\n\n        try:\n            return await self.clients[client_type].request(\n                target, request_data, timeout\n            )\n        except Exception as e:\n            logger.error(f\"Exception requesting from {target}: {e}\")\n            raise CommunicationRequestError() from e\n\n    async def respond(self, target: str, response: Message) -&gt; None:\n        \"\"\"Respond to a request. If the proper ZMQ client type is not found, it\n        will be created.\n\n        Args:\n            target: The target to respond to\n            response: The response to send\n\n        Raises:\n            CommunicationRespondError: If there was an error responding to the\n                target\n            CommunicationNotInitializedError: If the communication channels are not\n                initialized\n            CommunicationShutdownError: If the communication channels are shutdown\n        \"\"\"\n\n        self._ensure_initialized()\n\n        client_type = RepClientType.from_topic(target)\n\n        if client_type not in self.clients:\n            logger.warning(\n                \"Client type %s not found for rep topic %s, creating client\",\n                client_type,\n                target,\n            )\n            await self.create_clients(client_type)\n\n        try:\n            await self.clients[client_type].respond(target, response)\n        except Exception as e:\n            logger.error(f\"Exception responding to {target}: {e}\")\n            raise CommunicationResponseError() from e\n\n    async def push(self, topic: TopicType, message: Message) -&gt; None:\n        \"\"\"Push a message to a topic. If the proper ZMQ client type is not found,\n        it will be created.\n\n        Args:\n            topic: The topic to push the message to\n            message: The message to push\n\n        Raises:\n            CommunicationPushError: If there was an error pushing the message\n            CommunicationNotInitializedError: If the communication channels are not\n                initialized\n            CommunicationShutdownError: If the communication channels are shutdown\n        \"\"\"\n\n        self._ensure_initialized()\n\n        client_type = PushClientType.from_topic(topic)\n\n        if client_type not in self.clients:\n            logger.warning(\n                \"Client type %s not found for push, creating client\",\n                client_type,\n            )\n            await self.create_clients(client_type)\n\n        try:\n            await self.clients[client_type].push(message)\n        except Exception as e:\n            logger.error(f\"Exception pushing data: {e}\")\n            raise CommunicationPushError() from e\n\n    async def pull(\n        self,\n        topic: TopicType,\n        callback: Callable[[Message], None],\n    ) -&gt; None:\n        \"\"\"Pull a message from a topic. If the proper ZMQ client type is not found,\n        it will be created.\n\n        Args:\n            topic: The topic to pull the message from\n            callback: The callback to call when a message is received\n\n        Raises:\n            CommunicationPullError: If there was an error pulling the message\n            CommunicationNotInitializedError: If the communication channels are not\n                initialized\n            CommunicationShutdownError: If the communication channels are shutdown\n        \"\"\"\n\n        logger.debug(f\"Pulling data from {topic}\")\n\n        self._ensure_initialized()\n\n        client_type = PullClientType.from_topic(topic)\n\n        if client_type not in self.clients:\n            logger.warning(\n                \"Client type %s not found for pull, creating client\",\n                client_type,\n            )\n            await self.create_clients(client_type)\n\n        # Only adds to the callback list, does not block, and does not raise an exception\n        await self.clients[client_type].pull(topic, callback)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.context","title":"<code>context</code>  <code>property</code>","text":"<p>Get the ZeroMQ context.</p> <p>Returns:</p> Type Description <code>Context</code> <p>ZeroMQ context</p>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.is_initialized","title":"<code>is_initialized</code>  <code>property</code>","text":"<p>Check if communication channels are initialized.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if communication channels are initialized, False otherwise</p>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.is_shutdown","title":"<code>is_shutdown</code>  <code>property</code>","text":"<p>Check if communication channels are shutdown.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if communication channels are shutdown, False otherwise</p>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.__init__","title":"<code>__init__(config=None)</code>","text":"<p>Initialize ZMQ communication.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ZMQCommunicationConfig | None</code> <p>ZMQCommunicationConfig object with configuration parameters</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>def __init__(\n    self,\n    config: ZMQCommunicationConfig | None = None,\n) -&gt; None:\n    \"\"\"Initialize ZMQ communication.\n\n    Args:\n        config: ZMQCommunicationConfig object with configuration parameters\n    \"\"\"\n    self.stop_event: asyncio.Event = asyncio.Event()\n    self.initialized_event: asyncio.Event = asyncio.Event()\n    self.config = config or ZMQCommunicationConfig()\n\n    # Generate client_id if not provided\n    if not self.config.client_id:\n        self.config.client_id = f\"client_{uuid.uuid4().hex[:8]}\"\n\n    self._context: zmq.asyncio.Context | None = None\n    self.clients: dict[ClientType, ZMQClient] = {}\n\n    logger.debug(\n        \"ZMQ communication using protocol: %s with client ID: %s\",\n        type(self.config.protocol_config).__name__,\n        self.config.client_id,\n    )\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.create_clients","title":"<code>create_clients(*types)</code>  <code>async</code>","text":"<p>Create and initialize ZMQ clients based on the client types.</p> <p>Parameters:</p> Name Type Description Default <code>types</code> <code>ClientType</code> <p>List of ClientType enums indicating the types of clients to</p> <code>()</code> <p>Raises:</p> Type Description <code>CommunicationClientCreationError</code> <p>If the clients were not created successfully</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def create_clients(self, *types: ClientType) -&gt; None:\n    \"\"\"Create and initialize ZMQ clients based on the client types.\n\n    Args:\n        types: List of ClientType enums indicating the types of clients to\n        create and initialize\n\n    Raises:\n        CommunicationClientCreationError: If the clients were not created\n            successfully\n    \"\"\"\n\n    for client_type in types:\n        if client_type in self.clients:\n            continue\n\n        if isinstance(client_type, PubClientType):\n            client = self._create_pub_client(client_type)\n\n        elif isinstance(client_type, SubClientType):\n            client = self._create_sub_client(client_type)\n\n        elif isinstance(client_type, PushClientType):\n            client = self._create_push_client(client_type)\n\n        elif isinstance(client_type, PullClientType):\n            client = self._create_pull_client(client_type)\n\n        elif isinstance(client_type, ReqClientType):\n            client = self._create_req_client(client_type)\n\n        elif isinstance(client_type, RepClientType):\n            client = self._create_rep_client(client_type)\n\n        else:\n            raise CommunicationClientCreationError(\n                f\"Invalid client type: {client_type}\"\n            )\n\n        await client.initialize()\n\n        self.clients[client_type] = client\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.initialize","title":"<code>initialize()</code>  <code>async</code>","text":"<p>Initialize communication channels.</p> <p>Returns:</p> Type Description <code>None</code> <p>True if initialization was successful, False otherwise</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def initialize(self) -&gt; None:\n    \"\"\"Initialize communication channels.\n\n    Returns:\n        True if initialization was successful, False otherwise\n    \"\"\"\n    if self.is_initialized:\n        return\n\n    self._context = zmq.asyncio.Context()\n    self.initialized_event.set()\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.publish","title":"<code>publish(topic, message)</code>  <code>async</code>","text":"<p>Publish a message to a topic. If the client type is not found, it will be created.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>The topic to publish the message to</p> required <code>message</code> <code>Message</code> <p>The message to publish</p> required <p>Raises:</p> Type Description <code>CommunicationPublishError</code> <p>If the message was not published successfully</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def publish(self, topic: TopicType, message: Message) -&gt; None:\n    \"\"\"Publish a message to a topic. If the client type is not found, it will\n    be created.\n\n    Args:\n        topic: The topic to publish the message to\n        message: The message to publish\n\n    Raises:\n        CommunicationPublishError: If the message was not published successfully\n    \"\"\"\n\n    self._ensure_initialized()\n    client_type = PubClientType.from_topic(topic)\n\n    if client_type not in self.clients:\n        logger.warning(\n            \"Client type %s not found for pub topic %s, creating client\",\n            client_type,\n            topic,\n        )\n        await self.create_clients(client_type)\n\n    try:\n        await self.clients[client_type].publish(topic, message)\n    except Exception as e:\n        logger.error(\n            \"Exception publishing message to topic: %s, message: %s, error: %s\",\n            topic,\n            message,\n            e,\n        )\n        raise CommunicationPublishError() from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.pull","title":"<code>pull(topic, callback)</code>  <code>async</code>","text":"<p>Pull a message from a topic. If the proper ZMQ client type is not found, it will be created.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>The topic to pull the message from</p> required <code>callback</code> <code>Callable[[Message], None]</code> <p>The callback to call when a message is received</p> required <p>Raises:</p> Type Description <code>CommunicationPullError</code> <p>If there was an error pulling the message</p> <code>CommunicationNotInitializedError</code> <p>If the communication channels are not initialized</p> <code>CommunicationShutdownError</code> <p>If the communication channels are shutdown</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def pull(\n    self,\n    topic: TopicType,\n    callback: Callable[[Message], None],\n) -&gt; None:\n    \"\"\"Pull a message from a topic. If the proper ZMQ client type is not found,\n    it will be created.\n\n    Args:\n        topic: The topic to pull the message from\n        callback: The callback to call when a message is received\n\n    Raises:\n        CommunicationPullError: If there was an error pulling the message\n        CommunicationNotInitializedError: If the communication channels are not\n            initialized\n        CommunicationShutdownError: If the communication channels are shutdown\n    \"\"\"\n\n    logger.debug(f\"Pulling data from {topic}\")\n\n    self._ensure_initialized()\n\n    client_type = PullClientType.from_topic(topic)\n\n    if client_type not in self.clients:\n        logger.warning(\n            \"Client type %s not found for pull, creating client\",\n            client_type,\n        )\n        await self.create_clients(client_type)\n\n    # Only adds to the callback list, does not block, and does not raise an exception\n    await self.clients[client_type].pull(topic, callback)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.push","title":"<code>push(topic, message)</code>  <code>async</code>","text":"<p>Push a message to a topic. If the proper ZMQ client type is not found, it will be created.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>The topic to push the message to</p> required <code>message</code> <code>Message</code> <p>The message to push</p> required <p>Raises:</p> Type Description <code>CommunicationPushError</code> <p>If there was an error pushing the message</p> <code>CommunicationNotInitializedError</code> <p>If the communication channels are not initialized</p> <code>CommunicationShutdownError</code> <p>If the communication channels are shutdown</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def push(self, topic: TopicType, message: Message) -&gt; None:\n    \"\"\"Push a message to a topic. If the proper ZMQ client type is not found,\n    it will be created.\n\n    Args:\n        topic: The topic to push the message to\n        message: The message to push\n\n    Raises:\n        CommunicationPushError: If there was an error pushing the message\n        CommunicationNotInitializedError: If the communication channels are not\n            initialized\n        CommunicationShutdownError: If the communication channels are shutdown\n    \"\"\"\n\n    self._ensure_initialized()\n\n    client_type = PushClientType.from_topic(topic)\n\n    if client_type not in self.clients:\n        logger.warning(\n            \"Client type %s not found for push, creating client\",\n            client_type,\n        )\n        await self.create_clients(client_type)\n\n    try:\n        await self.clients[client_type].push(message)\n    except Exception as e:\n        logger.error(f\"Exception pushing data: {e}\")\n        raise CommunicationPushError() from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.request","title":"<code>request(target, request_data, timeout=5.0)</code>  <code>async</code>","text":"<p>Request a message from a target. If the proper ZMQ client type is not found, it will be created.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>The target to request from</p> required <code>request_data</code> <code>Message</code> <p>The data to request</p> required <code>timeout</code> <code>float</code> <p>The timeout for the request</p> <code>5.0</code> <p>Returns:</p> Type Description <code>Message</code> <p>The response from the target</p> <p>Raises:</p> Type Description <code>CommunicationRequestError</code> <p>If there was an error requesting from the target</p> <code>CommunicationNotInitializedError</code> <p>If the communication channels are not initialized</p> <code>CommunicationShutdownError</code> <p>If the communication channels are shutdown</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def request(\n    self,\n    target: str,\n    request_data: Message,\n    timeout: float = 5.0,\n) -&gt; Message:\n    \"\"\"Request a message from a target. If the proper ZMQ client type is not\n    found, it will be created.\n\n    Args:\n        target: The target to request from\n        request_data: The data to request\n        timeout: The timeout for the request\n\n    Returns:\n        The response from the target\n\n    Raises:\n        CommunicationRequestError: If there was an error requesting from the\n            target\n        CommunicationNotInitializedError: If the communication channels are not\n            initialized\n        CommunicationShutdownError: If the communication channels are shutdown\n    \"\"\"\n\n    self._ensure_initialized()\n\n    client_type = ReqClientType.from_topic(target)\n\n    if client_type not in self.clients:\n        logger.warning(\n            \"Client type %s not found for req topic %s, creating client\",\n            client_type,\n            target,\n        )\n        await self.create_clients(client_type)\n\n    try:\n        return await self.clients[client_type].request(\n            target, request_data, timeout\n        )\n    except Exception as e:\n        logger.error(f\"Exception requesting from {target}: {e}\")\n        raise CommunicationRequestError() from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.respond","title":"<code>respond(target, response)</code>  <code>async</code>","text":"<p>Respond to a request. If the proper ZMQ client type is not found, it will be created.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>The target to respond to</p> required <code>response</code> <code>Message</code> <p>The response to send</p> required <p>Raises:</p> Type Description <code>CommunicationRespondError</code> <p>If there was an error responding to the target</p> <code>CommunicationNotInitializedError</code> <p>If the communication channels are not initialized</p> <code>CommunicationShutdownError</code> <p>If the communication channels are shutdown</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def respond(self, target: str, response: Message) -&gt; None:\n    \"\"\"Respond to a request. If the proper ZMQ client type is not found, it\n    will be created.\n\n    Args:\n        target: The target to respond to\n        response: The response to send\n\n    Raises:\n        CommunicationRespondError: If there was an error responding to the\n            target\n        CommunicationNotInitializedError: If the communication channels are not\n            initialized\n        CommunicationShutdownError: If the communication channels are shutdown\n    \"\"\"\n\n    self._ensure_initialized()\n\n    client_type = RepClientType.from_topic(target)\n\n    if client_type not in self.clients:\n        logger.warning(\n            \"Client type %s not found for rep topic %s, creating client\",\n            client_type,\n            target,\n        )\n        await self.create_clients(client_type)\n\n    try:\n        await self.clients[client_type].respond(target, response)\n    except Exception as e:\n        logger.error(f\"Exception responding to {target}: {e}\")\n        raise CommunicationResponseError() from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.shutdown","title":"<code>shutdown()</code>  <code>async</code>","text":"<p>Gracefully shutdown communication channels.</p> <p>This method will wait for all clients to shutdown before shutting down the context.</p> <p>Returns:</p> Type Description <code>None</code> <p>True if shutdown was successful, False otherwise</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Gracefully shutdown communication channels.\n\n    This method will wait for all clients to shutdown before shutting down\n    the context.\n\n    Returns:\n        True if shutdown was successful, False otherwise\n    \"\"\"\n    if self.is_shutdown:\n        logger.debug(\"ZMQ communication already shutdown\")\n        return\n\n    try:\n        if not self.stop_event.is_set():\n            self.stop_event.set()\n\n        logger.debug(\n            f\"Shutting down ZMQ communication for client {self.config.client_id}\"\n        )\n        await asyncio.gather(\n            *(client.shutdown() for client in self.clients.values())\n        )\n\n        if self.context:\n            self.context.term()\n\n        self._context = None\n        logger.debug(\"ZMQ communication shutdown successfully\")\n\n    except Exception as e:\n        logger.error(f\"Exception shutting down ZMQ communication: {e}\")\n        raise CommunicationShutdownError(\n            \"Failed to shutdown ZMQ communication\"\n        ) from e\n\n    finally:\n        self.clients = {}\n        self._context = None\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQCommunication.subscribe","title":"<code>subscribe(topic, callback)</code>  <code>async</code>","text":"<p>Subscribe to a topic. If the proper ZMQ client type is not found, it will be created.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>TopicType</code> <p>The topic to subscribe to</p> required <code>callback</code> <code>Callable[[Message], Coroutine[Any, Any, None]]</code> <p>The callback to call when a message is received</p> required <p>Raises:</p> Type Description <code>CommunicationSubscribeError</code> <p>If there was an error subscribing to the topic</p> <code>CommunicationNotInitializedError</code> <p>If the communication channels are not initialized</p> <code>CommunicationShutdownError</code> <p>If the communication channels are shutdown</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def subscribe(\n    self,\n    topic: TopicType,\n    callback: Callable[[Message], Coroutine[Any, Any, None]],\n) -&gt; None:\n    \"\"\"Subscribe to a topic. If the proper ZMQ client type is not found, it\n    will be created.\n\n    Args:\n        topic: The topic to subscribe to\n        callback: The callback to call when a message is received\n\n    Raises:\n        CommunicationSubscribeError: If there was an error subscribing to the\n            topic\n        CommunicationNotInitializedError: If the communication channels are not\n            initialized\n        CommunicationShutdownError: If the communication channels are shutdown\n    \"\"\"\n\n    self._ensure_initialized()\n\n    client_type = SubClientType.from_topic(topic)\n\n    if client_type not in self.clients:\n        logger.debug(\n            \"Client type %s not found for sub topic %s, creating client\",\n            client_type,\n            topic,\n        )\n        await self.create_clients(client_type)\n\n    try:\n        await self.clients[client_type].subscribe(topic, callback)\n    except Exception as e:\n        logger.error(f\"Exception subscribing to topic: {e}\")\n        raise CommunicationSubscribeError() from e\n</code></pre>"},{"location":"api/#aiperfcommonconfigloader","title":"aiperf.common.config.loader","text":""},{"location":"api/#aiperf.common.config.loader.load_service_config","title":"<code>load_service_config()</code>","text":"<p>Load the service configuration.</p> Source code in <code>aiperf/common/config/loader.py</code> <pre><code>def load_service_config() -&gt; ServiceConfig:\n    \"\"\"Load the service configuration.\"\"\"\n    # TODO: implement\n    return ServiceConfig()\n</code></pre>"},{"location":"api/#aiperfcommonconfigservice_config","title":"aiperf.common.config.service_config","text":""},{"location":"api/#aiperf.common.config.service_config.ServiceConfig","title":"<code>ServiceConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base configuration for all services.</p> <p>This class provides the common configuration parameters needed by all services.</p> Source code in <code>aiperf/common/config/service_config.py</code> <pre><code>class ServiceConfig(BaseModel):\n    \"\"\"Base configuration for all services.\n\n    This class provides the common configuration parameters needed by all services.\n    \"\"\"\n\n    # TODO: this needs to be cleaned up and finalized\n\n    service_run_type: ServiceRunType = Field(\n        default=ServiceRunType.MULTIPROCESSING,\n        description=\"Type of service run (MULTIPROCESSING, KUBERNETES)\",\n    )\n    comm_backend: CommunicationBackend = Field(\n        default=CommunicationBackend.ZMQ_TCP,\n        description=\"Communication backend to use\",\n    )\n    comm_config: BaseModel = Field(\n        default=ZMQCommunicationConfig(),\n        description=\"Communication configuration\",\n    )\n    heartbeat_timeout: float = Field(\n        default=60.0,\n        description=\"Time in seconds after which a service is considered dead if no \"\n        \"heartbeat received\",\n    )\n    registration_timeout: float = Field(\n        default=60.0,\n        description=\"Time in seconds to wait for all required services to register\",\n    )\n    command_timeout: float = Field(\n        default=10.0,\n        description=\"Default timeout for command responses\",\n    )\n    heartbeat_interval: float = Field(\n        default=10.0,\n        description=\"Interval in seconds between heartbeat messages\",\n    )\n    min_workers: int = Field(\n        default=5,\n        description=\"Minimum number of idle workers to maintain\",\n    )\n    max_workers: int = Field(\n        default=100,\n        description=\"Maximum number of workers to create\",\n    )\n    target_idle_workers: int = Field(\n        default=10,\n        description=\"Target number of idle workers to maintain\",\n    )\n</code></pre>"},{"location":"api/#aiperfcommonenums","title":"aiperf.common.enums","text":""},{"location":"api/#aiperf.common.enums.TopicType","title":"<code>TopicType = Topic | DataTopic</code>  <code>module-attribute</code>","text":"<p>Union of all the various different topic types supported by the system, for use in type hinting.</p>"},{"location":"api/#aiperf.common.enums.CommandType","title":"<code>CommandType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>List of commands that the SystemController can send to component services.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class CommandType(StrEnum):\n    \"\"\"List of commands that the SystemController can send to component services.\"\"\"\n\n    START = \"start\"\n    STOP = \"stop\"\n    CONFIGURE = \"configure\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.CommunicationBackend","title":"<code>CommunicationBackend</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Supported communication backends.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class CommunicationBackend(StrEnum):\n    \"\"\"Supported communication backends.\"\"\"\n\n    ZMQ_TCP = \"zmq_tcp\"\n    \"\"\"ZeroMQ backend using TCP sockets.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.CommunicationBackend.ZMQ_TCP","title":"<code>ZMQ_TCP = 'zmq_tcp'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZeroMQ backend using TCP sockets.</p>"},{"location":"api/#aiperf.common.enums.DataTopic","title":"<code>DataTopic</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>TBD. Specific data topics for use in the future.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class DataTopic(StrEnum):\n    \"\"\"TBD. Specific data topics for use in the future.\"\"\"\n\n    DATASET = \"dataset_data\"\n    RECORDS = \"records_data\"\n    WORKER = \"worker_data\"\n    POST_PROCESSOR = \"post_processor_data\"\n    RESULTS = \"results\"\n    METRICS = \"metrics\"\n    CONVERSATION = \"conversation_data\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.MessageType","title":"<code>MessageType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>The various types of messages that can be sent between services.</p> <p>The message type is used to determine what Pydantic model the payload maps to. The mappings between message types and payload types are defined in the payload definitions.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class MessageType(StrEnum):\n    \"\"\"The various types of messages that can be sent between services.\n\n    The message type is used to determine what Pydantic model the payload maps to.\n    The mappings between message types and payload types are defined in the\n    payload definitions.\n    \"\"\"\n\n    UNKNOWN = \"unknown\"\n    \"\"\"A placeholder value for when the message type is not known.\"\"\"\n\n    REGISTRATION = \"registration\"\n    \"\"\"A message sent by a component service to register itself with the\n    system controller.\"\"\"\n\n    HEARTBEAT = \"heartbeat\"\n    \"\"\"A message sent by a component service to the system controller to indicate it\n    is still running.\"\"\"\n\n    COMMAND = \"command\"\n    \"\"\"A message sent by the system controller to a component service to command it\n    to do something.\"\"\"\n\n    RESPONSE = \"response\"\n    \"\"\"A message sent by a component service to the system controller to respond\n    to a command.\"\"\"\n\n    STATUS = \"status\"\n    \"\"\"A notification sent by a component service to the system controller to\n    report its status.\"\"\"\n\n    ERROR = \"error\"\n    \"\"\"A message sent by a component service to the system controller to\n    report an error.\"\"\"\n\n    CREDIT_DROP = \"credit_drop\"\n    \"\"\"A message sent by the Timing Manager service to allocate credits\n    for a worker.\"\"\"\n\n    CREDIT_RETURN = \"credit_return\"\n    \"\"\"A message sent by the Worker services to return credits to the credit pool.\"\"\"\n\n    DATA = \"data\"\n    \"\"\"A message containing data. This is TBD.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.MessageType.COMMAND","title":"<code>COMMAND = 'command'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by the system controller to a component service to command it to do something.</p>"},{"location":"api/#aiperf.common.enums.MessageType.CREDIT_DROP","title":"<code>CREDIT_DROP = 'credit_drop'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by the Timing Manager service to allocate credits for a worker.</p>"},{"location":"api/#aiperf.common.enums.MessageType.CREDIT_RETURN","title":"<code>CREDIT_RETURN = 'credit_return'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by the Worker services to return credits to the credit pool.</p>"},{"location":"api/#aiperf.common.enums.MessageType.DATA","title":"<code>DATA = 'data'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message containing data. This is TBD.</p>"},{"location":"api/#aiperf.common.enums.MessageType.ERROR","title":"<code>ERROR = 'error'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by a component service to the system controller to report an error.</p>"},{"location":"api/#aiperf.common.enums.MessageType.HEARTBEAT","title":"<code>HEARTBEAT = 'heartbeat'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by a component service to the system controller to indicate it is still running.</p>"},{"location":"api/#aiperf.common.enums.MessageType.REGISTRATION","title":"<code>REGISTRATION = 'registration'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by a component service to register itself with the system controller.</p>"},{"location":"api/#aiperf.common.enums.MessageType.RESPONSE","title":"<code>RESPONSE = 'response'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by a component service to the system controller to respond to a command.</p>"},{"location":"api/#aiperf.common.enums.MessageType.STATUS","title":"<code>STATUS = 'status'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A notification sent by a component service to the system controller to report its status.</p>"},{"location":"api/#aiperf.common.enums.MessageType.UNKNOWN","title":"<code>UNKNOWN = 'unknown'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A placeholder value for when the message type is not known.</p>"},{"location":"api/#aiperf.common.enums.ServiceRegistrationStatus","title":"<code>ServiceRegistrationStatus</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Defines the various states a service can be in during registration with the SystemController.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class ServiceRegistrationStatus(StrEnum):\n    \"\"\"Defines the various states a service can be in during registration with\n    the SystemController.\"\"\"\n\n    UNREGISTERED = \"unregistered\"\n    \"\"\"The service is not registered with the SystemController. This is the\n    initial state.\"\"\"\n\n    WAITING = \"waiting\"\n    \"\"\"The service is waiting for the SystemController to register it.\n    This is a temporary state that should be followed by REGISTERED.\"\"\"\n\n    REGISTERED = \"registered\"\n    \"\"\"The service is registered with the SystemController.\"\"\"\n\n    TIMEOUT = \"timeout\"\n    \"\"\"The service registration timed out.\"\"\"\n\n    ERROR = \"error\"\n    \"\"\"The service registration failed.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.ServiceRegistrationStatus.ERROR","title":"<code>ERROR = 'error'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service registration failed.</p>"},{"location":"api/#aiperf.common.enums.ServiceRegistrationStatus.REGISTERED","title":"<code>REGISTERED = 'registered'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is registered with the SystemController.</p>"},{"location":"api/#aiperf.common.enums.ServiceRegistrationStatus.TIMEOUT","title":"<code>TIMEOUT = 'timeout'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service registration timed out.</p>"},{"location":"api/#aiperf.common.enums.ServiceRegistrationStatus.UNREGISTERED","title":"<code>UNREGISTERED = 'unregistered'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is not registered with the SystemController. This is the initial state.</p>"},{"location":"api/#aiperf.common.enums.ServiceRegistrationStatus.WAITING","title":"<code>WAITING = 'waiting'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is waiting for the SystemController to register it. This is a temporary state that should be followed by REGISTERED.</p>"},{"location":"api/#aiperf.common.enums.ServiceRunType","title":"<code>ServiceRunType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>The different ways the SystemController should run the component services.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class ServiceRunType(StrEnum):\n    \"\"\"The different ways the SystemController should run the component services.\"\"\"\n\n    MULTIPROCESSING = \"process\"\n    \"\"\"Run each service as a separate process.\n    This is the default way for single-node deployments.\"\"\"\n\n    KUBERNETES = \"k8s\"\n    \"\"\"Run each service as a separate Kubernetes pod.\n    This is the default way for multi-node deployments.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.ServiceRunType.KUBERNETES","title":"<code>KUBERNETES = 'k8s'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Run each service as a separate Kubernetes pod. This is the default way for multi-node deployments.</p>"},{"location":"api/#aiperf.common.enums.ServiceRunType.MULTIPROCESSING","title":"<code>MULTIPROCESSING = 'process'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Run each service as a separate process. This is the default way for single-node deployments.</p>"},{"location":"api/#aiperf.common.enums.ServiceState","title":"<code>ServiceState</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>States a service can be in throughout its lifecycle.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class ServiceState(StrEnum):\n    \"\"\"States a service can be in throughout its lifecycle.\"\"\"\n\n    UNKNOWN = \"unknown\"\n\n    INITIALIZING = \"initializing\"\n    \"\"\"The service is currently initializing. This is a temporary state that should be\n    followed by READY.\"\"\"\n\n    READY = \"ready\"\n    \"\"\"The service has initialized and is ready to be configured or started.\"\"\"\n\n    STARTING = \"starting\"\n    \"\"\"The service is starting. This is a temporary state that should be followed\n    by RUNNING.\"\"\"\n\n    RUNNING = \"running\"\n\n    STOPPING = \"stopping\"\n    \"\"\"The service is stopping. This is a temporary state that should be followed\n    by STOPPED.\"\"\"\n\n    STOPPED = \"stopped\"\n\n    ERROR = \"error\"\n    \"\"\"The service is currently in an error state.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.ServiceState.ERROR","title":"<code>ERROR = 'error'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is currently in an error state.</p>"},{"location":"api/#aiperf.common.enums.ServiceState.INITIALIZING","title":"<code>INITIALIZING = 'initializing'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is currently initializing. This is a temporary state that should be followed by READY.</p>"},{"location":"api/#aiperf.common.enums.ServiceState.READY","title":"<code>READY = 'ready'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service has initialized and is ready to be configured or started.</p>"},{"location":"api/#aiperf.common.enums.ServiceState.STARTING","title":"<code>STARTING = 'starting'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is starting. This is a temporary state that should be followed by RUNNING.</p>"},{"location":"api/#aiperf.common.enums.ServiceState.STOPPING","title":"<code>STOPPING = 'stopping'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is stopping. This is a temporary state that should be followed by STOPPED.</p>"},{"location":"api/#aiperf.common.enums.ServiceType","title":"<code>ServiceType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Types of services in the AIPerf system.</p> <p>This is used to identify the service type when registering with the SystemController. It can also be used for tracking purposes if multiple instances of the same service type are running.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class ServiceType(StrEnum):\n    \"\"\"Types of services in the AIPerf system.\n\n    This is used to identify the service type when registering with the\n    SystemController. It can also be used for tracking purposes if multiple\n    instances of the same service type are running.\n    \"\"\"\n\n    SYSTEM_CONTROLLER = \"system_controller\"\n    DATASET_MANAGER = \"dataset_manager\"\n    TIMING_MANAGER = \"timing_manager\"\n    RECORDS_MANAGER = \"records_manager\"\n    POST_PROCESSOR_MANAGER = \"post_processor_manager\"\n    WORKER_MANAGER = \"worker_manager\"\n    WORKER = \"worker\"\n    TEST = \"test_service\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.StrEnum","title":"<code>StrEnum</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Base class for string-based enums.</p> <p>Using this as a base class allows enum values to be used directly as strings without having to use .value.</p> Example <p>class Pet(StrEnum): ...     DOG = \"dog\" ...     CAT = \"cat\" ... Pet.DOG 'dog' print(f\"{Pet.DOG}\") 'dog' print(f\"{Pet.DOG!r}\") 'Pet.DOG'</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class StrEnum(str, Enum):\n    \"\"\"Base class for string-based enums.\n\n    Using this as a base class allows enum values to be used directly as\n    strings without having to use .value.\n\n    Example:\n        &gt;&gt;&gt; class Pet(StrEnum):\n        ...     DOG = \"dog\"\n        ...     CAT = \"cat\"\n        ...\n        &gt;&gt;&gt; Pet.DOG\n        'dog'\n        &gt;&gt;&gt; print(f\"{Pet.DOG}\")\n        'dog'\n        &gt;&gt;&gt; print(f\"{Pet.DOG!r}\")\n        'Pet.DOG'\n    \"\"\"\n\n    def __str__(self) -&gt; str:\n        return self.value\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}.{self.name}\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.Topic","title":"<code>Topic</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Communication topics for the main messaging bus. Right now, there is some overlap between Topic and MessageType.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class Topic(StrEnum):\n    \"\"\"Communication topics for the main messaging bus.\n    Right now, there is some overlap between Topic and MessageType.\"\"\"\n\n    CREDIT_DROP = \"credit_drop\"\n    CREDIT_RETURN = \"credit_return\"\n    REGISTRATION = \"registration\"\n    COMMAND = \"command\"\n    RESPONSE = \"response\"\n    STATUS = \"status\"\n    HEARTBEAT = \"heartbeat\"\n</code></pre>"},{"location":"api/#aiperfcommonexceptions","title":"aiperf.common.exceptions","text":""},{"location":"api/#aiperf.common.exceptions.AIPerfError","title":"<code>AIPerfError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base class for all exceptions raised by AIPerf.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class AIPerfError(Exception):\n    \"\"\"Base class for all exceptions raised by AIPerf.\"\"\"\n\n    def __str__(self) -&gt; str:\n        return f\"{self.__class__.__name__}: {super().__str__()}\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.AIPerfMultiError","title":"<code>AIPerfMultiError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Exception raised when running multiple tasks and one or more fail.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class AIPerfMultiError(AIPerfError):\n    \"\"\"Exception raised when running multiple tasks and one or more fail.\"\"\"\n\n    def __init__(self, message: str, exceptions: list[Exception]) -&gt; None:\n        super().__init__(f\"{message}: {','.join([str(e) for e in exceptions])}\")\n        self.exceptions = exceptions\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationClientCreationError","title":"<code>CommunicationClientCreationError</code>","text":"<p>               Bases: <code>CommunicationError</code></p> <p>Exception raised when communication channels fail to create a client.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationClientCreationError(CommunicationError):\n    \"\"\"Exception raised when communication channels fail to create a client.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationClientNotFoundError","title":"<code>CommunicationClientNotFoundError</code>","text":"<p>               Bases: <code>CommunicationError</code></p> <p>Exception raised when a communication client is not found.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationClientNotFoundError(CommunicationError):\n    \"\"\"Exception raised when a communication client is not found.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationCreateError","title":"<code>CommunicationCreateError</code>","text":"<p>               Bases: <code>CommunicationError</code></p> <p>Exception raised when communication channels fail to create a client.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationCreateError(CommunicationError):\n    \"\"\"Exception raised when communication channels fail to create a client.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationError","title":"<code>CommunicationError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Base class for all communication exceptions.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationError(AIPerfError):\n    \"\"\"Base class for all communication exceptions.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationInitializationError","title":"<code>CommunicationInitializationError</code>","text":"<p>               Bases: <code>CommunicationError</code></p> <p>Exception raised when communication channels fail to initialize.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationInitializationError(CommunicationError):\n    \"\"\"Exception raised when communication channels fail to initialize.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationNotInitializedError","title":"<code>CommunicationNotInitializedError</code>","text":"<p>               Bases: <code>CommunicationError</code></p> <p>Exception raised when communication channels are not initialized.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationNotInitializedError(CommunicationError):\n    \"\"\"Exception raised when communication channels are not initialized.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationPublishError","title":"<code>CommunicationPublishError</code>","text":"<p>               Bases: <code>CommunicationError</code></p> <p>Exception raised when communication channels fail to publish a message.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationPublishError(CommunicationError):\n    \"\"\"Exception raised when communication channels fail to publish a message.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationPullError","title":"<code>CommunicationPullError</code>","text":"<p>               Bases: <code>CommunicationError</code></p> <p>Exception raised when communication channels fail to pull a message from a topic.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationPullError(CommunicationError):\n    \"\"\"Exception raised when communication channels fail to pull a message from\n    a topic.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationPushError","title":"<code>CommunicationPushError</code>","text":"<p>               Bases: <code>CommunicationError</code></p> <p>Exception raised when communication channels fail to push a message to a topic.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationPushError(CommunicationError):\n    \"\"\"Exception raised when communication channels fail to push a message to\n    a topic.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationRequestError","title":"<code>CommunicationRequestError</code>","text":"<p>               Bases: <code>CommunicationError</code></p> <p>Exception raised when communication channels fail to send a request.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationRequestError(CommunicationError):\n    \"\"\"Exception raised when communication channels fail to send a request.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationResponseError","title":"<code>CommunicationResponseError</code>","text":"<p>               Bases: <code>CommunicationError</code></p> <p>Exception raised when communication channels fail to receive a response.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationResponseError(CommunicationError):\n    \"\"\"Exception raised when communication channels fail to receive a response.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationShutdownError","title":"<code>CommunicationShutdownError</code>","text":"<p>               Bases: <code>CommunicationError</code></p> <p>Exception raised when communication channels fail to shutdown.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationShutdownError(CommunicationError):\n    \"\"\"Exception raised when communication channels fail to shutdown.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationSubscribeError","title":"<code>CommunicationSubscribeError</code>","text":"<p>               Bases: <code>CommunicationError</code></p> <p>Exception raised when communication channels fail to subscribe to a topic.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationSubscribeError(CommunicationError):\n    \"\"\"Exception raised when communication channels fail to subscribe to a topic.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ConfigError","title":"<code>ConfigError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Base class for all exceptions raised by configuration errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ConfigError(AIPerfError):\n    \"\"\"Base class for all exceptions raised by configuration errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ConfigLoadError","title":"<code>ConfigLoadError</code>","text":"<p>               Bases: <code>ConfigError</code></p> <p>Exception raised for configuration load errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ConfigLoadError(ConfigError):\n    \"\"\"Exception raised for configuration load errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ConfigParseError","title":"<code>ConfigParseError</code>","text":"<p>               Bases: <code>ConfigError</code></p> <p>Exception raised for configuration parse errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ConfigParseError(ConfigError):\n    \"\"\"Exception raised for configuration parse errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ConfigValidationError","title":"<code>ConfigValidationError</code>","text":"<p>               Bases: <code>ConfigError</code></p> <p>Exception raised for configuration validation errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ConfigValidationError(ConfigError):\n    \"\"\"Exception raised for configuration validation errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.FactoryCreationError","title":"<code>FactoryCreationError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Exception raised when a factory encounters an error while creating a class.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class FactoryCreationError(AIPerfError):\n    \"\"\"Exception raised when a factory encounters an error while creating a class.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.GeneratorConfigurationError","title":"<code>GeneratorConfigurationError</code>","text":"<p>               Bases: <code>GeneratorError</code></p> <p>Exception raised for data generator configuration errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class GeneratorConfigurationError(GeneratorError):\n    \"\"\"Exception raised for data generator configuration errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.GeneratorError","title":"<code>GeneratorError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Base class for all exceptions raised by data generator modules.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class GeneratorError(AIPerfError):\n    \"\"\"Base class for all exceptions raised by data generator modules.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.GeneratorInitializationError","title":"<code>GeneratorInitializationError</code>","text":"<p>               Bases: <code>GeneratorError</code></p> <p>Exception raised for data generator initialization errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class GeneratorInitializationError(GeneratorError):\n    \"\"\"Exception raised for data generator initialization errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ServiceCleanupError","title":"<code>ServiceCleanupError</code>","text":"<p>               Bases: <code>ServiceError</code></p> <p>Exception raised for service cleanup errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ServiceCleanupError(ServiceError):\n    \"\"\"Exception raised for service cleanup errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ServiceConfigureError","title":"<code>ServiceConfigureError</code>","text":"<p>               Bases: <code>ServiceError</code></p> <p>Exception raised for service configure errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ServiceConfigureError(ServiceError):\n    \"\"\"Exception raised for service configure errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ServiceError","title":"<code>ServiceError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Base class for all exceptions raised by services.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ServiceError(AIPerfError):\n    \"\"\"Base class for all exceptions raised by services.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ServiceHeartbeatError","title":"<code>ServiceHeartbeatError</code>","text":"<p>               Bases: <code>ServiceError</code></p> <p>Exception raised for service heartbeat errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ServiceHeartbeatError(ServiceError):\n    \"\"\"Exception raised for service heartbeat errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ServiceInitializationError","title":"<code>ServiceInitializationError</code>","text":"<p>               Bases: <code>ServiceError</code></p> <p>Exception raised for service initialization errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ServiceInitializationError(ServiceError):\n    \"\"\"Exception raised for service initialization errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ServiceMessageProcessingError","title":"<code>ServiceMessageProcessingError</code>","text":"<p>               Bases: <code>ServiceError</code></p> <p>Exception raised for service message processing errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ServiceMessageProcessingError(ServiceError):\n    \"\"\"Exception raised for service message processing errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ServiceRegistrationError","title":"<code>ServiceRegistrationError</code>","text":"<p>               Bases: <code>ServiceError</code></p> <p>Exception raised for service registration errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ServiceRegistrationError(ServiceError):\n    \"\"\"Exception raised for service registration errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ServiceRunError","title":"<code>ServiceRunError</code>","text":"<p>               Bases: <code>ServiceError</code></p> <p>Exception raised for service run errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ServiceRunError(ServiceError):\n    \"\"\"Exception raised for service run errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ServiceStartError","title":"<code>ServiceStartError</code>","text":"<p>               Bases: <code>ServiceError</code></p> <p>Exception raised for service start errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ServiceStartError(ServiceError):\n    \"\"\"Exception raised for service start errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ServiceStatusError","title":"<code>ServiceStatusError</code>","text":"<p>               Bases: <code>ServiceError</code></p> <p>Exception raised for service status errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ServiceStatusError(ServiceError):\n    \"\"\"Exception raised for service status errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ServiceStopError","title":"<code>ServiceStopError</code>","text":"<p>               Bases: <code>ServiceError</code></p> <p>Exception raised for service stop errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ServiceStopError(ServiceError):\n    \"\"\"Exception raised for service stop errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.TokenizerError","title":"<code>TokenizerError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Base class for tokenizer exceptions.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class TokenizerError(AIPerfError):\n    \"\"\"Base class for tokenizer exceptions.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.TokenizerInitializationError","title":"<code>TokenizerInitializationError</code>","text":"<p>               Bases: <code>TokenizerError</code></p> <p>Exception raised for errors during tokenizer initialization.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class TokenizerInitializationError(TokenizerError):\n    \"\"\"Exception raised for errors during tokenizer initialization.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.UnsupportedHookError","title":"<code>UnsupportedHookError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Exception raised when a hook is defined on a class that does not support it.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class UnsupportedHookError(AIPerfError):\n    \"\"\"Exception raised when a hook is defined on a class that does not support it.\"\"\"\n</code></pre>"},{"location":"api/#aiperfcommonfactories","title":"aiperf.common.factories","text":""},{"location":"api/#aiperf.common.factories.CommunicationFactory","title":"<code>CommunicationFactory</code>","text":"<p>               Bases: <code>FactoryMixin['CommunicationBackend', 'BaseCommunication']</code></p> <p>Factory for registering and creating BaseCommunication instances based on the specified communication backend.</p> <p>Example: ```python     # Register a new communication backend     @CommunicationFactory.register(CommunicationBackend.ZMQ_TCP)     class ZMQCommunication(BaseCommunication):         pass</p> <pre><code># Create a new communication instance\ncommunication = CommunicationFactory.create_instance(\n    CommunicationBackend.ZMQ_TCP,\n    config=ZMQTCPCommunicationConfig(\n        host=\"localhost\", port=5555, timeout=10.0),\n)\n</code></pre> Source code in <code>aiperf/common/factories.py</code> <pre><code>class CommunicationFactory(FactoryMixin[\"CommunicationBackend\", \"BaseCommunication\"]):\n    \"\"\"Factory for registering and creating BaseCommunication instances based on the specified communication backend.\n\n    Example:\n    ```python\n        # Register a new communication backend\n        @CommunicationFactory.register(CommunicationBackend.ZMQ_TCP)\n        class ZMQCommunication(BaseCommunication):\n            pass\n\n        # Create a new communication instance\n        communication = CommunicationFactory.create_instance(\n            CommunicationBackend.ZMQ_TCP,\n            config=ZMQTCPCommunicationConfig(\n                host=\"localhost\", port=5555, timeout=10.0),\n        )\n    \"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.factories.FactoryMixin","title":"<code>FactoryMixin</code>","text":"<p>               Bases: <code>Generic[ClassEnumT, ClassProtocolT]</code></p> <p>Defines a mixin for all factories, which supports registering and creating instances of classes.</p> <p>This mixin is used to create a factory for a given class type and protocol.</p> <p>Example:</p> <pre><code>    # Define a new enum for the expected implementation types\n    # This is optional, but recommended for type safety.\n    class DatasetLoaderType(StrEnum):\n        FILE = \"file\"\n        S3 = \"s3\"\n\n    # Define a new class protocol.\n    class DatasetLoaderProtocol(Protocol):\n        def load(self) -&gt; Dataset:\n            pass\n\n    # Create a new factory for a given class type and protocol.\n    class DatasetFactory(FactoryMixin[DatasetLoaderType, DatasetLoaderProtocol]):\n        pass\n\n    # Register a new class type mapping to its corresponding class. It should implement the class protocol.\n    @DatasetFactory.register(DatasetLoaderType.FILE)\n    class FileDatasetLoader:\n        def __init__(self, filename: str):\n            self.filename = filename\n\n        def load(self) -&gt; Dataset:\n            return Dataset.from_file(self.filename)\n\n    DatasetConfig = {\n        \"type\": DatasetLoaderType.FILE,\n        \"filename\": \"data.csv\"\n    }\n\n    # Create a new instance of the class.\n    if DatasetConfig[\"type\"] == DatasetLoaderType.FILE:\n        dataset_instance = DatasetFactory.create_instance(DatasetLoaderType.FILE, filename=DatasetConfig[\"filename\"])\n    else:\n        raise ValueError(f\"Unsupported dataset loader type: {DatasetConfig['type']}\")\n\n    dataset_instance.load()\n</code></pre> Source code in <code>aiperf/common/factories.py</code> <pre><code>class FactoryMixin(Generic[ClassEnumT, ClassProtocolT]):\n    \"\"\"Defines a mixin for all factories, which supports registering and creating instances of classes.\n\n    This mixin is used to create a factory for a given class type and protocol.\n\n    Example:\n    ```python\n        # Define a new enum for the expected implementation types\n        # This is optional, but recommended for type safety.\n        class DatasetLoaderType(StrEnum):\n            FILE = \"file\"\n            S3 = \"s3\"\n\n        # Define a new class protocol.\n        class DatasetLoaderProtocol(Protocol):\n            def load(self) -&gt; Dataset:\n                pass\n\n        # Create a new factory for a given class type and protocol.\n        class DatasetFactory(FactoryMixin[DatasetLoaderType, DatasetLoaderProtocol]):\n            pass\n\n        # Register a new class type mapping to its corresponding class. It should implement the class protocol.\n        @DatasetFactory.register(DatasetLoaderType.FILE)\n        class FileDatasetLoader:\n            def __init__(self, filename: str):\n                self.filename = filename\n\n            def load(self) -&gt; Dataset:\n                return Dataset.from_file(self.filename)\n\n        DatasetConfig = {\n            \"type\": DatasetLoaderType.FILE,\n            \"filename\": \"data.csv\"\n        }\n\n        # Create a new instance of the class.\n        if DatasetConfig[\"type\"] == DatasetLoaderType.FILE:\n            dataset_instance = DatasetFactory.create_instance(DatasetLoaderType.FILE, filename=DatasetConfig[\"filename\"])\n        else:\n            raise ValueError(f\"Unsupported dataset loader type: {DatasetConfig['type']}\")\n\n        dataset_instance.load()\n    ```\n    \"\"\"\n\n    logger = logging.getLogger(__name__)\n\n    _registry: dict[ClassEnumT | str, type[ClassProtocolT]]\n    _override_priorities: dict[ClassEnumT | str, int]\n\n    def __init_subclass__(cls) -&gt; None:\n        cls._registry = {}\n        cls._override_priorities = {}\n        super().__init_subclass__()\n\n    @classmethod\n    def register(\n        cls, class_type: ClassEnumT | str, override_priority: int = 0\n    ) -&gt; Callable:\n        \"\"\"Register a new class type mapping to its corresponding class.\n\n        Args:\n            class_type: The type of class to register\n            override_priority: The priority of the override. The higher the priority,\n                the more precedence the override has when multiple classes are registered\n                for the same class type. Built-in classes have a priority of 0.\n\n        Returns:\n            Decorator for the class that implements the class protocol\n        \"\"\"\n\n        def decorator(class_cls: type[ClassProtocolT]) -&gt; type[ClassProtocolT]:\n            existing_priority = cls._override_priorities.get(class_type, -1)\n            if class_type in cls._registry and existing_priority &gt;= override_priority:\n                # TODO: Will logging be initialized before this method is called?\n                cls.logger.warning(\n                    \"%r class %s already registered with same or higher priority \"\n                    \"(%s). The new registration of class %s with priority \"\n                    \"%s will be ignored.\",\n                    class_type,\n                    cls._registry[class_type].__name__,\n                    existing_priority,\n                    class_cls.__name__,\n                    override_priority,\n                )\n                return class_cls\n\n            if class_type not in cls._registry:\n                cls.logger.debug(\n                    \"%r class %s registered with priority %s.\",\n                    class_type,\n                    class_cls.__name__,\n                    override_priority,\n                )\n            else:\n                cls.logger.debug(\n                    \"%r class %s with priority %s overrides \"\n                    \"already registered class %s with lower priority (%s).\",\n                    class_type,\n                    class_cls.__name__,\n                    override_priority,\n                    cls._registry[class_type].__name__,\n                    existing_priority,\n                )\n            cls._registry[class_type] = class_cls\n            cls._override_priorities[class_type] = override_priority\n            return class_cls\n\n        return decorator\n\n    @classmethod\n    def create_instance(\n        cls,\n        class_type: ClassEnumT | str,\n        *args: Any,\n        **kwargs: Any,\n    ) -&gt; ClassProtocolT:\n        \"\"\"Create a new class instance.\n\n        Args:\n            class_type: The type of class to create\n            *args: Positional arguments for the class\n            **kwargs: Keyword arguments for the class\n\n        Returns:\n            The created class instance\n\n        Raises:\n            FactoryCreationError: If the class type is not registered or there is an error creating the instance\n        \"\"\"\n        if class_type not in cls._registry:\n            raise FactoryCreationError(f\"No implementation found for {class_type!r}.\")\n        try:\n            return cls._registry[class_type](*args, **kwargs)\n        except Exception as e:\n            raise FactoryCreationError(\n                f\"Error creating {class_type!r} instance: {e}\"\n            ) from e\n\n    @classmethod\n    def get_class_from_type(cls, class_type: ClassEnumT | str) -&gt; type[ClassProtocolT]:\n        \"\"\"Get the class from a class type.\n\n        Args:\n            class_type: The class type to get the class from\n\n        Returns:\n            The class for the given class type\n\n        Raises:\n            TypeError: If the class type is not registered\n        \"\"\"\n        if class_type not in cls._registry:\n            raise TypeError(\n                f\"No class found for {class_type!r}. Please register the class first.\"\n            )\n        return cls._registry[class_type]\n</code></pre>"},{"location":"api/#aiperf.common.factories.FactoryMixin.create_instance","title":"<code>create_instance(class_type, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a new class instance.</p> <p>Parameters:</p> Name Type Description Default <code>class_type</code> <code>ClassEnumT | str</code> <p>The type of class to create</p> required <code>*args</code> <code>Any</code> <p>Positional arguments for the class</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments for the class</p> <code>{}</code> <p>Returns:</p> Type Description <code>ClassProtocolT</code> <p>The created class instance</p> <p>Raises:</p> Type Description <code>FactoryCreationError</code> <p>If the class type is not registered or there is an error creating the instance</p> Source code in <code>aiperf/common/factories.py</code> <pre><code>@classmethod\ndef create_instance(\n    cls,\n    class_type: ClassEnumT | str,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; ClassProtocolT:\n    \"\"\"Create a new class instance.\n\n    Args:\n        class_type: The type of class to create\n        *args: Positional arguments for the class\n        **kwargs: Keyword arguments for the class\n\n    Returns:\n        The created class instance\n\n    Raises:\n        FactoryCreationError: If the class type is not registered or there is an error creating the instance\n    \"\"\"\n    if class_type not in cls._registry:\n        raise FactoryCreationError(f\"No implementation found for {class_type!r}.\")\n    try:\n        return cls._registry[class_type](*args, **kwargs)\n    except Exception as e:\n        raise FactoryCreationError(\n            f\"Error creating {class_type!r} instance: {e}\"\n        ) from e\n</code></pre>"},{"location":"api/#aiperf.common.factories.FactoryMixin.get_class_from_type","title":"<code>get_class_from_type(class_type)</code>  <code>classmethod</code>","text":"<p>Get the class from a class type.</p> <p>Parameters:</p> Name Type Description Default <code>class_type</code> <code>ClassEnumT | str</code> <p>The class type to get the class from</p> required <p>Returns:</p> Type Description <code>type[ClassProtocolT]</code> <p>The class for the given class type</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the class type is not registered</p> Source code in <code>aiperf/common/factories.py</code> <pre><code>@classmethod\ndef get_class_from_type(cls, class_type: ClassEnumT | str) -&gt; type[ClassProtocolT]:\n    \"\"\"Get the class from a class type.\n\n    Args:\n        class_type: The class type to get the class from\n\n    Returns:\n        The class for the given class type\n\n    Raises:\n        TypeError: If the class type is not registered\n    \"\"\"\n    if class_type not in cls._registry:\n        raise TypeError(\n            f\"No class found for {class_type!r}. Please register the class first.\"\n        )\n    return cls._registry[class_type]\n</code></pre>"},{"location":"api/#aiperf.common.factories.FactoryMixin.register","title":"<code>register(class_type, override_priority=0)</code>  <code>classmethod</code>","text":"<p>Register a new class type mapping to its corresponding class.</p> <p>Parameters:</p> Name Type Description Default <code>class_type</code> <code>ClassEnumT | str</code> <p>The type of class to register</p> required <code>override_priority</code> <code>int</code> <p>The priority of the override. The higher the priority, the more precedence the override has when multiple classes are registered for the same class type. Built-in classes have a priority of 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>Callable</code> <p>Decorator for the class that implements the class protocol</p> Source code in <code>aiperf/common/factories.py</code> <pre><code>@classmethod\ndef register(\n    cls, class_type: ClassEnumT | str, override_priority: int = 0\n) -&gt; Callable:\n    \"\"\"Register a new class type mapping to its corresponding class.\n\n    Args:\n        class_type: The type of class to register\n        override_priority: The priority of the override. The higher the priority,\n            the more precedence the override has when multiple classes are registered\n            for the same class type. Built-in classes have a priority of 0.\n\n    Returns:\n        Decorator for the class that implements the class protocol\n    \"\"\"\n\n    def decorator(class_cls: type[ClassProtocolT]) -&gt; type[ClassProtocolT]:\n        existing_priority = cls._override_priorities.get(class_type, -1)\n        if class_type in cls._registry and existing_priority &gt;= override_priority:\n            # TODO: Will logging be initialized before this method is called?\n            cls.logger.warning(\n                \"%r class %s already registered with same or higher priority \"\n                \"(%s). The new registration of class %s with priority \"\n                \"%s will be ignored.\",\n                class_type,\n                cls._registry[class_type].__name__,\n                existing_priority,\n                class_cls.__name__,\n                override_priority,\n            )\n            return class_cls\n\n        if class_type not in cls._registry:\n            cls.logger.debug(\n                \"%r class %s registered with priority %s.\",\n                class_type,\n                class_cls.__name__,\n                override_priority,\n            )\n        else:\n            cls.logger.debug(\n                \"%r class %s with priority %s overrides \"\n                \"already registered class %s with lower priority (%s).\",\n                class_type,\n                class_cls.__name__,\n                override_priority,\n                cls._registry[class_type].__name__,\n                existing_priority,\n            )\n        cls._registry[class_type] = class_cls\n        cls._override_priorities[class_type] = override_priority\n        return class_cls\n\n    return decorator\n</code></pre>"},{"location":"api/#aiperf.common.factories.ServiceFactory","title":"<code>ServiceFactory</code>","text":"<p>               Bases: <code>FactoryMixin['ServiceType', 'BaseService']</code></p> <p>Factory for registering and creating BaseService instances based on the specified service type.</p> <p>Example:</p> <pre><code>    # Register a new service type\n    @ServiceFactory.register(ServiceType.DATASET_MANAGER)\n    class DatasetManager(BaseService):\n        pass\n\n    # Create a new service instance in a separate process\n    service_class = ServiceFactory.get_class_from_type(service_type)\n\n    process = Process(\n        target=bootstrap_and_run_service,\n        name=f\"{service_type}_process\",\n        args=(service_class, self.config),\n        daemon=False,\n    )\n</code></pre> Source code in <code>aiperf/common/factories.py</code> <pre><code>class ServiceFactory(FactoryMixin[\"ServiceType\", \"BaseService\"]):\n    \"\"\"Factory for registering and creating BaseService instances based on the specified service type.\n\n    Example:\n    ```python\n        # Register a new service type\n        @ServiceFactory.register(ServiceType.DATASET_MANAGER)\n        class DatasetManager(BaseService):\n            pass\n\n        # Create a new service instance in a separate process\n        service_class = ServiceFactory.get_class_from_type(service_type)\n\n        process = Process(\n            target=bootstrap_and_run_service,\n            name=f\"{service_type}_process\",\n            args=(service_class, self.config),\n            daemon=False,\n        )\n    ```\n    \"\"\"\n</code></pre>"},{"location":"api/#aiperfcommonhooks","title":"aiperf.common.hooks","text":"<p>This module provides an extensive hook system for AIPerf. It is designed to be used as a mixin for classes that support hooks. It provides a simple interface for registering and running hooks.</p> <p>Classes should inherit from the :class:<code>HooksMixin</code>, and specify the supported hook types by decorating the class with the :func:<code>supports_hooks</code> decorator.</p> <p>The hook functions are registered by decorating functions with the various hook decorators such as :func:<code>on_init</code>, :func:<code>on_start</code>, :func:<code>on_stop</code>, etc.</p> <p>The hooks are run by calling the :meth:<code>HooksMixin.run_hooks</code> or :meth:<code>HooksMixin.run_hooks_async</code> methods on the class.</p> <p>More than one hook can be registered for a given hook type, and classes that inherit from classes with existing hooks will inherit the hooks from the base classes as well.</p>"},{"location":"api/#aiperf.common.hooks.AIPERF_HOOK_TYPE","title":"<code>AIPERF_HOOK_TYPE = '__aiperf_hook_type__'</code>  <code>module-attribute</code>","text":"<p>Constant attribute name that marks a function's hook type.</p>"},{"location":"api/#aiperf.common.hooks.HookType","title":"<code>HookType = AIPerfHook | str</code>  <code>module-attribute</code>","text":"<p>Type alias for valid hook types. This is a union of the AIPerfHook enum and any user-defined custom strings.</p>"},{"location":"api/#aiperf.common.hooks.AIPerfHook","title":"<code>AIPerfHook</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum for the various AIPerf hooks.</p> <p>Note: If you add a new hook, you must also add it to the @supports_hooks decorator of the class you wish to use the hook in.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>class AIPerfHook(Enum):\n    \"\"\"Enum for the various AIPerf hooks.\n\n    Note: If you add a new hook, you must also add it to the @supports_hooks\n    decorator of the class you wish to use the hook in.\n    \"\"\"\n\n    ON_INIT = \"__aiperf_on_init__\"\n    ON_RUN = \"__aiperf_on_run__\"\n    ON_CONFIGURE = \"__aiperf_on_configure__\"\n    ON_START = \"__aiperf_on_start__\"\n    ON_STOP = \"__aiperf_on_stop__\"\n    ON_CLEANUP = \"__aiperf_on_cleanup__\"\n\n    ON_SET_STATE = \"__aiperf_on_set_state__\"\n\n    AIPERF_TASK = \"__aiperf_task__\"\n</code></pre>"},{"location":"api/#aiperf.common.hooks.AIPerfTaskMixin","title":"<code>AIPerfTaskMixin</code>","text":"<p>               Bases: <code>HooksMixin</code></p> <p>Mixin to add task support to a class. It abstracts away the details of the :class:<code>AIPerfTask</code> and provides a simple interface for registering and running tasks. It hooks into the :meth:<code>HooksMixin.on_init</code> and :meth:<code>HooksMixin.on_stop</code> hooks to start and stop the tasks.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>@supports_hooks(AIPerfHook.AIPERF_TASK, AIPerfHook.ON_INIT, AIPerfHook.ON_STOP)\nclass AIPerfTaskMixin(HooksMixin):\n    \"\"\"Mixin to add task support to a class. It abstracts away the details of the\n    :class:`AIPerfTask` and provides a simple interface for registering and running tasks.\n    It hooks into the :meth:`HooksMixin.on_init` and :meth:`HooksMixin.on_stop` hooks to\n    start and stop the tasks.\n    \"\"\"\n\n    # TODO: Once we create a Mixin for `self.stop_event`, we can avoid\n    # having the user to call `while not self.stop_event.is_set()`\n\n    def __init__(self):\n        super().__init__()\n        self.registered_tasks: dict[str, asyncio.Task] = {}\n\n    @on_init\n    async def _start_tasks(self):\n        \"\"\"Start all the registered tasks in the background.\"\"\"\n        for hook in self.get_hooks(AIPerfHook.AIPERF_TASK):\n            if inspect.iscoroutinefunction(hook):\n                task = asyncio.create_task(hook())\n            else:\n                task = asyncio.create_task(asyncio.to_thread(hook))\n            self.registered_tasks[hook.__name__] = task\n\n    @on_stop\n    async def _stop_tasks(self):\n        \"\"\"Stop all the background tasks. This will wait for all the tasks to complete.\"\"\"\n        for task in self.registered_tasks.values():\n            task.cancel()\n\n        # Wait for all tasks to complete\n        with contextlib.suppress(asyncio.CancelledError):\n            await asyncio.gather(*self.registered_tasks.values())\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HookSystem","title":"<code>HookSystem</code>","text":"<p>System for managing hooks.</p> <p>This class is responsible for managing the hooks for a class. It will store the hooks in a dictionary, and provide methods to register and run the hooks.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>class HookSystem:\n    \"\"\"\n    System for managing hooks.\n\n    This class is responsible for managing the hooks for a class. It will\n    store the hooks in a dictionary, and provide methods to register and run\n    the hooks.\n    \"\"\"\n\n    def __init__(self, supported_hooks: set[HookType]):\n        \"\"\"\n        Initialize the hook system.\n\n        Args:\n            supported_hooks: The hook types that the class supports.\n        \"\"\"\n\n        self.supported_hooks: set[HookType] = supported_hooks\n        self._hooks: dict[HookType, list[Callable]] = {}\n\n    def register_hook(self, hook_type: HookType, func: Callable):\n        \"\"\"Register a hook function for a given hook type.\n\n        Args:\n            hook_type: The hook type to register the function for.\n            func: The function to register.\n        \"\"\"\n        if hook_type not in self.supported_hooks:\n            raise UnsupportedHookError(f\"Hook {hook_type} is not supported by class.\")\n\n        self._hooks.setdefault(hook_type, []).append(func)\n\n    def get_hooks(self, hook_type: HookType) -&gt; list[Callable]:\n        \"\"\"Get all the registered hooks for the given hook type.\n\n        Args:\n            hook_type: The hook type to get the hooks for.\n\n        Returns:\n            A list of the hooks for the given hook type.\n        \"\"\"\n        return self._hooks.get(hook_type, [])\n\n    async def run_hooks(self, hook_type: HookType, *args, **kwargs):\n        \"\"\"\n        Run all the hooks for a given hook type serially. This will wait for each\n        hook to complete before running the next one.\n\n        Args:\n            hook_type: The hook type to run.\n            *args: The arguments to pass to the hooks.\n            **kwargs: The keyword arguments to pass to the hooks.\n        \"\"\"\n        if hook_type not in self.supported_hooks:\n            raise UnsupportedHookError(f\"Hook {hook_type} is not supported by class.\")\n\n        exceptions: list[Exception] = []\n        for func in self.get_hooks(hook_type):\n            try:\n                if inspect.iscoroutinefunction(func):\n                    await func(*args, **kwargs)\n                else:\n                    await asyncio.to_thread(func, *args, **kwargs)\n            except Exception as e:\n                logger.error(f\"Error running hook {func.__name__}: {e}\")\n                exceptions.append(e)\n\n        if exceptions:\n            raise AIPerfMultiError(\"Errors running hooks\", exceptions)\n\n    async def run_hooks_async(self, hook_type: HookType, *args, **kwargs):\n        \"\"\"\n        Run all the hooks for a given hook type concurrently. This will run all\n        the hooks at the same time and return when all the hooks have completed.\n\n        Args:\n            hook_type: The hook type to run.\n            *args: The arguments to pass to the hooks.\n            **kwargs: The keyword arguments to pass to the hooks.\n        \"\"\"\n        if hook_type not in self.supported_hooks:\n            raise UnsupportedHookError(f\"Hook {hook_type} is not supported by class.\")\n\n        coroutines: list[Awaitable] = []\n        for func in self.get_hooks(hook_type):\n            if inspect.iscoroutinefunction(func):\n                coroutines.append(func(*args, **kwargs))\n            else:\n                coroutines.append(asyncio.to_thread(func, *args, **kwargs))\n\n        if coroutines:\n            results = await asyncio.gather(*coroutines, return_exceptions=True)\n\n            exceptions = [result for result in results if isinstance(result, Exception)]\n            if exceptions:\n                raise AIPerfMultiError(\"Errors running hooks\", exceptions)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HookSystem.__init__","title":"<code>__init__(supported_hooks)</code>","text":"<p>Initialize the hook system.</p> <p>Parameters:</p> Name Type Description Default <code>supported_hooks</code> <code>set[HookType]</code> <p>The hook types that the class supports.</p> required Source code in <code>aiperf/common/hooks.py</code> <pre><code>def __init__(self, supported_hooks: set[HookType]):\n    \"\"\"\n    Initialize the hook system.\n\n    Args:\n        supported_hooks: The hook types that the class supports.\n    \"\"\"\n\n    self.supported_hooks: set[HookType] = supported_hooks\n    self._hooks: dict[HookType, list[Callable]] = {}\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HookSystem.get_hooks","title":"<code>get_hooks(hook_type)</code>","text":"<p>Get all the registered hooks for the given hook type.</p> <p>Parameters:</p> Name Type Description Default <code>hook_type</code> <code>HookType</code> <p>The hook type to get the hooks for.</p> required <p>Returns:</p> Type Description <code>list[Callable]</code> <p>A list of the hooks for the given hook type.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def get_hooks(self, hook_type: HookType) -&gt; list[Callable]:\n    \"\"\"Get all the registered hooks for the given hook type.\n\n    Args:\n        hook_type: The hook type to get the hooks for.\n\n    Returns:\n        A list of the hooks for the given hook type.\n    \"\"\"\n    return self._hooks.get(hook_type, [])\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HookSystem.register_hook","title":"<code>register_hook(hook_type, func)</code>","text":"<p>Register a hook function for a given hook type.</p> <p>Parameters:</p> Name Type Description Default <code>hook_type</code> <code>HookType</code> <p>The hook type to register the function for.</p> required <code>func</code> <code>Callable</code> <p>The function to register.</p> required Source code in <code>aiperf/common/hooks.py</code> <pre><code>def register_hook(self, hook_type: HookType, func: Callable):\n    \"\"\"Register a hook function for a given hook type.\n\n    Args:\n        hook_type: The hook type to register the function for.\n        func: The function to register.\n    \"\"\"\n    if hook_type not in self.supported_hooks:\n        raise UnsupportedHookError(f\"Hook {hook_type} is not supported by class.\")\n\n    self._hooks.setdefault(hook_type, []).append(func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HookSystem.run_hooks","title":"<code>run_hooks(hook_type, *args, **kwargs)</code>  <code>async</code>","text":"<p>Run all the hooks for a given hook type serially. This will wait for each hook to complete before running the next one.</p> <p>Parameters:</p> Name Type Description Default <code>hook_type</code> <code>HookType</code> <p>The hook type to run.</p> required <code>*args</code> <p>The arguments to pass to the hooks.</p> <code>()</code> <code>**kwargs</code> <p>The keyword arguments to pass to the hooks.</p> <code>{}</code> Source code in <code>aiperf/common/hooks.py</code> <pre><code>async def run_hooks(self, hook_type: HookType, *args, **kwargs):\n    \"\"\"\n    Run all the hooks for a given hook type serially. This will wait for each\n    hook to complete before running the next one.\n\n    Args:\n        hook_type: The hook type to run.\n        *args: The arguments to pass to the hooks.\n        **kwargs: The keyword arguments to pass to the hooks.\n    \"\"\"\n    if hook_type not in self.supported_hooks:\n        raise UnsupportedHookError(f\"Hook {hook_type} is not supported by class.\")\n\n    exceptions: list[Exception] = []\n    for func in self.get_hooks(hook_type):\n        try:\n            if inspect.iscoroutinefunction(func):\n                await func(*args, **kwargs)\n            else:\n                await asyncio.to_thread(func, *args, **kwargs)\n        except Exception as e:\n            logger.error(f\"Error running hook {func.__name__}: {e}\")\n            exceptions.append(e)\n\n    if exceptions:\n        raise AIPerfMultiError(\"Errors running hooks\", exceptions)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HookSystem.run_hooks_async","title":"<code>run_hooks_async(hook_type, *args, **kwargs)</code>  <code>async</code>","text":"<p>Run all the hooks for a given hook type concurrently. This will run all the hooks at the same time and return when all the hooks have completed.</p> <p>Parameters:</p> Name Type Description Default <code>hook_type</code> <code>HookType</code> <p>The hook type to run.</p> required <code>*args</code> <p>The arguments to pass to the hooks.</p> <code>()</code> <code>**kwargs</code> <p>The keyword arguments to pass to the hooks.</p> <code>{}</code> Source code in <code>aiperf/common/hooks.py</code> <pre><code>async def run_hooks_async(self, hook_type: HookType, *args, **kwargs):\n    \"\"\"\n    Run all the hooks for a given hook type concurrently. This will run all\n    the hooks at the same time and return when all the hooks have completed.\n\n    Args:\n        hook_type: The hook type to run.\n        *args: The arguments to pass to the hooks.\n        **kwargs: The keyword arguments to pass to the hooks.\n    \"\"\"\n    if hook_type not in self.supported_hooks:\n        raise UnsupportedHookError(f\"Hook {hook_type} is not supported by class.\")\n\n    coroutines: list[Awaitable] = []\n    for func in self.get_hooks(hook_type):\n        if inspect.iscoroutinefunction(func):\n            coroutines.append(func(*args, **kwargs))\n        else:\n            coroutines.append(asyncio.to_thread(func, *args, **kwargs))\n\n    if coroutines:\n        results = await asyncio.gather(*coroutines, return_exceptions=True)\n\n        exceptions = [result for result in results if isinstance(result, Exception)]\n        if exceptions:\n            raise AIPerfMultiError(\"Errors running hooks\", exceptions)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HooksMixin","title":"<code>HooksMixin</code>","text":"<p>Mixin to add hook support to a class. It abstracts away the details of the :class:<code>HookSystem</code> and provides a simple interface for registering and running hooks.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>class HooksMixin:\n    \"\"\"\n    Mixin to add hook support to a class. It abstracts away the details of the\n    :class:`HookSystem` and provides a simple interface for registering and running hooks.\n    \"\"\"\n\n    # Class attributes that are set by the :func:`supports_hooks` decorator\n    supported_hooks: set[HookType] = set()\n\n    def __init__(self):\n        \"\"\"\n        Initialize the hook system and register all functions that are decorated with a hook decorator.\n        \"\"\"\n        # Initialize the hook system\n        self._hook_system = HookSystem(self.supported_hooks)\n\n        # Register all functions that are decorated with a hook decorator\n        # Iterate through MRO in reverse order to ensure base class hooks are registered first\n        for cls in reversed(self.__class__.__mro__):\n            # Skip object and other non-hook classes\n            if not issubclass(cls, HooksMixin):\n                continue\n\n            # Get methods defined directly in this class (not inherited)\n            for _, attr in cls.__dict__.items():\n                if callable(attr) and hasattr(attr, AIPERF_HOOK_TYPE):\n                    # Get the hook type from the function\n                    hook_type = getattr(attr, AIPERF_HOOK_TYPE)\n                    # Bind the method to the instance\n                    bound_method = attr.__get__(self, cls)\n                    # Register the function with the hook type\n                    self.register_hook(hook_type, bound_method)\n\n    def register_hook(self, hook_type: HookType, func: Callable):\n        \"\"\"Register a hook function for a given hook type.\n\n        Args:\n            hook_type: The hook type to register the function for.\n            func: The function to register.\n        \"\"\"\n        self._hook_system.register_hook(hook_type, func)\n\n    async def run_hooks(self, hook_type: HookType, *args, **kwargs):\n        \"\"\"Run all the hooks serially. See :meth:`HookSystem.run_hooks`.\"\"\"\n        await self._hook_system.run_hooks(hook_type, *args, **kwargs)\n\n    async def run_hooks_async(self, hook_type: HookType, *args, **kwargs):\n        \"\"\"Run all the hooks concurrently. See :meth:`HookSystem.run_hooks_async`.\"\"\"\n        await self._hook_system.run_hooks_async(hook_type, *args, **kwargs)\n\n    def get_hooks(self, hook_type: HookType) -&gt; list[Callable]:\n        \"\"\"Get all the registered hooks for the given hook type. See :meth:`HookSystem.get_hooks`.\"\"\"\n        return self._hook_system.get_hooks(hook_type)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HooksMixin.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the hook system and register all functions that are decorated with a hook decorator.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initialize the hook system and register all functions that are decorated with a hook decorator.\n    \"\"\"\n    # Initialize the hook system\n    self._hook_system = HookSystem(self.supported_hooks)\n\n    # Register all functions that are decorated with a hook decorator\n    # Iterate through MRO in reverse order to ensure base class hooks are registered first\n    for cls in reversed(self.__class__.__mro__):\n        # Skip object and other non-hook classes\n        if not issubclass(cls, HooksMixin):\n            continue\n\n        # Get methods defined directly in this class (not inherited)\n        for _, attr in cls.__dict__.items():\n            if callable(attr) and hasattr(attr, AIPERF_HOOK_TYPE):\n                # Get the hook type from the function\n                hook_type = getattr(attr, AIPERF_HOOK_TYPE)\n                # Bind the method to the instance\n                bound_method = attr.__get__(self, cls)\n                # Register the function with the hook type\n                self.register_hook(hook_type, bound_method)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HooksMixin.get_hooks","title":"<code>get_hooks(hook_type)</code>","text":"<p>Get all the registered hooks for the given hook type. See :meth:<code>HookSystem.get_hooks</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def get_hooks(self, hook_type: HookType) -&gt; list[Callable]:\n    \"\"\"Get all the registered hooks for the given hook type. See :meth:`HookSystem.get_hooks`.\"\"\"\n    return self._hook_system.get_hooks(hook_type)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HooksMixin.register_hook","title":"<code>register_hook(hook_type, func)</code>","text":"<p>Register a hook function for a given hook type.</p> <p>Parameters:</p> Name Type Description Default <code>hook_type</code> <code>HookType</code> <p>The hook type to register the function for.</p> required <code>func</code> <code>Callable</code> <p>The function to register.</p> required Source code in <code>aiperf/common/hooks.py</code> <pre><code>def register_hook(self, hook_type: HookType, func: Callable):\n    \"\"\"Register a hook function for a given hook type.\n\n    Args:\n        hook_type: The hook type to register the function for.\n        func: The function to register.\n    \"\"\"\n    self._hook_system.register_hook(hook_type, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HooksMixin.run_hooks","title":"<code>run_hooks(hook_type, *args, **kwargs)</code>  <code>async</code>","text":"<p>Run all the hooks serially. See :meth:<code>HookSystem.run_hooks</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>async def run_hooks(self, hook_type: HookType, *args, **kwargs):\n    \"\"\"Run all the hooks serially. See :meth:`HookSystem.run_hooks`.\"\"\"\n    await self._hook_system.run_hooks(hook_type, *args, **kwargs)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HooksMixin.run_hooks_async","title":"<code>run_hooks_async(hook_type, *args, **kwargs)</code>  <code>async</code>","text":"<p>Run all the hooks concurrently. See :meth:<code>HookSystem.run_hooks_async</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>async def run_hooks_async(self, hook_type: HookType, *args, **kwargs):\n    \"\"\"Run all the hooks concurrently. See :meth:`HookSystem.run_hooks_async`.\"\"\"\n    await self._hook_system.run_hooks_async(hook_type, *args, **kwargs)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.aiperf_task","title":"<code>aiperf_task(func)</code>","text":"<p>Decorator to indicate that the function is a task function. It will be started and stopped automatically by the base class lifecycle. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def aiperf_task(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to indicate that the function is a task function. It will be started\n    and stopped automatically by the base class lifecycle.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.AIPERF_TASK, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.hook_decorator","title":"<code>hook_decorator(hook_type, func)</code>","text":"<p>Generic decorator to specify that the function should be called during a specific hook.</p> <p>Parameters:</p> Name Type Description Default <code>hook_type</code> <code>HookType</code> <p>The hook type to decorate the function with.</p> required <code>func</code> <code>Callable</code> <p>The function to decorate.</p> required <p>Returns:     The decorated function.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def hook_decorator(hook_type: HookType, func: Callable) -&gt; Callable:\n    \"\"\"Generic decorator to specify that the function should be called during\n    a specific hook.\n\n    Args:\n        hook_type: The hook type to decorate the function with.\n        func: The function to decorate.\n    Returns:\n        The decorated function.\n    \"\"\"\n    setattr(func, AIPERF_HOOK_TYPE, hook_type)\n    return func\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_cleanup","title":"<code>on_cleanup(func)</code>","text":"<p>Decorator to specify that the function should be called during cleanup. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_cleanup(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called during cleanup.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_CLEANUP, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_configure","title":"<code>on_configure(func)</code>","text":"<p>Decorator to specify that the function should be called during the service configuration. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_configure(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called during the service configuration.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_CONFIGURE, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_init","title":"<code>on_init(func)</code>","text":"<p>Decorator to specify that the function should be called during initialization. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_init(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called during initialization.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_INIT, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_run","title":"<code>on_run(func)</code>","text":"<p>Decorator to specify that the function should be called during run. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_run(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called during run.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_RUN, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_set_state","title":"<code>on_set_state(func)</code>","text":"<p>Decorator to specify that the function should be called when the service state is set. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_set_state(\n    func: Callable[[Any, ServiceState], None],\n) -&gt; Callable[[Any, ServiceState], None]:\n    \"\"\"Decorator to specify that the function should be called when the service state is set.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_SET_STATE, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_start","title":"<code>on_start(func)</code>","text":"<p>Decorator to specify that the function should be called during start. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_start(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called during start.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_START, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_stop","title":"<code>on_stop(func)</code>","text":"<p>Decorator to specify that the function should be called during stop. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_stop(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called during stop.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_STOP, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.supports_hooks","title":"<code>supports_hooks(*supported_hook_types)</code>","text":"<p>Decorator to indicate that a class supports hooks and sets the supported hook types.</p> <p>Parameters:</p> Name Type Description Default <code>supported_hook_types</code> <code>HookType</code> <p>The hook types that the class supports.</p> <code>()</code> <p>Returns:</p> Type Description <code>Callable[[type], type]</code> <p>The decorated class</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def supports_hooks(\n    *supported_hook_types: HookType,\n) -&gt; Callable[[type], type]:\n    \"\"\"Decorator to indicate that a class supports hooks and sets the\n    supported hook types.\n\n    Args:\n        supported_hook_types: The hook types that the class supports.\n\n    Returns:\n        The decorated class\n    \"\"\"\n\n    def decorator(cls: type) -&gt; type:\n        # Ensure the class inherits from HooksMixin\n        if not issubclass(cls, HooksMixin):\n            raise TypeError(f\"Class {cls.__name__} does not inherit from HooksMixin.\")\n\n        # Inherit any hooks defined by base classes in the MRO (Method Resolution Order).\n        base_hooks = [\n            base.supported_hooks\n            for base in cls.__mro__[1:]  # Skip this class itself (cls)\n            if issubclass(\n                base, HooksMixin\n            )  # Only include classes that inherit from HooksMixin\n        ]\n\n        # Set the supported hooks to be the union of the existing base hooks and the new supported hook types.\n        cls.supported_hooks = set.union(*base_hooks, set(supported_hook_types))\n        return cls\n\n    return decorator\n</code></pre>"},{"location":"api/#aiperfcommonmodels","title":"aiperf.common.models","text":""},{"location":"api/#aiperf.common.models.Message","title":"<code>Message = Union[BaseMessage, DataMessage, HeartbeatMessage, RegistrationMessage, StatusMessage, CommandMessage, CreditDropMessage, CreditReturnMessage, ErrorMessage]</code>  <code>module-attribute</code>","text":"<p>Union of all message types. This is used as a type hint when a function accepts a message as an argument.</p> <p>Example:</p> <pre><code>&gt;&gt;&gt; def process_message(message: Message) -&gt; None:\n...     if isinstance(message, DataMessage):\n...         print(message.payload.data)\n...     elif isinstance(message, HeartbeatMessage):\n...         print(message.payload.state)\n</code></pre>"},{"location":"api/#aiperf.common.models.Payload","title":"<code>Payload = Union[DataPayload, HeartbeatPayload, RegistrationPayload, StatusPayload, CommandPayload, CreditDropPayload, CreditReturnPayload, ErrorPayload]</code>  <code>module-attribute</code>","text":"<p>This is a union of all the payload types that can be sent and received.</p> <p>This is used with Pydantic's <code>discriminator</code> to allow for polymorphic payloads, and automatic type coercion when receiving messages.</p>"},{"location":"api/#aiperf.common.models.BaseMessage","title":"<code>BaseMessage</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base message model with common fields for all messages. The payload can be any of the payload types defined by the payloads.py module.</p> <p>The message type is determined by the discriminator field <code>message_type</code>. This is used by the Pydantic <code>discriminator</code> argument to determine the type of the payload automatically when the message is deserialized from a JSON string.</p> <p>To serialize a message to a JSON string, use the <code>model_dump_json</code> method. To deserialize a message from a JSON string, use the <code>model_validate_json</code> method.</p> <p>Example:</p> <pre><code>&gt;&gt;&gt; message = BaseMessage(\n...     service_id=\"service_1\",\n...     request_id=\"request_1\",\n...     payload=DataPayload(data=\"Hello, world!\"),\n... )\n&gt;&gt;&gt; json_string = message.model_dump_json()\n&gt;&gt;&gt; print(json_string)\n{\"payload\": {\"data\": \"Hello, world!\"}, \"service_id\": \"service_1\", \"request_id\": \"request_1\"}\n&gt;&gt;&gt; deserialized_message = BaseMessage.model_validate_json(json_string)\n&gt;&gt;&gt; print(deserialized_message)\nBaseMessage(\n    payload=DataPayload(data=\"Hello, world!\"),\n    service_id=\"service_1\",\n    request_id=\"request_1\",\n    timestamp=1716278400000000000,\n)\n&gt;&gt;&gt; print(deserialized_message.payload.data)\nHello, world!\n</code></pre> Source code in <code>aiperf/common/models.py</code> <pre><code>class BaseMessage(BaseModel):\n    \"\"\"Base message model with common fields for all messages.\n    The payload can be any of the payload types defined by the payloads.py module.\n\n    The message type is determined by the discriminator field `message_type`. This is\n    used by the Pydantic `discriminator` argument to determine the type of the\n    payload automatically when the message is deserialized from a JSON string.\n\n    To serialize a message to a JSON string, use the `model_dump_json` method.\n    To deserialize a message from a JSON string, use the `model_validate_json`\n    method.\n\n    Example:\n    ```python\n    &gt;&gt;&gt; message = BaseMessage(\n    ...     service_id=\"service_1\",\n    ...     request_id=\"request_1\",\n    ...     payload=DataPayload(data=\"Hello, world!\"),\n    ... )\n    &gt;&gt;&gt; json_string = message.model_dump_json()\n    &gt;&gt;&gt; print(json_string)\n    {\"payload\": {\"data\": \"Hello, world!\"}, \"service_id\": \"service_1\", \"request_id\": \"request_1\"}\n    &gt;&gt;&gt; deserialized_message = BaseMessage.model_validate_json(json_string)\n    &gt;&gt;&gt; print(deserialized_message)\n    BaseMessage(\n        payload=DataPayload(data=\"Hello, world!\"),\n        service_id=\"service_1\",\n        request_id=\"request_1\",\n        timestamp=1716278400000000000,\n    )\n    &gt;&gt;&gt; print(deserialized_message.payload.data)\n    Hello, world!\n    ```\n    \"\"\"\n\n    service_id: str | None = Field(\n        default=None,\n        description=\"ID of the service sending the response\",\n    )\n    timestamp: int = Field(\n        default_factory=time.time_ns,\n        description=\"Time when the response was created\",\n    )\n    request_id: str | None = Field(\n        default=None,\n        description=\"ID of the request\",\n    )\n    payload: Payload = Field(\n        ...,\n        discriminator=\"message_type\",\n        description=\"Payload of the response\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.models.BasePayload","title":"<code>BasePayload</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Base model for all payload data. Each payload type must inherit from this class, and override the <code>message_type</code> field.</p> <p>This is used with Pydantic's <code>discriminator</code> to allow for polymorphic payloads, and automatic type coercion when receiving messages.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class BasePayload(BaseModel, ABC):\n    \"\"\"Base model for all payload data. Each payload type must inherit\n    from this class, and override the `message_type` field.\n\n    This is used with Pydantic's `discriminator` to allow for polymorphic payloads,\n    and automatic type coercion when receiving messages.\n    \"\"\"\n\n    # Note: Literal[MessageType.UNKNOWN] is required due to the way the\n    # discriminator is implemented in Pydantic, it requires everything to be a\n    # literal.\n    message_type: Literal[MessageType.UNKNOWN] = Field(\n        ...,\n        description=\"Type of message this payload represents\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.models.CommandMessage","title":"<code>CommandMessage</code>","text":"<p>               Bases: <code>BaseMessage</code></p> <p>Message containing command data.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class CommandMessage(BaseMessage):\n    \"\"\"Message containing command data.\"\"\"\n\n    payload: CommandPayload\n</code></pre>"},{"location":"api/#aiperf.common.models.CommandPayload","title":"<code>CommandPayload</code>","text":"<p>               Bases: <code>BasePayload</code></p> <p>Command payload sent to services to request an action.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class CommandPayload(BasePayload):\n    \"\"\"Command payload sent to services to request an action.\"\"\"\n\n    message_type: Literal[MessageType.COMMAND] = MessageType.COMMAND\n\n    command: CommandType = Field(\n        ...,\n        description=\"Command to execute\",\n    )\n    command_id: str = Field(\n        default_factory=lambda: uuid.uuid4().hex[:8],\n        description=\"Unique identifier for this command\",\n    )\n    require_response: bool = Field(\n        default=False,\n        description=\"Whether a response is required for this command\",\n    )\n    target_service_id: str | None = Field(\n        default=None,\n        description=\"ID of the target service for this command\",\n    )\n    data: BaseModel | None = Field(\n        default=None,\n        description=\"Data to send with the command\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.models.CreditDropMessage","title":"<code>CreditDropMessage</code>","text":"<p>               Bases: <code>BaseMessage</code></p> <p>Message indicating that a credit has been dropped.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class CreditDropMessage(BaseMessage):\n    \"\"\"Message indicating that a credit has been dropped.\"\"\"\n\n    payload: CreditDropPayload\n</code></pre>"},{"location":"api/#aiperf.common.models.CreditDropPayload","title":"<code>CreditDropPayload</code>","text":"<p>               Bases: <code>BasePayload</code></p> <p>Credit drop payload sent to services to request a credit drop.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class CreditDropPayload(BasePayload):\n    \"\"\"Credit drop payload sent to services to request a credit drop.\"\"\"\n\n    message_type: Literal[MessageType.CREDIT_DROP] = MessageType.CREDIT_DROP\n\n    amount: int = Field(\n        ...,\n        description=\"Amount of credits to drop\",\n    )\n    timestamp: int = Field(\n        default_factory=time.time_ns, description=\"Timestamp of the credit drop\"\n    )\n</code></pre>"},{"location":"api/#aiperf.common.models.CreditReturnMessage","title":"<code>CreditReturnMessage</code>","text":"<p>               Bases: <code>BaseMessage</code></p> <p>Message indicating that a credit has been returned.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class CreditReturnMessage(BaseMessage):\n    \"\"\"Message indicating that a credit has been returned.\"\"\"\n\n    payload: CreditReturnPayload\n</code></pre>"},{"location":"api/#aiperf.common.models.CreditReturnPayload","title":"<code>CreditReturnPayload</code>","text":"<p>               Bases: <code>BasePayload</code></p> <p>Credit return payload sent to services to request a credit return.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class CreditReturnPayload(BasePayload):\n    \"\"\"Credit return payload sent to services to request a credit return.\"\"\"\n\n    message_type: Literal[MessageType.CREDIT_RETURN] = MessageType.CREDIT_RETURN\n\n    amount: int = Field(\n        ...,\n        description=\"Amount of credits to return\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.models.DataMessage","title":"<code>DataMessage</code>","text":"<p>               Bases: <code>BaseMessage</code></p> <p>Message containing data.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class DataMessage(BaseMessage):\n    \"\"\"Message containing data.\"\"\"\n\n    payload: DataPayload\n</code></pre>"},{"location":"api/#aiperf.common.models.DataPayload","title":"<code>DataPayload</code>","text":"<p>               Bases: <code>BasePayload</code></p> <p>Base model for data payloads with metadata.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class DataPayload(BasePayload):\n    \"\"\"Base model for data payloads with metadata.\"\"\"\n\n    message_type: Literal[MessageType.DATA] = MessageType.DATA\n</code></pre>"},{"location":"api/#aiperf.common.models.ErrorMessage","title":"<code>ErrorMessage</code>","text":"<p>               Bases: <code>BaseMessage</code></p> <p>Message containing error data.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class ErrorMessage(BaseMessage):\n    \"\"\"Message containing error data.\"\"\"\n\n    payload: ErrorPayload\n</code></pre>"},{"location":"api/#aiperf.common.models.ErrorPayload","title":"<code>ErrorPayload</code>","text":"<p>               Bases: <code>BasePayload</code></p> <p>Exception payload sent by services to report an error.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class ErrorPayload(BasePayload):\n    \"\"\"Exception payload sent by services to report an error.\"\"\"\n\n    message_type: Literal[MessageType.ERROR] = MessageType.ERROR\n\n    error_code: str | None = Field(\n        default=None,\n        description=\"Exception code\",\n    )\n    error_message: str | None = Field(\n        default=None,\n        description=\"Exception message\",\n    )\n    error_details: dict[str, Any] | None = Field(\n        default=None,\n        description=\"Additional details about the error\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.models.HeartbeatMessage","title":"<code>HeartbeatMessage</code>","text":"<p>               Bases: <code>BaseMessage</code></p> <p>Message containing heartbeat data.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class HeartbeatMessage(BaseMessage):\n    \"\"\"Message containing heartbeat data.\"\"\"\n\n    payload: HeartbeatPayload\n</code></pre>"},{"location":"api/#aiperf.common.models.HeartbeatPayload","title":"<code>HeartbeatPayload</code>","text":"<p>               Bases: <code>StatusPayload</code></p> <p>Heartbeat payload sent periodically by services.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class HeartbeatPayload(StatusPayload):\n    \"\"\"Heartbeat payload sent periodically by services.\"\"\"\n\n    message_type: Literal[MessageType.HEARTBEAT] = MessageType.HEARTBEAT\n\n    state: ServiceState = ServiceState.RUNNING\n</code></pre>"},{"location":"api/#aiperf.common.models.RegistrationMessage","title":"<code>RegistrationMessage</code>","text":"<p>               Bases: <code>BaseMessage</code></p> <p>Message containing registration data.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class RegistrationMessage(BaseMessage):\n    \"\"\"Message containing registration data.\"\"\"\n\n    payload: RegistrationPayload\n</code></pre>"},{"location":"api/#aiperf.common.models.RegistrationPayload","title":"<code>RegistrationPayload</code>","text":"<p>               Bases: <code>StatusPayload</code></p> <p>Registration payload sent by services to register themselves.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class RegistrationPayload(StatusPayload):\n    \"\"\"Registration payload sent by services to register themselves.\"\"\"\n\n    message_type: Literal[MessageType.REGISTRATION] = MessageType.REGISTRATION\n\n    state: ServiceState = ServiceState.READY\n</code></pre>"},{"location":"api/#aiperf.common.models.ServiceRunInfo","title":"<code>ServiceRunInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base model for tracking service run information.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class ServiceRunInfo(BaseModel):\n    \"\"\"Base model for tracking service run information.\"\"\"\n\n    service_type: ServiceType = Field(\n        ...,\n        description=\"The type of service\",\n    )\n    registration_status: ServiceRegistrationStatus = Field(\n        ...,\n        description=\"The registration status of the service\",\n    )\n    service_id: str = Field(\n        ...,\n        description=\"The ID of the service\",\n    )\n    first_seen: int | None = Field(\n        default_factory=time.time_ns,\n        description=\"The first time the service was seen\",\n    )\n    last_seen: int | None = Field(\n        default_factory=time.time_ns,\n        description=\"The last time the service was seen\",\n    )\n    state: ServiceState = Field(\n        default=ServiceState.UNKNOWN,\n        description=\"The current state of the service\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.models.StatusMessage","title":"<code>StatusMessage</code>","text":"<p>               Bases: <code>BaseMessage</code></p> <p>Message containing status data.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class StatusMessage(BaseMessage):\n    \"\"\"Message containing status data.\"\"\"\n\n    payload: StatusPayload\n</code></pre>"},{"location":"api/#aiperf.common.models.StatusPayload","title":"<code>StatusPayload</code>","text":"<p>               Bases: <code>BasePayload</code></p> <p>Status payload sent by services to report their current state.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class StatusPayload(BasePayload):\n    \"\"\"Status payload sent by services to report their current state.\"\"\"\n\n    message_type: Literal[MessageType.STATUS] = MessageType.STATUS\n\n    state: ServiceState = Field(\n        ...,\n        description=\"Current state of the service\",\n    )\n    service_type: ServiceType = Field(\n        ...,\n        description=\"Type of service\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig","title":"<code>ZMQCommunicationConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for ZMQ communication.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class ZMQCommunicationConfig(BaseModel):\n    \"\"\"Configuration for ZMQ communication.\"\"\"\n\n    protocol_config: ZMQTCPTransportConfig = Field(\n        default_factory=ZMQTCPTransportConfig,\n        description=\"Configuration for the selected transport protocol\",\n    )\n    client_id: str | None = Field(\n        default=None, description=\"Client ID, will be generated if not provided\"\n    )\n\n    @property\n    def controller_pub_sub_address(self) -&gt; str:\n        \"\"\"Get the controller pub/sub address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.protocol_config.host}:{self.protocol_config.controller_pub_sub_port}\"\n\n    @property\n    def component_pub_sub_address(self) -&gt; str:\n        \"\"\"Get the component pub/sub address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.protocol_config.host}:{self.protocol_config.component_pub_sub_port}\"\n\n    @property\n    def inference_push_pull_address(self) -&gt; str:\n        \"\"\"Get the inference push/pull address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.protocol_config.host}:{self.protocol_config.inference_push_pull_port}\"\n\n    @property\n    def records_address(self) -&gt; str:\n        \"\"\"Get the records address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.protocol_config.host}:{self.protocol_config.records_port}\"\n\n    @property\n    def conversation_data_address(self) -&gt; str:\n        \"\"\"Get the conversation data address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.protocol_config.host}:{self.protocol_config.conversation_data_port}\"\n\n    @property\n    def credit_drop_address(self) -&gt; str:\n        \"\"\"Get the credit drop address based on protocol configuration.\"\"\"\n        return (\n            f\"tcp://{self.protocol_config.host}:{self.protocol_config.credit_drop_port}\"\n        )\n\n    @property\n    def credit_return_address(self) -&gt; str:\n        \"\"\"Get the credit return address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.protocol_config.host}:{self.protocol_config.credit_return_port}\"\n</code></pre>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.component_pub_sub_address","title":"<code>component_pub_sub_address</code>  <code>property</code>","text":"<p>Get the component pub/sub address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.controller_pub_sub_address","title":"<code>controller_pub_sub_address</code>  <code>property</code>","text":"<p>Get the controller pub/sub address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.conversation_data_address","title":"<code>conversation_data_address</code>  <code>property</code>","text":"<p>Get the conversation data address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.credit_drop_address","title":"<code>credit_drop_address</code>  <code>property</code>","text":"<p>Get the credit drop address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.credit_return_address","title":"<code>credit_return_address</code>  <code>property</code>","text":"<p>Get the credit return address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.inference_push_pull_address","title":"<code>inference_push_pull_address</code>  <code>property</code>","text":"<p>Get the inference push/pull address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.records_address","title":"<code>records_address</code>  <code>property</code>","text":"<p>Get the records address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQTCPTransportConfig","title":"<code>ZMQTCPTransportConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for TCP transport.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class ZMQTCPTransportConfig(BaseModel):\n    \"\"\"Configuration for TCP transport.\"\"\"\n\n    host: str = Field(\n        default=\"0.0.0.0\",\n        description=\"Host address for TCP connections\",\n    )\n    controller_pub_sub_port: int = Field(\n        default=5555, description=\"Port for controller pub/sub messages\"\n    )\n    component_pub_sub_port: int = Field(\n        default=5556, description=\"Port for component pub/sub messages\"\n    )\n    inference_push_pull_port: int = Field(\n        default=5557, description=\"Port for inference push/pull messages\"\n    )\n    req_rep_port: int = Field(\n        default=5558, description=\"Port for sending and receiving requests\"\n    )\n    push_pull_port: int = Field(\n        default=5559, description=\"Port for pushing and pulling data\"\n    )\n    records_port: int = Field(default=5560, description=\"Port for record data\")\n    conversation_data_port: int = Field(\n        default=5561, description=\"Port for conversation data\"\n    )\n    credit_drop_port: int = Field(\n        default=5562, description=\"Port for credit drop operations\"\n    )\n    credit_return_port: int = Field(\n        default=5563, description=\"Port for credit return operations\"\n    )\n</code></pre>"},{"location":"api/#aiperfcommonservicebase_component_service","title":"aiperf.common.service.base_component_service","text":""},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService","title":"<code>BaseComponentService</code>","text":"<p>               Bases: <code>BaseService</code></p> <p>Base class for all Component services.</p> <p>This class provides a common interface for all Component services in the AIPerf framework such as the Timing Manager, Dataset Manager, etc.</p> <p>It extends the BaseService by: - Subscribing to the command topic - Processing command messages - Sending registration requests to the system controller - Sending heartbeat notifications to the system controller - Sending status notifications to the system controller - Helpers to create heartbeat, registration, and status messages - Request the appropriate communication clients for a component service</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>class BaseComponentService(BaseService):\n    \"\"\"Base class for all Component services.\n\n    This class provides a common interface for all Component services in the AIPerf\n    framework such as the Timing Manager, Dataset Manager, etc.\n\n    It extends the BaseService by:\n    - Subscribing to the command topic\n    - Processing command messages\n    - Sending registration requests to the system controller\n    - Sending heartbeat notifications to the system controller\n    - Sending status notifications to the system controller\n    - Helpers to create heartbeat, registration, and status messages\n    - Request the appropriate communication clients for a component service\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n\n    @property\n    def required_clients(self) -&gt; list[ClientType]:\n        \"\"\"The communication clients required by the service.\n\n        The component services subscribe to controller messages and publish\n        component messages.\n        \"\"\"\n        return [\n            *(super().required_clients or []),\n            PubClientType.COMPONENT,\n            SubClientType.CONTROLLER,\n        ]\n\n    # TODO: The configure method is turning into a service hook\n    # @abstractmethod\n    # async def _configure(self, payload: Payload) -&gt; None:\n    #     \"\"\"Configure the service with the given configuration payload.\n\n    #     This method is called when a configure command is received from the controller.\n    #     It should be implemented by the derived class to configure the service.\n\n    #     The service should validate the payload and configure itself accordingly.\n    #     If successful, the service should publish a success message to the controller.\n    #     On failure, the service should publish an error message to the controller.\n\n    #     Args:\n    #         payload: The configuration payload. This is a union type of all the possible\n    #         configuration payloads.\n\n    #     \"\"\"\n    #     pass\n\n    @on_run\n    async def _on_run(self) -&gt; None:\n        \"\"\"Automatically subscribe to the command topic and register the service\n        with the system controller when the run hook is called.\n\n        This method will:\n        - Subscribe to the command topic\n        - Wait for the communication to be fully initialized\n        - Register the service with the system controller\n        \"\"\"\n        # Subscribe to the command topic\n        try:\n            await self.comms.subscribe(\n                Topic.COMMAND,\n                self.process_command_message,\n            )\n        except Exception as e:\n            self.logger.error(\"Exception subscribing to command topic: %s\", e)\n            raise CommunicationSubscribeError(\n                \"Failed to subscribe to command topic\"\n            ) from e\n\n        # TODO: Find a way to wait for the communication to be fully initialized\n        # FIXME: This is a hack to ensure the communication is fully initialized\n        await asyncio.sleep(1)\n\n        # Register the service\n        try:\n            await self.register()\n            await asyncio.sleep(0.5)\n        except Exception as e:\n            raise ServiceRegistrationError() from e\n\n    @aiperf_task\n    async def _heartbeat_task(self) -&gt; None:\n        \"\"\"Starts a background task to send heartbeats at regular intervals. It\n        will continue to send heartbeats even if an error occurs until the stop\n        event is set.\n        \"\"\"\n        while not self.stop_event.is_set():\n            # Sleep first to avoid sending a heartbeat before the registration\n            # message has been published\n            await asyncio.sleep(self._heartbeat_interval)\n\n            try:\n                await self.send_heartbeat()\n            except Exception as e:\n                self.logger.warning(\"Exception sending heartbeat: %s\", e)\n                # continue to keep sending heartbeats regardless of the error\n\n        self.logger.debug(\"Heartbeat task stopped\")\n\n    async def send_heartbeat(self) -&gt; None:\n        \"\"\"Send a heartbeat notification to the system controller.\"\"\"\n        heartbeat_message = self.create_heartbeat_message()\n        self.logger.debug(\"Sending heartbeat: %s\", heartbeat_message)\n        try:\n            await self.comms.publish(\n                topic=Topic.HEARTBEAT,\n                message=heartbeat_message,\n            )\n        except Exception as e:\n            raise ServiceHeartbeatError from e\n\n    async def register(self) -&gt; None:\n        \"\"\"Publish a registration request to the system controller.\n\n        This method should be called after the service has been initialized and is\n        ready to start processing messages.\n        \"\"\"\n        self.logger.debug(\n            \"Attempting to register service %s (%s) with system controller\",\n            self.service_type,\n            self.service_id,\n        )\n        try:\n            await self.comms.publish(\n                topic=Topic.REGISTRATION,\n                message=self.create_registration_message(),\n            )\n        except Exception as e:\n            raise ServiceRegistrationError() from e\n\n    async def process_command_message(self, message: CommandMessage) -&gt; None:\n        \"\"\"Process a command message received from the controller.\n\n        This method will process the command message and execute the appropriate action.\n        \"\"\"\n        if message.payload.target_service_id not in [None, self.service_id]:\n            return  # Ignore commands meant for other services\n\n        cmd = message.payload.command\n        if cmd == CommandType.START:\n            await self.start()\n\n        elif cmd == CommandType.STOP:\n            self.stop_event.set()\n\n        elif cmd == CommandType.CONFIGURE:\n            await self.run_hooks(AIPerfHook.ON_CONFIGURE, message)\n\n        else:\n            self.logger.warning(f\"{self.service_type} received unknown command: {cmd}\")\n\n    @on_set_state\n    async def _on_set_state(self, state: ServiceState) -&gt; None:\n        \"\"\"Action to take when the service state is set.\n\n        This method will also publish the status message to the status topic if the\n        communications are initialized.\n        \"\"\"\n        if self._comms and self._comms.is_initialized:\n            await self.comms.publish(\n                topic=Topic.STATUS,\n                message=self.create_status_message(state),\n            )\n\n    def create_heartbeat_message(self) -&gt; HeartbeatMessage:\n        \"\"\"Create a heartbeat notification message.\"\"\"\n        return cast(\n            HeartbeatMessage,\n            self.create_message(\n                HeartbeatPayload(\n                    service_type=self.service_type,\n                )\n            ),\n        )\n\n    def create_registration_message(self) -&gt; RegistrationMessage:\n        \"\"\"Create a registration request message.\"\"\"\n        return cast(\n            RegistrationMessage,\n            self.create_message(\n                RegistrationPayload(\n                    service_type=self.service_type,\n                )\n            ),\n        )\n\n    def create_status_message(self, state: ServiceState) -&gt; StatusMessage:\n        \"\"\"Create a status notification message.\"\"\"\n        return cast(\n            StatusMessage,\n            self.create_message(\n                StatusPayload(\n                    state=state,\n                    service_type=self.service_type,\n                )\n            ),\n        )\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.required_clients","title":"<code>required_clients</code>  <code>property</code>","text":"<p>The communication clients required by the service.</p> <p>The component services subscribe to controller messages and publish component messages.</p>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.create_heartbeat_message","title":"<code>create_heartbeat_message()</code>","text":"<p>Create a heartbeat notification message.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>def create_heartbeat_message(self) -&gt; HeartbeatMessage:\n    \"\"\"Create a heartbeat notification message.\"\"\"\n    return cast(\n        HeartbeatMessage,\n        self.create_message(\n            HeartbeatPayload(\n                service_type=self.service_type,\n            )\n        ),\n    )\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.create_registration_message","title":"<code>create_registration_message()</code>","text":"<p>Create a registration request message.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>def create_registration_message(self) -&gt; RegistrationMessage:\n    \"\"\"Create a registration request message.\"\"\"\n    return cast(\n        RegistrationMessage,\n        self.create_message(\n            RegistrationPayload(\n                service_type=self.service_type,\n            )\n        ),\n    )\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.create_status_message","title":"<code>create_status_message(state)</code>","text":"<p>Create a status notification message.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>def create_status_message(self, state: ServiceState) -&gt; StatusMessage:\n    \"\"\"Create a status notification message.\"\"\"\n    return cast(\n        StatusMessage,\n        self.create_message(\n            StatusPayload(\n                state=state,\n                service_type=self.service_type,\n            )\n        ),\n    )\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.process_command_message","title":"<code>process_command_message(message)</code>  <code>async</code>","text":"<p>Process a command message received from the controller.</p> <p>This method will process the command message and execute the appropriate action.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>async def process_command_message(self, message: CommandMessage) -&gt; None:\n    \"\"\"Process a command message received from the controller.\n\n    This method will process the command message and execute the appropriate action.\n    \"\"\"\n    if message.payload.target_service_id not in [None, self.service_id]:\n        return  # Ignore commands meant for other services\n\n    cmd = message.payload.command\n    if cmd == CommandType.START:\n        await self.start()\n\n    elif cmd == CommandType.STOP:\n        self.stop_event.set()\n\n    elif cmd == CommandType.CONFIGURE:\n        await self.run_hooks(AIPerfHook.ON_CONFIGURE, message)\n\n    else:\n        self.logger.warning(f\"{self.service_type} received unknown command: {cmd}\")\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.register","title":"<code>register()</code>  <code>async</code>","text":"<p>Publish a registration request to the system controller.</p> <p>This method should be called after the service has been initialized and is ready to start processing messages.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>async def register(self) -&gt; None:\n    \"\"\"Publish a registration request to the system controller.\n\n    This method should be called after the service has been initialized and is\n    ready to start processing messages.\n    \"\"\"\n    self.logger.debug(\n        \"Attempting to register service %s (%s) with system controller\",\n        self.service_type,\n        self.service_id,\n    )\n    try:\n        await self.comms.publish(\n            topic=Topic.REGISTRATION,\n            message=self.create_registration_message(),\n        )\n    except Exception as e:\n        raise ServiceRegistrationError() from e\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.send_heartbeat","title":"<code>send_heartbeat()</code>  <code>async</code>","text":"<p>Send a heartbeat notification to the system controller.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>async def send_heartbeat(self) -&gt; None:\n    \"\"\"Send a heartbeat notification to the system controller.\"\"\"\n    heartbeat_message = self.create_heartbeat_message()\n    self.logger.debug(\"Sending heartbeat: %s\", heartbeat_message)\n    try:\n        await self.comms.publish(\n            topic=Topic.HEARTBEAT,\n            message=heartbeat_message,\n        )\n    except Exception as e:\n        raise ServiceHeartbeatError from e\n</code></pre>"},{"location":"api/#aiperfcommonservicebase_controller_service","title":"aiperf.common.service.base_controller_service","text":""},{"location":"api/#aiperf.common.service.base_controller_service.BaseControllerService","title":"<code>BaseControllerService</code>","text":"<p>               Bases: <code>BaseService</code></p> <p>Base class for all controller services, such as the System Controller.</p> <p>This class provides a common interface for all controller services in the AIPerf framework. It inherits from the BaseService class and implements the required methods for controller services.</p> <p>It extends the BaseService by: - Starting the service automatically when the run hook is called - Helpers to create command messages to be sent to a specific service - Request the appropriate communication clients for a controller service</p> Source code in <code>aiperf/common/service/base_controller_service.py</code> <pre><code>class BaseControllerService(BaseService):\n    \"\"\"Base class for all controller services, such as the System Controller.\n\n    This class provides a common interface for all controller services in the AIPerf\n    framework. It inherits from the BaseService class and implements the required\n    methods for controller services.\n\n    It extends the BaseService by:\n    - Starting the service automatically when the run hook is called\n    - Helpers to create command messages to be sent to a specific service\n    - Request the appropriate communication clients for a controller service\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n\n    @property\n    def required_clients(self) -&gt; list[ClientType]:\n        \"\"\"The communication clients required by the service.\n\n        The controller service subscribes to controller messages and publishes\n        to components.\n        \"\"\"\n        return [\n            *(super().required_clients or []),\n            PubClientType.CONTROLLER,\n            SubClientType.COMPONENT,\n        ]\n\n    @on_run\n    async def _on_run(self) -&gt; None:\n        \"\"\"Automatically start the service when the run hook is called.\"\"\"\n        await self.start()\n\n    def create_command_message(\n        self,\n        command: CommandType,\n        target_service_id: str,\n        data: Any | None = None,\n    ) -&gt; Message:\n        \"\"\"Create a command message to be sent to a specific service.\n\n        Args:\n            command: The command to send\n            target_service_id: The ID of the service to send the command to\n            data: Optional data to send with the command.\n\n        Returns:\n            A command message\n        \"\"\"\n        return self.create_message(\n            CommandPayload(\n                command=command,\n                target_service_id=target_service_id,\n                data=data,\n            )\n        )\n</code></pre>"},{"location":"api/#aiperf.common.service.base_controller_service.BaseControllerService.required_clients","title":"<code>required_clients</code>  <code>property</code>","text":"<p>The communication clients required by the service.</p> <p>The controller service subscribes to controller messages and publishes to components.</p>"},{"location":"api/#aiperf.common.service.base_controller_service.BaseControllerService.create_command_message","title":"<code>create_command_message(command, target_service_id, data=None)</code>","text":"<p>Create a command message to be sent to a specific service.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>CommandType</code> <p>The command to send</p> required <code>target_service_id</code> <code>str</code> <p>The ID of the service to send the command to</p> required <code>data</code> <code>Any | None</code> <p>Optional data to send with the command.</p> <code>None</code> <p>Returns:</p> Type Description <code>Message</code> <p>A command message</p> Source code in <code>aiperf/common/service/base_controller_service.py</code> <pre><code>def create_command_message(\n    self,\n    command: CommandType,\n    target_service_id: str,\n    data: Any | None = None,\n) -&gt; Message:\n    \"\"\"Create a command message to be sent to a specific service.\n\n    Args:\n        command: The command to send\n        target_service_id: The ID of the service to send the command to\n        data: Optional data to send with the command.\n\n    Returns:\n        A command message\n    \"\"\"\n    return self.create_message(\n        CommandPayload(\n            command=command,\n            target_service_id=target_service_id,\n            data=data,\n        )\n    )\n</code></pre>"},{"location":"api/#aiperfcommonservicebase_service","title":"aiperf.common.service.base_service","text":""},{"location":"api/#aiperf.common.service.base_service.BaseService","title":"<code>BaseService</code>","text":"<p>               Bases: <code>BaseServiceInterface</code>, <code>ABC</code>, <code>AIPerfTaskMixin</code></p> <p>Base class for all AIPerf services, providing common functionality for communication, state management, and lifecycle operations.</p> <p>This class provides the foundation for implementing the various services of the AIPerf system. Some of the abstract methods are implemented here, while others are still required to be implemented by derived classes.</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>@supports_hooks(\n    AIPerfHook.ON_INIT,\n    AIPerfHook.ON_RUN,\n    AIPerfHook.ON_CONFIGURE,\n    AIPerfHook.ON_START,\n    AIPerfHook.ON_STOP,\n    AIPerfHook.ON_CLEANUP,\n    AIPerfHook.ON_SET_STATE,\n    AIPerfHook.AIPERF_TASK,\n)\nclass BaseService(BaseServiceInterface, ABC, AIPerfTaskMixin):\n    \"\"\"Base class for all AIPerf services, providing common functionality for\n    communication, state management, and lifecycle operations.\n\n    This class provides the foundation for implementing the various services of the\n    AIPerf system. Some of the abstract methods are implemented here, while others\n    are still required to be implemented by derived classes.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        self.service_id: str = (\n            service_id or f\"{self.service_type}_{uuid.uuid4().hex[:8]}\"\n        )\n        self.service_config = service_config\n\n        self.logger = logging.getLogger(self.service_type)\n        self.logger.debug(\n            f\"Initializing {self.service_type} service (id: {self.service_id})\"\n        )\n\n        self._state: ServiceState = ServiceState.UNKNOWN\n        self._heartbeat_interval = self.service_config.heartbeat_interval\n\n        self.stop_event = asyncio.Event()\n        self.initialized_event = asyncio.Event()\n\n        self._comms: BaseCommunication | None = None\n\n        # Set to store signal handler tasks\n        self._signal_tasks = set()\n\n        try:\n            import setproctitle\n\n            setproctitle.setproctitle(f\"aiperf {self.service_id}\")\n        except Exception:\n            # setproctitle is not available on all platforms, so we ignore the error\n            self.logger.debug(\"Failed to set process title, ignoring\")\n\n        super().__init__()\n        self.logger.debug(\"__init__ finished for %s\", self.__class__.__name__)\n\n    @property\n    def comms(self) -&gt; BaseCommunication:\n        \"\"\"\n        Get the communication object for the service.\n        Raises:\n            CommunicationNotInitializedError: If the communication is not initialized\n        \"\"\"\n        if not self._comms:\n            raise CommunicationNotInitializedError()\n        return self._comms\n\n    @property\n    def state(self) -&gt; ServiceState:\n        \"\"\"The current state of the service.\"\"\"\n        return self._state\n\n    @property\n    def is_initialized(self) -&gt; bool:\n        \"\"\"Check if service is initialized.\n\n        Returns:\n            True if service is initialized, False otherwise\n        \"\"\"\n        return self.initialized_event.is_set()\n\n    @property\n    def is_shutdown(self) -&gt; bool:\n        \"\"\"Check if service is shutdown.\n\n        Returns:\n            True if service is shutdown, False otherwise\n        \"\"\"\n        return self.stop_event.is_set()\n\n    # Note: Not using as a setter so it can be overridden by derived classes and still\n    # be async\n    async def set_state(self, state: ServiceState) -&gt; None:\n        \"\"\"Set the state of the service. This method implements\n        the `BaseServiceInterface.set_state` method.\n\n        This method will:\n        - Set the service state to the given state\n        - Call all registered `AIPerfHook.ON_SET_STATE` hooks\n        \"\"\"\n        self._state = state\n        await self.run_hooks(AIPerfHook.ON_SET_STATE, state)\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize the service communication and signal handlers. This method implements\n        the `BaseServiceInterface.initialize` method.\n\n        This method will:\n        - Set the service to `ServiceState.INITIALIZING` state\n        - Set up signal handlers for graceful shutdown\n        - Allow time for the event loop to start\n        - Initialize communication\n        - Call all registered `AIPerfHook.ON_INIT` hooks\n        - Set the service to `ServiceState.READY` state\n        - Set the initialized asyncio event\n        \"\"\"\n        self._state = ServiceState.INITIALIZING\n        # Set up signal handlers for graceful shutdown\n        self._setup_signal_handlers()\n        # Allow time for the event loop to start\n        await asyncio.sleep(0.1)\n\n        # Initialize communication\n        try:\n            self._comms = CommunicationFactory.create_instance(\n                self.service_config.comm_backend,\n                config=self.service_config.comm_config,\n            )\n        except Exception as e:\n            self.logger.exception(\n                \"Failed to create communication for service %s (id: %s)\",\n                self.service_type,\n                self.service_id,\n            )\n            raise CommunicationCreateError from e\n\n        try:\n            await self._comms.initialize()\n        except Exception as e:\n            self.logger.exception(\n                \"Failed to initialize communication for service %s (id: %s)\",\n                self.service_type,\n                self.service_id,\n            )\n            raise ServiceInitializationError from e\n\n        if len(self.required_clients) &gt; 0:\n            # Create the communication clients ahead of time\n            self.logger.debug(\n                \"%s: Creating communication clients (%s)\",\n                self.service_type,\n                self.required_clients,\n            )\n\n            try:\n                await self._comms.create_clients(*self.required_clients)\n            except Exception as e:\n                self.logger.exception(\n                    \"Failed to create communication clients for service %s (id: %s)\",\n                    self.service_type,\n                    self.service_id,\n                )\n                raise CommunicationClientCreationError from e\n\n        # Initialize any derived service components\n        try:\n            await self.run_hooks(AIPerfHook.ON_INIT)\n        except AIPerfMultiError as e:\n            self.logger.exception(\n                \"Failed to initialize service %s (id: %s)\",\n                self.service_type,\n                self.service_id,\n            )\n            raise ServiceInitializationError from e\n\n        await self.set_state(ServiceState.READY)\n\n        self.initialized_event.set()\n\n    async def run_forever(self) -&gt; None:\n        \"\"\"Run the service in a loop until the stop event is set. This method implements\n        the `BaseServiceInterface.run_forever` method.\n\n        This method will:\n        - Call the initialize method to initialize the service\n        - Call all registered `AIPerfHook.RUN` hooks\n        - Wait for the stop event to be set\n        - Shuts down the service when the stop event is set\n\n        This method will be called as the main entry point for the service.\n        \"\"\"\n        try:\n            self.logger.debug(\n                \"Running %s service (id: %s)\", self.service_type, self.service_id\n            )\n\n            try:\n                await self.initialize()\n            except Exception as e:\n                self.logger.exception(\n                    \"Failed to initialize service %s (id: %s)\",\n                    self.service_type,\n                    self.service_id,\n                )\n                raise ServiceRunError from e\n\n            try:\n                await self.run_hooks(AIPerfHook.ON_RUN)\n            except AIPerfMultiError as e:\n                self.logger.exception(\n                    \"Failed to run service %s (id: %s)\",\n                    self.service_type,\n                    self.service_id,\n                )\n                raise ServiceRunError from e\n\n        except asyncio.CancelledError:\n            self.logger.debug(\"Service %s execution cancelled\", self.service_type)\n            return\n\n        except Exception as e:\n            self.logger.exception(\"Service %s execution failed:\", self.service_type)\n            _ = await self.set_state(ServiceState.ERROR)\n            raise ServiceRunError(\n                \"Service %s execution failed\", self.service_type\n            ) from e\n\n        await self._forever_loop()\n\n    async def _forever_loop(self) -&gt; None:\n        \"\"\"\n        This method will be called by the `run_forever` method to allow the service to run\n        indefinitely. This method is not expected to be overridden by derived classes.\n\n        This method will:\n        - Wait for the stop event to be set\n        - Shuts down the service when the stop event is set\n        \"\"\"\n        while not self.stop_event.is_set():\n            try:\n                self.logger.debug(\n                    \"Service %s waiting for stop event\", self.service_type\n                )\n                # Wait forever for the stop event to be set\n                await self.stop_event.wait()\n\n            except (KeyboardInterrupt, SystemExit, asyncio.CancelledError):\n                self.logger.debug(\"Service %s execution cancelled\", self.service_type)\n                self.stop_event.set()\n\n            except Exception:\n                self.logger.exception(\n                    \"Caught unexpected exception in service %s execution\",\n                    self.service_type,\n                )\n            finally:\n                # Shutdown the service\n                try:\n                    await self.stop()\n                except Exception as e:\n                    self.logger.exception(\n                        \"Exception stopping service %s\", self.service_type\n                    )\n                    raise ServiceStopError(\n                        \"Exception stopping service %s\", self.service_type\n                    ) from e\n\n    async def start(self) -&gt; None:\n        \"\"\"Start the service and its components. This method implements\n        the `BaseServiceInterface.start` method.\n\n        This method should be called to start the service after it has been initialized\n        and configured.\n\n        This method will:\n        - Set the service to `ServiceState.STARTING` state\n        - Call all registered `AIPerfHook.ON_START` hooks\n        - Set the service to `ServiceState.RUNNING` state\n        \"\"\"\n\n        try:\n            self.logger.debug(\n                \"Starting %s service (id: %s)\", self.service_type, self.service_id\n            )\n            _ = await self.set_state(ServiceState.STARTING)\n\n            await self.run_hooks(AIPerfHook.ON_START)\n\n            _ = await self.set_state(ServiceState.RUNNING)\n\n        except asyncio.CancelledError:\n            self.logger.debug(\"Service %s execution cancelled\", self.service_type)\n\n        except Exception as e:\n            self.logger.exception(\n                \"Failed to start service %s (id: %s)\",\n                self.service_type,\n                self.service_id,\n            )\n            self._state = ServiceState.ERROR\n\n            raise ServiceStartError(\n                \"Failed to start service %s (id: %s)\",\n                self.service_type,\n                self.service_id,\n            ) from e\n\n    async def stop(self) -&gt; None:\n        \"\"\"Stop the service and clean up its components. This method implements\n        the `BaseServiceInterface.stop` method.\n\n        This method will:\n        - Set the service to `ServiceState.STOPPING` state\n        - Call all registered `AIPerfHook.ON_STOP` hooks\n        - Shutdown the service communication component\n        - Call all registered `AIPerfHook.ON_CLEANUP` hooks\n        - Set the service to `ServiceState.STOPPED` state\n        \"\"\"\n        try:\n            if self.state == ServiceState.STOPPED:\n                self.logger.warning(\n                    \"Service %s state %s is already STOPPED, ignoring stop request\",\n                    self.service_type,\n                    self.state,\n                )\n                return\n\n            # ignore if we were unable to send the STOPPING state message\n            _ = await self.set_state(ServiceState.STOPPING)\n\n            # Signal the run method to exit if it hasn't already\n            if not self.stop_event.is_set():\n                self.stop_event.set()\n\n            # Custom stop logic implemented by derived classes\n            with contextlib.suppress(asyncio.CancelledError):\n                await self.run_hooks(AIPerfHook.ON_STOP)\n\n            # Shutdown communication component\n            if self._comms and not self._comms.is_shutdown:\n                await self._comms.shutdown()\n\n            # Custom cleanup logic implemented by derived classes\n            with contextlib.suppress(asyncio.CancelledError):\n                await self.run_hooks(AIPerfHook.ON_CLEANUP)\n\n            # Set the state to STOPPED. Communications are shutdown, so we don't need to\n            # publish a status message\n            self._state = ServiceState.STOPPED\n            self.logger.debug(\n                \"Service %s (id: %s) stopped\", self.service_type, self.service_id\n            )\n\n        except Exception as e:\n            self.logger.exception(\n                \"Failed to stop service %s (id: %s)\",\n                self.service_type,\n                self.service_id,\n            )\n            self._state = ServiceState.ERROR\n            raise ServiceStopError(\n                \"Failed to stop service %s (id: %s)\",\n                self.service_type,\n                self.service_id,\n            ) from e\n\n    async def configure(self, message: Message) -&gt; None:\n        \"\"\"Configure the service with the given configuration. This method implements\n        the `BaseServiceInterface.configure` method.\n\n        This method will:\n        - Call all registered AIPerfHook.ON_CONFIGURE hooks\n        \"\"\"\n        await self.run_hooks(AIPerfHook.ON_CONFIGURE, message)\n\n    def create_message(\n        self, payload: Payload, request_id: str | None = None\n    ) -&gt; Message:\n        \"\"\"Create a message of the given type, and pre-fill the service_id.\n\n        Args:\n            payload: The payload of the message\n            request_id: optional The request id of this message, or the request id of the\n                message this is a response to\n\n        Returns:\n            A message of the given type\n        \"\"\"\n        message = BaseMessage(\n            service_id=self.service_id,\n            request_id=request_id,\n            payload=payload,\n        )\n        return message\n\n    def _setup_signal_handlers(self) -&gt; None:\n        \"\"\"This method will set up signal handlers for the SIGTERM and SIGINT signals\n        in order to trigger a graceful shutdown of the service.\n        \"\"\"\n        loop = asyncio.get_running_loop()\n\n        def signal_handler(sig: int) -&gt; None:\n            # Create a task and store it so it doesn't get garbage collected\n            task = asyncio.create_task(self._handle_signal(sig))\n\n            # Store the task somewhere to prevent it from being garbage collected\n            # before it completes\n            self._signal_tasks.add(task)\n            task.add_done_callback(self._signal_tasks.discard)\n\n        for sig in (signal.SIGTERM, signal.SIGINT):\n            loop.add_signal_handler(sig, lambda s=sig: signal_handler(s))\n\n    async def _handle_signal(self, sig: int) -&gt; None:\n        \"\"\"Handle received signals by triggering graceful shutdown.\n\n        Args:\n            sig: The signal number received\n        \"\"\"\n        signal_name = signal.Signals(sig).name\n        self.logger.debug(\n            \"%s: Received signal %s, initiating graceful shutdown\",\n            self.service_type,\n            signal_name,\n        )\n\n        self.stop_event.set()\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.comms","title":"<code>comms</code>  <code>property</code>","text":"<p>Get the communication object for the service. Raises:     CommunicationNotInitializedError: If the communication is not initialized</p>"},{"location":"api/#aiperf.common.service.base_service.BaseService.is_initialized","title":"<code>is_initialized</code>  <code>property</code>","text":"<p>Check if service is initialized.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if service is initialized, False otherwise</p>"},{"location":"api/#aiperf.common.service.base_service.BaseService.is_shutdown","title":"<code>is_shutdown</code>  <code>property</code>","text":"<p>Check if service is shutdown.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if service is shutdown, False otherwise</p>"},{"location":"api/#aiperf.common.service.base_service.BaseService.state","title":"<code>state</code>  <code>property</code>","text":"<p>The current state of the service.</p>"},{"location":"api/#aiperf.common.service.base_service.BaseService.configure","title":"<code>configure(message)</code>  <code>async</code>","text":"<p>Configure the service with the given configuration. This method implements the <code>BaseServiceInterface.configure</code> method.</p> <p>This method will: - Call all registered AIPerfHook.ON_CONFIGURE hooks</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>async def configure(self, message: Message) -&gt; None:\n    \"\"\"Configure the service with the given configuration. This method implements\n    the `BaseServiceInterface.configure` method.\n\n    This method will:\n    - Call all registered AIPerfHook.ON_CONFIGURE hooks\n    \"\"\"\n    await self.run_hooks(AIPerfHook.ON_CONFIGURE, message)\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.create_message","title":"<code>create_message(payload, request_id=None)</code>","text":"<p>Create a message of the given type, and pre-fill the service_id.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>Payload</code> <p>The payload of the message</p> required <code>request_id</code> <code>str | None</code> <p>optional The request id of this message, or the request id of the message this is a response to</p> <code>None</code> <p>Returns:</p> Type Description <code>Message</code> <p>A message of the given type</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>def create_message(\n    self, payload: Payload, request_id: str | None = None\n) -&gt; Message:\n    \"\"\"Create a message of the given type, and pre-fill the service_id.\n\n    Args:\n        payload: The payload of the message\n        request_id: optional The request id of this message, or the request id of the\n            message this is a response to\n\n    Returns:\n        A message of the given type\n    \"\"\"\n    message = BaseMessage(\n        service_id=self.service_id,\n        request_id=request_id,\n        payload=payload,\n    )\n    return message\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.initialize","title":"<code>initialize()</code>  <code>async</code>","text":"<p>Initialize the service communication and signal handlers. This method implements the <code>BaseServiceInterface.initialize</code> method.</p> <p>This method will: - Set the service to <code>ServiceState.INITIALIZING</code> state - Set up signal handlers for graceful shutdown - Allow time for the event loop to start - Initialize communication - Call all registered <code>AIPerfHook.ON_INIT</code> hooks - Set the service to <code>ServiceState.READY</code> state - Set the initialized asyncio event</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>async def initialize(self) -&gt; None:\n    \"\"\"Initialize the service communication and signal handlers. This method implements\n    the `BaseServiceInterface.initialize` method.\n\n    This method will:\n    - Set the service to `ServiceState.INITIALIZING` state\n    - Set up signal handlers for graceful shutdown\n    - Allow time for the event loop to start\n    - Initialize communication\n    - Call all registered `AIPerfHook.ON_INIT` hooks\n    - Set the service to `ServiceState.READY` state\n    - Set the initialized asyncio event\n    \"\"\"\n    self._state = ServiceState.INITIALIZING\n    # Set up signal handlers for graceful shutdown\n    self._setup_signal_handlers()\n    # Allow time for the event loop to start\n    await asyncio.sleep(0.1)\n\n    # Initialize communication\n    try:\n        self._comms = CommunicationFactory.create_instance(\n            self.service_config.comm_backend,\n            config=self.service_config.comm_config,\n        )\n    except Exception as e:\n        self.logger.exception(\n            \"Failed to create communication for service %s (id: %s)\",\n            self.service_type,\n            self.service_id,\n        )\n        raise CommunicationCreateError from e\n\n    try:\n        await self._comms.initialize()\n    except Exception as e:\n        self.logger.exception(\n            \"Failed to initialize communication for service %s (id: %s)\",\n            self.service_type,\n            self.service_id,\n        )\n        raise ServiceInitializationError from e\n\n    if len(self.required_clients) &gt; 0:\n        # Create the communication clients ahead of time\n        self.logger.debug(\n            \"%s: Creating communication clients (%s)\",\n            self.service_type,\n            self.required_clients,\n        )\n\n        try:\n            await self._comms.create_clients(*self.required_clients)\n        except Exception as e:\n            self.logger.exception(\n                \"Failed to create communication clients for service %s (id: %s)\",\n                self.service_type,\n                self.service_id,\n            )\n            raise CommunicationClientCreationError from e\n\n    # Initialize any derived service components\n    try:\n        await self.run_hooks(AIPerfHook.ON_INIT)\n    except AIPerfMultiError as e:\n        self.logger.exception(\n            \"Failed to initialize service %s (id: %s)\",\n            self.service_type,\n            self.service_id,\n        )\n        raise ServiceInitializationError from e\n\n    await self.set_state(ServiceState.READY)\n\n    self.initialized_event.set()\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.run_forever","title":"<code>run_forever()</code>  <code>async</code>","text":"<p>Run the service in a loop until the stop event is set. This method implements the <code>BaseServiceInterface.run_forever</code> method.</p> <p>This method will: - Call the initialize method to initialize the service - Call all registered <code>AIPerfHook.RUN</code> hooks - Wait for the stop event to be set - Shuts down the service when the stop event is set</p> <p>This method will be called as the main entry point for the service.</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>async def run_forever(self) -&gt; None:\n    \"\"\"Run the service in a loop until the stop event is set. This method implements\n    the `BaseServiceInterface.run_forever` method.\n\n    This method will:\n    - Call the initialize method to initialize the service\n    - Call all registered `AIPerfHook.RUN` hooks\n    - Wait for the stop event to be set\n    - Shuts down the service when the stop event is set\n\n    This method will be called as the main entry point for the service.\n    \"\"\"\n    try:\n        self.logger.debug(\n            \"Running %s service (id: %s)\", self.service_type, self.service_id\n        )\n\n        try:\n            await self.initialize()\n        except Exception as e:\n            self.logger.exception(\n                \"Failed to initialize service %s (id: %s)\",\n                self.service_type,\n                self.service_id,\n            )\n            raise ServiceRunError from e\n\n        try:\n            await self.run_hooks(AIPerfHook.ON_RUN)\n        except AIPerfMultiError as e:\n            self.logger.exception(\n                \"Failed to run service %s (id: %s)\",\n                self.service_type,\n                self.service_id,\n            )\n            raise ServiceRunError from e\n\n    except asyncio.CancelledError:\n        self.logger.debug(\"Service %s execution cancelled\", self.service_type)\n        return\n\n    except Exception as e:\n        self.logger.exception(\"Service %s execution failed:\", self.service_type)\n        _ = await self.set_state(ServiceState.ERROR)\n        raise ServiceRunError(\n            \"Service %s execution failed\", self.service_type\n        ) from e\n\n    await self._forever_loop()\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.set_state","title":"<code>set_state(state)</code>  <code>async</code>","text":"<p>Set the state of the service. This method implements the <code>BaseServiceInterface.set_state</code> method.</p> <p>This method will: - Set the service state to the given state - Call all registered <code>AIPerfHook.ON_SET_STATE</code> hooks</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>async def set_state(self, state: ServiceState) -&gt; None:\n    \"\"\"Set the state of the service. This method implements\n    the `BaseServiceInterface.set_state` method.\n\n    This method will:\n    - Set the service state to the given state\n    - Call all registered `AIPerfHook.ON_SET_STATE` hooks\n    \"\"\"\n    self._state = state\n    await self.run_hooks(AIPerfHook.ON_SET_STATE, state)\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.start","title":"<code>start()</code>  <code>async</code>","text":"<p>Start the service and its components. This method implements the <code>BaseServiceInterface.start</code> method.</p> <p>This method should be called to start the service after it has been initialized and configured.</p> <p>This method will: - Set the service to <code>ServiceState.STARTING</code> state - Call all registered <code>AIPerfHook.ON_START</code> hooks - Set the service to <code>ServiceState.RUNNING</code> state</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>async def start(self) -&gt; None:\n    \"\"\"Start the service and its components. This method implements\n    the `BaseServiceInterface.start` method.\n\n    This method should be called to start the service after it has been initialized\n    and configured.\n\n    This method will:\n    - Set the service to `ServiceState.STARTING` state\n    - Call all registered `AIPerfHook.ON_START` hooks\n    - Set the service to `ServiceState.RUNNING` state\n    \"\"\"\n\n    try:\n        self.logger.debug(\n            \"Starting %s service (id: %s)\", self.service_type, self.service_id\n        )\n        _ = await self.set_state(ServiceState.STARTING)\n\n        await self.run_hooks(AIPerfHook.ON_START)\n\n        _ = await self.set_state(ServiceState.RUNNING)\n\n    except asyncio.CancelledError:\n        self.logger.debug(\"Service %s execution cancelled\", self.service_type)\n\n    except Exception as e:\n        self.logger.exception(\n            \"Failed to start service %s (id: %s)\",\n            self.service_type,\n            self.service_id,\n        )\n        self._state = ServiceState.ERROR\n\n        raise ServiceStartError(\n            \"Failed to start service %s (id: %s)\",\n            self.service_type,\n            self.service_id,\n        ) from e\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.stop","title":"<code>stop()</code>  <code>async</code>","text":"<p>Stop the service and clean up its components. This method implements the <code>BaseServiceInterface.stop</code> method.</p> <p>This method will: - Set the service to <code>ServiceState.STOPPING</code> state - Call all registered <code>AIPerfHook.ON_STOP</code> hooks - Shutdown the service communication component - Call all registered <code>AIPerfHook.ON_CLEANUP</code> hooks - Set the service to <code>ServiceState.STOPPED</code> state</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>async def stop(self) -&gt; None:\n    \"\"\"Stop the service and clean up its components. This method implements\n    the `BaseServiceInterface.stop` method.\n\n    This method will:\n    - Set the service to `ServiceState.STOPPING` state\n    - Call all registered `AIPerfHook.ON_STOP` hooks\n    - Shutdown the service communication component\n    - Call all registered `AIPerfHook.ON_CLEANUP` hooks\n    - Set the service to `ServiceState.STOPPED` state\n    \"\"\"\n    try:\n        if self.state == ServiceState.STOPPED:\n            self.logger.warning(\n                \"Service %s state %s is already STOPPED, ignoring stop request\",\n                self.service_type,\n                self.state,\n            )\n            return\n\n        # ignore if we were unable to send the STOPPING state message\n        _ = await self.set_state(ServiceState.STOPPING)\n\n        # Signal the run method to exit if it hasn't already\n        if not self.stop_event.is_set():\n            self.stop_event.set()\n\n        # Custom stop logic implemented by derived classes\n        with contextlib.suppress(asyncio.CancelledError):\n            await self.run_hooks(AIPerfHook.ON_STOP)\n\n        # Shutdown communication component\n        if self._comms and not self._comms.is_shutdown:\n            await self._comms.shutdown()\n\n        # Custom cleanup logic implemented by derived classes\n        with contextlib.suppress(asyncio.CancelledError):\n            await self.run_hooks(AIPerfHook.ON_CLEANUP)\n\n        # Set the state to STOPPED. Communications are shutdown, so we don't need to\n        # publish a status message\n        self._state = ServiceState.STOPPED\n        self.logger.debug(\n            \"Service %s (id: %s) stopped\", self.service_type, self.service_id\n        )\n\n    except Exception as e:\n        self.logger.exception(\n            \"Failed to stop service %s (id: %s)\",\n            self.service_type,\n            self.service_id,\n        )\n        self._state = ServiceState.ERROR\n        raise ServiceStopError(\n            \"Failed to stop service %s (id: %s)\",\n            self.service_type,\n            self.service_id,\n        ) from e\n</code></pre>"},{"location":"api/#aiperfcommonservicebase_service_interface","title":"aiperf.common.service.base_service_interface","text":""},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface","title":"<code>BaseServiceInterface</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base interface for all services.</p> <p>This class provides the base foundation for which every service should provide. Some methods are required to be implemented by derived classes, while others are meant to be implemented by the base class.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>class BaseServiceInterface(ABC):\n    \"\"\"Base interface for all services.\n\n    This class provides the base foundation for which every service should provide. Some\n    methods are required to be implemented by derived classes, while others are\n    meant to be implemented by the base class.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def required_clients(self) -&gt; list[ClientType]:\n        \"\"\"The communication clients required by the service. If nothing is returned,\n        the service will be responsible for creating its own clients.\n\n        This property should be implemented by derived classes to specify the\n        communication clients that the service requires.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type/name of the service.\n\n        This property should be implemented by derived classes to specify the\n        type/name of the service.\"\"\"\n        # TODO: We can do this better by using a decorator to set the service type\n        pass\n\n    @abstractmethod\n    async def set_state(self, state: ServiceState) -&gt; None:\n        \"\"\"Set the state of the service.\n\n        This method will be implemented by the base class, and extra\n        functionality can be added by derived classes via the `@on_set_state`\n        decorator.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize the service.\n\n        This method will be implemented by the base class.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def start(self) -&gt; None:\n        \"\"\"Start the service. It should be called after the service has been initialized\n        and configured.\n\n        This method will be implemented by the base class, and extra\n        functionality can be added by derived classes via the `@on_start`\n        decorator.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def stop(self) -&gt; None:\n        \"\"\"Stop the service.\n\n        This method will be implemented by the base class, and extra\n        functionality can be added by derived classes via the `@on_stop`\n        decorator.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def configure(self, message: Message) -&gt; None:\n        \"\"\"Configure the service with the given configuration.\n\n        This method will be implemented by the base class, and extra\n        functionality can be added by derived classes via the `@on_configure`\n        decorator.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def run_forever(self) -&gt; None:\n        \"\"\"Run the service. This method will be the primary entry point for the service\n        and will be called by the bootstrap script. It should not return until the\n        service is completely shutdown.\n\n        This method will be implemented by the base class. Any additional\n        functionality can be added by derived classes via the `@on_run`\n        decorator.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def _forever_loop(self) -&gt; None:\n        \"\"\"Run the service in a loop until the stop event is set. This method will be\n        called by the `run` method to allow the service to run indefinitely.\n\n        This method will be implemented by the base class, and is not expected to be\n        overridden by derived classes.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.required_clients","title":"<code>required_clients</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The communication clients required by the service. If nothing is returned, the service will be responsible for creating its own clients.</p> <p>This property should be implemented by derived classes to specify the communication clients that the service requires.</p>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.service_type","title":"<code>service_type</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The type/name of the service.</p> <p>This property should be implemented by derived classes to specify the type/name of the service.</p>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.configure","title":"<code>configure(message)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Configure the service with the given configuration.</p> <p>This method will be implemented by the base class, and extra functionality can be added by derived classes via the <code>@on_configure</code> decorator.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>@abstractmethod\nasync def configure(self, message: Message) -&gt; None:\n    \"\"\"Configure the service with the given configuration.\n\n    This method will be implemented by the base class, and extra\n    functionality can be added by derived classes via the `@on_configure`\n    decorator.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.initialize","title":"<code>initialize()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Initialize the service.</p> <p>This method will be implemented by the base class.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>@abstractmethod\nasync def initialize(self) -&gt; None:\n    \"\"\"Initialize the service.\n\n    This method will be implemented by the base class.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.run_forever","title":"<code>run_forever()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Run the service. This method will be the primary entry point for the service and will be called by the bootstrap script. It should not return until the service is completely shutdown.</p> <p>This method will be implemented by the base class. Any additional functionality can be added by derived classes via the <code>@on_run</code> decorator.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>@abstractmethod\nasync def run_forever(self) -&gt; None:\n    \"\"\"Run the service. This method will be the primary entry point for the service\n    and will be called by the bootstrap script. It should not return until the\n    service is completely shutdown.\n\n    This method will be implemented by the base class. Any additional\n    functionality can be added by derived classes via the `@on_run`\n    decorator.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.set_state","title":"<code>set_state(state)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Set the state of the service.</p> <p>This method will be implemented by the base class, and extra functionality can be added by derived classes via the <code>@on_set_state</code> decorator.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>@abstractmethod\nasync def set_state(self, state: ServiceState) -&gt; None:\n    \"\"\"Set the state of the service.\n\n    This method will be implemented by the base class, and extra\n    functionality can be added by derived classes via the `@on_set_state`\n    decorator.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.start","title":"<code>start()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Start the service. It should be called after the service has been initialized and configured.</p> <p>This method will be implemented by the base class, and extra functionality can be added by derived classes via the <code>@on_start</code> decorator.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>@abstractmethod\nasync def start(self) -&gt; None:\n    \"\"\"Start the service. It should be called after the service has been initialized\n    and configured.\n\n    This method will be implemented by the base class, and extra\n    functionality can be added by derived classes via the `@on_start`\n    decorator.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.stop","title":"<code>stop()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Stop the service.</p> <p>This method will be implemented by the base class, and extra functionality can be added by derived classes via the <code>@on_stop</code> decorator.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>@abstractmethod\nasync def stop(self) -&gt; None:\n    \"\"\"Stop the service.\n\n    This method will be implemented by the base class, and extra\n    functionality can be added by derived classes via the `@on_stop`\n    decorator.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperfcommontokenizer","title":"aiperf.common.tokenizer","text":""},{"location":"api/#aiperf.common.tokenizer.Tokenizer","title":"<code>Tokenizer</code>","text":"<p>This class provides a simplified interface for using Huggingface tokenizers, with default arguments for common operations.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>class Tokenizer:\n    \"\"\"\n    This class provides a simplified interface for using Huggingface\n    tokenizers, with default arguments for common operations.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"\n        Initialize the tokenizer with default values for call, encode, and decode.\n        \"\"\"\n        self._tokenizer = None\n        self._call_args = {\"add_special_tokens\": False}\n        self._encode_args = {\"add_special_tokens\": False}\n        self._decode_args = {\"skip_special_tokens\": True}\n\n    @classmethod\n    def from_pretrained(\n        cls,\n        name: str,\n        trust_remote_code: bool = False,\n        revision: str = \"main\",\n    ) -&gt; \"Tokenizer\":\n        \"\"\"\n        Factory to load a tokenizer for the given pretrained model name.\n\n        Args:\n            name: The name or path of the pretrained tokenizer model.\n            trust_remote_code: Whether to trust remote code when loading the tokenizer.\n            revision: The specific model version to use.\n        \"\"\"\n        tokenizer = cls()\n        tokenizer._set_tokenizer(name, trust_remote_code, revision)\n        return tokenizer\n\n    def _set_tokenizer(self, name: str, trust_remote_code: bool, revision: str) -&gt; None:\n        \"\"\"\n        Set the tokenizer from Huggingface.co or local filesystem.\n\n        Args:\n            name: The name or path of the tokenizer.\n            trust_remote_code: Whether to trust remote code when loading the tokenizer.\n            revision: The specific model version to use.\n        \"\"\"\n        try:\n            # Silence tokenizer warning on import and first use\n            with (\n                contextlib.redirect_stdout(io.StringIO()) as _,\n                contextlib.redirect_stderr(io.StringIO()),\n            ):\n                from transformers import AutoTokenizer\n                from transformers import logging as token_logger\n\n                token_logger.set_verbosity_error()\n                tokenizer = AutoTokenizer.from_pretrained(\n                    name, trust_remote_code=trust_remote_code, revision=revision\n                )\n        except Exception as e:\n            raise TokenizerInitializationError(e) from e\n        self._tokenizer = tokenizer\n\n    def __call__(self, text, **kwargs) -&gt; \"BatchEncoding\":\n        \"\"\"\n        Call the underlying Huggingface tokenizer with default arguments,\n        which can be overridden by kwargs.\n\n        Args:\n            text: The input text to tokenize.\n\n        Returns:\n            A BatchEncoding object containing the tokenized output.\n        \"\"\"\n        if self._tokenizer is None:\n            raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n        return self._tokenizer(text, **{**self._call_args, **kwargs})\n\n    def encode(self, text, **kwargs) -&gt; list[int]:\n        \"\"\"\n        Encode the input text into a list of token IDs.\n\n        This method calls the underlying Huggingface tokenizer's encode\n        method with default arguments, which can be overridden by kwargs.\n\n        Args:\n            text: The input text to encode.\n\n        Returns:\n            A list of token IDs.\n        \"\"\"\n        if self._tokenizer is None:\n            raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n        return self._tokenizer.encode(text, **{**self._encode_args, **kwargs})\n\n    def decode(self, token_ids, **kwargs) -&gt; str:\n        \"\"\"\n        Decode a list of token IDs back into a string.\n\n        This method calls the underlying Huggingface tokenizer's decode\n        method with default arguments, which can be overridden by kwargs.\n\n        Args:\n            token_ids: A list of token IDs to decode.\n\n        Returns:\n            The decoded string.\n        \"\"\"\n        if self._tokenizer is None:\n            raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n        return self._tokenizer.decode(token_ids, **{**self._decode_args, **kwargs})\n\n    def bos_token_id(self) -&gt; int:\n        \"\"\"\n        Return the beginning-of-sequence (BOS) token ID.\n        \"\"\"\n        if self._tokenizer is None:\n            raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n        return self._tokenizer.bos_token_id\n\n    def __repr__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the underlying tokenizer.\n\n        Returns:\n            The string representation of the tokenizer.\n        \"\"\"\n        return self._tokenizer.__repr__()\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Return a user-friendly string representation of the underlying tokenizer.\n\n        Returns:\n            The string representation of the tokenizer.\n        \"\"\"\n        return self._tokenizer.__str__()\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.__call__","title":"<code>__call__(text, **kwargs)</code>","text":"<p>Call the underlying Huggingface tokenizer with default arguments, which can be overridden by kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>The input text to tokenize.</p> required <p>Returns:</p> Type Description <code>BatchEncoding</code> <p>A BatchEncoding object containing the tokenized output.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def __call__(self, text, **kwargs) -&gt; \"BatchEncoding\":\n    \"\"\"\n    Call the underlying Huggingface tokenizer with default arguments,\n    which can be overridden by kwargs.\n\n    Args:\n        text: The input text to tokenize.\n\n    Returns:\n        A BatchEncoding object containing the tokenized output.\n    \"\"\"\n    if self._tokenizer is None:\n        raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n    return self._tokenizer(text, **{**self._call_args, **kwargs})\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the tokenizer with default values for call, encode, and decode.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"\n    Initialize the tokenizer with default values for call, encode, and decode.\n    \"\"\"\n    self._tokenizer = None\n    self._call_args = {\"add_special_tokens\": False}\n    self._encode_args = {\"add_special_tokens\": False}\n    self._decode_args = {\"skip_special_tokens\": True}\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the underlying tokenizer.</p> <p>Returns:</p> Type Description <code>str</code> <p>The string representation of the tokenizer.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"\n    Return a string representation of the underlying tokenizer.\n\n    Returns:\n        The string representation of the tokenizer.\n    \"\"\"\n    return self._tokenizer.__repr__()\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.__str__","title":"<code>__str__()</code>","text":"<p>Return a user-friendly string representation of the underlying tokenizer.</p> <p>Returns:</p> Type Description <code>str</code> <p>The string representation of the tokenizer.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Return a user-friendly string representation of the underlying tokenizer.\n\n    Returns:\n        The string representation of the tokenizer.\n    \"\"\"\n    return self._tokenizer.__str__()\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.bos_token_id","title":"<code>bos_token_id()</code>","text":"<p>Return the beginning-of-sequence (BOS) token ID.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def bos_token_id(self) -&gt; int:\n    \"\"\"\n    Return the beginning-of-sequence (BOS) token ID.\n    \"\"\"\n    if self._tokenizer is None:\n        raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n    return self._tokenizer.bos_token_id\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.decode","title":"<code>decode(token_ids, **kwargs)</code>","text":"<p>Decode a list of token IDs back into a string.</p> <p>This method calls the underlying Huggingface tokenizer's decode method with default arguments, which can be overridden by kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>token_ids</code> <p>A list of token IDs to decode.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The decoded string.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def decode(self, token_ids, **kwargs) -&gt; str:\n    \"\"\"\n    Decode a list of token IDs back into a string.\n\n    This method calls the underlying Huggingface tokenizer's decode\n    method with default arguments, which can be overridden by kwargs.\n\n    Args:\n        token_ids: A list of token IDs to decode.\n\n    Returns:\n        The decoded string.\n    \"\"\"\n    if self._tokenizer is None:\n        raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n    return self._tokenizer.decode(token_ids, **{**self._decode_args, **kwargs})\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.encode","title":"<code>encode(text, **kwargs)</code>","text":"<p>Encode the input text into a list of token IDs.</p> <p>This method calls the underlying Huggingface tokenizer's encode method with default arguments, which can be overridden by kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>The input text to encode.</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>A list of token IDs.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def encode(self, text, **kwargs) -&gt; list[int]:\n    \"\"\"\n    Encode the input text into a list of token IDs.\n\n    This method calls the underlying Huggingface tokenizer's encode\n    method with default arguments, which can be overridden by kwargs.\n\n    Args:\n        text: The input text to encode.\n\n    Returns:\n        A list of token IDs.\n    \"\"\"\n    if self._tokenizer is None:\n        raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n    return self._tokenizer.encode(text, **{**self._encode_args, **kwargs})\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.from_pretrained","title":"<code>from_pretrained(name, trust_remote_code=False, revision='main')</code>  <code>classmethod</code>","text":"<p>Factory to load a tokenizer for the given pretrained model name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name or path of the pretrained tokenizer model.</p> required <code>trust_remote_code</code> <code>bool</code> <p>Whether to trust remote code when loading the tokenizer.</p> <code>False</code> <code>revision</code> <code>str</code> <p>The specific model version to use.</p> <code>'main'</code> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>@classmethod\ndef from_pretrained(\n    cls,\n    name: str,\n    trust_remote_code: bool = False,\n    revision: str = \"main\",\n) -&gt; \"Tokenizer\":\n    \"\"\"\n    Factory to load a tokenizer for the given pretrained model name.\n\n    Args:\n        name: The name or path of the pretrained tokenizer model.\n        trust_remote_code: Whether to trust remote code when loading the tokenizer.\n        revision: The specific model version to use.\n    \"\"\"\n    tokenizer = cls()\n    tokenizer._set_tokenizer(name, trust_remote_code, revision)\n    return tokenizer\n</code></pre>"},{"location":"api/#aiperfcommonutils","title":"aiperf.common.utils","text":""},{"location":"api/#aiperf.common.utils.call_all_functions","title":"<code>call_all_functions(funcs, *args, **kwargs)</code>  <code>async</code>","text":"<p>Call all functions in the list with the given name.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <p>The object to call the functions on.</p> required <code>func_names</code> <p>The names of the functions to call.</p> required <code>*args</code> <p>The arguments to pass to the functions.</p> <code>()</code> <code>**kwargs</code> <p>The keyword arguments to pass to the functions.</p> <code>{}</code> <p>Raises:</p> Type Description <code>AIPerfMultiError</code> <p>If any of the functions raise an exception.</p> Source code in <code>aiperf/common/utils.py</code> <pre><code>async def call_all_functions(funcs: list[Callable], *args, **kwargs) -&gt; None:\n    \"\"\"Call all functions in the list with the given name.\n\n    Args:\n        obj: The object to call the functions on.\n        func_names: The names of the functions to call.\n        *args: The arguments to pass to the functions.\n        **kwargs: The keyword arguments to pass to the functions.\n\n    Raises:\n        AIPerfMultiError: If any of the functions raise an exception.\n    \"\"\"\n\n    exceptions = []\n    for func in funcs:\n        try:\n            if inspect.iscoroutinefunction(func):\n                await func(*args, **kwargs)\n            else:\n                func(*args, **kwargs)\n        except Exception as e:\n            # TODO: error handling, logging\n            traceback.print_exc()\n            exceptions.append(e)\n\n    if len(exceptions) &gt; 0:\n        raise AIPerfMultiError(\"Errors calling functions\", exceptions)\n</code></pre>"},{"location":"api/#aiperf.common.utils.call_all_functions_self","title":"<code>call_all_functions_self(self_, funcs, *args, **kwargs)</code>  <code>async</code>","text":"<p>Call all functions in the list with the given name.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <p>The object to call the functions on.</p> required <code>func_names</code> <p>The names of the functions to call.</p> required <code>*args</code> <p>The arguments to pass to the functions.</p> <code>()</code> <code>**kwargs</code> <p>The keyword arguments to pass to the functions.</p> <code>{}</code> <p>Raises:</p> Type Description <code>AIPerfMultiError</code> <p>If any of the functions raise an exception.</p> Source code in <code>aiperf/common/utils.py</code> <pre><code>async def call_all_functions_self(\n    self_: object, funcs: list[Callable], *args, **kwargs\n) -&gt; None:\n    \"\"\"Call all functions in the list with the given name.\n\n    Args:\n        obj: The object to call the functions on.\n        func_names: The names of the functions to call.\n        *args: The arguments to pass to the functions.\n        **kwargs: The keyword arguments to pass to the functions.\n\n    Raises:\n        AIPerfMultiError: If any of the functions raise an exception.\n    \"\"\"\n\n    exceptions = []\n    for func in funcs:\n        try:\n            if inspect.iscoroutinefunction(func):\n                await func(self_, *args, **kwargs)\n            else:\n                func(self_, *args, **kwargs)\n        except Exception as e:\n            # TODO: error handling, logging\n            traceback.print_exc()\n            exceptions.append(e)\n\n    if len(exceptions) &gt; 0:\n        raise AIPerfMultiError(\"Errors calling functions\", exceptions)\n</code></pre>"},{"location":"api/#aiperfservicesdatasetdataset_manager","title":"aiperf.services.dataset.dataset_manager","text":""},{"location":"api/#aiperf.services.dataset.dataset_manager.DatasetManager","title":"<code>DatasetManager</code>","text":"<p>               Bases: <code>BaseComponentService</code></p> <p>The DatasetManager primary responsibility is to manage the data generation or acquisition. For synthetic generation, it contains the code to generate the prompts or tokens. It will have an API for dataset acquisition of a dataset if available in a remote repository or database.</p> Source code in <code>aiperf/services/dataset/dataset_manager.py</code> <pre><code>@ServiceFactory.register(ServiceType.DATASET_MANAGER)\nclass DatasetManager(BaseComponentService):\n    \"\"\"\n    The DatasetManager primary responsibility is to manage the data generation or acquisition.\n    For synthetic generation, it contains the code to generate the prompts or tokens.\n    It will have an API for dataset acquisition of a dataset if available in a remote repository or database.\n    \"\"\"\n\n    def __init__(\n        self,\n        service_config: ServiceConfig,\n        service_id: str | None = None,\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Initializing dataset manager\")\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.DATASET_MANAGER\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize dataset manager-specific components.\"\"\"\n        self.logger.debug(\"Initializing dataset manager\")\n        # TODO: Implement dataset manager initialization\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the dataset manager.\"\"\"\n        self.logger.debug(\"Starting dataset manager\")\n        # TODO: Implement dataset manager start\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the dataset manager.\"\"\"\n        self.logger.debug(\"Stopping dataset manager\")\n        # TODO: Implement dataset manager stop\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up dataset manager-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up dataset manager\")\n        # TODO: Implement dataset manager cleanup\n\n    @on_configure\n    async def _configure(self, payload: BasePayload) -&gt; None:\n        \"\"\"Configure the dataset manager.\"\"\"\n        self.logger.debug(f\"Configuring dataset manager with payload: {payload}\")\n</code></pre>"},{"location":"api/#aiperf.services.dataset.dataset_manager.DatasetManager.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.dataset.dataset_manager.main","title":"<code>main()</code>","text":"<p>Main entry point for the dataset manager.</p> Source code in <code>aiperf/services/dataset/dataset_manager.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the dataset manager.\"\"\"\n\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(DatasetManager)\n</code></pre>"},{"location":"api/#aiperfservicesdatasetgeneratoraudio","title":"aiperf.services.dataset.generator.audio","text":""},{"location":"api/#aiperf.services.dataset.generator.audio.AudioGenerator","title":"<code>AudioGenerator</code>","text":"<p>A class for generating synthetic audio data.</p> <p>This class provides methods to create audio samples with specified characteristics such as format (WAV, MP3), length, sampling rate, bit depth, and number of channels. It supports validation of audio parameters to ensure compatibility with chosen formats.</p> Source code in <code>aiperf/services/dataset/generator/audio.py</code> <pre><code>class AudioGenerator:\n    \"\"\"\n    A class for generating synthetic audio data.\n\n    This class provides methods to create audio samples with specified\n    characteristics such as format (WAV, MP3), length, sampling rate,\n    bit depth, and number of channels. It supports validation of audio\n    parameters to ensure compatibility with chosen formats.\n    \"\"\"\n\n    @staticmethod\n    def _sample_positive_normal(\n        mean: float, stddev: float, min_value: float = 0.1\n    ) -&gt; float:\n        \"\"\"\n        Sample from a normal distribution ensuring positive values without distorting the distribution.\n        Uses rejection sampling to maintain the proper shape of the distribution.\n\n        Args:\n            mean: Mean value for the normal distribution\n            stddev: Standard deviation for the normal distribution\n            min_value: Minimum acceptable value\n\n        Returns:\n            A positive sample from the normal distribution\n\n        Raises:\n            GeneratorConfigurationError: If mean is less than min_value\n        \"\"\"\n        if mean &lt; min_value:\n            raise GeneratorConfigurationError(\n                f\"Mean value ({mean}) must be greater than min_value ({min_value})\"\n            )\n\n        while True:\n            sample = np.random.normal(mean, stddev)\n            if sample &gt;= min_value:\n                return sample\n\n    @staticmethod\n    def _validate_sampling_rate(sampling_rate: int, audio_format: AudioFormat) -&gt; None:\n        \"\"\"\n        Validate sampling rate for the given output format.\n\n        Args:\n            sampling_rate: Sampling rate in Hz\n            audio_format: Audio format\n\n        Raises:\n            GeneratorConfigurationError: If sampling rate is not supported for the given format\n        \"\"\"\n        if (\n            audio_format == AudioFormat.MP3\n            and sampling_rate not in MP3_SUPPORTED_SAMPLE_RATES\n        ):\n            supported_rates = sorted(MP3_SUPPORTED_SAMPLE_RATES)\n            raise GeneratorConfigurationError(\n                f\"MP3 format only supports the following sample rates (in Hz): {supported_rates}. \"\n                f\"Got {sampling_rate} Hz. Please choose a supported rate from the list.\"\n            )\n\n    @staticmethod\n    def _validate_bit_depth(bit_depth: int) -&gt; None:\n        \"\"\"\n        Validate bit depth is supported.\n\n        Args:\n            bit_depth: Bit depth in bits\n\n        Raises:\n            GeneratorConfigurationError: If bit depth is not supported\n        \"\"\"\n        if bit_depth not in SUPPORTED_BIT_DEPTHS:\n            supported_depths = sorted(SUPPORTED_BIT_DEPTHS.keys())\n            raise GeneratorConfigurationError(\n                f\"Unsupported bit depth: {bit_depth}. \"\n                f\"Supported bit depths are: {supported_depths}\"\n            )\n\n    # TODO: uncomment when ConfigAudio is implemented\n    # @staticmethod\n    # def create_synthetic_audio(config: ConfigAudio) -&gt; str:\n    @staticmethod\n    def create_synthetic_audio(config) -&gt; str:\n        \"\"\"\n        Generate audio data with specified parameters.\n\n        Args:\n            config: ConfigAudio object containing audio generation parameters\n\n        Returns:\n            Data URI containing base64-encoded audio data with format specification\n\n        Raises:\n            GeneratorConfigurationError: If any of the following conditions are met:\n                - audio_length_mean is less than 0.1 seconds\n                - channels is not 1 (mono) or 2 (stereo)\n                - sampling rate is not supported for MP3 format\n                - bit depth is not supported (must be 8, 16, 24, or 32)\n                - audio format is not supported (must be 'wav' or 'mp3')\n        \"\"\"\n        if config.num_channels not in (1, 2):\n            raise GeneratorConfigurationError(\n                \"Only mono (1) and stereo (2) channels are supported\"\n            )\n\n        # Sample audio length (in seconds) using rejection sampling\n        audio_length = AudioGenerator._sample_positive_normal(\n            config.length.mean, config.length.stddev\n        )\n\n        # Randomly select sampling rate and bit depth\n        sampling_rate = int(\n            np.random.choice(config.sample_rates) * 1000\n        )  # Convert kHz to Hz\n        bit_depth = np.random.choice(config.depths)\n\n        # Validate sampling rate and bit depth\n        AudioGenerator._validate_sampling_rate(sampling_rate, config.format)\n        AudioGenerator._validate_bit_depth(bit_depth)\n\n        # Generate synthetic audio data (gaussian noise)\n        num_samples = int(audio_length * sampling_rate)\n        audio_data = np.random.normal(\n            0,\n            0.3,\n            (\n                (num_samples, config.num_channels)\n                if config.num_channels &gt; 1\n                else num_samples\n            ),\n        )\n\n        # Ensure the signal is within [-1, 1] range\n        audio_data = np.clip(audio_data, -1, 1)\n\n        # Scale to the appropriate bit depth range\n        max_val = 2 ** (bit_depth - 1) - 1\n        numpy_type, _ = SUPPORTED_BIT_DEPTHS[bit_depth]\n        audio_data = (audio_data * max_val).astype(numpy_type)\n\n        # Write audio using soundfile\n        output_buffer = io.BytesIO()\n\n        # Select appropriate subtype based on format\n        if config.format == AudioFormat.MP3:\n            subtype = \"MPEG_LAYER_III\"\n        elif config.format == AudioFormat.WAV:\n            _, subtype = SUPPORTED_BIT_DEPTHS[bit_depth]\n        else:\n            raise GeneratorConfigurationError(\n                f\"Unsupported audio format: {config.format.name}. \"\n                f\"Supported formats are: {AudioFormat.WAV.name}, {AudioFormat.MP3.name}\"\n            )\n\n        sf.write(\n            output_buffer,\n            audio_data,\n            sampling_rate,\n            format=config.format.name,\n            subtype=subtype,\n        )\n        audio_bytes = output_buffer.getvalue()\n\n        # Encode to base64 with data URI scheme: \"{format},{data}\"\n        base64_data = base64.b64encode(audio_bytes).decode(\"utf-8\")\n        return f\"{config.format.name.lower()},{base64_data}\"\n</code></pre>"},{"location":"api/#aiperf.services.dataset.generator.audio.AudioGenerator.create_synthetic_audio","title":"<code>create_synthetic_audio(config)</code>  <code>staticmethod</code>","text":"<p>Generate audio data with specified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <p>ConfigAudio object containing audio generation parameters</p> required <p>Returns:</p> Type Description <code>str</code> <p>Data URI containing base64-encoded audio data with format specification</p> <p>Raises:</p> Type Description <code>GeneratorConfigurationError</code> <p>If any of the following conditions are met: - audio_length_mean is less than 0.1 seconds - channels is not 1 (mono) or 2 (stereo) - sampling rate is not supported for MP3 format - bit depth is not supported (must be 8, 16, 24, or 32) - audio format is not supported (must be 'wav' or 'mp3')</p> Source code in <code>aiperf/services/dataset/generator/audio.py</code> <pre><code>@staticmethod\ndef create_synthetic_audio(config) -&gt; str:\n    \"\"\"\n    Generate audio data with specified parameters.\n\n    Args:\n        config: ConfigAudio object containing audio generation parameters\n\n    Returns:\n        Data URI containing base64-encoded audio data with format specification\n\n    Raises:\n        GeneratorConfigurationError: If any of the following conditions are met:\n            - audio_length_mean is less than 0.1 seconds\n            - channels is not 1 (mono) or 2 (stereo)\n            - sampling rate is not supported for MP3 format\n            - bit depth is not supported (must be 8, 16, 24, or 32)\n            - audio format is not supported (must be 'wav' or 'mp3')\n    \"\"\"\n    if config.num_channels not in (1, 2):\n        raise GeneratorConfigurationError(\n            \"Only mono (1) and stereo (2) channels are supported\"\n        )\n\n    # Sample audio length (in seconds) using rejection sampling\n    audio_length = AudioGenerator._sample_positive_normal(\n        config.length.mean, config.length.stddev\n    )\n\n    # Randomly select sampling rate and bit depth\n    sampling_rate = int(\n        np.random.choice(config.sample_rates) * 1000\n    )  # Convert kHz to Hz\n    bit_depth = np.random.choice(config.depths)\n\n    # Validate sampling rate and bit depth\n    AudioGenerator._validate_sampling_rate(sampling_rate, config.format)\n    AudioGenerator._validate_bit_depth(bit_depth)\n\n    # Generate synthetic audio data (gaussian noise)\n    num_samples = int(audio_length * sampling_rate)\n    audio_data = np.random.normal(\n        0,\n        0.3,\n        (\n            (num_samples, config.num_channels)\n            if config.num_channels &gt; 1\n            else num_samples\n        ),\n    )\n\n    # Ensure the signal is within [-1, 1] range\n    audio_data = np.clip(audio_data, -1, 1)\n\n    # Scale to the appropriate bit depth range\n    max_val = 2 ** (bit_depth - 1) - 1\n    numpy_type, _ = SUPPORTED_BIT_DEPTHS[bit_depth]\n    audio_data = (audio_data * max_val).astype(numpy_type)\n\n    # Write audio using soundfile\n    output_buffer = io.BytesIO()\n\n    # Select appropriate subtype based on format\n    if config.format == AudioFormat.MP3:\n        subtype = \"MPEG_LAYER_III\"\n    elif config.format == AudioFormat.WAV:\n        _, subtype = SUPPORTED_BIT_DEPTHS[bit_depth]\n    else:\n        raise GeneratorConfigurationError(\n            f\"Unsupported audio format: {config.format.name}. \"\n            f\"Supported formats are: {AudioFormat.WAV.name}, {AudioFormat.MP3.name}\"\n        )\n\n    sf.write(\n        output_buffer,\n        audio_data,\n        sampling_rate,\n        format=config.format.name,\n        subtype=subtype,\n    )\n    audio_bytes = output_buffer.getvalue()\n\n    # Encode to base64 with data URI scheme: \"{format},{data}\"\n    base64_data = base64.b64encode(audio_bytes).decode(\"utf-8\")\n    return f\"{config.format.name.lower()},{base64_data}\"\n</code></pre>"},{"location":"api/#aiperfservicesdatasetgeneratorimage","title":"aiperf.services.dataset.generator.image","text":""},{"location":"api/#aiperf.services.dataset.generator.image.ImageGenerator","title":"<code>ImageGenerator</code>","text":"<p>A class that generates images from source images.</p> <p>This class provides methods to create synthetic images by resizing source images (located in the 'assets/source_images' directory) to specified dimensions and converting them to a chosen image format (e.g., PNG, JPEG). The dimensions can be randomized based on mean and standard deviation values.</p> Source code in <code>aiperf/services/dataset/generator/image.py</code> <pre><code>class ImageGenerator:\n    \"\"\"A class that generates images from source images.\n\n    This class provides methods to create synthetic images by resizing\n    source images (located in the 'assets/source_images' directory)\n    to specified dimensions and converting them to a chosen image format (e.g., PNG, JPEG).\n    The dimensions can be randomized based on mean and standard deviation values.\n    \"\"\"\n\n    @classmethod\n    def create_synthetic_image(\n        cls,\n        image_width_mean: int,\n        image_width_stddev: int,\n        image_height_mean: int,\n        image_height_stddev: int,\n        image_format: ImageFormat | None = None,\n    ) -&gt; str:\n        \"\"\"Generate an image with the provided parameters.\n\n        Args:\n            image_width_mean: The mean width of the image.\n            image_width_stddev: The standard deviation of the image width.\n            image_height_mean: The mean height of the image.\n            image_height_stddev: The standard deviation of the image height.\n            image_format: The format of the image.\n\n        Returns:\n            A base64 encoded string of the generated image.\n        \"\"\"\n        if image_format is None:\n            image_format = random.choice(list(ImageFormat))\n        width = cls._sample_random_positive_integer(\n            image_width_mean, image_width_stddev\n        )\n        height = cls._sample_random_positive_integer(\n            image_height_mean, image_height_stddev\n        )\n\n        image = cls._sample_source_image()\n        image = image.resize(size=(width, height))\n        base64_image = utils.encode_image(image, image_format.name)\n\n        return f\"data:image/{image_format.name.lower()};base64,{base64_image}\"\n\n    @classmethod\n    def _sample_source_image(cls):\n        \"\"\"Sample one image among the source images.\n\n        Returns:\n            A PIL Image object randomly selected from the source images.\n        \"\"\"\n        filepath = Path(__file__).parent.resolve() / \"assets\" / \"source_images\" / \"*\"\n        filenames = glob.glob(str(filepath))\n        if not filenames:\n            raise ValueError(f\"No source images found in '{filepath}'\")\n        return Image.open(random.choice(filenames))\n\n    @classmethod\n    def _sample_random_positive_integer(cls, mean: int, stddev: int) -&gt; int:\n        \"\"\"Sample a random positive integer from a Gaussian distribution.\n\n        Args:\n            mean: The mean of the Gaussian distribution.\n            stddev: The standard deviation of the Gaussian distribution.\n\n        Returns:\n            A positive integer sampled from the distribution. If the sampled\n            number is zero, it returns 1.\n        \"\"\"\n        n = int(abs(random.gauss(mean, stddev)))\n        return n if n != 0 else 1  # avoid zero\n</code></pre>"},{"location":"api/#aiperf.services.dataset.generator.image.ImageGenerator.create_synthetic_image","title":"<code>create_synthetic_image(image_width_mean, image_width_stddev, image_height_mean, image_height_stddev, image_format=None)</code>  <code>classmethod</code>","text":"<p>Generate an image with the provided parameters.</p> <p>Parameters:</p> Name Type Description Default <code>image_width_mean</code> <code>int</code> <p>The mean width of the image.</p> required <code>image_width_stddev</code> <code>int</code> <p>The standard deviation of the image width.</p> required <code>image_height_mean</code> <code>int</code> <p>The mean height of the image.</p> required <code>image_height_stddev</code> <code>int</code> <p>The standard deviation of the image height.</p> required <code>image_format</code> <code>ImageFormat | None</code> <p>The format of the image.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A base64 encoded string of the generated image.</p> Source code in <code>aiperf/services/dataset/generator/image.py</code> <pre><code>@classmethod\ndef create_synthetic_image(\n    cls,\n    image_width_mean: int,\n    image_width_stddev: int,\n    image_height_mean: int,\n    image_height_stddev: int,\n    image_format: ImageFormat | None = None,\n) -&gt; str:\n    \"\"\"Generate an image with the provided parameters.\n\n    Args:\n        image_width_mean: The mean width of the image.\n        image_width_stddev: The standard deviation of the image width.\n        image_height_mean: The mean height of the image.\n        image_height_stddev: The standard deviation of the image height.\n        image_format: The format of the image.\n\n    Returns:\n        A base64 encoded string of the generated image.\n    \"\"\"\n    if image_format is None:\n        image_format = random.choice(list(ImageFormat))\n    width = cls._sample_random_positive_integer(\n        image_width_mean, image_width_stddev\n    )\n    height = cls._sample_random_positive_integer(\n        image_height_mean, image_height_stddev\n    )\n\n    image = cls._sample_source_image()\n    image = image.resize(size=(width, height))\n    base64_image = utils.encode_image(image, image_format.name)\n\n    return f\"data:image/{image_format.name.lower()};base64,{base64_image}\"\n</code></pre>"},{"location":"api/#aiperfservicesdatasetgeneratorprompt","title":"aiperf.services.dataset.generator.prompt","text":""},{"location":"api/#aiperf.services.dataset.generator.prompt.PromptGenerator","title":"<code>PromptGenerator</code>","text":"<p>A class for generating synthetic prompts from a text corpus.</p> <p>This class loads a text corpus (e.g., Shakespearean text), tokenizes it, and uses the tokenized corpus to generate synthetic prompts of specified lengths. It supports generating prompts with a target number of tokens (with optional randomization around a mean and standard deviation) and can reuse previously generated token blocks to optimize generation for certain use cases. It also allows for the creation of a pool of prefix prompts that can be randomly selected.</p> Source code in <code>aiperf/services/dataset/generator/prompt.py</code> <pre><code>class PromptGenerator:\n    \"\"\"A class for generating synthetic prompts from a text corpus.\n\n    This class loads a text corpus (e.g., Shakespearean text), tokenizes it,\n    and uses the tokenized corpus to generate synthetic prompts of specified\n    lengths. It supports generating prompts with a target number of tokens\n    (with optional randomization around a mean and standard deviation) and\n    can reuse previously generated token blocks to optimize generation for\n    certain use cases. It also allows for the creation of a pool of prefix\n    prompts that can be randomly selected.\n    \"\"\"\n\n    _tokenized_corpus = None\n    _corpus_length = 0\n    _prefix_prompts: list[str] = []\n    _cache: dict[int, list[int]] = {}\n\n    @classmethod\n    def create_synthetic_prompt(\n        cls,\n        tokenizer: Tokenizer,\n        prompt_tokens_mean: int = 550,\n        prompt_tokens_stddev: int = 250,\n        hash_ids: list[int] | None = None,\n        block_size: int = 512,\n    ) -&gt; str:\n        \"\"\"\n        Generate a synthetic prompt with a specific number of tokens.\n\n        Args:\n            tokenizer: Tokenizer instance.\n            prompt_tokens_mean: Mean number of tokens in the prompt.\n            prompt_tokens_stddev: Standard deviation for the number of tokens in the prompt.\n            hash_ids: Optional list of integers for token reuse.\n            block_size: Size of the token block for reuse.\n\n        Returns:\n            A synthetic prompt as a string.\n        \"\"\"\n        if cls._tokenized_corpus is None:\n            cls._initialize_corpus(tokenizer)\n\n        if hash_ids:\n            return cls._generate_prompt_with_token_reuse(\n                tokenizer, prompt_tokens_mean, hash_ids, block_size\n            )\n\n        num_prompt_tokens = max(\n            0, int(random.gauss(prompt_tokens_mean, prompt_tokens_stddev))\n        )\n\n        return cls._generate_prompt(tokenizer, num_prompt_tokens)\n\n    @classmethod\n    def _initialize_corpus(\n        cls, tokenizer: Tokenizer, corpus_file: str = DEFAULT_CORPUS_FILE\n    ) -&gt; None:\n        \"\"\"\n        Load and tokenize the corpus once, storing it for reuse.\n\n        Args:\n            tokenizer: Tokenizer for tokenizing the corpus.\n            corpus_file: Path to the corpus file.\n        \"\"\"\n        corpus_path = pathlib.Path(__file__).parent / corpus_file\n\n        with open(corpus_path) as f:\n            lines = f.readlines()\n\n        def tokenize_chunk(chunk):\n            cleaned_text = \" \".join(line.strip() for line in chunk if line.strip())\n            tokens = tokenizer.encode(cleaned_text)\n            return tokens\n\n        num_threads = os.cpu_count()\n        if num_threads is None:\n            num_threads = 4\n        chunk_size = len(lines) // num_threads\n        chunks = [lines[i : i + chunk_size] for i in range(0, len(lines), chunk_size)]\n\n        with ThreadPoolExecutor(max_workers=num_threads) as executor:\n            tokenized_chunks = list(executor.map(tokenize_chunk, chunks))\n\n        cls._tokenized_corpus = [token for chunk in tokenized_chunks for token in chunk]\n        cls._corpus_length = len(cls._tokenized_corpus)\n\n    @classmethod\n    def _generate_prompt_tokens(cls, num_tokens: int) -&gt; list[int]:\n        \"\"\"\n        Generate a prompt containing exactly `num_tokens` using the preloaded tokenized corpus.\n\n        Args:\n            num_tokens: Number of tokens required in the prompt.\n\n        Returns:\n            A synthetic prompt of tokens.\n\n        Raises:\n            GeneratorInitializationError: If the tokenized corpus is not initialized\n        \"\"\"\n        if not cls._tokenized_corpus:\n            raise GeneratorInitializationError(\"Tokenized corpus is not initialized.\")\n        if num_tokens &gt; cls._corpus_length:\n            logger.warning(\n                f\"Requested prompt length {num_tokens} is longer than the corpus. \"\n                f\"Returning a prompt of length {cls._corpus_length}.\"\n            )\n\n        start_idx = random.randrange(cls._corpus_length)\n\n        end_idx = start_idx + num_tokens\n        prompt_tokens = cls._tokenized_corpus[start_idx:end_idx]\n        if end_idx &gt; cls._corpus_length:\n            prompt_tokens += cls._tokenized_corpus[: end_idx - cls._corpus_length]\n\n        return prompt_tokens\n\n    @classmethod\n    def _generate_prompt(cls, tokenizer: Tokenizer, num_tokens: int) -&gt; str:\n        \"\"\"\n        Generate a prompt containing exactly `num_tokens` using the preloaded tokenized corpus.\n\n        Args:\n            tokenizer: Tokenizer instance.\n            num_tokens: Number of tokens required in the prompt.\n\n        Returns:\n            A synthetic prompt as a string.\n        \"\"\"\n        return tokenizer.decode(cls._generate_prompt_tokens(num_tokens))\n\n    @classmethod\n    def _generate_prompt_with_token_reuse(\n        cls,\n        tokenizer: Tokenizer,\n        num_tokens: int,\n        prompt_hash_list: list[int],\n        block_size: int,\n    ) -&gt; str:\n        \"\"\"\n        Generate a prompt containing exactly `num_tokens` by reusing previously generated prompts\n        stored in `_cache`. Each hash index in `prompt_hash_list` corresponds to a block of\n        `block_size` tokens. If a hash index is found in `_cache`, its stored prompt is reused.\n        Otherwise, a new prompt is generated using `_generate_prompt()` and stored in `_cache`.\n\n        Args:\n            tokenizer : Tokenizer\n                The tokenizer used to generate prompts.\n            num_tokens : int\n                The number of tokens required in the prompt.\n            prompt_hash_list : list[int]\n                A list of hash indices used for token reuse.\n            block_size : int\n                The number of tokens allocated per hash block (default 512).\n\n        Returns:\n            str: A synthetic prompt as a string.\n\n        Raises:\n            GeneratorConfigurationError: If the input parameters are not compatible.\n        \"\"\"\n        final_prompt: list[int] = []\n        size_to_use = block_size\n        last_hash_length = num_tokens - ((len(prompt_hash_list) - 1) * block_size)\n        if last_hash_length &lt;= 0 or block_size &lt; last_hash_length:\n            raise GeneratorConfigurationError(\n                f\"Input_length: {num_tokens}, Hash_ids: {prompt_hash_list}, Block_size: {block_size} \"\n                f\"are not compatible. The final hash id length: {last_hash_length} must be greater \"\n                f\"than 0 and less than or equal to {block_size}.\"\n            )\n        for index, hash_index in enumerate(prompt_hash_list):\n            if index == len(prompt_hash_list) - 1:\n                size_to_use = num_tokens - (index * block_size)\n            if hash_index not in cls._cache:\n                # To ensure that the prompt doesn't merge chunks, we pop the last token\n                # and insert the bos token at the beginning. Length is maintained and\n                # the prompt generates the expected number of tokens.\n                prompt_tokens = cls._generate_prompt_tokens(size_to_use)\n                prompt_tokens.pop(0)\n                prompt_tokens.insert(0, tokenizer.bos_token_id())\n                cls._cache[hash_index] = prompt_tokens\n            final_prompt.extend(cls._cache[hash_index])\n        prompt = tokenizer.decode(final_prompt, skip_special_tokens=False)\n\n        return prompt\n\n    @classmethod\n    def create_prefix_prompts_pool(\n        cls, tokenizer: Tokenizer, num_prompts: int, prompt_length: int\n    ) -&gt; None:\n        \"\"\"\n        Generate a pool of prefix prompts.\n\n        Args:\n            tokenizer: Tokenizer instance.\n            num_prompts: Number of prefix prompts to generate.\n            prompt_length: Number of tokens per prefix prompt.\n        \"\"\"\n        if cls._tokenized_corpus is None:\n            cls._initialize_corpus(tokenizer)\n\n        cls._prefix_prompts = [\n            cls._generate_prompt(tokenizer, prompt_length) for _ in range(num_prompts)\n        ]\n\n    @classmethod\n    def get_random_prefix_prompt(cls) -&gt; str:\n        \"\"\"\n        Fetch a random prefix prompt from the pool.\n\n        Returns:\n            A random prefix prompt.\n\n        Raises:\n            GeneratorInitializationError: If the prefix prompts pool is empty.\n        \"\"\"\n        if not cls._prefix_prompts:\n            raise GeneratorInitializationError(\n                \"Prefix prompts pool is empty. Call `create_prefix_prompts_pool` first.\"\n            )\n        return random.choice(cls._prefix_prompts)\n</code></pre>"},{"location":"api/#aiperf.services.dataset.generator.prompt.PromptGenerator.create_prefix_prompts_pool","title":"<code>create_prefix_prompts_pool(tokenizer, num_prompts, prompt_length)</code>  <code>classmethod</code>","text":"<p>Generate a pool of prefix prompts.</p> <p>Parameters:</p> Name Type Description Default <code>tokenizer</code> <code>Tokenizer</code> <p>Tokenizer instance.</p> required <code>num_prompts</code> <code>int</code> <p>Number of prefix prompts to generate.</p> required <code>prompt_length</code> <code>int</code> <p>Number of tokens per prefix prompt.</p> required Source code in <code>aiperf/services/dataset/generator/prompt.py</code> <pre><code>@classmethod\ndef create_prefix_prompts_pool(\n    cls, tokenizer: Tokenizer, num_prompts: int, prompt_length: int\n) -&gt; None:\n    \"\"\"\n    Generate a pool of prefix prompts.\n\n    Args:\n        tokenizer: Tokenizer instance.\n        num_prompts: Number of prefix prompts to generate.\n        prompt_length: Number of tokens per prefix prompt.\n    \"\"\"\n    if cls._tokenized_corpus is None:\n        cls._initialize_corpus(tokenizer)\n\n    cls._prefix_prompts = [\n        cls._generate_prompt(tokenizer, prompt_length) for _ in range(num_prompts)\n    ]\n</code></pre>"},{"location":"api/#aiperf.services.dataset.generator.prompt.PromptGenerator.create_synthetic_prompt","title":"<code>create_synthetic_prompt(tokenizer, prompt_tokens_mean=550, prompt_tokens_stddev=250, hash_ids=None, block_size=512)</code>  <code>classmethod</code>","text":"<p>Generate a synthetic prompt with a specific number of tokens.</p> <p>Parameters:</p> Name Type Description Default <code>tokenizer</code> <code>Tokenizer</code> <p>Tokenizer instance.</p> required <code>prompt_tokens_mean</code> <code>int</code> <p>Mean number of tokens in the prompt.</p> <code>550</code> <code>prompt_tokens_stddev</code> <code>int</code> <p>Standard deviation for the number of tokens in the prompt.</p> <code>250</code> <code>hash_ids</code> <code>list[int] | None</code> <p>Optional list of integers for token reuse.</p> <code>None</code> <code>block_size</code> <code>int</code> <p>Size of the token block for reuse.</p> <code>512</code> <p>Returns:</p> Type Description <code>str</code> <p>A synthetic prompt as a string.</p> Source code in <code>aiperf/services/dataset/generator/prompt.py</code> <pre><code>@classmethod\ndef create_synthetic_prompt(\n    cls,\n    tokenizer: Tokenizer,\n    prompt_tokens_mean: int = 550,\n    prompt_tokens_stddev: int = 250,\n    hash_ids: list[int] | None = None,\n    block_size: int = 512,\n) -&gt; str:\n    \"\"\"\n    Generate a synthetic prompt with a specific number of tokens.\n\n    Args:\n        tokenizer: Tokenizer instance.\n        prompt_tokens_mean: Mean number of tokens in the prompt.\n        prompt_tokens_stddev: Standard deviation for the number of tokens in the prompt.\n        hash_ids: Optional list of integers for token reuse.\n        block_size: Size of the token block for reuse.\n\n    Returns:\n        A synthetic prompt as a string.\n    \"\"\"\n    if cls._tokenized_corpus is None:\n        cls._initialize_corpus(tokenizer)\n\n    if hash_ids:\n        return cls._generate_prompt_with_token_reuse(\n            tokenizer, prompt_tokens_mean, hash_ids, block_size\n        )\n\n    num_prompt_tokens = max(\n        0, int(random.gauss(prompt_tokens_mean, prompt_tokens_stddev))\n    )\n\n    return cls._generate_prompt(tokenizer, num_prompt_tokens)\n</code></pre>"},{"location":"api/#aiperf.services.dataset.generator.prompt.PromptGenerator.get_random_prefix_prompt","title":"<code>get_random_prefix_prompt()</code>  <code>classmethod</code>","text":"<p>Fetch a random prefix prompt from the pool.</p> <p>Returns:</p> Type Description <code>str</code> <p>A random prefix prompt.</p> <p>Raises:</p> Type Description <code>GeneratorInitializationError</code> <p>If the prefix prompts pool is empty.</p> Source code in <code>aiperf/services/dataset/generator/prompt.py</code> <pre><code>@classmethod\ndef get_random_prefix_prompt(cls) -&gt; str:\n    \"\"\"\n    Fetch a random prefix prompt from the pool.\n\n    Returns:\n        A random prefix prompt.\n\n    Raises:\n        GeneratorInitializationError: If the prefix prompts pool is empty.\n    \"\"\"\n    if not cls._prefix_prompts:\n        raise GeneratorInitializationError(\n            \"Prefix prompts pool is empty. Call `create_prefix_prompts_pool` first.\"\n        )\n    return random.choice(cls._prefix_prompts)\n</code></pre>"},{"location":"api/#aiperfservicesdatasetgeneratorutils","title":"aiperf.services.dataset.generator.utils","text":""},{"location":"api/#aiperf.services.dataset.generator.utils.encode_image","title":"<code>encode_image(img, format)</code>","text":"<p>Encodes an image into base64 encoded string.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>Image</code> <p>The PIL Image object to encode.</p> required <code>format</code> <code>str</code> <p>The image format to use (e.g., \"JPEG\", \"PNG\").</p> required <p>Returns:</p> Type Description <code>str</code> <p>A base64 encoded string representation of the image.</p> Source code in <code>aiperf/services/dataset/generator/utils.py</code> <pre><code>def encode_image(img: Image, format: str) -&gt; str:\n    \"\"\"Encodes an image into base64 encoded string.\n\n    Args:\n        img: The PIL Image object to encode.\n        format: The image format to use (e.g., \"JPEG\", \"PNG\").\n\n    Returns:\n        A base64 encoded string representation of the image.\n    \"\"\"\n    # JPEG does not support P or RGBA mode (commonly used for PNG) so it needs\n    # to be converted to RGB before an image can be saved as JPEG format.\n    if format == \"JPEG\" and img.mode != \"RGB\":\n        img = img.convert(\"RGB\")\n\n    buffer = BytesIO()\n    img.save(buffer, format=format)\n    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n</code></pre>"},{"location":"api/#aiperfservicespost_processor_managerpost_processor_manager","title":"aiperf.services.post_processor_manager.post_processor_manager","text":""},{"location":"api/#aiperf.services.post_processor_manager.post_processor_manager.PostProcessorManager","title":"<code>PostProcessorManager</code>","text":"<p>               Bases: <code>BaseComponentService</code></p> <p>PostProcessorManager is primarily responsible for iterating over the records to generate metrics and other conclusions from the records.</p> Source code in <code>aiperf/services/post_processor_manager/post_processor_manager.py</code> <pre><code>@ServiceFactory.register(ServiceType.POST_PROCESSOR_MANAGER)\nclass PostProcessorManager(BaseComponentService):\n    \"\"\"PostProcessorManager is primarily responsible for iterating over the\n    records to generate metrics and other conclusions from the records.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Initializing post processor manager\")\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.POST_PROCESSOR_MANAGER\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize post processor manager-specific components.\"\"\"\n        self.logger.debug(\"Initializing post processor manager\")\n        # TODO: Implement post processor manager initialization\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the post processor manager.\"\"\"\n        self.logger.debug(\"Starting post processor manager\")\n        # TODO: Implement post processor manager start\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the post processor manager.\"\"\"\n        self.logger.debug(\"Stopping post processor manager\")\n        # TODO: Implement post processor manager stop\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up post processor manager-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up post processor manager\")\n        # TODO: Implement post processor manager cleanup\n\n    @on_configure\n    async def _configure(self, payload: BasePayload) -&gt; None:\n        \"\"\"Configure the post processor manager.\"\"\"\n        self.logger.debug(f\"Configuring post processor manager with payload: {payload}\")\n</code></pre>"},{"location":"api/#aiperf.services.post_processor_manager.post_processor_manager.PostProcessorManager.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.post_processor_manager.post_processor_manager.main","title":"<code>main()</code>","text":"<p>Main entry point for the post processor manager.</p> Source code in <code>aiperf/services/post_processor_manager/post_processor_manager.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the post processor manager.\"\"\"\n\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(PostProcessorManager)\n</code></pre>"},{"location":"api/#aiperfservicesrecords_managerrecords_manager","title":"aiperf.services.records_manager.records_manager","text":""},{"location":"api/#aiperf.services.records_manager.records_manager.RecordsManager","title":"<code>RecordsManager</code>","text":"<p>               Bases: <code>BaseComponentService</code></p> <p>The RecordsManager service is primarily responsible for holding the results returned from the workers.</p> Source code in <code>aiperf/services/records_manager/records_manager.py</code> <pre><code>@ServiceFactory.register(ServiceType.RECORDS_MANAGER)\nclass RecordsManager(BaseComponentService):\n    \"\"\"\n    The RecordsManager service is primarily responsible for holding the\n    results returned from the workers.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Initializing records manager\")\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.RECORDS_MANAGER\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize records manager-specific components.\"\"\"\n        self.logger.debug(\"Initializing records manager\")\n        # TODO: Implement records manager initialization\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the records manager.\"\"\"\n        self.logger.debug(\"Starting records manager\")\n        # TODO: Implement records manager start\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the records manager.\"\"\"\n        self.logger.debug(\"Stopping records manager\")\n        # TODO: Implement records manager stop\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up records manager-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up records manager\")\n        # TODO: Implement records manager cleanup\n\n    @on_configure\n    async def _configure(self, payload: BasePayload) -&gt; None:\n        \"\"\"Configure the records manager.\"\"\"\n        self.logger.debug(f\"Configuring records manager with payload: {payload}\")\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.records_manager.RecordsManager.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.records_manager.records_manager.main","title":"<code>main()</code>","text":"<p>Main entry point for the records manager.</p> Source code in <code>aiperf/services/records_manager/records_manager.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the records manager.\"\"\"\n\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(RecordsManager)\n</code></pre>"},{"location":"api/#aiperfservicesservice_managerbase","title":"aiperf.services.service_manager.base","text":""},{"location":"api/#aiperf.services.service_manager.base.BaseServiceManager","title":"<code>BaseServiceManager</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for service managers. It provides a common interface for managing services and a way to look up service information by service ID.</p> Source code in <code>aiperf/services/service_manager/base.py</code> <pre><code>class BaseServiceManager(ABC):\n    \"\"\"\n    Base class for service managers. It provides a common interface for\n    managing services and a way to look up service information by service ID.\n    \"\"\"\n\n    def __init__(\n        self, required_service_types: list[ServiceType], config: ServiceConfig\n    ):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.required_service_types = required_service_types\n        self.config = config\n\n        # Maps to track service information\n        self.service_map: dict[ServiceType, list[ServiceRunInfo]] = {}\n\n        # Create service ID map for component lookups\n        self.service_id_map: dict[str, ServiceRunInfo] = {}\n\n    @abstractmethod\n    async def initialize_all_services(self) -&gt; None:\n        \"\"\"Initialize all required services.\"\"\"\n        pass\n\n    @abstractmethod\n    async def stop_all_services(self) -&gt; None:\n        \"\"\"Stop all managed services.\"\"\"\n        pass\n\n    @abstractmethod\n    async def wait_for_all_services_registration(\n        self, stop_event: asyncio.Event, timeout_seconds: int = 30\n    ) -&gt; None:\n        \"\"\"Wait for all required services to be registered.\"\"\"\n        pass\n\n    @abstractmethod\n    async def wait_for_all_services_start(self) -&gt; None:\n        \"\"\"Wait for all required services to be started.\"\"\"\n        pass\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.base.BaseServiceManager.initialize_all_services","title":"<code>initialize_all_services()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Initialize all required services.</p> Source code in <code>aiperf/services/service_manager/base.py</code> <pre><code>@abstractmethod\nasync def initialize_all_services(self) -&gt; None:\n    \"\"\"Initialize all required services.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.base.BaseServiceManager.stop_all_services","title":"<code>stop_all_services()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Stop all managed services.</p> Source code in <code>aiperf/services/service_manager/base.py</code> <pre><code>@abstractmethod\nasync def stop_all_services(self) -&gt; None:\n    \"\"\"Stop all managed services.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.base.BaseServiceManager.wait_for_all_services_registration","title":"<code>wait_for_all_services_registration(stop_event, timeout_seconds=30)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Wait for all required services to be registered.</p> Source code in <code>aiperf/services/service_manager/base.py</code> <pre><code>@abstractmethod\nasync def wait_for_all_services_registration(\n    self, stop_event: asyncio.Event, timeout_seconds: int = 30\n) -&gt; None:\n    \"\"\"Wait for all required services to be registered.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.base.BaseServiceManager.wait_for_all_services_start","title":"<code>wait_for_all_services_start()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Wait for all required services to be started.</p> Source code in <code>aiperf/services/service_manager/base.py</code> <pre><code>@abstractmethod\nasync def wait_for_all_services_start(self) -&gt; None:\n    \"\"\"Wait for all required services to be started.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperfservicesservice_managerkubernetes","title":"aiperf.services.service_manager.kubernetes","text":""},{"location":"api/#aiperf.services.service_manager.kubernetes.KubernetesServiceManager","title":"<code>KubernetesServiceManager</code>","text":"<p>               Bases: <code>BaseServiceManager</code></p> <p>Service Manager for starting and stopping services in a Kubernetes cluster.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>class KubernetesServiceManager(BaseServiceManager):\n    \"\"\"\n    Service Manager for starting and stopping services in a Kubernetes cluster.\n    \"\"\"\n\n    def __init__(\n        self, required_service_types: list[ServiceType], config: ServiceConfig\n    ):\n        super().__init__(required_service_types, config)\n\n    async def initialize_all_services(self) -&gt; None:\n        \"\"\"Initialize all required services as Kubernetes pods.\"\"\"\n        self.logger.debug(\"Initializing all required services as Kubernetes pods\")\n        # TODO: Implement Kubernetes\n        raise NotImplementedError(\n            \"KubernetesServiceManager.initialize_all_services not implemented\"\n        )\n\n    async def stop_all_services(self) -&gt; None:\n        \"\"\"Stop all required services as Kubernetes pods.\"\"\"\n        self.logger.debug(\"Stopping all required services as Kubernetes pods\")\n        # TODO: Implement Kubernetes\n        raise NotImplementedError(\n            \"KubernetesServiceManager.stop_all_services not implemented\"\n        )\n\n    async def wait_for_all_services_registration(\n        self, stop_event: asyncio.Event, timeout_seconds: int = 30\n    ) -&gt; None:\n        \"\"\"Wait for all required services to be registered in Kubernetes.\"\"\"\n        self.logger.debug(\n            \"Waiting for all required services to be registered in Kubernetes\"\n        )\n        # TODO: Implement Kubernetes\n        raise NotImplementedError(\n            \"KubernetesServiceManager.wait_for_all_services_registration not implemented\"\n        )\n\n    async def wait_for_all_services_start(self) -&gt; None:\n        \"\"\"Wait for all required services to be started in Kubernetes.\"\"\"\n        self.logger.debug(\n            \"Waiting for all required services to be started in Kubernetes\"\n        )\n        # TODO: Implement Kubernetes\n        raise NotImplementedError(\n            \"KubernetesServiceManager.wait_for_all_services_start not implemented\"\n        )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.kubernetes.KubernetesServiceManager.initialize_all_services","title":"<code>initialize_all_services()</code>  <code>async</code>","text":"<p>Initialize all required services as Kubernetes pods.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>async def initialize_all_services(self) -&gt; None:\n    \"\"\"Initialize all required services as Kubernetes pods.\"\"\"\n    self.logger.debug(\"Initializing all required services as Kubernetes pods\")\n    # TODO: Implement Kubernetes\n    raise NotImplementedError(\n        \"KubernetesServiceManager.initialize_all_services not implemented\"\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.kubernetes.KubernetesServiceManager.stop_all_services","title":"<code>stop_all_services()</code>  <code>async</code>","text":"<p>Stop all required services as Kubernetes pods.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>async def stop_all_services(self) -&gt; None:\n    \"\"\"Stop all required services as Kubernetes pods.\"\"\"\n    self.logger.debug(\"Stopping all required services as Kubernetes pods\")\n    # TODO: Implement Kubernetes\n    raise NotImplementedError(\n        \"KubernetesServiceManager.stop_all_services not implemented\"\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.kubernetes.KubernetesServiceManager.wait_for_all_services_registration","title":"<code>wait_for_all_services_registration(stop_event, timeout_seconds=30)</code>  <code>async</code>","text":"<p>Wait for all required services to be registered in Kubernetes.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>async def wait_for_all_services_registration(\n    self, stop_event: asyncio.Event, timeout_seconds: int = 30\n) -&gt; None:\n    \"\"\"Wait for all required services to be registered in Kubernetes.\"\"\"\n    self.logger.debug(\n        \"Waiting for all required services to be registered in Kubernetes\"\n    )\n    # TODO: Implement Kubernetes\n    raise NotImplementedError(\n        \"KubernetesServiceManager.wait_for_all_services_registration not implemented\"\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.kubernetes.KubernetesServiceManager.wait_for_all_services_start","title":"<code>wait_for_all_services_start()</code>  <code>async</code>","text":"<p>Wait for all required services to be started in Kubernetes.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>async def wait_for_all_services_start(self) -&gt; None:\n    \"\"\"Wait for all required services to be started in Kubernetes.\"\"\"\n    self.logger.debug(\n        \"Waiting for all required services to be started in Kubernetes\"\n    )\n    # TODO: Implement Kubernetes\n    raise NotImplementedError(\n        \"KubernetesServiceManager.wait_for_all_services_start not implemented\"\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.kubernetes.ServiceKubernetesRunInfo","title":"<code>ServiceKubernetesRunInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about a service running in a Kubernetes pod.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>class ServiceKubernetesRunInfo(BaseModel):\n    \"\"\"Information about a service running in a Kubernetes pod.\"\"\"\n\n    pod_name: str\n    node_name: str\n    namespace: str\n</code></pre>"},{"location":"api/#aiperfservicesservice_managermultiprocess","title":"aiperf.services.service_manager.multiprocess","text":""},{"location":"api/#aiperf.services.service_manager.multiprocess.MultiProcessRunInfo","title":"<code>MultiProcessRunInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about a service running as a multiprocessing process.</p> Source code in <code>aiperf/services/service_manager/multiprocess.py</code> <pre><code>class MultiProcessRunInfo(BaseModel):\n    \"\"\"Information about a service running as a multiprocessing process.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    process: Process | None = Field(default=None)\n    service_type: ServiceType = Field(\n        ...,\n        description=\"Type of service running in the process\",\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.multiprocess.MultiProcessServiceManager","title":"<code>MultiProcessServiceManager</code>","text":"<p>               Bases: <code>BaseServiceManager</code></p> <p>Service Manager for starting and stopping services as multiprocessing processes.</p> Source code in <code>aiperf/services/service_manager/multiprocess.py</code> <pre><code>class MultiProcessServiceManager(BaseServiceManager):\n    \"\"\"\n    Service Manager for starting and stopping services as multiprocessing processes.\n    \"\"\"\n\n    def __init__(\n        self, required_service_types: list[ServiceType], config: ServiceConfig\n    ):\n        super().__init__(required_service_types, config)\n        self.multi_process_info: list[MultiProcessRunInfo] = []\n\n    async def initialize_all_services(self) -&gt; None:\n        \"\"\"Start all required services as multiprocessing processes.\"\"\"\n        self.logger.debug(\"Starting all required services as multiprocessing processes\")\n\n        # Create and start all service processes\n        for service_type in self.required_service_types:\n            service_class = ServiceFactory.get_class_from_type(service_type)\n\n            process = Process(\n                target=bootstrap_and_run_service,\n                name=f\"{service_type}_process\",\n                args=(service_class, self.config),\n                daemon=False,\n            )\n            process.start()\n\n            self.logger.debug(\n                \"Service %s started as process (pid: %d)\",\n                service_type,\n                process.pid,\n            )\n\n            self.multi_process_info.append(\n                MultiProcessRunInfo(process=process, service_type=service_type)\n            )\n\n            # Sleep to allow the service to register\n            await asyncio.sleep(0.01)\n\n    async def stop_all_services(self) -&gt; None:\n        \"\"\"Stop all required services as multiprocessing processes.\"\"\"\n        self.logger.debug(\"Stopping all service processes\")\n\n        # Wait for all to finish in parallel\n        await asyncio.gather(\n            *[self._wait_for_process(info) for info in self.multi_process_info]\n        )\n\n    async def wait_for_all_services_registration(\n        self, stop_event: asyncio.Event, timeout_seconds: int = 30\n    ) -&gt; None:\n        \"\"\"Wait for all required services to be registered.\n\n        Args:\n            stop_event: Event to check if operation should be cancelled\n            timeout_seconds: Maximum time to wait in seconds\n\n        Raises:\n            Exception if any service failed to register, None otherwise\n        \"\"\"\n        self.logger.debug(\"Waiting for all required services to register...\")\n\n        # Get the set of required service types for checking completion\n        required_types = set(self.required_service_types)\n\n        # TODO: Can this be done better by using asyncio.Event()?\n\n        try:\n            async with asyncio.timeout(timeout_seconds):\n                while not stop_event.is_set():\n                    # Get all registered service types from the id map\n                    registered_types = {\n                        service_info.service_type\n                        for service_info in self.service_id_map.values()\n                        if service_info.registration_status\n                        == ServiceRegistrationStatus.REGISTERED\n                    }\n\n                    # Check if all required types are registered\n                    if required_types.issubset(registered_types):\n                        return\n\n                    # Wait a bit before checking again\n                    await asyncio.sleep(0.5)\n\n        except asyncio.TimeoutError:\n            # Log which services didn't register in time\n            registered_types = {\n                service_info.service_type\n                for service_info in self.service_id_map.values()\n                if service_info.registration_status\n                == ServiceRegistrationStatus.REGISTERED\n            }\n\n            for service_type in required_types - registered_types:\n                self.logger.warning(\n                    f\"Service {service_type} failed to register within timeout\"\n                )\n\n    async def wait_for_all_services_start(self) -&gt; None:\n        \"\"\"Wait for all required services to be started.\"\"\"\n        self.logger.debug(\"Waiting for all required services to start...\")\n\n        # TODO: Implement this\n        self.logger.warning(\"wait_for_all_services_start not implemented\")\n\n    async def _wait_for_process(self, info: MultiProcessRunInfo) -&gt; None:\n        \"\"\"Wait for a process to terminate with timeout handling.\"\"\"\n        if not info.process or not info.process.is_alive():\n            return\n\n        try:\n            info.process.terminate()\n            await asyncio.wait_for(\n                asyncio.to_thread(\n                    info.process.join, timeout=1.0\n                ),  # Add timeout to join\n                timeout=5.0,  # Overall timeout\n            )\n            self.logger.debug(\n                \"Service %s process stopped (pid: %d)\",\n                info.service_type,\n                info.process.pid,\n            )\n        except asyncio.TimeoutError:\n            self.logger.warning(\n                \"Service %s process (pid: %d) did not terminate gracefully, killing\",\n                info.service_type,\n                info.process.pid,\n            )\n            info.process.kill()\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.multiprocess.MultiProcessServiceManager.initialize_all_services","title":"<code>initialize_all_services()</code>  <code>async</code>","text":"<p>Start all required services as multiprocessing processes.</p> Source code in <code>aiperf/services/service_manager/multiprocess.py</code> <pre><code>async def initialize_all_services(self) -&gt; None:\n    \"\"\"Start all required services as multiprocessing processes.\"\"\"\n    self.logger.debug(\"Starting all required services as multiprocessing processes\")\n\n    # Create and start all service processes\n    for service_type in self.required_service_types:\n        service_class = ServiceFactory.get_class_from_type(service_type)\n\n        process = Process(\n            target=bootstrap_and_run_service,\n            name=f\"{service_type}_process\",\n            args=(service_class, self.config),\n            daemon=False,\n        )\n        process.start()\n\n        self.logger.debug(\n            \"Service %s started as process (pid: %d)\",\n            service_type,\n            process.pid,\n        )\n\n        self.multi_process_info.append(\n            MultiProcessRunInfo(process=process, service_type=service_type)\n        )\n\n        # Sleep to allow the service to register\n        await asyncio.sleep(0.01)\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.multiprocess.MultiProcessServiceManager.stop_all_services","title":"<code>stop_all_services()</code>  <code>async</code>","text":"<p>Stop all required services as multiprocessing processes.</p> Source code in <code>aiperf/services/service_manager/multiprocess.py</code> <pre><code>async def stop_all_services(self) -&gt; None:\n    \"\"\"Stop all required services as multiprocessing processes.\"\"\"\n    self.logger.debug(\"Stopping all service processes\")\n\n    # Wait for all to finish in parallel\n    await asyncio.gather(\n        *[self._wait_for_process(info) for info in self.multi_process_info]\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.multiprocess.MultiProcessServiceManager.wait_for_all_services_registration","title":"<code>wait_for_all_services_registration(stop_event, timeout_seconds=30)</code>  <code>async</code>","text":"<p>Wait for all required services to be registered.</p> <p>Parameters:</p> Name Type Description Default <code>stop_event</code> <code>Event</code> <p>Event to check if operation should be cancelled</p> required <code>timeout_seconds</code> <code>int</code> <p>Maximum time to wait in seconds</p> <code>30</code> Source code in <code>aiperf/services/service_manager/multiprocess.py</code> <pre><code>async def wait_for_all_services_registration(\n    self, stop_event: asyncio.Event, timeout_seconds: int = 30\n) -&gt; None:\n    \"\"\"Wait for all required services to be registered.\n\n    Args:\n        stop_event: Event to check if operation should be cancelled\n        timeout_seconds: Maximum time to wait in seconds\n\n    Raises:\n        Exception if any service failed to register, None otherwise\n    \"\"\"\n    self.logger.debug(\"Waiting for all required services to register...\")\n\n    # Get the set of required service types for checking completion\n    required_types = set(self.required_service_types)\n\n    # TODO: Can this be done better by using asyncio.Event()?\n\n    try:\n        async with asyncio.timeout(timeout_seconds):\n            while not stop_event.is_set():\n                # Get all registered service types from the id map\n                registered_types = {\n                    service_info.service_type\n                    for service_info in self.service_id_map.values()\n                    if service_info.registration_status\n                    == ServiceRegistrationStatus.REGISTERED\n                }\n\n                # Check if all required types are registered\n                if required_types.issubset(registered_types):\n                    return\n\n                # Wait a bit before checking again\n                await asyncio.sleep(0.5)\n\n    except asyncio.TimeoutError:\n        # Log which services didn't register in time\n        registered_types = {\n            service_info.service_type\n            for service_info in self.service_id_map.values()\n            if service_info.registration_status\n            == ServiceRegistrationStatus.REGISTERED\n        }\n\n        for service_type in required_types - registered_types:\n            self.logger.warning(\n                f\"Service {service_type} failed to register within timeout\"\n            )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.multiprocess.MultiProcessServiceManager.wait_for_all_services_start","title":"<code>wait_for_all_services_start()</code>  <code>async</code>","text":"<p>Wait for all required services to be started.</p> Source code in <code>aiperf/services/service_manager/multiprocess.py</code> <pre><code>async def wait_for_all_services_start(self) -&gt; None:\n    \"\"\"Wait for all required services to be started.\"\"\"\n    self.logger.debug(\"Waiting for all required services to start...\")\n\n    # TODO: Implement this\n    self.logger.warning(\"wait_for_all_services_start not implemented\")\n</code></pre>"},{"location":"api/#aiperfservicessystem_controllersystem_controller","title":"aiperf.services.system_controller.system_controller","text":""},{"location":"api/#aiperf.services.system_controller.system_controller.SystemController","title":"<code>SystemController</code>","text":"<p>               Bases: <code>BaseControllerService</code></p> <p>System Controller service.</p> <p>This service is responsible for managing the lifecycle of all other services. It will start, stop, and configure all other services.</p> Source code in <code>aiperf/services/system_controller/system_controller.py</code> <pre><code>@ServiceFactory.register(ServiceType.SYSTEM_CONTROLLER)\nclass SystemController(BaseControllerService):\n    \"\"\"System Controller service.\n\n    This service is responsible for managing the lifecycle of all other services.\n    It will start, stop, and configure all other services.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Creating System Controller\")\n\n        # List of required service types, in no particular order\n        self.required_service_types: list[ServiceType] = [\n            ServiceType.DATASET_MANAGER,\n            ServiceType.TIMING_MANAGER,\n            ServiceType.WORKER_MANAGER,\n            ServiceType.RECORDS_MANAGER,\n            ServiceType.POST_PROCESSOR_MANAGER,\n        ]\n\n        self.service_manager: BaseServiceManager | None = None\n        self.logger.debug(\"System Controller created\")\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.SYSTEM_CONTROLLER\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize system controller-specific components.\n\n        This method will:\n        - Initialize the service manager\n        - Subscribe to relevant messages\n        \"\"\"\n        self.logger.debug(\"Initializing System Controller\")\n\n        if self.service_config.service_run_type == ServiceRunType.MULTIPROCESSING:\n            self.service_manager = MultiProcessServiceManager(\n                self.required_service_types, self.service_config\n            )\n\n        elif self.service_config.service_run_type == ServiceRunType.KUBERNETES:\n            self.service_manager = KubernetesServiceManager(\n                self.required_service_types, self.service_config\n            )\n\n        else:\n            raise ConfigError(\n                f\"Unsupported service run type: {self.service_config.service_run_type}\"\n            )\n\n        # Subscribe to relevant messages\n        try:\n            await self.comms.subscribe(\n                topic=Topic.REGISTRATION,\n                callback=self._process_registration_message,\n            )\n        except Exception as e:\n            self.logger.error(\"Failed to subscribe to registration topic: %s\", e)\n            raise CommunicationSubscribeError from e\n\n        try:\n            await self.comms.subscribe(\n                topic=Topic.HEARTBEAT,\n                callback=self._process_heartbeat_message,\n            )\n        except Exception as e:\n            self.logger.error(\"Failed to subscribe to heartbeat topic: %s\", e)\n            raise CommunicationSubscribeError from e\n\n        try:\n            await self.comms.subscribe(\n                topic=Topic.STATUS,\n                callback=self._process_status_message,\n            )\n        except Exception as e:\n            self.logger.error(\"Failed to subscribe to status topic: %s\", e)\n            raise CommunicationSubscribeError from e\n\n        self.logger.debug(\n            \"System controller waiting for 1 second to ensure that the \"\n            \"communication is initialized\"\n        )\n\n        # wait 1 second to ensure that the communication is initialized\n        await asyncio.sleep(1)\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the system controller and launch required services.\n\n        This method will:\n        - Initialize all required services\n        - Wait for all required services to be registered\n        - Start all required services\n        \"\"\"\n        self.logger.debug(\"Starting System Controller\")\n\n        # Start all required services\n        try:\n            await self.service_manager.initialize_all_services()\n        except Exception as e:\n            self.logger.error(\"Failed to initialize all services: %s\", e)\n            raise ServiceInitializationError from e\n\n        try:\n            # Wait for all required services to be registered\n            await self.service_manager.wait_for_all_services_registration(\n                self.stop_event\n            )\n\n            if self.stop_event.is_set():\n                self.logger.debug(\n                    \"System Controller stopped before all services registered\"\n                )\n                return  # Don't continue with the rest of the initialization\n\n        except Exception as e:\n            self.logger.error(\n                \"Not all required services registered within the timeout period\"\n            )\n            raise ServiceInitializationError(\n                \"Not all required services registered within the timeout period\"\n            ) from e\n\n        self.logger.debug(\"All required services registered successfully\")\n\n        self.logger.info(\"AIPerf System is READY\")\n        # Wait for all required services to be started\n        await self.start_all_services()\n        try:\n            await self.service_manager.wait_for_all_services_start()\n        except Exception as e:\n            self.logger.error(\"Failed to wait for all services to start: %s\", e)\n            raise ServiceInitializationError from e\n\n        if self.stop_event.is_set():\n            self.logger.debug(\"System Controller stopped before all services started\")\n            return  # Don't continue with the rest of the initialization\n\n        self.logger.debug(\"All required services started successfully\")\n        self.logger.info(\"AIPerf System is RUNNING\")\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the system controller and all running services.\n\n        This method will:\n        - Stop all running services\n        \"\"\"\n        self.logger.debug(\"Stopping System Controller\")\n        self.logger.info(\"AIPerf System is SHUTTING DOWN\")\n\n        try:\n            await self.service_manager.stop_all_services()\n        except Exception as e:\n            self.logger.error(\"Failed to stop all services: %s\", e)\n            raise ServiceStopError from e\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up system controller-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up System Controller\")\n        # TODO: Additional cleanup if needed\n\n    async def start_all_services(self) -&gt; None:\n        \"\"\"Start all required services.\"\"\"\n        self.logger.debug(\"Starting services\")\n        for service_info in self.service_manager.service_id_map.values():\n            if service_info.state == ServiceState.READY:\n                try:\n                    await self.send_command_to_service(\n                        target_service_id=service_info.service_id,\n                        command=CommandType.START,\n                    )\n\n                except Exception as e:\n                    self.logger.warning(\"Failed to start service: %s\", e)\n                    # Continue to the next service\n                    # TODO: should we have some sort of retries?\n                    continue\n\n    async def _process_registration_message(self, message: RegistrationMessage) -&gt; None:\n        \"\"\"Process a registration response from a service. It will\n        add the service to the service manager and send a configure command\n        to the service.\n\n        Args:\n            message: The registration response to process\n        \"\"\"\n        service_id = message.service_id\n        service_type = message.payload.service_type\n\n        self.logger.debug(\n            f\"Processing registration from {service_type} with ID: {service_id}\"\n        )\n\n        service_info = ServiceRunInfo(\n            registration_status=ServiceRegistrationStatus.REGISTERED,\n            service_type=service_type,\n            service_id=service_id,\n            first_seen=time.time_ns(),\n            state=ServiceState.READY,\n            last_seen=time.time_ns(),\n        )\n\n        self.service_manager.service_id_map[service_id] = service_info\n        if service_type not in self.service_manager.service_map:\n            self.service_manager.service_map[service_type] = []\n        self.service_manager.service_map[service_type].append(service_info)\n\n        is_required = service_type in self.required_service_types\n        self.logger.debug(\n            f\"Registered {'required' if is_required else 'non-required'} \"\n            f\"service: {service_type} with ID: {service_id}\"\n        )\n\n        # Send configure command to the newly registered service\n        # TODO: Retrieve the configuration to send to the service\n        try:\n            await self.send_command_to_service(\n                target_service_id=service_id,\n                command=CommandType.CONFIGURE,\n                data=None,\n            )\n        except Exception as e:\n            self.logger.error(\n                f\"Failed to send configure command to {service_type} (ID: {service_id}): {e}\"\n            )\n            raise ServiceConfigureError from e\n\n        self.logger.debug(\n            f\"Sent configure command to {service_type} (ID: {service_id})\"\n        )\n\n    async def _process_heartbeat_message(self, message: HeartbeatMessage) -&gt; None:\n        \"\"\"Process a heartbeat response from a service. It will\n        update the last seen timestamp and state of the service.\n\n        Args:\n            message: The heartbeat response to process\n        \"\"\"\n        service_id = message.service_id\n        service_type = message.payload.service_type\n        timestamp = message.timestamp\n\n        self.logger.debug(f\"Received heartbeat from {service_type} (ID: {service_id})\")\n\n        # Update the last heartbeat timestamp if the component exists\n        try:\n            service_info = self.service_manager.service_id_map.get(service_id)\n            service_info.last_seen = timestamp\n            service_info.state = message.payload.state\n            self.logger.debug(f\"Updated heartbeat for {service_id} to {timestamp}\")\n        except Exception:\n            self.logger.warning(\n                f\"Received heartbeat from unknown service: {service_id} ({service_type})\"\n            )\n\n    async def _process_status_message(self, message: StatusMessage) -&gt; None:\n        \"\"\"Process a status response from a service. It will\n        update the state of the service with the service manager.\n\n        Args:\n            message: The status response to process\n        \"\"\"\n        service_id = message.service_id\n        service_type = message.payload.service_type\n        state = message.payload.state\n\n        self.logger.debug(\n            f\"Received status update from {service_type} (ID: {service_id}): {state}\"\n        )\n\n        # Update the component state if the component exists\n        try:\n            service_info = self.service_manager.service_id_map.get(service_id)\n            service_info.state = message.payload.state\n            self.logger.debug(f\"Updated state for {service_id} to {state}\")\n        except Exception:\n            self.logger.warning(\n                f\"Received status update from un-registered service: {service_id} ({service_type})\"\n            )\n\n    async def send_command_to_service(\n        self,\n        target_service_id: str,\n        command: CommandType,\n        data: Any | None = None,\n    ) -&gt; None:\n        \"\"\"Send a command to a specific service.\n\n        Args:\n            target_service_id: ID of the target service\n            command: The command to send (from CommandType enum).\n            data: Optional data to send with the command.\n\n        Raises:\n            CommunicationNotInitializedError if the communication is not initialized\n            CommunicationPublishError if the command was not sent successfully\n        \"\"\"\n        if not self._comms:\n            self.logger.error(\"Cannot send command: Communication is not initialized\")\n            raise CommunicationNotInitializedError()\n\n        # Create command response using the helper method\n        command_message = self.create_command_message(\n            command=command,\n            target_service_id=target_service_id,\n            data=data,\n        )\n\n        # Publish command response\n        try:\n            await self.comms.publish(\n                topic=Topic.COMMAND,\n                message=command_message,\n            )\n        except Exception as e:\n            self.logger.error(\"Exception publishing command: %s\", e)\n            raise CommunicationPublishError from e\n</code></pre>"},{"location":"api/#aiperf.services.system_controller.system_controller.SystemController.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.system_controller.system_controller.SystemController.send_command_to_service","title":"<code>send_command_to_service(target_service_id, command, data=None)</code>  <code>async</code>","text":"<p>Send a command to a specific service.</p> <p>Parameters:</p> Name Type Description Default <code>target_service_id</code> <code>str</code> <p>ID of the target service</p> required <code>command</code> <code>CommandType</code> <p>The command to send (from CommandType enum).</p> required <code>data</code> <code>Any | None</code> <p>Optional data to send with the command.</p> <code>None</code> Source code in <code>aiperf/services/system_controller/system_controller.py</code> <pre><code>async def send_command_to_service(\n    self,\n    target_service_id: str,\n    command: CommandType,\n    data: Any | None = None,\n) -&gt; None:\n    \"\"\"Send a command to a specific service.\n\n    Args:\n        target_service_id: ID of the target service\n        command: The command to send (from CommandType enum).\n        data: Optional data to send with the command.\n\n    Raises:\n        CommunicationNotInitializedError if the communication is not initialized\n        CommunicationPublishError if the command was not sent successfully\n    \"\"\"\n    if not self._comms:\n        self.logger.error(\"Cannot send command: Communication is not initialized\")\n        raise CommunicationNotInitializedError()\n\n    # Create command response using the helper method\n    command_message = self.create_command_message(\n        command=command,\n        target_service_id=target_service_id,\n        data=data,\n    )\n\n    # Publish command response\n    try:\n        await self.comms.publish(\n            topic=Topic.COMMAND,\n            message=command_message,\n        )\n    except Exception as e:\n        self.logger.error(\"Exception publishing command: %s\", e)\n        raise CommunicationPublishError from e\n</code></pre>"},{"location":"api/#aiperf.services.system_controller.system_controller.SystemController.start_all_services","title":"<code>start_all_services()</code>  <code>async</code>","text":"<p>Start all required services.</p> Source code in <code>aiperf/services/system_controller/system_controller.py</code> <pre><code>async def start_all_services(self) -&gt; None:\n    \"\"\"Start all required services.\"\"\"\n    self.logger.debug(\"Starting services\")\n    for service_info in self.service_manager.service_id_map.values():\n        if service_info.state == ServiceState.READY:\n            try:\n                await self.send_command_to_service(\n                    target_service_id=service_info.service_id,\n                    command=CommandType.START,\n                )\n\n            except Exception as e:\n                self.logger.warning(\"Failed to start service: %s\", e)\n                # Continue to the next service\n                # TODO: should we have some sort of retries?\n                continue\n</code></pre>"},{"location":"api/#aiperf.services.system_controller.system_controller.main","title":"<code>main()</code>","text":"<p>Main entry point for the system controller.</p> Source code in <code>aiperf/services/system_controller/system_controller.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the system controller.\"\"\"\n\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(SystemController)\n</code></pre>"},{"location":"api/#aiperfservicestiming_managertiming_manager","title":"aiperf.services.timing_manager.timing_manager","text":""},{"location":"api/#aiperf.services.timing_manager.timing_manager.TimingManager","title":"<code>TimingManager</code>","text":"<p>               Bases: <code>BaseComponentService</code></p> <p>The TimingManager service is responsible to generate the schedule and issuing timing credits for requests.</p> Source code in <code>aiperf/services/timing_manager/timing_manager.py</code> <pre><code>@ServiceFactory.register(ServiceType.TIMING_MANAGER)\nclass TimingManager(BaseComponentService):\n    \"\"\"\n    The TimingManager service is responsible to generate the schedule and issuing\n    timing credits for requests.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self._credit_lock = asyncio.Lock()\n        self._credits_available = 100\n        self.logger.debug(\"Initializing timing manager\")\n        self._credit_drop_task: asyncio.Task | None = None\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.TIMING_MANAGER\n\n    @property\n    def required_clients(self) -&gt; list[ClientType]:\n        \"\"\"The communication clients required by the service.\"\"\"\n        return [\n            *(super().required_clients or []),\n            PullClientType.CREDIT_RETURN,\n            PushClientType.CREDIT_DROP,\n        ]\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize timing manager-specific components.\"\"\"\n        self.logger.debug(\"Initializing timing manager\")\n        # TODO: Implement timing manager initialization\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the timing manager.\"\"\"\n        self.logger.debug(\"Starting timing manager\")\n        # TODO: Implement timing manager start\n        await self.comms.pull(\n            topic=Topic.CREDIT_RETURN,\n            callback=self._on_credit_return,\n        )\n        await self.set_state(ServiceState.RUNNING)\n        await asyncio.sleep(3)\n\n        self._credit_drop_task = asyncio.create_task(self._issue_credit_drops())\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the timing manager.\"\"\"\n        self.logger.debug(\"Stopping timing manager\")\n        # TODO: Implement timing manager stop\n        if self._credit_drop_task and not self._credit_drop_task.done():\n            self._credit_drop_task.cancel()\n            with contextlib.suppress(asyncio.CancelledError):\n                await self._credit_drop_task\n            self._credit_drop_task = None\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up timing manager-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up timing manager\")\n        # TODO: Implement timing manager cleanup\n\n    @on_configure\n    async def _configure(self, payload: BasePayload) -&gt; None:\n        \"\"\"Configure the timing manager.\"\"\"\n        self.logger.debug(f\"Configuring timing manager with payload: {payload}\")\n        # TODO: Implement timing manager configuration\n\n    async def _issue_credit_drops(self) -&gt; None:\n        \"\"\"Issue credit drops to workers.\"\"\"\n        self.logger.debug(\"Issuing credit drops to workers\")\n        # TODO: Actually implement real credit drop logic\n        while not self.stop_event.is_set():\n            try:\n                await asyncio.sleep(0.1)\n\n                async with self._credit_lock:\n                    if self._credits_available &lt;= 0:\n                        self.logger.warning(\n                            \"No credits available, skipping credit drop\"\n                        )\n                        continue\n                    self.logger.debug(\"Issuing credit drop\")\n                    self._credits_available -= 1\n\n                await self.comms.push(\n                    topic=Topic.CREDIT_DROP,\n                    message=self.create_message(\n                        payload=CreditDropPayload(\n                            amount=1,\n                            timestamp=time.time_ns(),\n                        ),\n                    ),\n                )\n            except asyncio.CancelledError:\n                self.logger.debug(\"Credit drop task cancelled\")\n                break\n            except Exception as e:\n                self.logger.error(f\"Exception issuing credit drop: {e}\")\n                await asyncio.sleep(0.1)\n\n    async def _on_credit_return(self, message: Message) -&gt; None:\n        \"\"\"Process a credit return response.\n\n        Args:\n            message: The response received from the pull request\n        \"\"\"\n        self.logger.debug(f\"Processing credit return: {message.payload}\")\n        async with self._credit_lock:\n            self._credits_available += message.payload.amount\n</code></pre>"},{"location":"api/#aiperf.services.timing_manager.timing_manager.TimingManager.required_clients","title":"<code>required_clients</code>  <code>property</code>","text":"<p>The communication clients required by the service.</p>"},{"location":"api/#aiperf.services.timing_manager.timing_manager.TimingManager.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.timing_manager.timing_manager.main","title":"<code>main()</code>","text":"<p>Main entry point for the timing manager.</p> Source code in <code>aiperf/services/timing_manager/timing_manager.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the timing manager.\"\"\"\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(TimingManager)\n</code></pre>"},{"location":"api/#aiperfservicesworkerworker","title":"aiperf.services.worker.worker","text":""},{"location":"api/#aiperf.services.worker.worker.Worker","title":"<code>Worker</code>","text":"<p>               Bases: <code>BaseService</code></p> <p>Worker is primarily responsible for converting the data into the appropriate format for the interface being used by the server. Also responsible for managing the conversation between turns.</p> Source code in <code>aiperf/services/worker/worker.py</code> <pre><code>class Worker(BaseService):\n    \"\"\"Worker is primarily responsible for converting the data into the appropriate\n    format for the interface being used by the server. Also responsible for managing\n    the conversation between turns.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Initializing worker\")\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.WORKER\n\n    @property\n    def required_clients(self) -&gt; list[ClientType]:\n        \"\"\"The communication clients required by the service.\"\"\"\n        return [\n            *(super().required_clients or []),\n            PullClientType.CREDIT_DROP,\n            PushClientType.CREDIT_RETURN,\n        ]\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize worker-specific components.\"\"\"\n        self.logger.debug(\"Initializing worker\")\n\n    @on_run\n    async def _run(self) -&gt; None:\n        \"\"\"Automatically start the worker in the run method.\"\"\"\n        await self.start()\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the worker.\"\"\"\n        self.logger.debug(\"Starting worker\")\n        # Subscribe to the credit drop topic\n        await self.comms.pull(\n            topic=Topic.CREDIT_DROP,\n            callback=self._process_credit_drop,\n        )\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the worker.\"\"\"\n        self.logger.debug(\"Stopping worker\")\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up worker-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up worker\")\n\n    async def _process_credit_drop(self, message: CreditDropMessage) -&gt; None:\n        \"\"\"Process a credit drop response.\n\n        Args:\n            message: The message received from the credit drop\n        \"\"\"\n        self.logger.debug(f\"Processing credit drop: {message}\")\n        # TODO: Implement actual worker logic\n        await asyncio.sleep(1)  # Simulate some processing time\n\n        self.logger.debug(\"Returning credits\")\n        await self.comms.push(\n            topic=Topic.CREDIT_RETURN,\n            message=self.create_message(\n                payload=CreditReturnPayload(amount=1),\n            ),\n        )\n</code></pre>"},{"location":"api/#aiperf.services.worker.worker.Worker.required_clients","title":"<code>required_clients</code>  <code>property</code>","text":"<p>The communication clients required by the service.</p>"},{"location":"api/#aiperf.services.worker.worker.Worker.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.worker.worker.main","title":"<code>main()</code>","text":"<p>Main entry point for the worker.</p> Source code in <code>aiperf/services/worker/worker.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the worker.\"\"\"\n\n    import uvloop\n\n    from aiperf.common.config.loader import load_service_config\n\n    # Load the service configuration\n    cfg = load_service_config()\n\n    # Create and run the worker\n    worker = Worker(cfg)\n    uvloop.run(worker.run_forever())\n</code></pre>"},{"location":"api/#aiperfservicesworker_managerworker_manager","title":"aiperf.services.worker_manager.worker_manager","text":""},{"location":"api/#aiperf.services.worker_manager.worker_manager.WorkerManager","title":"<code>WorkerManager</code>","text":"<p>               Bases: <code>BaseComponentService</code></p> <p>The WorkerManager service is primary responsibility is to pull data from the dataset manager after receiving the timing credit from the timing manager. It will then push the request data to the worker to issue to the request.</p> Source code in <code>aiperf/services/worker_manager/worker_manager.py</code> <pre><code>@ServiceFactory.register(ServiceType.WORKER_MANAGER)\nclass WorkerManager(BaseComponentService):\n    \"\"\"\n    The WorkerManager service is primary responsibility is to pull data from the dataset manager\n    after receiving the timing credit from the timing manager. It will then push the request data\n    to the worker to issue to the request.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Initializing worker manager\")\n        self.workers: dict[str, WorkerProcess] = {}\n        # TODO: Need to implement some sort of max workers\n        self.cpu_count = multiprocessing.cpu_count()\n        self.worker_count = self.cpu_count\n        self.logger.debug(\n            f\"Detected {self.cpu_count} CPU threads. Spawning {self.worker_count} workers\"\n        )\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.WORKER_MANAGER\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize worker manager-specific components.\"\"\"\n        self.logger.debug(\"Initializing worker manager\")\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the worker manager.\"\"\"\n        self.logger.debug(\"Starting worker manager\")\n\n        # Spawn workers based on CPU count\n        if self.service_config.service_run_type == ServiceRunType.MULTIPROCESSING:\n            await self._spawn_multiprocessing_workers()\n\n        elif self.service_config.service_run_type == ServiceRunType.KUBERNETES:\n            await self._spawn_kubernetes_workers()\n\n        else:\n            self.logger.warning(\n                f\"Unsupported run type: {self.service_config.service_run_type}\"\n            )\n            raise ConfigError(\n                f\"Unsupported run type: {self.service_config.service_run_type}\"\n            )\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the worker manager.\"\"\"\n        self.logger.debug(\"Stopping worker manager\")\n        # TODO: This needs to be investigated, as currently we handle the exit signal\n        #       by all workers already, so need to understand best way to handle this\n        # # Stop all workers\n        # if self.service_config.service_run_type == ServiceRunType.MULTIPROCESSING:\n        #     await self._stop_multiprocessing_workers()\n        # elif self.service_config.service_run_type == ServiceRunType.KUBERNETES:\n        #     await self._stop_kubernetes_workers()\n        # else:\n        #     self.logger.warning(\n        #         f\"Unsupported run type: {self.service_config.service_run_type}\"\n        #     )\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up worker manager-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up worker manager\")\n        self.workers.clear()\n\n    async def _spawn_kubernetes_workers(self) -&gt; None:\n        \"\"\"Spawn worker processes using Kubernetes.\"\"\"\n        self.logger.debug(f\"Spawning {self.worker_count} worker processes\")\n\n        # TODO: Implement Kubernetes start\n        raise NotImplementedError(\"Kubernetes start not implemented\")\n\n    async def _stop_kubernetes_workers(self) -&gt; None:\n        \"\"\"Stop worker processes using Kubernetes.\"\"\"\n        self.logger.debug(\"Stopping all worker processes\")\n\n        # TODO: Implement Kubernetes stop\n        raise NotImplementedError(\"Kubernetes stop not implemented\")\n\n    async def _spawn_multiprocessing_workers(self) -&gt; None:\n        \"\"\"Spawn worker processes using multiprocessing.\"\"\"\n        self.logger.debug(f\"Spawning {self.worker_count} worker processes\")\n\n        for i in range(self.worker_count):\n            worker_id = f\"worker_{i}\"\n            process = multiprocessing.Process(\n                target=bootstrap_and_run_service,\n                name=f\"worker_{i}_process\",\n                args=(Worker, self.service_config),\n                daemon=True,\n            )\n            process.start()\n            self.workers[worker_id] = WorkerProcess(\n                worker_id=worker_id, process=process\n            )\n            self.logger.debug(\n                f\"Started worker process {worker_id} (pid: {process.pid})\"\n            )\n\n    async def _stop_multiprocessing_workers(self) -&gt; None:\n        \"\"\"Stop all multiprocessing worker processes.\"\"\"\n        self.logger.debug(\"Stopping all worker processes\")\n\n        # First terminate all processes\n        for worker_id, worker_info in self.workers.items():\n            self.logger.debug(f\"Stopping worker process {worker_id} {worker_info}\")\n            process = worker_info.process\n            if process and process.is_alive():\n                self.logger.debug(\n                    f\"Terminating worker process {worker_id} (pid: {process.pid})\"\n                )\n                process.terminate()\n\n        # Then wait for all to finish\n        await asyncio.gather(\n            *[\n                self._wait_for_process(worker_id, worker_info.process)\n                for worker_id, worker_info in self.workers.items()\n                if worker_info.process\n            ]\n        )\n\n        self.logger.debug(\"All worker processes stopped\")\n\n    async def _wait_for_process(\n        self, worker_id: str, process: multiprocessing.Process\n    ) -&gt; None:\n        \"\"\"Wait for a process to terminate with timeout handling.\"\"\"\n        try:\n            await asyncio.wait_for(\n                asyncio.to_thread(process.join, timeout=1.0),  # Add timeout to join\n                timeout=5.0,  # Overall timeout\n            )\n            self.logger.debug(\n                f\"Worker process {worker_id} (pid: {process.pid}) stopped\"\n            )\n        except asyncio.TimeoutError:\n            self.logger.warning(\n                f\"Worker process {worker_id} (pid: {process.pid}) did not \"\n                f\"terminate gracefully, killing\"\n            )\n            process.kill()\n\n    @on_configure\n    async def _configure(self, payload: BasePayload) -&gt; None:\n        \"\"\"Configure the worker manager.\"\"\"\n        self.logger.debug(f\"Configuring worker manager with payload: {payload}\")\n</code></pre>"},{"location":"api/#aiperf.services.worker_manager.worker_manager.WorkerManager.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.worker_manager.worker_manager.WorkerProcess","title":"<code>WorkerProcess</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about a worker process.</p> Source code in <code>aiperf/services/worker_manager/worker_manager.py</code> <pre><code>class WorkerProcess(BaseModel):\n    \"\"\"Information about a worker process.\"\"\"\n\n    worker_id: str = Field(..., description=\"ID of the worker process\")\n    process: Any = Field(None, description=\"Process object or task\")\n</code></pre>"},{"location":"api/#aiperf.services.worker_manager.worker_manager.main","title":"<code>main()</code>","text":"<p>Main entry point for the worker manager.</p> Source code in <code>aiperf/services/worker_manager/worker_manager.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the worker manager.\"\"\"\n\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(WorkerManager)\n</code></pre>"},{"location":"api/#aiperftestsbase_test_component_service","title":"aiperf.tests.base_test_component_service","text":"<p>Base test class for component services.</p>"},{"location":"api/#aiperf.tests.base_test_component_service.BaseTestComponentService","title":"<code>BaseTestComponentService</code>","text":"<p>               Bases: <code>BaseTestService</code></p> <p>Base class for testing component services.</p> <p>This extends BaseTestService with specific tests for the component service functionality such as heartbeat, registration, and status updates.</p> Source code in <code>aiperf/tests/base_test_component_service.py</code> <pre><code>class BaseTestComponentService(BaseTestService):\n    \"\"\"\n    Base class for testing component services.\n\n    This extends BaseTestService with specific tests for the component service\n    functionality such as heartbeat, registration, and status updates.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"\n        Return the service class to test.\n\n        Returns:\n            The BaseComponentService class for testing\n        \"\"\"\n        return BaseComponentService\n\n    async def test_service_heartbeat(\n        self, initialized_service: BaseComponentService, mock_communication: MagicMock\n    ) -&gt; None:\n        \"\"\"\n        Test that the service sends heartbeat messages correctly.\n\n        Verifies:\n        1. The service generates and sends a valid heartbeat message\n        2. The message contains the correct service information\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        # Directly send a heartbeat instead of waiting for the task\n        await service.send_heartbeat()\n\n        # Check that a heartbeat message was published\n        assert Topic.HEARTBEAT in mock_communication.mock_data.published_messages\n        assert len(mock_communication.mock_data.published_messages[Topic.HEARTBEAT]) &gt; 0\n\n        # Verify heartbeat message contents\n        heartbeat_msg = mock_communication.mock_data.published_messages[\n            Topic.HEARTBEAT\n        ][0]\n        assert heartbeat_msg.service_id == service.service_id\n        assert heartbeat_msg.payload.service_type == service.service_type\n\n    async def test_service_registration(\n        self, initialized_service: BaseComponentService, mock_communication: MagicMock\n    ) -&gt; None:\n        \"\"\"\n        Test that the service registers with the system controller.\n\n        Verifies:\n        1. The service sends a registration message to the controller\n        2. The registration message contains the correct service information\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        # Register the service\n        await service.register()\n\n        # Check that a registration message was published\n        assert Topic.REGISTRATION in mock_communication.mock_data.published_messages\n\n        # Verify registration message contents\n        registration_msg = mock_communication.mock_data.published_messages[\n            Topic.REGISTRATION\n        ][0]\n        assert registration_msg.service_id == service.service_id\n        assert registration_msg.payload.service_type == service.service_type\n\n    async def test_service_status_update(\n        self, initialized_service: BaseComponentService, mock_communication: MagicMock\n    ) -&gt; None:\n        \"\"\"\n        Test that the service updates its status correctly.\n\n        Verifies:\n        1. The service publishes status messages when state changes\n        2. The status message contains the correct state and service information\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        # Update the service status\n        await service.set_state(ServiceState.READY)\n\n        # Check that a status message was published\n        assert Topic.STATUS in mock_communication.mock_data.published_messages\n\n        # Verify status message contents\n        status_msg = mock_communication.mock_data.published_messages[Topic.STATUS][0]\n        assert status_msg.service_id == service.service_id\n        assert status_msg.payload.service_type == service.service_type\n        assert status_msg.payload.state == ServiceState.READY\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_component_service.BaseTestComponentService.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to test.</p> <p>Returns:</p> Type Description <code>type[BaseService]</code> <p>The BaseComponentService class for testing</p> Source code in <code>aiperf/tests/base_test_component_service.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"\n    Return the service class to test.\n\n    Returns:\n        The BaseComponentService class for testing\n    \"\"\"\n    return BaseComponentService\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_component_service.BaseTestComponentService.test_service_heartbeat","title":"<code>test_service_heartbeat(initialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Test that the service sends heartbeat messages correctly.</p> <p>Verifies: 1. The service generates and sends a valid heartbeat message 2. The message contains the correct service information</p> Source code in <code>aiperf/tests/base_test_component_service.py</code> <pre><code>async def test_service_heartbeat(\n    self, initialized_service: BaseComponentService, mock_communication: MagicMock\n) -&gt; None:\n    \"\"\"\n    Test that the service sends heartbeat messages correctly.\n\n    Verifies:\n    1. The service generates and sends a valid heartbeat message\n    2. The message contains the correct service information\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    # Directly send a heartbeat instead of waiting for the task\n    await service.send_heartbeat()\n\n    # Check that a heartbeat message was published\n    assert Topic.HEARTBEAT in mock_communication.mock_data.published_messages\n    assert len(mock_communication.mock_data.published_messages[Topic.HEARTBEAT]) &gt; 0\n\n    # Verify heartbeat message contents\n    heartbeat_msg = mock_communication.mock_data.published_messages[\n        Topic.HEARTBEAT\n    ][0]\n    assert heartbeat_msg.service_id == service.service_id\n    assert heartbeat_msg.payload.service_type == service.service_type\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_component_service.BaseTestComponentService.test_service_registration","title":"<code>test_service_registration(initialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Test that the service registers with the system controller.</p> <p>Verifies: 1. The service sends a registration message to the controller 2. The registration message contains the correct service information</p> Source code in <code>aiperf/tests/base_test_component_service.py</code> <pre><code>async def test_service_registration(\n    self, initialized_service: BaseComponentService, mock_communication: MagicMock\n) -&gt; None:\n    \"\"\"\n    Test that the service registers with the system controller.\n\n    Verifies:\n    1. The service sends a registration message to the controller\n    2. The registration message contains the correct service information\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    # Register the service\n    await service.register()\n\n    # Check that a registration message was published\n    assert Topic.REGISTRATION in mock_communication.mock_data.published_messages\n\n    # Verify registration message contents\n    registration_msg = mock_communication.mock_data.published_messages[\n        Topic.REGISTRATION\n    ][0]\n    assert registration_msg.service_id == service.service_id\n    assert registration_msg.payload.service_type == service.service_type\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_component_service.BaseTestComponentService.test_service_status_update","title":"<code>test_service_status_update(initialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Test that the service updates its status correctly.</p> <p>Verifies: 1. The service publishes status messages when state changes 2. The status message contains the correct state and service information</p> Source code in <code>aiperf/tests/base_test_component_service.py</code> <pre><code>async def test_service_status_update(\n    self, initialized_service: BaseComponentService, mock_communication: MagicMock\n) -&gt; None:\n    \"\"\"\n    Test that the service updates its status correctly.\n\n    Verifies:\n    1. The service publishes status messages when state changes\n    2. The status message contains the correct state and service information\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    # Update the service status\n    await service.set_state(ServiceState.READY)\n\n    # Check that a status message was published\n    assert Topic.STATUS in mock_communication.mock_data.published_messages\n\n    # Verify status message contents\n    status_msg = mock_communication.mock_data.published_messages[Topic.STATUS][0]\n    assert status_msg.service_id == service.service_id\n    assert status_msg.payload.service_type == service.service_type\n    assert status_msg.payload.state == ServiceState.READY\n</code></pre>"},{"location":"api/#aiperftestsbase_test_controller_service","title":"aiperf.tests.base_test_controller_service","text":"<p>Base test class for controller services.</p>"},{"location":"api/#aiperf.tests.base_test_controller_service.BaseTestControllerService","title":"<code>BaseTestControllerService</code>","text":"<p>               Bases: <code>BaseTestService</code></p> <p>Base class for testing controller services.</p> <p>This extends BaseTestService with specific tests for controller service functionality such as command sending, service registration handling, and monitoring of component services.</p> Source code in <code>aiperf/tests/base_test_controller_service.py</code> <pre><code>class BaseTestControllerService(BaseTestService):\n    \"\"\"\n    Base class for testing controller services.\n\n    This extends BaseTestService with specific tests for controller service\n    functionality such as command sending, service registration handling,\n    and monitoring of component services.\n    \"\"\"\n\n    async def test_controller_command_publishing(\n        self, initialized_service: BaseControllerService, mock_communication: MagicMock\n    ) -&gt; None:\n        \"\"\"\n        Test that the controller can publish command messages.\n\n        Verifies the controller can send properly formatted commands to components.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        # Create a test command message\n        test_service_id = \"test_service_123\"\n        command = CommandType.START\n\n        # Create a command message\n        command_payload = CommandPayload(\n            command=command,\n            target_service_id=test_service_id,\n        )\n        command_message = service.create_message(command_payload)\n\n        # Publish the command\n        await service.comms.publish(Topic.COMMAND, command_message)\n\n        # Check that the command was published\n        assert Topic.COMMAND in mock_communication.mock_data.published_messages\n        assert len(mock_communication.mock_data.published_messages[Topic.COMMAND]) == 1\n\n        # Verify command message\n        published_cmd = mock_communication.mock_data.published_messages[Topic.COMMAND][\n            0\n        ]\n        assert published_cmd.service_id == service.service_id\n        assert published_cmd.payload.command == command\n        assert published_cmd.payload.target_service_id == test_service_id\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_controller_service.BaseTestControllerService.test_controller_command_publishing","title":"<code>test_controller_command_publishing(initialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Test that the controller can publish command messages.</p> <p>Verifies the controller can send properly formatted commands to components.</p> Source code in <code>aiperf/tests/base_test_controller_service.py</code> <pre><code>async def test_controller_command_publishing(\n    self, initialized_service: BaseControllerService, mock_communication: MagicMock\n) -&gt; None:\n    \"\"\"\n    Test that the controller can publish command messages.\n\n    Verifies the controller can send properly formatted commands to components.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    # Create a test command message\n    test_service_id = \"test_service_123\"\n    command = CommandType.START\n\n    # Create a command message\n    command_payload = CommandPayload(\n        command=command,\n        target_service_id=test_service_id,\n    )\n    command_message = service.create_message(command_payload)\n\n    # Publish the command\n    await service.comms.publish(Topic.COMMAND, command_message)\n\n    # Check that the command was published\n    assert Topic.COMMAND in mock_communication.mock_data.published_messages\n    assert len(mock_communication.mock_data.published_messages[Topic.COMMAND]) == 1\n\n    # Verify command message\n    published_cmd = mock_communication.mock_data.published_messages[Topic.COMMAND][\n        0\n    ]\n    assert published_cmd.service_id == service.service_id\n    assert published_cmd.payload.command == command\n    assert published_cmd.payload.target_service_id == test_service_id\n</code></pre>"},{"location":"api/#aiperftestsbase_test_service","title":"aiperf.tests.base_test_service","text":"<p>Base test class for testing AIPerf services.</p>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService","title":"<code>BaseTestService</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base test class for all service tests.</p> <p>This class provides common test methods and fixtures for testing AIPerf services. Specific service test classes should inherit from this class and implement service-specific fixtures and tests.</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>class BaseTestService(ABC):\n    \"\"\"\n    Base test class for all service tests.\n\n    This class provides common test methods and fixtures for testing\n    AIPerf services. Specific service test classes should inherit from\n    this class and implement service-specific fixtures and tests.\n    \"\"\"\n\n    @pytest.fixture(autouse=True)\n    def no_sleep(self, monkeypatch) -&gt; None:\n        \"\"\"\n        Patch asyncio.sleep with a no-op to prevent test delays.\n\n        This ensures tests don't need to wait for real sleep calls.\n        \"\"\"\n        monkeypatch.setattr(asyncio, \"sleep\", async_noop)\n\n    @pytest.fixture(autouse=True)\n    def patch_communication_factory(\n        self, mock_communication: MagicMock\n    ) -&gt; Generator[None, None, None]:\n        \"\"\"\n        Patch the communication factory to always return our mock communication.\n\n        This ensures no real communication is attempted during tests.\n        \"\"\"\n        with patch(\n            \"aiperf.common.factories.CommunicationFactory.create_instance\",\n            return_value=mock_communication,\n        ):\n            yield\n\n    @abstractmethod\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"\n        Return the service class to test.\n\n        Must be implemented by subclasses to specify which service is being tested.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method\")\n\n    @pytest.fixture\n    def service_config(self) -&gt; ServiceConfig:\n        \"\"\"\n        Create a service configuration for testing.\n\n        Returns:\n            A ServiceConfig instance with test settings\n        \"\"\"\n        return ServiceConfig(\n            service_run_type=ServiceRunType.MULTIPROCESSING,\n            comm_backend=CommunicationBackend.ZMQ_TCP,\n        )\n\n    @pytest.fixture\n    async def uninitialized_service(\n        self,\n        service_class: type[BaseService],\n        service_config: ServiceConfig,\n    ) -&gt; AsyncGenerator[BaseService, None]:\n        \"\"\"\n        Create an uninitialized instance of the service under test.\n\n        This provides a service instance before initialize() has been called,\n        allowing tests to verify initialization behavior.\n\n        Returns:\n            An uninitialized instance of the service\n\n        Example usage:\n        ```python\n        async def test_service_initialization(uninitialized_service: BaseService):\n            service = await async_fixture(uninitialized_service)\n            await service.initialize()\n        ```\n        \"\"\"\n        # Patch the heartbeat task otherwise it will run forever\n        with patch(\n            \"aiperf.common.service.base_component_service.BaseComponentService._heartbeat_task\",\n            lambda: None,\n        ):\n            service = service_class(service_config=service_config)\n            yield service\n\n    @pytest.fixture\n    async def initialized_service(\n        self,\n        uninitialized_service: BaseService,\n        mock_communication: MagicMock,\n    ) -&gt; AsyncGenerator[BaseService, None]:\n        \"\"\"\n        Create and initialize the service under test.\n\n        This fixture sets up a complete service instance ready for testing,\n        with the communication layer mocked.\n\n        Returns:\n            An initialized instance of the service\n\n        Example usage:\n        ```python\n        async def test_service_foo(initialized_service: BaseService):\n            service = await async_fixture(initialized_service)\n            await service.foo()\n        ```\n        \"\"\"\n        service = await async_fixture(uninitialized_service)\n\n        await service.initialize()\n\n        yield service\n\n    @pytest.mark.asyncio\n    async def test_service_initialization(\n        self, uninitialized_service: BaseService, mock_communication: MagicMock\n    ) -&gt; None:\n        \"\"\"\n        Test that the service initializes correctly. This will be executed\n        for every service that inherits from BaseTestService.\n\n        This verifies:\n        1. The service has a valid ID and type\n        2. The service transitions to the correct state during initialization\n        3. The service's internal initialization method is called\n        \"\"\"\n        service = await async_fixture(uninitialized_service)\n\n        # Check that the service has an ID and type\n        assert service.service_id is not None\n        assert service.service_type is not None\n\n        # Check that the service is not initialized\n        assert service.state == ServiceState.UNKNOWN\n\n        # Initialize the service\n        await service.initialize()\n\n        # Check that the service is initialized and in the READY state\n        assert service.is_initialized\n        assert service.state == ServiceState.READY\n\n        await service.stop()\n\n    @pytest.mark.asyncio\n    async def test_service_start_stop(self, initialized_service: BaseService) -&gt; None:\n        \"\"\"\n        Test that the service can start and stop correctly. This will be executed\n        for every service that inherits from BaseTestService.\n\n        This verifies:\n        1. The service transitions to the `ServiceState.RUNNING` state when started\n        2. The service transitions to the `ServiceState.STOPPED` state when stopped\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        # Start the service\n        await service.start()\n        assert service.state == ServiceState.RUNNING\n\n        # Stop the service\n        await service.stop()\n        assert service.state == ServiceState.STOPPED\n\n    @pytest.mark.parametrize(\n        \"state\",\n        [state for state in ServiceState if state != ServiceState.UNKNOWN],\n    )\n    @pytest.mark.asyncio\n    async def test_service_state_transitions(\n        self, initialized_service: BaseService, state: ServiceState\n    ) -&gt; None:\n        \"\"\"\n        Test that the service can transition to all possible states. This will be executed\n        for every service that inherits from BaseTestService.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        # Update the service state\n        await service.set_state(state)\n\n        # Check that the service state was updated\n        assert service.state == state\n\n    @pytest.mark.asyncio\n    async def test_service_run_does_not_start(\n        self, initialized_service: BaseService\n    ) -&gt; None:\n        \"\"\"\n        Test that the service does not start when the run method is called (default behavior). This will be executed\n        for every service that inherits from BaseTestService.\n        \"\"\"\n        service = await async_fixture(MagicMock(wraps=initialized_service))\n\n        service._forever_loop.return_value = None\n        await service.run_forever()\n        assert not service.start.called\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.initialized_service","title":"<code>initialized_service(uninitialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Create and initialize the service under test.</p> <p>This fixture sets up a complete service instance ready for testing, with the communication layer mocked.</p> <p>Returns:</p> Type Description <code>AsyncGenerator[BaseService, None]</code> <p>An initialized instance of the service</p> <p>Example usage:</p> <pre><code>async def test_service_foo(initialized_service: BaseService):\n    service = await async_fixture(initialized_service)\n    await service.foo()\n</code></pre> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.fixture\nasync def initialized_service(\n    self,\n    uninitialized_service: BaseService,\n    mock_communication: MagicMock,\n) -&gt; AsyncGenerator[BaseService, None]:\n    \"\"\"\n    Create and initialize the service under test.\n\n    This fixture sets up a complete service instance ready for testing,\n    with the communication layer mocked.\n\n    Returns:\n        An initialized instance of the service\n\n    Example usage:\n    ```python\n    async def test_service_foo(initialized_service: BaseService):\n        service = await async_fixture(initialized_service)\n        await service.foo()\n    ```\n    \"\"\"\n    service = await async_fixture(uninitialized_service)\n\n    await service.initialize()\n\n    yield service\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.no_sleep","title":"<code>no_sleep(monkeypatch)</code>","text":"<p>Patch asyncio.sleep with a no-op to prevent test delays.</p> <p>This ensures tests don't need to wait for real sleep calls.</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.fixture(autouse=True)\ndef no_sleep(self, monkeypatch) -&gt; None:\n    \"\"\"\n    Patch asyncio.sleep with a no-op to prevent test delays.\n\n    This ensures tests don't need to wait for real sleep calls.\n    \"\"\"\n    monkeypatch.setattr(asyncio, \"sleep\", async_noop)\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.patch_communication_factory","title":"<code>patch_communication_factory(mock_communication)</code>","text":"<p>Patch the communication factory to always return our mock communication.</p> <p>This ensures no real communication is attempted during tests.</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.fixture(autouse=True)\ndef patch_communication_factory(\n    self, mock_communication: MagicMock\n) -&gt; Generator[None, None, None]:\n    \"\"\"\n    Patch the communication factory to always return our mock communication.\n\n    This ensures no real communication is attempted during tests.\n    \"\"\"\n    with patch(\n        \"aiperf.common.factories.CommunicationFactory.create_instance\",\n        return_value=mock_communication,\n    ):\n        yield\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.service_class","title":"<code>service_class()</code>  <code>abstractmethod</code>","text":"<p>Return the service class to test.</p> <p>Must be implemented by subclasses to specify which service is being tested.</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@abstractmethod\n@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"\n    Return the service class to test.\n\n    Must be implemented by subclasses to specify which service is being tested.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement this method\")\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.service_config","title":"<code>service_config()</code>","text":"<p>Create a service configuration for testing.</p> <p>Returns:</p> Type Description <code>ServiceConfig</code> <p>A ServiceConfig instance with test settings</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.fixture\ndef service_config(self) -&gt; ServiceConfig:\n    \"\"\"\n    Create a service configuration for testing.\n\n    Returns:\n        A ServiceConfig instance with test settings\n    \"\"\"\n    return ServiceConfig(\n        service_run_type=ServiceRunType.MULTIPROCESSING,\n        comm_backend=CommunicationBackend.ZMQ_TCP,\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.test_service_initialization","title":"<code>test_service_initialization(uninitialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Test that the service initializes correctly. This will be executed for every service that inherits from BaseTestService.</p> <p>This verifies: 1. The service has a valid ID and type 2. The service transitions to the correct state during initialization 3. The service's internal initialization method is called</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_service_initialization(\n    self, uninitialized_service: BaseService, mock_communication: MagicMock\n) -&gt; None:\n    \"\"\"\n    Test that the service initializes correctly. This will be executed\n    for every service that inherits from BaseTestService.\n\n    This verifies:\n    1. The service has a valid ID and type\n    2. The service transitions to the correct state during initialization\n    3. The service's internal initialization method is called\n    \"\"\"\n    service = await async_fixture(uninitialized_service)\n\n    # Check that the service has an ID and type\n    assert service.service_id is not None\n    assert service.service_type is not None\n\n    # Check that the service is not initialized\n    assert service.state == ServiceState.UNKNOWN\n\n    # Initialize the service\n    await service.initialize()\n\n    # Check that the service is initialized and in the READY state\n    assert service.is_initialized\n    assert service.state == ServiceState.READY\n\n    await service.stop()\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.test_service_run_does_not_start","title":"<code>test_service_run_does_not_start(initialized_service)</code>  <code>async</code>","text":"<p>Test that the service does not start when the run method is called (default behavior). This will be executed for every service that inherits from BaseTestService.</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_service_run_does_not_start(\n    self, initialized_service: BaseService\n) -&gt; None:\n    \"\"\"\n    Test that the service does not start when the run method is called (default behavior). This will be executed\n    for every service that inherits from BaseTestService.\n    \"\"\"\n    service = await async_fixture(MagicMock(wraps=initialized_service))\n\n    service._forever_loop.return_value = None\n    await service.run_forever()\n    assert not service.start.called\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.test_service_start_stop","title":"<code>test_service_start_stop(initialized_service)</code>  <code>async</code>","text":"<p>Test that the service can start and stop correctly. This will be executed for every service that inherits from BaseTestService.</p> <p>This verifies: 1. The service transitions to the <code>ServiceState.RUNNING</code> state when started 2. The service transitions to the <code>ServiceState.STOPPED</code> state when stopped</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_service_start_stop(self, initialized_service: BaseService) -&gt; None:\n    \"\"\"\n    Test that the service can start and stop correctly. This will be executed\n    for every service that inherits from BaseTestService.\n\n    This verifies:\n    1. The service transitions to the `ServiceState.RUNNING` state when started\n    2. The service transitions to the `ServiceState.STOPPED` state when stopped\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    # Start the service\n    await service.start()\n    assert service.state == ServiceState.RUNNING\n\n    # Stop the service\n    await service.stop()\n    assert service.state == ServiceState.STOPPED\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.test_service_state_transitions","title":"<code>test_service_state_transitions(initialized_service, state)</code>  <code>async</code>","text":"<p>Test that the service can transition to all possible states. This will be executed for every service that inherits from BaseTestService.</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.mark.parametrize(\n    \"state\",\n    [state for state in ServiceState if state != ServiceState.UNKNOWN],\n)\n@pytest.mark.asyncio\nasync def test_service_state_transitions(\n    self, initialized_service: BaseService, state: ServiceState\n) -&gt; None:\n    \"\"\"\n    Test that the service can transition to all possible states. This will be executed\n    for every service that inherits from BaseTestService.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    # Update the service state\n    await service.set_state(state)\n\n    # Check that the service state was updated\n    assert service.state == state\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.uninitialized_service","title":"<code>uninitialized_service(service_class, service_config)</code>  <code>async</code>","text":"<p>Create an uninitialized instance of the service under test.</p> <p>This provides a service instance before initialize() has been called, allowing tests to verify initialization behavior.</p> <p>Returns:</p> Type Description <code>AsyncGenerator[BaseService, None]</code> <p>An uninitialized instance of the service</p> <p>Example usage:</p> <pre><code>async def test_service_initialization(uninitialized_service: BaseService):\n    service = await async_fixture(uninitialized_service)\n    await service.initialize()\n</code></pre> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.fixture\nasync def uninitialized_service(\n    self,\n    service_class: type[BaseService],\n    service_config: ServiceConfig,\n) -&gt; AsyncGenerator[BaseService, None]:\n    \"\"\"\n    Create an uninitialized instance of the service under test.\n\n    This provides a service instance before initialize() has been called,\n    allowing tests to verify initialization behavior.\n\n    Returns:\n        An uninitialized instance of the service\n\n    Example usage:\n    ```python\n    async def test_service_initialization(uninitialized_service: BaseService):\n        service = await async_fixture(uninitialized_service)\n        await service.initialize()\n    ```\n    \"\"\"\n    # Patch the heartbeat task otherwise it will run forever\n    with patch(\n        \"aiperf.common.service.base_component_service.BaseComponentService._heartbeat_task\",\n        lambda: None,\n    ):\n        service = service_class(service_config=service_config)\n        yield service\n</code></pre>"},{"location":"api/#aiperftestscommsmock_zmq","title":"aiperf.tests.comms.mock_zmq","text":""},{"location":"api/#aiperf.tests.comms.mock_zmq.MockCommunicationData","title":"<code>MockCommunicationData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Data structure to hold state information for mock communication objects.</p> Source code in <code>aiperf/tests/comms/mock_zmq.py</code> <pre><code>class MockCommunicationData(BaseModel):\n    \"\"\"Data structure to hold state information for mock communication objects.\"\"\"\n\n    published_messages: dict[Topic, list[Message]] = Field(default_factory=dict)\n    subscriptions: dict[str, Callable[[Message], Coroutine[Any, Any, None]]] = Field(\n        default_factory=dict\n    )\n    pull_callbacks: dict[Topic, Callable[[Message], None]] = Field(default_factory=dict)\n    push_messages: dict[Topic, Message] = Field(default_factory=dict)\n    requests: dict[str, Message] = Field(default_factory=dict)\n    responses: dict[str, Message] = Field(default_factory=dict)\n\n    def clear(self) -&gt; None:\n        self.published_messages.clear()\n        self.subscriptions.clear()\n        self.pull_callbacks.clear()\n        self.push_messages.clear()\n        self.requests.clear()\n        self.responses.clear()\n</code></pre>"},{"location":"api/#aiperf.tests.comms.mock_zmq.mock_zmq_communication","title":"<code>mock_zmq_communication()</code>","text":"<p>Create a mock communication object for testing service communication.</p> <p>This mock tracks published messages, subscriptions, pull callbacks, push messages, and requests and responses for verification in tests.</p> <p>Returns:</p> Type Description <code>MagicMock</code> <p>A MagicMock configured to behave like ZMQCommunication</p> Source code in <code>aiperf/tests/comms/mock_zmq.py</code> <pre><code>@pytest.fixture\ndef mock_zmq_communication() -&gt; MagicMock:\n    \"\"\"\n    Create a mock communication object for testing service communication.\n\n    This mock tracks published messages, subscriptions, pull callbacks,\n    push messages, and requests and responses for verification in tests.\n\n    Returns:\n        A MagicMock configured to behave like ZMQCommunication\n    \"\"\"\n    mock_comm = MagicMock(spec=ZMQCommunication)\n\n    # Configure basic behavior\n    mock_comm.initialize.return_value = None\n    mock_comm.shutdown.return_value = None\n    mock_comm.create_clients.return_value = None\n\n    mock_comm.mock_data = MockCommunicationData()\n\n    async def mock_publish(topic: Topic, message: Message) -&gt; None:\n        \"\"\"Mock implementation of publish that stores messages by topic.\"\"\"\n        if topic not in mock_comm.mock_data.published_messages:\n            mock_comm.mock_data.published_messages[topic] = []\n\n        mock_comm.mock_data.published_messages[topic].append(message)\n\n    mock_comm.publish.side_effect = mock_publish\n\n    async def mock_subscribe(\n        topic: str, callback: Callable[[Message], Coroutine[Any, Any, None]]\n    ) -&gt; None:\n        \"\"\"Mock implementation of subscribe that stores callbacks by topic.\"\"\"\n        mock_comm.mock_data.subscriptions[topic] = callback\n\n    mock_comm.subscribe.side_effect = mock_subscribe\n\n    async def mock_pull(topic: Topic, callback: Callable[[Message], None]) -&gt; None:\n        \"\"\"Mock implementation of pull that stores callbacks by topic.\"\"\"\n        mock_comm.mock_data.pull_callbacks[topic] = callback\n\n    mock_comm.pull.side_effect = mock_pull\n\n    async def mock_push(topic: Topic, message: Message) -&gt; None:\n        \"\"\"Mock implementation of push that stores messages by topic.\"\"\"\n        mock_comm.mock_data.push_messages[topic] = message\n\n    mock_comm.push.side_effect = mock_push\n\n    async def mock_request(target: str, request_data: Message) -&gt; Message:\n        \"\"\"Mock implementation of request that stores requests by target.\"\"\"\n        mock_comm.mock_data.requests[target] = request_data\n\n        # Return a fake mock response\n        return BaseMessage(\n            payload=DataPayload(),\n        )\n\n    mock_comm.request.side_effect = mock_request\n\n    async def mock_respond(target: str, response: Message) -&gt; None:\n        \"\"\"Mock implementation of respond that stores responses by target.\"\"\"\n        mock_comm.mock_data.responses[target] = response\n\n    mock_comm.respond.side_effect = mock_respond\n\n    return mock_comm\n</code></pre>"},{"location":"api/#aiperftestscommstest_zmq_communication","title":"aiperf.tests.comms.test_zmq_communication","text":"<p>Tests for the ZMQ communication module.</p>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication","title":"<code>TestZMQCommunication</code>","text":"<p>Tests for the ZMQ communication class.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nclass TestZMQCommunication:\n    \"\"\"Tests for the ZMQ communication class.\"\"\"\n\n    @pytest.fixture\n    def mock_config(self):\n        \"\"\"Return a mock configuration for ZMQCommunication.\"\"\"\n        return ZMQCommunicationConfig(\n            protocol_config=ZMQTCPTransportConfig(), client_id=\"test-client\"\n        )\n\n    @pytest.fixture\n    def zmq_communication(self, mock_config):\n        \"\"\"Return a ZMQCommunication instance for testing.\"\"\"\n        with patch(\"zmq.asyncio.Context\", MagicMock()) as mock_context:\n            # Set up the context mock to return properly\n            mock_context.return_value = MagicMock()\n            comm = ZMQCommunication(config=mock_config)\n            comm._context = mock_context\n            return comm\n\n    @pytest.fixture\n    def test_message(self):\n        \"\"\"Create a test response for communication tests.\"\"\"\n        return BaseMessage(\n            service_id=\"test-service\",\n            payload=DataPayload(),\n        )\n\n    @pytest.mark.asyncio\n    async def test_initialization(self, zmq_communication):\n        \"\"\"Test that the ZMQ communication initializes correctly.\"\"\"\n        result = await zmq_communication.initialize()\n        assert result is None\n        assert zmq_communication.is_initialized is True\n\n    @pytest.mark.asyncio\n    async def test_initialization_failure(self, zmq_communication):\n        \"\"\"Test initialization failure handling.\"\"\"\n        # Temporarily clear initialized_event to test error path\n        zmq_communication.initialized_event.clear()\n\n        # Create a mock implementation that raises an exception\n        async def mock_init_with_error():\n            raise CommunicationInitializationError(\"Test connection error\")\n\n        # Replace the original method and call to test error handling\n        original_init = zmq_communication.initialize\n        zmq_communication.initialize = mock_init_with_error\n\n        try:\n            with pytest.raises(\n                CommunicationInitializationError, match=\"Test connection error\"\n            ):\n                await zmq_communication.initialize()\n        finally:\n            # Restore the original method\n            zmq_communication.initialize = original_init\n\n    @pytest.mark.asyncio\n    async def test_create_clients(self, zmq_communication):\n        \"\"\"Test creating clients for different communication patterns.\"\"\"\n        # Mock the client socket creation\n        mock_client = AsyncMock()\n\n        # Patch the specific client classes and ensure they return our mock\n        with (\n            patch(\n                \"aiperf.common.comms.zmq.clients.ZMQPubClient\",\n                return_value=mock_client,\n            ),\n            patch(\n                \"aiperf.common.comms.zmq.clients.ZMQSubClient\",\n                return_value=mock_client,\n            ),\n        ):\n            # Call create_clients\n            await zmq_communication.create_clients(\n                PubClientType.COMPONENT, SubClientType.COMPONENT\n            )\n\n            # Verify clients were added to the dictionary\n            assert PubClientType.COMPONENT in zmq_communication.clients\n            assert SubClientType.COMPONENT in zmq_communication.clients\n\n            # Verify initialize was called for each client\n            assert len(zmq_communication.clients) == 2\n\n    @pytest.mark.asyncio\n    async def test_publish_message(self, zmq_communication, test_message):\n        \"\"\"Test publishing messages.\"\"\"\n        # Mock the socket publish method\n        mock_client = AsyncMock()\n        mock_client.publish.return_value = None\n\n        # Set up the client in the clients dictionary\n        zmq_communication.clients = {PubClientType.COMPONENT: mock_client}\n        zmq_communication.initialized_event.set()\n\n        # Publish a message\n        result = await zmq_communication.publish(Topic.STATUS, test_message)\n\n        # Verify the message was published\n        assert result is None\n        mock_client.publish.assert_called_once_with(Topic.STATUS, test_message)\n\n    @pytest.mark.asyncio\n    async def test_subscribe_to_topic(self, zmq_communication):\n        \"\"\"Test subscribing to a topic.\"\"\"\n        # Mock the client socket\n        mock_client = AsyncMock()\n        mock_client.subscribe.return_value = None\n\n        # Set up the client in the clients dictionary\n        zmq_communication.clients = {SubClientType.COMPONENT: mock_client}\n        zmq_communication.initialized_event.set()\n\n        # Create a callback function\n        async def callback(message: Message):\n            pass\n\n        # Subscribe to a topic\n        result = await zmq_communication.subscribe(Topic.STATUS, callback)\n\n        # Verify subscription was set up\n        assert result is None\n        mock_client.subscribe.assert_called_once_with(Topic.STATUS, callback)\n\n    @pytest.mark.asyncio\n    async def test_shutdown(self, zmq_communication):\n        \"\"\"Test graceful shutdown of communication.\"\"\"\n        # Mock the client socket\n        mock_client1 = AsyncMock()\n        mock_client1.shutdown.return_value = None\n        mock_client2 = AsyncMock()\n        mock_client2.shutdown.return_value = None\n\n        # Set up clients\n        zmq_communication.clients = {\n            PubClientType.COMPONENT: mock_client1,\n            SubClientType.COMPONENT: mock_client2,\n        }\n        zmq_communication.initialized_event.set()\n        zmq_communication.stop_event.clear()\n\n        # Mock the context with a patched shutdown method to avoid setting\n        # context to None\n        context_mock = MagicMock()\n        zmq_communication._context = context_mock\n\n        # Create a patched version of shutdown that doesn't set context to None\n        original_shutdown = zmq_communication.shutdown\n\n        async def patched_shutdown():\n            # Calls original gather but patch term() to prevent context from\n            # becoming None\n            with patch.object(zmq_communication, \"_context\", context_mock):\n                return await original_shutdown()\n\n        zmq_communication.shutdown = patched_shutdown\n\n        try:\n            # Shutdown the communication\n            result = await zmq_communication.shutdown()\n\n            # Verify both clients were shutdown\n            assert result is None\n            assert mock_client1.shutdown.called\n            assert mock_client2.shutdown.called\n            assert context_mock.term.called\n            assert zmq_communication.stop_event.is_set()\n        finally:\n            # Restore the original method\n            zmq_communication.shutdown = original_shutdown\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.mock_config","title":"<code>mock_config()</code>","text":"<p>Return a mock configuration for ZMQCommunication.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.fixture\ndef mock_config(self):\n    \"\"\"Return a mock configuration for ZMQCommunication.\"\"\"\n    return ZMQCommunicationConfig(\n        protocol_config=ZMQTCPTransportConfig(), client_id=\"test-client\"\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_create_clients","title":"<code>test_create_clients(zmq_communication)</code>  <code>async</code>","text":"<p>Test creating clients for different communication patterns.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_create_clients(self, zmq_communication):\n    \"\"\"Test creating clients for different communication patterns.\"\"\"\n    # Mock the client socket creation\n    mock_client = AsyncMock()\n\n    # Patch the specific client classes and ensure they return our mock\n    with (\n        patch(\n            \"aiperf.common.comms.zmq.clients.ZMQPubClient\",\n            return_value=mock_client,\n        ),\n        patch(\n            \"aiperf.common.comms.zmq.clients.ZMQSubClient\",\n            return_value=mock_client,\n        ),\n    ):\n        # Call create_clients\n        await zmq_communication.create_clients(\n            PubClientType.COMPONENT, SubClientType.COMPONENT\n        )\n\n        # Verify clients were added to the dictionary\n        assert PubClientType.COMPONENT in zmq_communication.clients\n        assert SubClientType.COMPONENT in zmq_communication.clients\n\n        # Verify initialize was called for each client\n        assert len(zmq_communication.clients) == 2\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_initialization","title":"<code>test_initialization(zmq_communication)</code>  <code>async</code>","text":"<p>Test that the ZMQ communication initializes correctly.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_initialization(self, zmq_communication):\n    \"\"\"Test that the ZMQ communication initializes correctly.\"\"\"\n    result = await zmq_communication.initialize()\n    assert result is None\n    assert zmq_communication.is_initialized is True\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_initialization_failure","title":"<code>test_initialization_failure(zmq_communication)</code>  <code>async</code>","text":"<p>Test initialization failure handling.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_initialization_failure(self, zmq_communication):\n    \"\"\"Test initialization failure handling.\"\"\"\n    # Temporarily clear initialized_event to test error path\n    zmq_communication.initialized_event.clear()\n\n    # Create a mock implementation that raises an exception\n    async def mock_init_with_error():\n        raise CommunicationInitializationError(\"Test connection error\")\n\n    # Replace the original method and call to test error handling\n    original_init = zmq_communication.initialize\n    zmq_communication.initialize = mock_init_with_error\n\n    try:\n        with pytest.raises(\n            CommunicationInitializationError, match=\"Test connection error\"\n        ):\n            await zmq_communication.initialize()\n    finally:\n        # Restore the original method\n        zmq_communication.initialize = original_init\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_message","title":"<code>test_message()</code>","text":"<p>Create a test response for communication tests.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.fixture\ndef test_message(self):\n    \"\"\"Create a test response for communication tests.\"\"\"\n    return BaseMessage(\n        service_id=\"test-service\",\n        payload=DataPayload(),\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_publish_message","title":"<code>test_publish_message(zmq_communication, test_message)</code>  <code>async</code>","text":"<p>Test publishing messages.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_publish_message(self, zmq_communication, test_message):\n    \"\"\"Test publishing messages.\"\"\"\n    # Mock the socket publish method\n    mock_client = AsyncMock()\n    mock_client.publish.return_value = None\n\n    # Set up the client in the clients dictionary\n    zmq_communication.clients = {PubClientType.COMPONENT: mock_client}\n    zmq_communication.initialized_event.set()\n\n    # Publish a message\n    result = await zmq_communication.publish(Topic.STATUS, test_message)\n\n    # Verify the message was published\n    assert result is None\n    mock_client.publish.assert_called_once_with(Topic.STATUS, test_message)\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_shutdown","title":"<code>test_shutdown(zmq_communication)</code>  <code>async</code>","text":"<p>Test graceful shutdown of communication.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_shutdown(self, zmq_communication):\n    \"\"\"Test graceful shutdown of communication.\"\"\"\n    # Mock the client socket\n    mock_client1 = AsyncMock()\n    mock_client1.shutdown.return_value = None\n    mock_client2 = AsyncMock()\n    mock_client2.shutdown.return_value = None\n\n    # Set up clients\n    zmq_communication.clients = {\n        PubClientType.COMPONENT: mock_client1,\n        SubClientType.COMPONENT: mock_client2,\n    }\n    zmq_communication.initialized_event.set()\n    zmq_communication.stop_event.clear()\n\n    # Mock the context with a patched shutdown method to avoid setting\n    # context to None\n    context_mock = MagicMock()\n    zmq_communication._context = context_mock\n\n    # Create a patched version of shutdown that doesn't set context to None\n    original_shutdown = zmq_communication.shutdown\n\n    async def patched_shutdown():\n        # Calls original gather but patch term() to prevent context from\n        # becoming None\n        with patch.object(zmq_communication, \"_context\", context_mock):\n            return await original_shutdown()\n\n    zmq_communication.shutdown = patched_shutdown\n\n    try:\n        # Shutdown the communication\n        result = await zmq_communication.shutdown()\n\n        # Verify both clients were shutdown\n        assert result is None\n        assert mock_client1.shutdown.called\n        assert mock_client2.shutdown.called\n        assert context_mock.term.called\n        assert zmq_communication.stop_event.is_set()\n    finally:\n        # Restore the original method\n        zmq_communication.shutdown = original_shutdown\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_subscribe_to_topic","title":"<code>test_subscribe_to_topic(zmq_communication)</code>  <code>async</code>","text":"<p>Test subscribing to a topic.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_subscribe_to_topic(self, zmq_communication):\n    \"\"\"Test subscribing to a topic.\"\"\"\n    # Mock the client socket\n    mock_client = AsyncMock()\n    mock_client.subscribe.return_value = None\n\n    # Set up the client in the clients dictionary\n    zmq_communication.clients = {SubClientType.COMPONENT: mock_client}\n    zmq_communication.initialized_event.set()\n\n    # Create a callback function\n    async def callback(message: Message):\n        pass\n\n    # Subscribe to a topic\n    result = await zmq_communication.subscribe(Topic.STATUS, callback)\n\n    # Verify subscription was set up\n    assert result is None\n    mock_client.subscribe.assert_called_once_with(Topic.STATUS, callback)\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.zmq_communication","title":"<code>zmq_communication(mock_config)</code>","text":"<p>Return a ZMQCommunication instance for testing.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.fixture\ndef zmq_communication(self, mock_config):\n    \"\"\"Return a ZMQCommunication instance for testing.\"\"\"\n    with patch(\"zmq.asyncio.Context\", MagicMock()) as mock_context:\n        # Set up the context mock to return properly\n        mock_context.return_value = MagicMock()\n        comm = ZMQCommunication(config=mock_config)\n        comm._context = mock_context\n        return comm\n</code></pre>"},{"location":"api/#aiperftestsconftest","title":"aiperf.tests.conftest","text":"<p>Shared fixtures for testing AIPerf services.</p> <p>This file contains fixtures that are automatically discovered by pytest and made available to test functions in the same directory and subdirectories.</p>"},{"location":"api/#aiperf.tests.conftest.mock_communication","title":"<code>mock_communication(mock_zmq_communication)</code>","text":"<p>Create a mock communication object for testing service communication.</p> <p>This mock tracks published messages and subscriptions for verification in tests.</p> <p>Returns:</p> Type Description <code>MagicMock</code> <p>An MagicMock configured to behave like ZMQCommunication</p> Source code in <code>aiperf/tests/conftest.py</code> <pre><code>@pytest.fixture\ndef mock_communication(mock_zmq_communication: MagicMock) -&gt; MagicMock:  # noqa: F811 : used as a fixture\n    \"\"\"\n    Create a mock communication object for testing service communication.\n\n    This mock tracks published messages and subscriptions for verification in tests.\n\n    Returns:\n        An MagicMock configured to behave like ZMQCommunication\n    \"\"\"\n    return mock_zmq_communication\n</code></pre>"},{"location":"api/#aiperf.tests.conftest.mock_zmq_context","title":"<code>mock_zmq_context()</code>","text":"<p>Fixture to provide a mock ZMQ context.</p> Source code in <code>aiperf/tests/conftest.py</code> <pre><code>@pytest.fixture\ndef mock_zmq_context() -&gt; Generator[MagicMock, None, None]:\n    \"\"\"Fixture to provide a mock ZMQ context.\"\"\"\n    zmq_context = MagicMock()\n    zmq_context.socket.return_value = mock_zmq_socket()\n\n    with patch(\"zmq.Context\", new_callable=zmq_context):\n        yield zmq_context\n</code></pre>"},{"location":"api/#aiperf.tests.conftest.mock_zmq_socket","title":"<code>mock_zmq_socket()</code>","text":"<p>Fixture to provide a mock ZMQ socket.</p> Source code in <code>aiperf/tests/conftest.py</code> <pre><code>@pytest.fixture\ndef mock_zmq_socket() -&gt; Generator[MagicMock, None, None]:\n    \"\"\"Fixture to provide a mock ZMQ socket.\"\"\"\n    zmq_socket = MagicMock()\n    with patch(\"zmq.Socket\", new_callable=zmq_socket):\n        yield zmq_socket\n</code></pre>"},{"location":"api/#aiperftestsservicestest_dataset_manager","title":"aiperf.tests.services.test_dataset_manager","text":"<p>Tests for the dataset manager service.</p>"},{"location":"api/#aiperf.tests.services.test_dataset_manager.DatasetManagerTestConfig","title":"<code>DatasetManagerTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for dataset manager tests.</p> Source code in <code>aiperf/tests/services/test_dataset_manager.py</code> <pre><code>class DatasetManagerTestConfig(BaseModel):\n    \"\"\"Configuration model for dataset manager tests.\"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_dataset_manager.TestDatasetManager","title":"<code>TestDatasetManager</code>","text":"<p>               Bases: <code>BaseTestComponentService</code></p> <p>Tests for the dataset manager service.</p> <p>This test class extends BaseTestComponentService to leverage common component service tests while adding dataset manager specific tests.</p> Source code in <code>aiperf/tests/services/test_dataset_manager.py</code> <pre><code>@pytest.mark.asyncio\nclass TestDatasetManager(BaseTestComponentService):\n    \"\"\"\n    Tests for the dataset manager service.\n\n    This test class extends BaseTestComponentService to leverage common\n    component service tests while adding dataset manager specific tests.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the service class to be tested.\"\"\"\n        return DatasetManager\n\n    @pytest.fixture\n    def dataset_config(self) -&gt; DatasetManagerTestConfig:\n        \"\"\"\n        Return a test configuration for the dataset manager.\n        \"\"\"\n        return DatasetManagerTestConfig()\n\n    async def test_dataset_manager_initialization(\n        self, initialized_service: DatasetManager\n    ) -&gt; None:\n        \"\"\"\n        Test that the dataset manager initializes with the correct service type.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n        assert service.service_type == ServiceType.DATASET_MANAGER\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_dataset_manager.TestDatasetManager.dataset_config","title":"<code>dataset_config()</code>","text":"<p>Return a test configuration for the dataset manager.</p> Source code in <code>aiperf/tests/services/test_dataset_manager.py</code> <pre><code>@pytest.fixture\ndef dataset_config(self) -&gt; DatasetManagerTestConfig:\n    \"\"\"\n    Return a test configuration for the dataset manager.\n    \"\"\"\n    return DatasetManagerTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_dataset_manager.TestDatasetManager.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to be tested.</p> Source code in <code>aiperf/tests/services/test_dataset_manager.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the service class to be tested.\"\"\"\n    return DatasetManager\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_dataset_manager.TestDatasetManager.test_dataset_manager_initialization","title":"<code>test_dataset_manager_initialization(initialized_service)</code>  <code>async</code>","text":"<p>Test that the dataset manager initializes with the correct service type.</p> Source code in <code>aiperf/tests/services/test_dataset_manager.py</code> <pre><code>async def test_dataset_manager_initialization(\n    self, initialized_service: DatasetManager\n) -&gt; None:\n    \"\"\"\n    Test that the dataset manager initializes with the correct service type.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n    assert service.service_type == ServiceType.DATASET_MANAGER\n</code></pre>"},{"location":"api/#aiperftestsservicestest_post_processor_manager","title":"aiperf.tests.services.test_post_processor_manager","text":"<p>Tests for the post processor manager service.</p>"},{"location":"api/#aiperf.tests.services.test_post_processor_manager.PostProcessorTestConfig","title":"<code>PostProcessorTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for post processor manager tests.</p> Source code in <code>aiperf/tests/services/test_post_processor_manager.py</code> <pre><code>class PostProcessorTestConfig(BaseModel):\n    \"\"\"Configuration model for post processor manager tests.\"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_post_processor_manager.TestPostProcessorManager","title":"<code>TestPostProcessorManager</code>","text":"<p>               Bases: <code>BaseTestComponentService</code></p> <p>Tests for the post processor manager service.</p> <p>This test class extends BaseTestComponentService to leverage common component service tests while adding post processor manager specific tests.</p> Source code in <code>aiperf/tests/services/test_post_processor_manager.py</code> <pre><code>@pytest.mark.asyncio\nclass TestPostProcessorManager(BaseTestComponentService):\n    \"\"\"\n    Tests for the post processor manager service.\n\n    This test class extends BaseTestComponentService to leverage common\n    component service tests while adding post processor manager specific tests.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the service class to be tested.\"\"\"\n        return PostProcessorManager\n\n    @pytest.fixture\n    def processor_config(self) -&gt; PostProcessorTestConfig:\n        \"\"\"\n        Return a test configuration for the post processor manager.\n        \"\"\"\n        return PostProcessorTestConfig()\n\n    async def test_post_processor_manager_initialization(\n        self, initialized_service: PostProcessorManager\n    ) -&gt; None:\n        \"\"\"\n        Test that the post processor manager initializes with the correct service type.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n        assert service.service_type == ServiceType.POST_PROCESSOR_MANAGER\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_post_processor_manager.TestPostProcessorManager.processor_config","title":"<code>processor_config()</code>","text":"<p>Return a test configuration for the post processor manager.</p> Source code in <code>aiperf/tests/services/test_post_processor_manager.py</code> <pre><code>@pytest.fixture\ndef processor_config(self) -&gt; PostProcessorTestConfig:\n    \"\"\"\n    Return a test configuration for the post processor manager.\n    \"\"\"\n    return PostProcessorTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_post_processor_manager.TestPostProcessorManager.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to be tested.</p> Source code in <code>aiperf/tests/services/test_post_processor_manager.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the service class to be tested.\"\"\"\n    return PostProcessorManager\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_post_processor_manager.TestPostProcessorManager.test_post_processor_manager_initialization","title":"<code>test_post_processor_manager_initialization(initialized_service)</code>  <code>async</code>","text":"<p>Test that the post processor manager initializes with the correct service type.</p> Source code in <code>aiperf/tests/services/test_post_processor_manager.py</code> <pre><code>async def test_post_processor_manager_initialization(\n    self, initialized_service: PostProcessorManager\n) -&gt; None:\n    \"\"\"\n    Test that the post processor manager initializes with the correct service type.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n    assert service.service_type == ServiceType.POST_PROCESSOR_MANAGER\n</code></pre>"},{"location":"api/#aiperftestsservicestest_records_manager","title":"aiperf.tests.services.test_records_manager","text":"<p>Tests for the records manager service.</p>"},{"location":"api/#aiperf.tests.services.test_records_manager.RecordsManagerTestConfig","title":"<code>RecordsManagerTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for records manager tests.</p> Source code in <code>aiperf/tests/services/test_records_manager.py</code> <pre><code>class RecordsManagerTestConfig(BaseModel):\n    \"\"\"Configuration model for records manager tests.\"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_records_manager.TestRecordsManager","title":"<code>TestRecordsManager</code>","text":"<p>               Bases: <code>BaseTestComponentService</code></p> <p>Tests for the records manager service.</p> <p>This test class extends BaseTestComponentService to leverage common component service tests while adding records manager specific tests.</p> Source code in <code>aiperf/tests/services/test_records_manager.py</code> <pre><code>@pytest.mark.asyncio\nclass TestRecordsManager(BaseTestComponentService):\n    \"\"\"\n    Tests for the records manager service.\n\n    This test class extends BaseTestComponentService to leverage common\n    component service tests while adding records manager specific tests.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the service class to be tested.\"\"\"\n        return RecordsManager\n\n    @pytest.fixture\n    def records_config(self) -&gt; RecordsManagerTestConfig:\n        \"\"\"\n        Return a test configuration for the records manager.\n        \"\"\"\n        return RecordsManagerTestConfig()\n\n    async def test_records_manager_initialization(\n        self, initialized_service: RecordsManager\n    ) -&gt; None:\n        \"\"\"\n        Test that the records manager initializes with the correct service type.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n        assert service.service_type == ServiceType.RECORDS_MANAGER\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_records_manager.TestRecordsManager.records_config","title":"<code>records_config()</code>","text":"<p>Return a test configuration for the records manager.</p> Source code in <code>aiperf/tests/services/test_records_manager.py</code> <pre><code>@pytest.fixture\ndef records_config(self) -&gt; RecordsManagerTestConfig:\n    \"\"\"\n    Return a test configuration for the records manager.\n    \"\"\"\n    return RecordsManagerTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_records_manager.TestRecordsManager.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to be tested.</p> Source code in <code>aiperf/tests/services/test_records_manager.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the service class to be tested.\"\"\"\n    return RecordsManager\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_records_manager.TestRecordsManager.test_records_manager_initialization","title":"<code>test_records_manager_initialization(initialized_service)</code>  <code>async</code>","text":"<p>Test that the records manager initializes with the correct service type.</p> Source code in <code>aiperf/tests/services/test_records_manager.py</code> <pre><code>async def test_records_manager_initialization(\n    self, initialized_service: RecordsManager\n) -&gt; None:\n    \"\"\"\n    Test that the records manager initializes with the correct service type.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n    assert service.service_type == ServiceType.RECORDS_MANAGER\n</code></pre>"},{"location":"api/#aiperftestsservicestest_system_controller","title":"aiperf.tests.services.test_system_controller","text":"<p>Tests for the system controller service.</p>"},{"location":"api/#aiperf.tests.services.test_system_controller.SystemControllerTestConfig","title":"<code>SystemControllerTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for system controller tests.</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>class SystemControllerTestConfig(BaseModel):\n    \"\"\"Configuration model for system controller tests.\"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_system_controller.TestSystemController","title":"<code>TestSystemController</code>","text":"<p>               Bases: <code>BaseTestControllerService</code></p> <p>Tests for the system controller service.</p> <p>This test class extends BaseTestControllerService to leverage common controller service tests while adding system controller specific tests. Tests include service lifecycle management, message handling, and coordination.</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>@pytest.mark.asyncio\nclass TestSystemController(BaseTestControllerService):\n    \"\"\"\n    Tests for the system controller service.\n\n    This test class extends BaseTestControllerService to leverage common\n    controller service tests while adding system controller specific tests.\n    Tests include service lifecycle management, message handling, and coordination.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the class to test.\"\"\"\n        return SystemController\n\n    @pytest.fixture\n    def controller_config(self) -&gt; SystemControllerTestConfig:\n        \"\"\"Return a test configuration for the system controller.\"\"\"\n        return SystemControllerTestConfig()\n\n    async def test_controller_subscriptions(\n        self, initialized_service: SystemController, mock_communication: MagicMock\n    ) -&gt; None:\n        \"\"\"Verifies the controller sets up subscriptions to receive messages from components.\"\"\"\n\n        await async_fixture(initialized_service)\n\n        # A SystemController should subscribe to registration, status, and heartbeat topics\n        expected_topics = [Topic.REGISTRATION, Topic.STATUS, Topic.HEARTBEAT]\n\n        for topic in expected_topics:\n            assert topic in mock_communication.mock_data.subscriptions\n            assert callable(mock_communication.mock_data.subscriptions[topic])\n\n    @pytest.fixture(autouse=True)\n    def service_manager_with_multiprocess(\n        self, monkeypatch, service_config\n    ) -&gt; MultiProcessServiceManager:\n        \"\"\"\n        Return a test service manager with multiprocess support.\n\n        This fixture mocks the initialization methods to avoid actual process creation.\n\n        Args:\n            monkeypatch: Pytest monkeypatch fixture for patching functions\n\n        Returns:\n            A MultiProcessServiceManager instance configured for testing\n        \"\"\"\n        # Create a proper async mock for the service methods\n        async_mock = AsyncMock(return_value=None)\n\n        monkeypatch.setattr(\n            MultiProcessServiceManager, \"wait_for_all_services_registration\", async_mock\n        )\n        monkeypatch.setattr(\n            MultiProcessServiceManager, \"initialize_all_services\", async_mock\n        )\n        monkeypatch.setattr(MultiProcessServiceManager, \"stop_all_services\", async_mock)\n        monkeypatch.setattr(\n            MultiProcessServiceManager, \"wait_for_all_services_start\", async_mock\n        )\n\n        multiprocess_manager = MultiProcessServiceManager(\n            required_service_types=[ServiceType.TEST],\n            config=service_config,\n        )\n\n        return multiprocess_manager\n\n    async def test_service_run_does_start(\n        self, initialized_service: SystemController\n    ) -&gt; None:\n        \"\"\"\n        Test that the service run method starts the service (added by BaseControllerService using @on_run).\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        with (\n            patch(\n                \"aiperf.services.system_controller.system_controller.SystemController._forever_loop\",\n                return_value=None,\n            ) as mock_forever_loop,\n            patch(\n                \"aiperf.services.system_controller.system_controller.SystemController.start\",\n                return_value=None,\n            ) as mock_start,\n        ):\n            await service.run_forever()\n            mock_forever_loop.assert_called_once()\n            mock_start.assert_called_once()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_system_controller.TestSystemController.controller_config","title":"<code>controller_config()</code>","text":"<p>Return a test configuration for the system controller.</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>@pytest.fixture\ndef controller_config(self) -&gt; SystemControllerTestConfig:\n    \"\"\"Return a test configuration for the system controller.\"\"\"\n    return SystemControllerTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_system_controller.TestSystemController.service_class","title":"<code>service_class()</code>","text":"<p>Return the class to test.</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the class to test.\"\"\"\n    return SystemController\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_system_controller.TestSystemController.service_manager_with_multiprocess","title":"<code>service_manager_with_multiprocess(monkeypatch, service_config)</code>","text":"<p>Return a test service manager with multiprocess support.</p> <p>This fixture mocks the initialization methods to avoid actual process creation.</p> <p>Parameters:</p> Name Type Description Default <code>monkeypatch</code> <p>Pytest monkeypatch fixture for patching functions</p> required <p>Returns:</p> Type Description <code>MultiProcessServiceManager</code> <p>A MultiProcessServiceManager instance configured for testing</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>@pytest.fixture(autouse=True)\ndef service_manager_with_multiprocess(\n    self, monkeypatch, service_config\n) -&gt; MultiProcessServiceManager:\n    \"\"\"\n    Return a test service manager with multiprocess support.\n\n    This fixture mocks the initialization methods to avoid actual process creation.\n\n    Args:\n        monkeypatch: Pytest monkeypatch fixture for patching functions\n\n    Returns:\n        A MultiProcessServiceManager instance configured for testing\n    \"\"\"\n    # Create a proper async mock for the service methods\n    async_mock = AsyncMock(return_value=None)\n\n    monkeypatch.setattr(\n        MultiProcessServiceManager, \"wait_for_all_services_registration\", async_mock\n    )\n    monkeypatch.setattr(\n        MultiProcessServiceManager, \"initialize_all_services\", async_mock\n    )\n    monkeypatch.setattr(MultiProcessServiceManager, \"stop_all_services\", async_mock)\n    monkeypatch.setattr(\n        MultiProcessServiceManager, \"wait_for_all_services_start\", async_mock\n    )\n\n    multiprocess_manager = MultiProcessServiceManager(\n        required_service_types=[ServiceType.TEST],\n        config=service_config,\n    )\n\n    return multiprocess_manager\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_system_controller.TestSystemController.test_controller_subscriptions","title":"<code>test_controller_subscriptions(initialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Verifies the controller sets up subscriptions to receive messages from components.</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>async def test_controller_subscriptions(\n    self, initialized_service: SystemController, mock_communication: MagicMock\n) -&gt; None:\n    \"\"\"Verifies the controller sets up subscriptions to receive messages from components.\"\"\"\n\n    await async_fixture(initialized_service)\n\n    # A SystemController should subscribe to registration, status, and heartbeat topics\n    expected_topics = [Topic.REGISTRATION, Topic.STATUS, Topic.HEARTBEAT]\n\n    for topic in expected_topics:\n        assert topic in mock_communication.mock_data.subscriptions\n        assert callable(mock_communication.mock_data.subscriptions[topic])\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_system_controller.TestSystemController.test_service_run_does_start","title":"<code>test_service_run_does_start(initialized_service)</code>  <code>async</code>","text":"<p>Test that the service run method starts the service (added by BaseControllerService using @on_run).</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>async def test_service_run_does_start(\n    self, initialized_service: SystemController\n) -&gt; None:\n    \"\"\"\n    Test that the service run method starts the service (added by BaseControllerService using @on_run).\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    with (\n        patch(\n            \"aiperf.services.system_controller.system_controller.SystemController._forever_loop\",\n            return_value=None,\n        ) as mock_forever_loop,\n        patch(\n            \"aiperf.services.system_controller.system_controller.SystemController.start\",\n            return_value=None,\n        ) as mock_start,\n    ):\n        await service.run_forever()\n        mock_forever_loop.assert_called_once()\n        mock_start.assert_called_once()\n</code></pre>"},{"location":"api/#aiperftestsservicestest_timing_manager","title":"aiperf.tests.services.test_timing_manager","text":"<p>Tests for the timing manager service.</p>"},{"location":"api/#aiperf.tests.services.test_timing_manager.TestTimingManager","title":"<code>TestTimingManager</code>","text":"<p>               Bases: <code>BaseTestComponentService</code></p> <p>Tests for the timing manager service.</p> <p>This test class extends BaseTestComponentService to leverage common component service tests while adding timing manager specific tests.</p> Source code in <code>aiperf/tests/services/test_timing_manager.py</code> <pre><code>@pytest.mark.asyncio\nclass TestTimingManager(BaseTestComponentService):\n    \"\"\"\n    Tests for the timing manager service.\n\n    This test class extends BaseTestComponentService to leverage common\n    component service tests while adding timing manager specific tests.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the service class to be tested.\"\"\"\n        return TimingManager\n\n    @pytest.fixture\n    def timing_config(self) -&gt; TimingManagerTestConfig:\n        \"\"\"\n        Return a test configuration for the timing manager.\n        \"\"\"\n        return TimingManagerTestConfig()\n\n    async def test_timing_manager_initialization(\n        self, initialized_service: TimingManager\n    ) -&gt; None:\n        \"\"\"\n        Test that the timing manager initializes with the correct service type.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n        assert service.service_type == ServiceType.TIMING_MANAGER\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_timing_manager.TestTimingManager.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to be tested.</p> Source code in <code>aiperf/tests/services/test_timing_manager.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the service class to be tested.\"\"\"\n    return TimingManager\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_timing_manager.TestTimingManager.test_timing_manager_initialization","title":"<code>test_timing_manager_initialization(initialized_service)</code>  <code>async</code>","text":"<p>Test that the timing manager initializes with the correct service type.</p> Source code in <code>aiperf/tests/services/test_timing_manager.py</code> <pre><code>async def test_timing_manager_initialization(\n    self, initialized_service: TimingManager\n) -&gt; None:\n    \"\"\"\n    Test that the timing manager initializes with the correct service type.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n    assert service.service_type == ServiceType.TIMING_MANAGER\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_timing_manager.TestTimingManager.timing_config","title":"<code>timing_config()</code>","text":"<p>Return a test configuration for the timing manager.</p> Source code in <code>aiperf/tests/services/test_timing_manager.py</code> <pre><code>@pytest.fixture\ndef timing_config(self) -&gt; TimingManagerTestConfig:\n    \"\"\"\n    Return a test configuration for the timing manager.\n    \"\"\"\n    return TimingManagerTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_timing_manager.TimingManagerTestConfig","title":"<code>TimingManagerTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for timing manager tests.</p> Source code in <code>aiperf/tests/services/test_timing_manager.py</code> <pre><code>class TimingManagerTestConfig(BaseModel):\n    \"\"\"Configuration model for timing manager tests.\"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperftestsservicestest_worker","title":"aiperf.tests.services.test_worker","text":"<p>Tests for the worker service.</p>"},{"location":"api/#aiperf.tests.services.test_worker.TestWorker","title":"<code>TestWorker</code>","text":"<p>               Bases: <code>BaseTestService</code></p> <p>Tests for the worker service.</p> <p>This test class extends BaseTestService since Worker is a direct subclass of BaseService, not a BaseComponentService.</p> Source code in <code>aiperf/tests/services/test_worker.py</code> <pre><code>@pytest.mark.asyncio\nclass TestWorker(BaseTestService):\n    \"\"\"\n    Tests for the worker service.\n\n    This test class extends BaseTestService since Worker is a direct subclass\n    of BaseService, not a BaseComponentService.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the service class to be tested.\"\"\"\n        return Worker\n\n    @pytest.fixture\n    def worker_config(self) -&gt; WorkerTestConfig:\n        \"\"\"\n        Return a test configuration for the worker.\n        \"\"\"\n        return WorkerTestConfig()\n\n    async def test_worker_initialization(self, initialized_service: Worker) -&gt; None:\n        \"\"\"\n        Test that the worker initializes with the correct configuration.\n\n        Verifies the worker service is properly instantiated with its configuration.\n        \"\"\"\n        # Basic existence checks\n        service = await async_fixture(initialized_service)\n        assert service is not None\n        assert service.service_config is not None\n        assert service.service_type == ServiceType.WORKER\n\n        # Initialize the worker\n        await service.initialize()\n\n        # Check the worker is properly initialized\n        assert service.is_initialized\n        assert service.state == ServiceState.READY\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker.TestWorker.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to be tested.</p> Source code in <code>aiperf/tests/services/test_worker.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the service class to be tested.\"\"\"\n    return Worker\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker.TestWorker.test_worker_initialization","title":"<code>test_worker_initialization(initialized_service)</code>  <code>async</code>","text":"<p>Test that the worker initializes with the correct configuration.</p> <p>Verifies the worker service is properly instantiated with its configuration.</p> Source code in <code>aiperf/tests/services/test_worker.py</code> <pre><code>async def test_worker_initialization(self, initialized_service: Worker) -&gt; None:\n    \"\"\"\n    Test that the worker initializes with the correct configuration.\n\n    Verifies the worker service is properly instantiated with its configuration.\n    \"\"\"\n    # Basic existence checks\n    service = await async_fixture(initialized_service)\n    assert service is not None\n    assert service.service_config is not None\n    assert service.service_type == ServiceType.WORKER\n\n    # Initialize the worker\n    await service.initialize()\n\n    # Check the worker is properly initialized\n    assert service.is_initialized\n    assert service.state == ServiceState.READY\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker.TestWorker.worker_config","title":"<code>worker_config()</code>","text":"<p>Return a test configuration for the worker.</p> Source code in <code>aiperf/tests/services/test_worker.py</code> <pre><code>@pytest.fixture\ndef worker_config(self) -&gt; WorkerTestConfig:\n    \"\"\"\n    Return a test configuration for the worker.\n    \"\"\"\n    return WorkerTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker.WorkerTestConfig","title":"<code>WorkerTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Test configuration for the workers.</p> Source code in <code>aiperf/tests/services/test_worker.py</code> <pre><code>class WorkerTestConfig(BaseModel):\n    \"\"\"\n    Test configuration for the workers.\n    \"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperftestsservicestest_worker_manager","title":"aiperf.tests.services.test_worker_manager","text":"<p>Tests for the worker manager service.</p>"},{"location":"api/#aiperf.tests.services.test_worker_manager.TestWorkerManager","title":"<code>TestWorkerManager</code>","text":"<p>               Bases: <code>BaseTestComponentService</code></p> <p>Tests for the worker manager service.</p> <p>This test class extends BaseTestComponentService to leverage common component service tests while adding worker manager specific tests.</p> Source code in <code>aiperf/tests/services/test_worker_manager.py</code> <pre><code>@pytest.mark.asyncio\nclass TestWorkerManager(BaseTestComponentService):\n    \"\"\"\n    Tests for the worker manager service.\n\n    This test class extends BaseTestComponentService to leverage common\n    component service tests while adding worker manager specific tests.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the service class to be tested.\"\"\"\n        return WorkerManager\n\n    @pytest.fixture\n    def worker_manager_config(self) -&gt; WorkerManagerTestConfig:\n        \"\"\"\n        Return a test configuration for the worker manager.\n        \"\"\"\n        return WorkerManagerTestConfig()\n\n    async def test_worker_manager_initialization(\n        self, initialized_service: WorkerManager\n    ) -&gt; None:\n        \"\"\"\n        Test that the worker manager initializes with the correct attributes.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n        assert service.service_type == ServiceType.WORKER_MANAGER\n        assert hasattr(service, \"workers\")\n        assert hasattr(service, \"cpu_count\")\n        assert service.cpu_count == multiprocessing.cpu_count()\n        assert service.worker_count == service.cpu_count\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker_manager.TestWorkerManager.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to be tested.</p> Source code in <code>aiperf/tests/services/test_worker_manager.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the service class to be tested.\"\"\"\n    return WorkerManager\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker_manager.TestWorkerManager.test_worker_manager_initialization","title":"<code>test_worker_manager_initialization(initialized_service)</code>  <code>async</code>","text":"<p>Test that the worker manager initializes with the correct attributes.</p> Source code in <code>aiperf/tests/services/test_worker_manager.py</code> <pre><code>async def test_worker_manager_initialization(\n    self, initialized_service: WorkerManager\n) -&gt; None:\n    \"\"\"\n    Test that the worker manager initializes with the correct attributes.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n    assert service.service_type == ServiceType.WORKER_MANAGER\n    assert hasattr(service, \"workers\")\n    assert hasattr(service, \"cpu_count\")\n    assert service.cpu_count == multiprocessing.cpu_count()\n    assert service.worker_count == service.cpu_count\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker_manager.TestWorkerManager.worker_manager_config","title":"<code>worker_manager_config()</code>","text":"<p>Return a test configuration for the worker manager.</p> Source code in <code>aiperf/tests/services/test_worker_manager.py</code> <pre><code>@pytest.fixture\ndef worker_manager_config(self) -&gt; WorkerManagerTestConfig:\n    \"\"\"\n    Return a test configuration for the worker manager.\n    \"\"\"\n    return WorkerManagerTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker_manager.WorkerManagerTestConfig","title":"<code>WorkerManagerTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for worker manager tests.</p> Source code in <code>aiperf/tests/services/test_worker_manager.py</code> <pre><code>class WorkerManagerTestConfig(BaseModel):\n    \"\"\"Configuration model for worker manager tests.\"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperfteststest_aiperf_task","title":"aiperf.tests.test_aiperf_task","text":""},{"location":"api/#aiperfteststest_audio_generator","title":"aiperf.tests.test_audio_generator","text":""},{"location":"api/#aiperf.tests.test_audio_generator.decode_audio","title":"<code>decode_audio(data_uri)</code>","text":"<p>Helper function to decode audio from data URI format.</p> <p>Parameters:</p> Name Type Description Default <code>data_uri</code> <code>str</code> <p>Data URI string in format \"format,b64_data\"</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, int]</code> <p>Tuple of (audio_data: np.ndarray, sample_rate: int)</p> Source code in <code>aiperf/tests/test_audio_generator.py</code> <pre><code>def decode_audio(data_uri: str) -&gt; tuple[np.ndarray, int]:\n    \"\"\"Helper function to decode audio from data URI format.\n\n    Args:\n        data_uri: Data URI string in format \"format,b64_data\"\n\n    Returns:\n        Tuple of (audio_data: np.ndarray, sample_rate: int)\n    \"\"\"\n    # Parse data URI\n    _, b64_data = data_uri.split(\",\")\n    decoded_data = base64.b64decode(b64_data)\n\n    # Load audio using soundfile - format is auto-detected from content\n    audio_data, sample_rate = sf.read(io.BytesIO(decoded_data))\n    return audio_data, sample_rate\n</code></pre>"},{"location":"api/#aiperfteststest_hooks","title":"aiperf.tests.test_hooks","text":""},{"location":"api/#aiperf.tests.test_hooks.test_hook_decorators","title":"<code>test_hook_decorators()</code>","text":"<p>Test the hook decorators.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>def test_hook_decorators():\n    \"\"\"Test the hook decorators.\"\"\"\n    test_hooks = MockHooks()\n\n    assert test_hooks.get_hooks(AIPerfHook.ON_INIT) == [\n        test_hooks.on_init_3,\n        test_hooks.on_init_2,\n        test_hooks.on_init_1,\n    ], \"Init hooks should be registered in the order they are defined\"\n    assert test_hooks.get_hooks(AIPerfHook.ON_CLEANUP) == [test_hooks.on_cleanup_1], (\n        \"Cleanup hooks should be registered\"\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_hook_inheritance","title":"<code>test_hook_inheritance()</code>","text":"<p>Test the hook inheritance.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>def test_hook_inheritance():\n    \"\"\"Test the hook inheritance.\"\"\"\n    test_hooks_inheritance = MockHooksInheritance()\n\n    assert test_hooks_inheritance.get_hooks(AIPerfHook.ON_INIT) == [\n        test_hooks_inheritance.on_init_3,\n        test_hooks_inheritance.on_init_2,\n        test_hooks_inheritance.on_init_1,\n        test_hooks_inheritance.on_init_4,\n    ], \"Init hooks should be registered in the order they are defined\"\n\n    assert test_hooks_inheritance.get_hooks(AIPerfHook.ON_CLEANUP) == [\n        test_hooks_inheritance.on_cleanup_1,\n        test_hooks_inheritance.on_cleanup_2,\n    ], \"Cleanup hooks should be registered in the order they are defined\"\n\n    assert test_hooks_inheritance.get_hooks(AIPerfHook.ON_START) == [\n        test_hooks_inheritance.on_start_1\n    ], \"Start hook should be registered\"\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_hook_ordering","title":"<code>test_hook_ordering()</code>","text":"<p>Test that the hook ordering is correct.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>def test_hook_ordering():\n    \"\"\"Test that the hook ordering is correct.\"\"\"\n\n    @supports_hooks(AIPerfHook.ON_INIT)\n    class Hooks(HooksMixin):\n        @on_init\n        async def on_init_2(self):\n            pass\n\n        @on_init\n        async def on_init_3(self):\n            pass\n\n        @on_init\n        async def on_init_1(self):\n            pass\n\n    hooks = Hooks()\n\n    # Ensure the hooks are added in the order they are defined\n    assert hooks.get_hooks(AIPerfHook.ON_INIT) == [\n        hooks.on_init_2,\n        hooks.on_init_3,\n        hooks.on_init_1,\n    ], \"Hooks should be registered in the order they are defined\"\n\n    class Hooks2(Hooks):\n        @on_init\n        async def on_init_0(self):\n            pass\n\n    hooks2 = Hooks2()\n\n    # Ensure that base hooks are registered before the subclass hooks\n    assert hooks2.get_hooks(AIPerfHook.ON_INIT) == [\n        # Base hooks\n        hooks2.on_init_2,\n        hooks2.on_init_3,\n        hooks2.on_init_1,\n        # Subclass hooks\n        hooks2.on_init_0,\n    ], \"Base hooks should be registered before subclass hooks\"\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_inheritance_hook_order","title":"<code>test_inheritance_hook_order()</code>  <code>async</code>","text":"<p>Test that the hook order is correct when using inheritance.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_inheritance_hook_order():\n    \"\"\"Test that the hook order is correct when using inheritance.\"\"\"\n\n    class MockHooksInheritance2(MockHooks):\n        @on_init\n        async def on_init_99(self):\n            assert self.on_init_1 in self.called_hooks\n            self.add_called_hook(self.on_init_99)\n\n        @on_init\n        async def on_init_0(self):\n            assert self.on_init_1 in self.called_hooks\n            self.add_called_hook(self.on_init_0)\n\n    test_hooks = MockHooksInheritance2()\n\n    await test_hooks.initialize()\n\n    assert test_hooks.on_init_0 in test_hooks.called_hooks, (\n        \"Subclass hook should be called\"\n    )\n    assert test_hooks.on_init_1 in test_hooks.called_hooks, \"Base hook should be called\"\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_inheritance_hook_override","title":"<code>test_inheritance_hook_override()</code>  <code>async</code>","text":"<p>Test that a hook that is overridden in a subclass does not call the base class hook.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_inheritance_hook_override():\n    \"\"\"Test that a hook that is overridden in a subclass does not call the base class hook.\"\"\"\n\n    class MockHooksInheritance3(MockHooks):\n        @on_init\n        async def on_init_1(self):\n            assert MockHooks.on_init_1 not in self.called_hooks\n            self.add_called_hook(self.on_init_1)\n\n    test_hooks = MockHooksInheritance3()\n\n    await test_hooks.initialize()\n\n    assert test_hooks.on_init_1 in test_hooks.called_hooks, (\n        \"Subclass hook should be called\"\n    )\n    assert MockHooks.on_init_1 not in test_hooks.called_hooks, (\n        \"Base hook should not be called\"\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_instance_additional_hooks","title":"<code>test_instance_additional_hooks()</code>  <code>async</code>","text":"<p>Test that additional hooks can be added to a class that supports hooks.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_instance_additional_hooks():\n    \"\"\"Test that additional hooks can be added to a class that supports hooks.\"\"\"\n    test_hooks = MockHooksInheritance()\n\n    async def custom_start_hook():\n        test_hooks.add_called_hook(custom_start_hook)\n\n    test_hooks.register_hook(AIPerfHook.ON_START, custom_start_hook)\n\n    assert test_hooks.get_hooks(AIPerfHook.ON_START) == [\n        test_hooks.on_start_1,\n        custom_start_hook,\n    ]\n\n    await test_hooks.start()\n\n    assert custom_start_hook in test_hooks.called_hooks, (\n        \"Custom start hook should be called\"\n    )\n    assert test_hooks.on_start_1 in test_hooks.called_hooks, (\n        \"Base start hook should be called\"\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_instance_additional_supported_hooks","title":"<code>test_instance_additional_supported_hooks()</code>  <code>async</code>","text":"<p>Test that additional hook types can be supported by a class</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_instance_additional_supported_hooks():\n    \"\"\"Test that additional hook types can be supported by a class\"\"\"\n    test_hooks = MockHooks()\n\n    async def custom_stop_hook():\n        test_hooks.add_called_hook(custom_stop_hook)\n\n    # this should raise an UnsupportedHookError because the hook type is not supported\n    with pytest.raises(UnsupportedHookError):\n        test_hooks.register_hook(AIPerfHook.ON_STOP, custom_stop_hook)\n\n    # Now we add the hook type to the supported hooks\n    test_hooks.supported_hooks.add(AIPerfHook.ON_STOP)\n\n    # Now we can register the hook and it will not raise an UnsupportedHookError\n    test_hooks.register_hook(AIPerfHook.ON_STOP, custom_stop_hook)\n\n    # Expect the hook to be in the list of hooks\n    assert test_hooks.get_hooks(AIPerfHook.ON_STOP) == [custom_stop_hook]\n\n    async def custom_init_hook():\n        test_hooks.called_hooks.add(custom_init_hook)\n        # Hack to allow the hook to run the newly added ON_STOP hook\n        await test_hooks.run_hooks_async(AIPerfHook.ON_STOP)\n\n    test_hooks.register_hook(\n        AIPerfHook.ON_INIT, custom_init_hook\n    )  # this should not raise an UnsupportedHookError\n\n    await test_hooks.initialize()\n\n    # Expect the custom init and stop hooks to have been called\n    assert custom_init_hook in test_hooks.called_hooks, (\n        \"Custom init hook should be called\"\n    )\n    assert custom_stop_hook in test_hooks.called_hooks, (\n        \"Custom stop hook should be called\"\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_unsupported_hook_decorator","title":"<code>test_unsupported_hook_decorator()</code>","text":"<p>Test that an UnsupportedHookError is raised when a hook is defined on a class that does not support it.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>def test_unsupported_hook_decorator():\n    \"\"\"Test that an UnsupportedHookError is raised when a hook is defined on a class\n    that does not support it.\n    \"\"\"\n\n    @supports_hooks(AIPerfHook.ON_CLEANUP)\n    class TestHooksUnsupported(MockHooks):\n        @on_start\n        async def _on_start_1(self):\n            self.add_called_hook(self._on_start_1)\n\n    with pytest.raises(UnsupportedHookError):\n        TestHooksUnsupported()  # this should raise an UnsupportedHookError\n</code></pre>"},{"location":"api/#aiperfteststest_image_generator","title":"aiperf.tests.test_image_generator","text":""},{"location":"api/#aiperfteststest_prompt_generator","title":"aiperf.tests.test_prompt_generator","text":""},{"location":"api/#aiperfteststest_tokenizer","title":"aiperf.tests.test_tokenizer","text":""},{"location":"api/#aiperftestsutilsasync_test_utils","title":"aiperf.tests.utils.async_test_utils","text":"<p>Utilities for testing asynchronous code.</p>"},{"location":"api/#aiperf.tests.utils.async_test_utils.async_fixture","title":"<code>async_fixture(fixture)</code>  <code>async</code>","text":"<p>Manually await an async pytest fixture.</p> <p>This is necessary because pytest fixtures are not awaited by default in test methods. If the fixture is an async generator, this will get the first yielded value.</p> <p>Parameters:</p> Name Type Description Default <code>fixture</code> <code>T</code> <p>The fixture to await</p> required <p>Returns:</p> Type Description <code>T</code> <p>The awaited fixture value</p> Source code in <code>aiperf/tests/utils/async_test_utils.py</code> <pre><code>async def async_fixture(fixture: T) -&gt; T:\n    \"\"\"\n    Manually await an async pytest fixture.\n\n    This is necessary because pytest fixtures are not awaited by default in test methods.\n    If the fixture is an async generator, this will get the first yielded value.\n\n    Args:\n        fixture: The fixture to await\n\n    Returns:\n        The awaited fixture value\n    \"\"\"\n    if hasattr(fixture, \"__aiter__\"):\n        # If it's an async generator, get the first yielded value\n        with contextlib.suppress(StopAsyncIteration):\n            async_gen = cast(AsyncIterator[Any], fixture)\n            value = await anext(async_gen)\n            return cast(T, value)\n\n    # Otherwise return the fixture as is\n    return fixture\n</code></pre>"},{"location":"api/#aiperf.tests.utils.async_test_utils.async_noop","title":"<code>async_noop(*args, **kwargs)</code>  <code>async</code>","text":"<p>A no-op async function for testing purposes.</p> <p>Can be used to replace asyncio.sleep, asyncio.wait_for, or other async calls in tests. Accepts any arguments but performs no operation and returns immediately.</p> Source code in <code>aiperf/tests/utils/async_test_utils.py</code> <pre><code>async def async_noop(*args, **kwargs) -&gt; None:\n    \"\"\"\n    A no-op async function for testing purposes.\n\n    Can be used to replace asyncio.sleep, asyncio.wait_for, or other async calls in tests.\n    Accepts any arguments but performs no operation and returns immediately.\n    \"\"\"\n    return\n</code></pre>"},{"location":"hook-system/","title":"Hook system","text":""},{"location":"hook-system/#aiperf-hook-system","title":"AIPerf Hook System","text":"<p>TODO: Once we create a Mixin for self.stop_event, we can avoid having the user to call <code>while not self.stop_event.is_set()</code></p> <p>The AIPerf Hook System provides a powerful, extensible mechanism for implementing lifecycle management and event-driven programming patterns. It enables clean separation of concerns by allowing components to register callbacks that execute at specific points during service execution.</p>"},{"location":"hook-system/#core-components","title":"Core Components","text":""},{"location":"hook-system/#1-hook-types-aiperfhook","title":"1. Hook Types (<code>AIPerfHook</code>)","text":"<p>The system defines standard lifecycle hooks:</p> <ul> <li><code>ON_INIT</code>: Initialization phase</li> <li><code>ON_RUN</code>: Main execution phase</li> <li><code>ON_CONFIGURE</code>: Configuration updates</li> <li><code>ON_START</code>: Service startup</li> <li><code>ON_STOP</code>: Service shutdown</li> <li><code>ON_CLEANUP</code>: Resource cleanup</li> </ul> <p>And additional usability hooks:</p> <ul> <li><code>ON_SET_STATE</code>: State transitions</li> <li><code>AIPERF_TASK</code>: Background task registration</li> </ul>"},{"location":"hook-system/#2-hook-system-hooksystem","title":"2. Hook System (<code>HookSystem</code>)","text":"<p>Manages hook registration and execution:</p> <pre><code>class HookSystem:\n    def __init__(self, supported_hooks: set[HookType]):\n        self.supported_hooks = supported_hooks\n        self._hooks: dict[HookType, list[Callable]] = {}\n</code></pre>"},{"location":"hook-system/#3-hooks-mixin-hooksmixin","title":"3. Hooks Mixin (<code>HooksMixin</code>)","text":"<p>Provides the interface for hook-enabled classes:</p> <pre><code>class HooksMixin:\n    supported_hooks: set[HookType] = set()\n\n    def __init__(self):\n        self._hook_system = HookSystem(self.supported_hooks)\n        # Auto-register decorated methods\n</code></pre>"},{"location":"hook-system/#usage-patterns","title":"Usage Patterns","text":""},{"location":"hook-system/#basic-implementation-self-contained","title":"Basic Implementation - Self Contained","text":"<p>Hooks can be defined and used by the same class</p> <pre><code>import asyncio\nfrom aiperf.common.hooks import HooksMixin, supports_hooks, on_init, on_cleanup, AIPerfHook\n\n@supports_hooks(AIPerfHook.ON_INIT, AIPerfHook.ON_CLEANUP)\nclass MyService(HooksMixin):\n    def __init__(self):\n        self.resources = []\n        # Make sure to call __init__ on the HooksMixin\n        super().__init__()\n\n    # Hook definitions\n\n    @on_init\n    async def _setup_database(self):\n        \"\"\"Initialize database connection.\"\"\"\n        self.db = await connect_to_database()\n        self.resources.append(self.db)\n\n    @on_init\n    async def _setup_cache(self):\n        \"\"\"Initialize cache system.\"\"\"\n        self.cache = await setup_redis_cache()\n        self.resources.append(self.cache)\n\n    @on_cleanup\n    async def _cleanup_resources(self):\n        \"\"\"Clean up all resources.\"\"\"\n        await asyncio.gather(*[\n            resource.close() for resource in self.resources\n        ])\n\n    # Top-level functions that will call the hooks\n\n    async def initialize(self):\n        await self.run_hooks_async(AIPerfHook.ON_INIT)\n\n    async def cleanup(self):\n        await self.run_hooks_async(AIPerfHook.ON_CLEANUP)\n</code></pre>"},{"location":"hook-system/#basic-implementation-inheritance","title":"Basic Implementation - Inheritance","text":"<p>Hooks can also be used to call additional functionality defined in subclasses. By calling <code>await self.run_hooks_async(AIPerfHook.ON_INIT)</code>, the base class is able to call all registered init functions no matter the subclass that defined it.</p> <pre><code>from aiperf.common.hooks import HooksMixin, supports_hooks, on_init, on_cleanup, AIPerfHook\n\n@supports_hooks(AIPerfHook.ON_INIT, AIPerfHook.ON_CLEANUP)\nclass MyHookService(HooksMixin):\n    \"\"\"Defines the top-level functionality that will call the registered hooks.\"\"\"\n    def __init__(self):\n        # Make sure to call __init__ on the HooksMixin\n        super().__init__()\n\n    async def initialize(self):\n        \"\"\"Runs all of the registered ON_INIT hooks\"\"\"\n        # Note: Using run_hooks without the _async will run them serially\n        await self.run_hooks(AIPerfHook.ON_INIT)\n\n    async def cleanup(self):\n        \"\"\"Runs all of the registered ON_CLEANUP hooks\"\"\"\n        await self.run_hooks_async(AIPerfHook.ON_CLEANUP)\n\n\nclass CustomService(MyHookService):\n    \"\"\"Defines functions that will be called by the lifecycle hooks\"\"\"\n    @on_init\n    async def _setup_database(self):\n        \"\"\"Initialize database connection.\"\"\"\n        self.db = await connect_to_database()\n        self.resources.append(self.db)\n\n    @on_init\n    async def _setup_cache(self):\n        \"\"\"Initialize cache system.\"\"\"\n        self.cache = await setup_redis_cache()\n        self.resources.append(self.cache)\n\n    @on_cleanup\n    async def _cleanup_cache(self):\n        await self.cache.close()\n\n    @on_cleanup\n    async def _cleanup_database(self):\n        await self.db.close()\n</code></pre>"},{"location":"hook-system/#hook-execution-flow","title":"Hook Execution Flow","text":"<pre><code>sequenceDiagram\n    participant C as \ud83d\udcf1 Client\n    participant CS as \ud83d\udd27 CustomService\n    participant MHS as \u2699\ufe0f MyHookService\n    participant HM as \ud83c\udfaf HooksMixin\n\n    Note over C, HM: Hook System Setup &amp; Registration\n    MHS--&gt;&gt;HM: \ud83d\udccb @supports_hooks(AIPerfHook.ON_INIT, ...)\n    CS--&gt;&gt;HM: \ud83d\udd17 @on_init (registration)\n\n    Note over C, HM: Hook Execution Flow\n    C-&gt;&gt;+MHS: \ud83d\ude80 initialize()\n    MHS-&gt;&gt;+HM: \u26a1 run_hooks_async(ON_INIT)\n\n    Note over HM: Parallel Hook Execution\n    loop \ud83d\udd04 For each registered hook\n        HM-&gt;&gt;+CS: \ud83c\udfac Execute hook function\n        CS--&gt;&gt;-HM: \u2705 Hook completed\n    end\n\n    HM--&gt;&gt;-MHS: \ud83c\udfc1 All hooks completed\n    MHS--&gt;&gt;-C: \u2728 Initialization complete\n\n    %% Custom styling for better visibility\n    %%{init: {\n        'theme': 'dark',\n        'themeVariables': {\n            'primaryColor': '#2196f3',\n            'primaryTextColor': '#ffffff',\n            'primaryBorderColor': '#1976d2',\n            'lineColor': '#90a4ae',\n            'secondaryColor': '#9c27b0',\n            'tertiaryColor': '#4caf50',\n            'background': '#263238',\n            'noteTextColor': '#ffffff',\n            'noteBkgColor': '#37474f',\n            'noteBorderColor': '#546e7a'\n        }\n    }}%%\n</code></pre>"},{"location":"hook-system/#inheritance-and-hook-composition","title":"Inheritance and Hook Composition","text":"<pre><code>@supports_hooks(AIPerfHook.ON_INIT, AIPerfHook.ON_CLEANUP)\nclass BaseService(HooksMixin):\n    @on_init\n    async def base_init(self):\n        self.logger.info(\"Base service initializing\")\n\n@supports_hooks(AIPerfHook.ON_START)  # Adds ON_START to inherited hooks\nclass WebService(BaseService):\n    @on_init\n    async def web_init(self):\n        self.logger.info(\"Web service initializing\")\n\n    @on_start\n    async def start_server(self):\n        self.server = await start_web_server()\n</code></pre> <p>Hook inheritance flow:</p> <pre><code>graph TD\n    A[\"**BaseService**\"] --&gt; B[\"*WebService*\"]\n    A --&gt; C[\"&lt;b&gt;Hooks:&lt;/b&gt;&lt;br/&gt;\u2022 ON_INIT&lt;br/&gt;\u2022 ON_CLEANUP\"]\n    B --&gt; D[\"&lt;b&gt;Inherited Hooks:&lt;/b&gt;&lt;br/&gt;\u2022 ON_INIT&lt;br/&gt;\u2022 ON_CLEANUP&lt;br/&gt;&lt;br/&gt;&lt;b&gt;Added Hook:&lt;/b&gt;&lt;br/&gt;\u2022 ON_START\"]\n\n    E[\"Hook Execution&lt;br/&gt;Order\"] --&gt; F[\"base_init()\"]\n    F --&gt; G[\"web_init()\"]\n\n    %% Styling for better visibility\n    style A fill:#bbdefb,stroke:#1976d2,stroke-width:2px,color:#000\n    style B fill:#c8e6c9,stroke:#388e3c,stroke-width:2px,color:#000\n    style C fill:#e1f5fe,stroke:#0277bd,stroke-width:2px,color:#000\n    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000\n    style E fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000\n    style F fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000\n    style G fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000\n\n    %% Better arrow styling\n    linkStyle 0 stroke:#666,stroke-width:2px\n    linkStyle 1 stroke:#666,stroke-width:2px\n    linkStyle 2 stroke:#666,stroke-width:2px\n    linkStyle 3 stroke:#666,stroke-width:2px\n    linkStyle 4 stroke:#666,stroke-width:2px\n</code></pre>"},{"location":"hook-system/#hook-registration-and-execution-order","title":"Hook Registration and Execution Order","text":"<p>Hooks are registered in a predictable, deterministic order that ensures proper initialization flow:</p>"},{"location":"hook-system/#1-across-classes-base-derived","title":"1. Across Classes: Base \u2192 Derived","text":"<pre><code>class BaseService(HooksMixin):\n    @on_init\n    async def base_setup(self):        # Registered 1st\n        pass\n\nclass MyService(BaseService):\n    @on_init\n    async def service_setup(self):     # Registered 2nd\n        pass\n</code></pre>"},{"location":"hook-system/#2-within-classes-definition-order","title":"2. Within Classes: Definition Order","text":"<pre><code>class MyService(BaseService):\n    @on_init\n    async def setup_database(self):    # Registered 1st\n        pass\n\n    @on_init\n    async def setup_cache(self):       # Registered 2nd\n        pass\n\n    @on_init\n    async def setup_metrics(self):     # Registered 3rd\n        pass\n</code></pre> <p>\ud83d\udca1 Key Point: Base class hooks always run before derived class hooks, ensuring that foundational components (communication, signals) are initialized before service-specific functionality.</p> <p>\u26a0\ufe0f Important: To maintain this execution order, you must use <code>run_hooks()</code> (serial execution). Using <code>run_hooks_async()</code> runs hooks concurrently and does not guarantee execution order, even though registration order is still deterministic.</p> <pre><code># \u2705 Preserves execution order (serial)\nawait self.run_hooks(AIPerfHook.ON_INIT)\n\n# \u274c No execution order guarantee (concurrent)\nawait self.run_hooks_async(AIPerfHook.ON_INIT)\n</code></pre>"},{"location":"hook-system/#advanced-features","title":"Advanced Features","text":""},{"location":"hook-system/#runtime-hook-registration","title":"Runtime Hook Registration","text":"<pre><code>service = MyService()\n\nasync def custom_monitoring_hook():\n    await send_metrics_to_monitoring_system()\n\n# Register hook at runtime using class instance\nservice.register_hook(AIPerfHook.ON_START, custom_monitoring_hook)\n</code></pre>"},{"location":"hook-system/#serial-vs-concurrent-execution","title":"Serial vs Concurrent Execution","text":"<pre><code># Serial execution (hooks run one after another). Each one is awaited individually.\nawait self.run_hooks(AIPerfHook.ON_INIT)\n\n# Concurrent execution (all hooks run simultaneously and are gathered at the end)\nawait self.run_hooks_async(AIPerfHook.ON_INIT)\n</code></pre>"},{"location":"hook-system/#error-handling","title":"Error Handling","text":""},{"location":"hook-system/#unsupported-hook-error","title":"Unsupported Hook Error","text":"<p>When a hook decorator is defined on a function within a class that does not support that hook type, an exception is raised. The reason for this is to cause traceability and prevent users from trying to hook into a functionality that is not implemented.</p> <pre><code>@supports_hooks(AIPerfHook.ON_INIT)\nclass LimitedService(HooksMixin):\n    @on_start  # This will raise UnsupportedHookError\n    async def invalid_hook(self):\n        pass\n</code></pre>"},{"location":"hook-system/#multi-error-handling","title":"Multi-Error Handling","text":"<p>When multiple hooks fail, the system collects all errors:</p> <pre><code>try:\n    await self.run_hooks(AIPerfHook.ON_INIT)\nexcept AIPerfMultiError as e:\n    for error in e.errors:\n        self.logger.error(f\"Hook failed: {error}\")\n</code></pre>"},{"location":"hook-system/#best-practices","title":"Best Practices","text":""},{"location":"hook-system/#1-hook-naming-convention","title":"1. Hook Naming Convention","text":"<pre><code>class MyService(BaseService):\n    @on_init\n    async def _initialize_database(self):  # Prefix with underscore\n        pass\n\n    @on_cleanup\n    async def _cleanup_connections(self):  # Descriptive names\n        pass\n</code></pre>"},{"location":"hook-system/#2-resource-management","title":"2. Resource Management","text":"<pre><code>@on_init\nasync def _setup_resources(self):\n    self.resources = []\n\n@on_cleanup\nasync def _cleanup_resources(self):\n    for resource in reversed(self.resources):  # LIFO cleanup\n        await resource.close()\n</code></pre>"},{"location":"hook-system/#3-error-isolation","title":"3. Error Isolation","text":"<pre><code>@on_init\nasync def _safe_initialization(self):\n    try:\n        await risky_operation()\n    except Exception as e:\n        self.logger.error(f\"Non-critical init failed: {e}\")\n        # Don't re-raise if operation is optional\n</code></pre>"},{"location":"hook-system/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Concurrent execution: Use <code>run_hooks_async()</code> for independent hooks</li> <li>Serial execution: Use <code>run_hooks()</code> when hooks have dependencies (ie. base class hooks must be called before subclass hooks)</li> <li>Hook registration: Happens once during <code>__init__</code>, minimal overhead</li> <li>Memory usage: Hooks are stored as method references bound to self, not duplicated</li> </ul> <p>The AIPerf Hook System provides a robust foundation for building extensible, maintainable services with clear lifecycle management and event-driven architecture patterns.</p>"},{"location":"hook-system/#the-special-aiperf_task-decorator","title":"The Special <code>@aiperf_task</code> Decorator","text":"<p>The <code>@aiperf_task</code> decorator is unique among the AIPerf hooks because it doesn't follow the typical hook execution pattern. Instead of being executed at specific lifecycle moments like other hooks, functions decorated with <code>@aiperf_task</code> are automatically registered as long-running background tasks that start when the service initializes and run continuously until the service shuts down.</p>"},{"location":"hook-system/#how-aiperf_task-works","title":"How <code>@aiperf_task</code> Works","text":"<p>The <code>@aiperf_task</code> decorator works through the <code>AIPerfTaskMixin</code> class, which provides automatic task lifecycle management:</p> <ol> <li>Discovery: All methods decorated with <code>@aiperf_task</code> are discovered during class initialization</li> <li>Automatic Startup: Tasks are automatically started during the <code>ON_INIT</code> hook phase</li> <li>Registration: Each task is created using <code>asyncio.create_task()</code> and stored in <code>registered_tasks</code></li> <li>Automatic Shutdown: Tasks are cancelled and cleaned up during the <code>ON_STOP</code> hook phase</li> </ol>"},{"location":"hook-system/#using-aiperftaskmixin","title":"Using <code>AIPerfTaskMixin</code>","text":"<p>To use <code>@aiperf_task</code> decorated methods, your class must inherit from <code>AIPerfTaskMixin</code>:</p> <pre><code>from aiperf.common.hooks import AIPerfTaskMixin, aiperf_task\nimport asyncio\n\nclass BackgroundService(AIPerfTaskMixin):\n    def __init__(self):\n        self.stop_event = asyncio.Event()\n        self.metrics = {}\n        super().__init__()  # Important: call super().__init__()\n\n    @aiperf_task\n    async def _monitor_system_health(self):\n        \"\"\"Continuously monitor system health metrics.\"\"\"\n        while not self.stop_event.is_set():\n            try:\n                # Collect system metrics\n                cpu_usage = await get_cpu_usage()\n                memory_usage = await get_memory_usage()\n\n                self.metrics.update({\n                    'cpu': cpu_usage,\n                    'memory': memory_usage,\n                    'timestamp': time.time()\n                })\n\n                # Check if metrics exceed thresholds\n                if cpu_usage &gt; 90:\n                    self.logger.warning(f\"High CPU usage: {cpu_usage}%\")\n\n                await asyncio.sleep(5)  # Poll every 5 seconds\n\n            except asyncio.CancelledError:\n                self.logger.info(\"Health monitoring task cancelled\")\n                break\n            except Exception as e:\n                self.logger.error(f\"Error in health monitoring: {e}\")\n                await asyncio.sleep(1)\n\n    # Manual lifecycle control\n    async def start_service(self):\n        \"\"\"Start the service and all background tasks.\"\"\"\n        await self.run_hooks(AIPerfHook.ON_INIT)  # This starts all @aiperf_task methods\n\n    async def stop_service(self):\n        \"\"\"Stop the service and all background tasks.\"\"\"\n        self.stop_event.set()  # Signal tasks to stop\n        await self.run_hooks(AIPerfHook.ON_STOP)   # This cancels and waits for all tasks\n</code></pre>"},{"location":"hook-system/#key-differences-from-other-hooks","title":"Key Differences from Other Hooks","text":"Aspect Regular Hooks (<code>@on_init</code>, <code>@on_start</code>, etc.) <code>@aiperf_task</code> Execution Called once at specific lifecycle events Run continuously as background tasks Lifecycle Short-lived, return after completion Long-lived, run until service shutdown Cancellation Not applicable Automatically cancelled on service stop Purpose Setup, teardown, event handling Background processing, monitoring, polling Mixin Required <code>HooksMixin</code> <code>AIPerfTaskMixin</code>"},{"location":"hook-system/#task-lifecycle-management","title":"Task Lifecycle Management","text":"<p>The <code>AIPerfTaskMixin</code> handles the complete lifecycle of <code>@aiperf_task</code> decorated methods:</p> <pre><code>class AIPerfTaskMixin(HooksMixin):\n    def __init__(self):\n        super().__init__()\n        self.registered_tasks: dict[str, asyncio.Task] = {}\n\n    @on_init\n    async def _start_tasks(self):\n        \"\"\"Start all the registered tasks.\"\"\"\n        for hook in self.get_hooks(AIPerfHook.AIPERF_TASK):\n            self.registered_tasks[hook.__name__] = asyncio.create_task(hook())\n\n    @on_stop\n    async def _stop_tasks(self):\n        \"\"\"Stop all the registered tasks.\"\"\"\n        for task in self.registered_tasks.values():\n            task.cancel()\n\n        # Wait for all tasks to complete\n        with contextlib.suppress(asyncio.CancelledError):\n            await asyncio.gather(*self.registered_tasks.values())\n</code></pre>"},{"location":"hook-system/#best-practices-for-aiperf_task","title":"Best Practices for <code>@aiperf_task</code>","text":""},{"location":"hook-system/#1-always-handle-cancellation","title":"1. Always Handle Cancellation","text":"<pre><code>@aiperf_task\nasync def _background_worker(self):\n    try:\n        while not self.stop_event.is_set():\n            await do_work()\n            await asyncio.sleep(1)\n    except asyncio.CancelledError:\n        # Perform cleanup if necessary\n        await cleanup_resources()\n        raise  # Re-raise to properly cancel the task\n</code></pre>"},{"location":"hook-system/#2-use-stop-events-for-graceful-shutdown","title":"2. Use Stop Events for Graceful Shutdown","text":"<pre><code>@aiperf_task\nasync def _poller(self):\n    while not self.stop_event.is_set():\n        try:\n            await poll_external_service()\n            await asyncio.sleep(10)\n        except asyncio.CancelledError:\n            break\n</code></pre>"},{"location":"hook-system/#3-include-error-handling-and-recovery","title":"3. Include Error Handling and Recovery","text":"<pre><code>@aiperf_task\nasync def _resilient_worker(self):\n    retry_count = 0\n    max_retries = 3\n\n    while not self.stop_event.is_set():\n        try:\n            await potentially_failing_operation()\n            retry_count = 0  # Reset on success\n\n        except asyncio.CancelledError:\n            break\n        except Exception as e:\n            retry_count += 1\n            if retry_count &gt; max_retries:\n                self.logger.error(f\"Task failed {max_retries} times, stopping\")\n                break\n\n            backoff_time = min(2 ** retry_count, 60)  # Exponential backoff\n            await asyncio.sleep(backoff_time)\n</code></pre>"},{"location":"hook-system/#4-avoid-blocking-operations","title":"4. Avoid Blocking Operations","text":"<pre><code>@aiperf_task\nasync def _file_processor(self):\n    while not self.stop_event.is_set():\n        try:\n            # Use asyncio.to_thread for blocking I/O\n            result = await asyncio.to_thread(cpu_intensive_operation)\n            await process_result(result)\n\n        except asyncio.CancelledError:\n            break\n</code></pre>"},{"location":"hook-system/#real-world-use-cases","title":"Real-World Use Cases","text":""},{"location":"hook-system/#network-communication-tasks","title":"Network Communication Tasks","text":"<pre><code>@aiperf_task\nasync def _message_receiver(self):\n    \"\"\"Continuously receive messages from ZMQ socket.\"\"\"\n    while not self.is_shutdown:\n        try:\n            message = await self.socket.recv_string()\n            await self.handle_message(message)\n        except asyncio.CancelledError:\n            break\n</code></pre>"},{"location":"hook-system/#periodic-maintenance-tasks","title":"Periodic Maintenance Tasks","text":"<pre><code>@aiperf_task\nasync def _cleanup_old_files(self):\n    \"\"\"Clean up old log files every hour.\"\"\"\n    while not self.stop_event.is_set():\n        try:\n            await cleanup_logs_older_than(days=7)\n            await asyncio.sleep(3600)  # Wait 1 hour\n        except asyncio.CancelledError:\n            break\n</code></pre>"},{"location":"hook-system/#health-check-and-heartbeat-tasks","title":"Health Check and Heartbeat Tasks","text":"<pre><code>@aiperf_task\nasync def _send_heartbeat(self):\n    \"\"\"Send periodic heartbeat messages.\"\"\"\n    while not self.stop_event.is_set():\n        try:\n            heartbeat = HeartbeatMessage(\n                service_id=self.service_id,\n                timestamp=time.time(),\n                status=\"healthy\"\n            )\n            await self.publish_heartbeat(heartbeat)\n            await asyncio.sleep(self.heartbeat_interval)\n        except asyncio.CancelledError:\n            break\n</code></pre>"},{"location":"hook-system/#task-registry-and-debugging","title":"Task Registry and Debugging","text":"<p>All <code>@aiperf_task</code> decorated methods are stored in <code>self.registered_tasks</code> with their function name as the key:</p> <pre><code># Access running tasks programmatically\nfor task_name, task in self.registered_tasks.items():\n    print(f\"Task {task_name}: {'running' if not task.done() else 'finished'}\")\n\n# Check if a specific task is running\nif '_monitor_system_health' in self.registered_tasks:\n    task = self.registered_tasks['_monitor_system_health']\n    if not task.done():\n        print(\"Health monitoring is active\")\n</code></pre>"},{"location":"hook-system/#integration-with-services","title":"Integration with Services","text":"<p>When using with AIPerf services that inherit from <code>BaseService</code>, the lifecycle is automatically managed:</p> <pre><code>from aiperf.common.service.base_service import BaseService\n\nclass MyService(BaseService):  # BaseService inherits from AIPerfTaskMixin\n    @aiperf_task\n    async def _background_processor(self):\n        while not self.stop_event.is_set():\n            await self.process_work()\n            await asyncio.sleep(1)\n\n    # Tasks will automatically start when service initializes\n    # Tasks will automatically stop when service shuts down\n</code></pre>"},{"location":"diagrams/Service%20Class%20Diagram/","title":"Service Class Diagram","text":"<pre><code>classDiagram\n    direction LR\n\n    %% Abstract classes\n    class AbstractBaseService {\n        &lt;&lt;abstract&gt;&gt;\n    }\n\n    %% Concrete base classes\n    class BaseService {\n        &lt;&lt;abstract&gt;&gt;\n    }\n\n    %% Specialized service types\n    class BaseComponentService {\n        &lt;&lt;abstract&gt;&gt;\n    }\n\n    class BaseControllerService {\n        &lt;&lt;abstract&gt;&gt;\n    }\n\n    %% Concrete service implementations\n    class SystemController {\n    }\n\n    class Worker {\n    }\n\n    class WorkerManager {\n    }\n\n    class DatasetManager {\n    }\n\n    class RecordsManager {\n    }\n\n    class TimingManager {\n    }\n\n    class PostProcessorManager {\n    }\n\n    %% Service management classes\n    class BaseServiceManager {\n        &lt;&lt;abstract&gt;&gt;\n    }\n\n    class MultiProcessServiceManager {\n    }\n\n    class KubernetesServiceManager {\n    }\n\n    %% Relationships\n    AbstractBaseService &lt;|-- BaseService\n    BaseService &lt;|-- BaseComponentService\n    BaseService &lt;|-- BaseControllerService\n    BaseService &lt;|-- Worker\n    BaseControllerService &lt;|-- SystemController\n    BaseComponentService &lt;|-- WorkerManager\n    BaseComponentService &lt;|-- DatasetManager\n    BaseComponentService &lt;|-- RecordsManager\n    BaseComponentService &lt;|-- TimingManager\n    BaseComponentService &lt;|-- PostProcessorManager\n\n\n    SystemController ..&gt; BaseServiceManager: uses\n    BaseServiceManager &lt;|-- MultiProcessServiceManager\n    BaseServiceManager &lt;|-- KubernetesServiceManager\n    WorkerManager --|&gt; Worker: spawns\n</code></pre>"}]}