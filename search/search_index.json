{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-aiperf-documentation","title":"Welcome to AIPerf Documentation","text":"<p>AIPerf is a package for performance testing of AI models.</p>"},{"location":"#overview","title":"Overview","text":"<ul> <li>Explore the documentation using the navigation menu.</li> <li>See the Development page for contributing and setup instructions.</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li>Install dependencies</li> <li>Run the CLI or use the Python API</li> </ol> <p>For more details, see the rest of the documentation.</p>"},{"location":"Development/","title":"Development","text":""},{"location":"Development/#aiperf-developers-guide","title":"AIPerf Developers Guide","text":"<p>This guide will help you set up your development environment and understand the AIPerf system architecture.</p>"},{"location":"Development/#quick-start","title":"Quick Start","text":""},{"location":"Development/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>Linux environment (preferred)</li> </ul>"},{"location":"Development/#development-environment-setup","title":"Development Environment Setup","text":"<p>Choose ONE option below!</p>"},{"location":"Development/#option-a-devcontainer-preferred","title":"Option A: Devcontainer (Preferred)","text":"<p>Supported by: - VS Code - Cursor - Pycharm</p> <p>Use your IDE to re-open the project folder inside the devcontainer. Usually available as a popup when you first load the project. This will automatically build and install all required dependencies</p>"},{"location":"Development/#option-b-using-make-native-alternative","title":"Option B: Using Make (Native Alternative)","text":"<pre><code>make first-time-setup\n</code></pre>   This command will: - Install uv if not present - Create a virtual environment - Install dependencies - Install pre-commit hooks"},{"location":"Development/#option-c-manual-native-alternative","title":"Option C: Manual (Native Alternative)","text":"<pre><code># Install uv package manager\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Create virtual environment\nuv venv --python 3.12\n\n# Activate virtual environment\nsource .venv/bin/activate\n\n# Install package in editable development mode\nuv pip install -e \".[dev]\"\n\n# Install pre-commit hooks\npre-commit install --install-hooks\n</code></pre>"},{"location":"Development/#running-aiperf","title":"Running AIPerf","text":"<ul> <li>Default mode:   ```bash   aiperf</li> </ul> <p># also same as running   aiperf --run-type process   ```</p> <ul> <li> <p>Kubernetes mode (not yet supported):   <code>bash   aiperf --run-type k8s</code></p> </li> <li> <p>With debug logging:   <code>bash   aiperf --log-level DEBUG</code></p> </li> <li> <p>View all options:   <code>bash   aiperf --help</code></p> </li> </ul> <p>Press <code>Ctrl-C</code> to stop the process normally.</p> <p>Note: Press <code>Ctrl-Z</code> followed by <code>disown</code>, then <code>pkill -9 aiperf</code> if the process gets \"stuck\".</p> <p>Each process is named after the service_id. To see the running processes, run:</p> <pre><code>pgrep -a \"aiperf\n\n2879138 aiperf system_controller_e3291509\n2879170 aiperf dataset_manager_d821a161\n2879173 aiperf timing_manager_5e8caf4b\n2879175 aiperf worker_manager_77393965\n2879177 aiperf records_manager_c16acdb0\n2879179 aiperf post_processor_manager_d595537b\n</code></pre>"},{"location":"Development/#development-commands","title":"Development Commands","text":"<p>The project includes an optional Makefile for common development tasks:</p> <pre><code>make help              # Show all available commands\nmake test              # Run tests\nmake test-verbose      # Run tests with debug logging\nmake coverage          # Run tests with coverage report\nmake lint              # Run linting with ruff\nmake lint-fix          # Auto-fix linting issues\nmake format            # Format code with ruff\nmake check-format      # Check code formatting\nmake clean             # Clean up cache files\nmake docker            # Build docker image\nmake install           # Install in editable mode\n</code></pre> <p>You can also look inside at the commands it runs if you prefer to run things manually.</p>"},{"location":"Development/#project-architecture","title":"Project Architecture","text":""},{"location":"Development/#directory-structure","title":"Directory Structure","text":"<pre><code>aiperf/\n\u251c\u2500\u2500 aiperf/                      # Main Python package\n\u2502   \u251c\u2500\u2500 cli.py                   # Command line interface\n\u2502   \u251c\u2500\u2500 common/                  # Shared utilities and components\n\u2502   \u2502   \u251c\u2500\u2500 bootstrap.py         # Service bootstrapping\n\u2502   \u2502   \u251c\u2500\u2500 comms/               # Communication system\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 base.py          # Base communication classes\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 client_enums.py  # Client type definitions\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 zmq/             # ZeroMQ implementation\n\u2502   \u2502   \u251c\u2500\u2500 config/              # Configuration management\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 service_config.py # Service configuration models\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 loader.py        # Configuration loading utilities\n\u2502   \u2502   \u251c\u2500\u2500 service/             # Base service framework\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 base_service.py              # Core service implementation\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 base_service_interface.py    # Service interface definition\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 base_component_service.py    # Component service base\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 base_controller_service.py   # Controller service base\n\u2502   \u2502   \u251c\u2500\u2500 enums.py             # System-wide enumerations\n\u2502   \u2502   \u251c\u2500\u2500 models.py            # Pydantic data models\n\u2502   \u2502   \u251c\u2500\u2500 exceptions.py        # Custom exception classes\n\u2502   \u2502   \u251c\u2500\u2500 factories.py         # Service factory patterns\n\u2502   \u2502   \u251c\u2500\u2500 hooks.py             # Service lifecycle hooks\n\u2502   \u2502   \u251c\u2500\u2500 tokenizer.py         # Text tokenization utilities\n\u2502   \u2502   \u2514\u2500\u2500 utils.py             # General utilities\n\u2502   \u251c\u2500\u2500 services/                # Microservices implementation\n\u2502   \u2502   \u251c\u2500\u2500 system_controller/   # System orchestration service\n\u2502   \u2502   \u251c\u2500\u2500 dataset/             # Dataset management service\n\u2502   \u2502   \u251c\u2500\u2500 timing_manager/      # Request timing and credit management\n\u2502   \u2502   \u251c\u2500\u2500 worker_manager/      # Worker process management\n\u2502   \u2502   \u251c\u2500\u2500 worker/              # Request execution workers\n\u2502   \u2502   \u251c\u2500\u2500 records_manager/     # Result storage and management\n\u2502   \u2502   \u251c\u2500\u2500 post_processor_manager/ # Result processing and metrics\n\u2502   \u2502   \u2514\u2500\u2500 service_manager/     # Service lifecycle management\n\u2502   \u2514\u2500\u2500 tests/                   # Test suite\n\u2502       \u251c\u2500\u2500 conftest.py          # Pytest configuration\n\u2502       \u251c\u2500\u2500 services/            # Service-specific tests\n\u2502       \u251c\u2500\u2500 comms/               # Communication tests\n\u2502       \u2514\u2500\u2500 utils/               # Utility tests\n\u251c\u2500\u2500 docs/                        # Documentation\n\u251c\u2500\u2500 tools/                       # Development tools\n\u251c\u2500\u2500 .devcontainer/               # VS Code dev container config\n\u251c\u2500\u2500 .github/                     # GitHub workflows\n\u251c\u2500\u2500 pyproject.toml               # Project configuration\n\u251c\u2500\u2500 Makefile                     # Development automation\n\u251c\u2500\u2500 Dockerfile                   # Container configuration\n\u2514\u2500\u2500 README.md                    # Project overview\n</code></pre>"},{"location":"Development/#system-architecture","title":"System Architecture","text":"<p>AIPerf implements a distributed microservices architecture built around a message-passing system using ZeroMQ.</p>"},{"location":"Development/#core-services","title":"Core Services","text":"<ol> <li>System Controller (<code>system_controller</code>)</li> <li>Is bootstrapped by the CLI</li> <li>Orchestrates the entire system</li> <li>Manages service lifecycle and health monitoring</li> <li> <p>Handles service registration and coordination</p> </li> <li> <p>Dataset Manager (<code>dataset</code>)</p> </li> <li>Manages data generation and acquisition</li> <li>Provides synthetic prompt/token generation</li> <li> <p>Handles remote dataset retrieval</p> </li> <li> <p>Worker Manager (<code>worker_manager</code>)</p> </li> <li>Coordinates request distribution to workers</li> <li>Manages timing credits from the timing manager</li> <li> <p>Handles worker process lifecycle</p> </li> <li> <p>Worker (<code>worker</code>)</p> </li> <li>Executes actual inference requests</li> <li>Formats data for specific API interfaces</li> <li> <p>Manages multi-turn conversations</p> </li> <li> <p>Timing Manager (<code>timing_manager</code>)</p> </li> <li>Generates request schedules</li> <li>Issues timing credits for request throttling</li> <li> <p>Controls system load patterns</p> </li> <li> <p>Records Manager (<code>records_manager</code>)</p> </li> <li>Stores and manages test results</li> <li> <p>Provides result persistence and retrieval</p> </li> <li> <p>Post-Processor Manager (<code>post_processor_manager</code>)</p> </li> <li>Processes collected results</li> <li>Generates metrics and performance reports</li> <li>Provides analysis and conclusions</li> </ol>"},{"location":"Development/#service-bootstrapping-flow","title":"Service Bootstrapping Flow","text":"<p>The following diagram shows how services are bootstrapped in the AIPerf system:</p> <pre><code>%%{init: {'theme':'dark'}}%%\nflowchart LR\n    CLI[\"`**CLI**\n    aiperf`\"]\n    CLIConfig[\"`**CLI Options**\n    --run-type\n    --log-level\n    --config`\"]\n    ConfigFile[\"`**Config File**\n    YAML Config`\"]\n\n    SC[\"`**System Controller**\n    Orchestrates System`\"]\n\n    DS[\"`**Dataset Manager**\n    Data Generation`\"]\n    TM[\"`**Timing Manager**\n    Request Scheduling`\"]\n    WM[\"`**Worker Manager**\n    Worker Queue`\"]\n    RM[\"`**Records Manager**\n    Result Storage`\"]\n    PM[\"`**Post-Processor Manager**\n    Metrics &amp; Analysis`\"]\n\n    W1[\"`**Worker 1**`\"]\n    W2[\"`**Worker 2**`\"]\n    WN[\"`**Worker N**`\"]\n\n    CLI --&gt;|Bootstraps| SC\n    CLIConfig --&gt; CLI\n    ConfigFile --&gt; CLI\n\n    SC --&gt;|Configure &amp; Start| DS\n    SC --&gt;|Configure &amp; Start| TM\n    SC --&gt;|Configure &amp; Start| WM\n    SC --&gt;|Configure &amp; Start| RM\n    SC --&gt;|Configure &amp; Start| PM\n\n    WM --&gt;|Spawn &amp; Configure| W1\n    WM --&gt;|Spawn &amp; Configure| W2\n    WM --&gt;|Spawn &amp; Configure| WN\n\n    style CLI fill:#1e3a8a,stroke:#3b82f6,stroke-width:2px,color:#ffffff\n    style ConfigFile fill:#7c2d12,stroke:#f97316,stroke-width:2px,color:#ffffff\n    style CLIConfig fill:#7c2d12,stroke:#f97316,stroke-width:2px,color:#ffffff\n    style SC fill:#166534,stroke:#22c55e,stroke-width:3px,color:#ffffff\n    style DS fill:#4338ca,stroke:#8b5cf6,stroke-width:2px,color:#ffffff\n    style TM fill:#4338ca,stroke:#8b5cf6,stroke-width:2px,color:#ffffff\n    style WM fill:#dc2626,stroke:#f87171,stroke-width:2px,color:#ffffff\n    style RM fill:#4338ca,stroke:#8b5cf6,stroke-width:2px,color:#ffffff\n    style PM fill:#4338ca,stroke:#8b5cf6,stroke-width:2px,color:#ffffff\n    style W1 fill:#be185d,stroke:#f472b6,stroke-width:2px,color:#ffffff\n    style W2 fill:#be185d,stroke:#f472b6,stroke-width:2px,color:#ffffff\n    style WN fill:#be185d,stroke:#f472b6,stroke-width:2px,color:#ffffff\n</code></pre>"},{"location":"Development/#communication-system","title":"Communication System","text":"<p>Services communicate using a strongly-typed message system:</p> <ul> <li>Topics: Categorized message channels (commands, status, data, heartbeat, etc.)</li> <li>Messages: Pydantic models ensuring type safety</li> <li>Service States: Well-defined lifecycle states with transitions</li> </ul> <p>Key communication patterns: - Command/Response: System controller to services - Status Updates: Services to system controller - Heartbeat: Automatic health monitoring - Credit System: Resource allocation and throttling</p>"},{"location":"Development/#service-framework","title":"Service Framework","text":"<p>All services inherit from <code>BaseService</code> which provides:</p>"},{"location":"Development/#automatic-features","title":"Automatic Features","text":"<ul> <li>Lifecycle Management: <code>initialize()</code> \u2192 <code>run()</code> \u2192 <code>configure()</code> \u2192 <code>start()</code> \u2192 <code>stop()</code> \u2192 <code>cleanup()</code></li> <li>State Management: Automatic state transitions with validation</li> <li>Communication: Message publishing/subscribing with type safety</li> <li>Health Monitoring: Automatic heartbeat generation</li> <li>Error Handling: Structured exception handling and recovery</li> </ul>"},{"location":"Development/#implementation-requirements","title":"Implementation Requirements","text":""},{"location":"Development/#implement-base-service-requirements","title":"Implement base service requirements","text":"<pre><code>    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Initializing records manager\")\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.RECORDS_MANAGER\n</code></pre>"},{"location":"Development/#service-factory-registration","title":"Service Factory Registration","text":"<p>Register the service with the ServiceFactory:</p> <pre><code>@ServiceFactory.register(ServiceType.RECORDS_MANAGER)\nclass RecordsManager(BaseComponentService):\n    \"\"\"\n    The RecordsManager service is primarily responsible for holding the\n    results returned from the workers.\n    \"\"\"\n</code></pre>"},{"location":"Development/#service-lifecycle-hooks","title":"Service Lifecycle Hooks","text":"<p>Use decorators to hook into lifecycle events:</p> <pre><code>    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize records manager-specific components.\"\"\"\n        self.logger.debug(\"Initializing records manager\")\n        # TODO: Implement records manager initialization\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the records manager.\"\"\"\n        self.logger.debug(\"Starting records manager\")\n        # TODO: Implement records manager start\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the records manager.\"\"\"\n        self.logger.debug(\"Stopping records manager\")\n        # TODO: Implement records manager stop\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up records manager-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up records manager\")\n        # TODO: Implement records manager cleanup\n\n    @on_configure\n    async def _configure(self, message: Message) -&gt; None:\n        \"\"\"Configure the records manager.\"\"\"\n        self.logger.debug(f\"Configuring records manager with message: {message}\")\n        # TODO: Implement records manager configuration\n</code></pre>"},{"location":"Development/#running-services","title":"Running Services","text":""},{"location":"Development/#bootstrapping","title":"Bootstrapping","text":"<p>Services are launched using the bootstrap system:</p> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the records manager.\"\"\"\n\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(RecordsManager)\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n</code></pre> <p>The bootstrap system: - Sets up uvloop for high-performance async I/O - Loads service configuration - Manages service lifecycle - Handles graceful shutdown</p>"},{"location":"Development/#configuration-management","title":"Configuration Management","text":"<p>Services are configured using Pydantic models:</p> <p>(TBD) Coming SOON</p> <pre><code>from aiperf.common.config import ServiceConfig\nfrom aiperf.common.enums import ServiceRunType\n\nconfig = ServiceConfig(\n    service_run_type=ServiceRunType.MULTIPROCESSING,\n    # Additional configuration options\n)\n</code></pre>"},{"location":"Development/#testing","title":"Testing","text":""},{"location":"Development/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests (provide basic coverage, no logging)\nmake test\n\n# Run with verbose output and debug logging, basic coverage\nmake test-verbose\n\n# Run with HTML coverage report, and no logging\nmake coverage\n\n# Run specific test file\npytest aiperf/tests/test_specific_file.py -v\n</code></pre>"},{"location":"Development/#test-structure","title":"Test Structure","text":"<ul> <li>Unit Tests: Test individual components in isolation</li> <li>Integration Tests: Test service interactions</li> <li>Base Test Classes: Shared test utilities and fixtures</li> </ul>"},{"location":"Development/#test-utilities","title":"Test Utilities","text":"<p>The test suite provides base classes for testing services:</p> <ul> <li><code>BaseTestService</code>: Base class for testing services</li> <li><code>BaseTestControllerService</code>: For testing controller services</li> <li><code>BaseTestComponentService</code>: For testing component-specific functionality</li> </ul>"},{"location":"Development/#code-quality","title":"Code Quality","text":""},{"location":"Development/#linting-and-formatting","title":"Linting and Formatting","text":"<p>The project uses <code>ruff</code> for both linting and formatting:</p> <pre><code># Check code style\nruff check .\n\n# Auto-fix issues\nruff check . --fix\n\n# Format code\nruff format .\n\n# Check formatting\nruff format . --check\n</code></pre>"},{"location":"Development/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Pre-commit hooks are automatically installed and run: - Code formatting with ruff - Import sorting - Basic syntax checking - Test execution on changed files</p>"},{"location":"Development/#configuration","title":"Configuration","text":"<p>Quality tools are configured in <code>pyproject.toml</code>: - Ruff: Line length 88, comprehensive rule set - Pytest: Async mode, coverage reporting - Coverage: HTML reports, skip covered lines</p>"},{"location":"Development/#development-best-practices","title":"Development Best Practices","text":""},{"location":"Development/#code-style","title":"Code Style","text":"<ul> <li>Follow PEP 8 guidelines</li> <li>Use Pydantic models for data structures</li> <li>Prefer enums for string choices (using our custom <code>CaseInsensitiveStrEnum</code>)</li> <li>Implement DRY principles</li> <li>Use type hints throughout</li> </ul>"},{"location":"Development/#testing_1","title":"Testing","text":"<ul> <li>Write tests for all new functionality</li> <li>Use pytest fixtures for shared setup</li> <li>Parameterize tests when appropriate</li> <li>Aim for high test coverage</li> <li>Test both success and failure cases</li> </ul>"},{"location":"Development/#service-development","title":"Service Development","text":"<ul> <li>Always inherit from appropriate base service class</li> <li>Use lifecycle hooks for setup/teardown</li> <li>Implement proper error handling</li> <li>Follow message-passing patterns</li> <li>Document service responsibilities clearly</li> </ul>"},{"location":"Development/#configuration_1","title":"Configuration","text":"<ul> <li>Use Pydantic models for configuration</li> <li>Validate configuration at startup</li> <li>Provide sensible defaults</li> <li>Support environment variable overrides</li> </ul>"},{"location":"Development/#troubleshooting","title":"Troubleshooting","text":""},{"location":"Development/#common-issues","title":"Common Issues","text":"<ol> <li>Services not starting: Check logs for initialization errors</li> <li>Communication failures: Verify ZeroMQ ports are available</li> <li>Test failures: Ensure virtual environment is activated</li> <li>Import errors: Run <code>pip install -e \".[dev]\"</code> to update dependencies</li> </ol>"},{"location":"Development/#debugging","title":"Debugging","text":"<ul> <li>Use <code>--log-level DEBUG</code> for detailed logging</li> <li>Check service states in system controller logs</li> <li>Monitor heartbeat messages for service health</li> <li>Use <code>make test-verbose</code> for detailed test output</li> </ul>"},{"location":"Development/#performance","title":"Performance","text":"<ul> <li>Services use uvloop for high-performance async I/O</li> <li>ZeroMQ provides efficient inter-service communication</li> <li>Multiprocessing mode distributes load across CPU cores</li> <li>Kubernetes mode enables horizontal scaling</li> </ul>"},{"location":"Development/#contributing","title":"Contributing","text":"<ol> <li>Follow the development setup instructions</li> <li>Create feature branches from main</li> <li>Write tests for new functionality</li> <li>Ensure all quality checks pass</li> <li>Submit pull requests with clear descriptions following proper naming</li> </ol> <p>For questions or issues, refer to the project documentation or open an issue in the repository.</p>"},{"location":"api/","title":"API Reference","text":"<p>This page contains the API documentation for all Python modules in the codebase (excluding init.py files).</p>"},{"location":"api/#aiperfcli","title":"aiperf.cli","text":""},{"location":"api/#aiperf.cli.main","title":"<code>main()</code>","text":"<p>Main entry point for the AIPerf system.</p> Source code in <code>aiperf/cli.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the AIPerf system.\"\"\"\n    parser = ArgumentParser(description=\"AIPerf Benchmarking System\")\n    parser.add_argument(\"--config\", type=str, help=\"Path to configuration file\")\n    parser.add_argument(\n        \"--log-level\",\n        type=str,\n        default=\"INFO\",\n        choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"],\n        help=\"Set the logging level\",\n    )\n    parser.add_argument(\n        \"--run-type\",\n        type=str,\n        default=\"process\",\n        choices=[\"process\", \"k8s\"],\n        help=\"Process manager backend to use \"\n        \"(multiprocessing: 'process', or kubernetes: 'k8s')\",\n    )\n    args = parser.parse_args()\n\n    # Set logging level for the root logger (affects all loggers)\n    logging.root.setLevel(getattr(logging, args.log_level))\n\n    # Set up logging to use Rich\n    handler = RichHandler(\n        rich_tracebacks=True,\n        show_path=True,\n        console=Console(),\n        tracebacks_show_locals=True,\n    )\n    logging.root.addHandler(handler)\n\n    # Load configuration\n    config = ServiceConfig(\n        service_run_type=args.run_type,\n    )\n\n    if args.config:\n        # In a real implementation, this would load from the specified file\n        logger.debug(\"Loading configuration from %s\", args.config)\n        # config.load_from_file(args.config)\n\n    # Create and start the system controller\n\n    logger.info(\"Starting AIPerf System\")\n    bootstrap_and_run_service(SystemController, service_config=config)\n    logger.info(\"AIPerf System exited\")\n</code></pre>"},{"location":"api/#aiperfcommonbootstrap","title":"aiperf.common.bootstrap","text":""},{"location":"api/#aiperf.common.bootstrap.bootstrap_and_run_service","title":"<code>bootstrap_and_run_service(service_class, service_config=None)</code>","text":"<p>Bootstrap the service and run it.</p> <p>This function will load the service configuration, create an instance of the service, and run it.</p> <p>Parameters:</p> Name Type Description Default <code>service_class</code> <code>type[BaseService]</code> <p>The service class of the service to run</p> required <code>service_config</code> <code>ServiceConfig | None</code> <p>The service configuration to use, if not provided, the service configuration will be loaded from the config file</p> <code>None</code> Source code in <code>aiperf/common/bootstrap.py</code> <pre><code>def bootstrap_and_run_service(\n    service_class: type[BaseService], service_config: ServiceConfig | None = None\n):\n    \"\"\"Bootstrap the service and run it.\n\n    This function will load the service configuration,\n    create an instance of the service, and run it.\n\n    Args:\n        service_class: The service class of the service to run\n        service_config: The service configuration to use, if not provided, the service\n            configuration will be loaded from the config file\n\n    \"\"\"\n    import uvloop\n\n    # Load the service configuration\n    if service_config is None:\n        from aiperf.common.config import load_service_config\n\n        service_config = load_service_config()\n\n    # Create the service instance and run it\n    service = service_class(service_config=service_config)\n    uvloop.run(service.run_forever())\n</code></pre>"},{"location":"api/#aiperfcommoncommsbase","title":"aiperf.common.comms.base","text":""},{"location":"api/#aiperf.common.comms.base.BaseCommunication","title":"<code>BaseCommunication</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for specifying the base communication layer for AIPerf components.</p> Source code in <code>aiperf/common/comms/base.py</code> <pre><code>class BaseCommunication(ABC):\n    \"\"\"Base class for specifying the base communication layer for AIPerf components.\"\"\"\n\n    @abstractmethod\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize communication channels.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def is_initialized(self) -&gt; bool:\n        \"\"\"Check if communication channels are initialized.\n\n        Returns:\n            True if communication channels are initialized, False otherwise\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def is_shutdown(self) -&gt; bool:\n        \"\"\"Check if communication channels are shutdown.\n\n        Returns:\n            True if communication channels are shutdown, False otherwise\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def shutdown(self) -&gt; None:\n        \"\"\"Gracefully shutdown communication channels.\"\"\"\n        pass\n\n    @abstractmethod\n    async def create_clients(self, *client_types: ClientType) -&gt; None:\n        \"\"\"Create the communication clients.\n\n        Args:\n            *client_types: The client types to create\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def publish(self, topic: Topic, message: Message) -&gt; None:\n        \"\"\"Publish a message to a topic.\n\n        Args:\n            topic: Topic to publish to\n            message: Message to publish\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def subscribe(\n        self,\n        topic: Topic,\n        callback: Callable[[Message], Coroutine[Any, Any, None]],\n    ) -&gt; None:\n        \"\"\"Subscribe to a topic.\n\n        Args:\n            topic: Topic to subscribe to\n            callback: Function to call when a message is received\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def request(\n        self,\n        topic: Topic,\n        message: Message,\n    ) -&gt; Message:\n        \"\"\"Send a request and wait for a response.\n\n        Args:\n            topic: Topic to send request to\n            message: Message to send\n\n        Returns:\n            Response message if successful\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def push(self, topic: Topic, message: Message) -&gt; None:\n        \"\"\"Push data to a target.\n\n        Args:\n            topic: Topic to push to\n            message: Message to be pushed\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def register_pull_callback(\n        self,\n        message_type: MessageType,\n        callback: Callable[[Message], Coroutine[Any, Any, None]],\n    ) -&gt; None:\n        \"\"\"Register a callback for a pull client.\n\n        Args:\n            message_type: The message type to register the callback for\n            callback: The callback to register\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.is_initialized","title":"<code>is_initialized</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Check if communication channels are initialized.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if communication channels are initialized, False otherwise</p>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.is_shutdown","title":"<code>is_shutdown</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Check if communication channels are shutdown.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if communication channels are shutdown, False otherwise</p>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.create_clients","title":"<code>create_clients(*client_types)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Create the communication clients.</p> <p>Parameters:</p> Name Type Description Default <code>*client_types</code> <code>ClientType</code> <p>The client types to create</p> <code>()</code> Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def create_clients(self, *client_types: ClientType) -&gt; None:\n    \"\"\"Create the communication clients.\n\n    Args:\n        *client_types: The client types to create\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.initialize","title":"<code>initialize()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Initialize communication channels.</p> Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def initialize(self) -&gt; None:\n    \"\"\"Initialize communication channels.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.publish","title":"<code>publish(topic, message)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Publish a message to a topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>Topic to publish to</p> required <code>message</code> <code>Message</code> <p>Message to publish</p> required Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def publish(self, topic: Topic, message: Message) -&gt; None:\n    \"\"\"Publish a message to a topic.\n\n    Args:\n        topic: Topic to publish to\n        message: Message to publish\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.push","title":"<code>push(topic, message)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Push data to a target.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>Topic to push to</p> required <code>message</code> <code>Message</code> <p>Message to be pushed</p> required Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def push(self, topic: Topic, message: Message) -&gt; None:\n    \"\"\"Push data to a target.\n\n    Args:\n        topic: Topic to push to\n        message: Message to be pushed\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.register_pull_callback","title":"<code>register_pull_callback(message_type, callback)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Register a callback for a pull client.</p> <p>Parameters:</p> Name Type Description Default <code>message_type</code> <code>MessageType</code> <p>The message type to register the callback for</p> required <code>callback</code> <code>Callable[[Message], Coroutine[Any, Any, None]]</code> <p>The callback to register</p> required Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def register_pull_callback(\n    self,\n    message_type: MessageType,\n    callback: Callable[[Message], Coroutine[Any, Any, None]],\n) -&gt; None:\n    \"\"\"Register a callback for a pull client.\n\n    Args:\n        message_type: The message type to register the callback for\n        callback: The callback to register\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.request","title":"<code>request(topic, message)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Send a request and wait for a response.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>Topic to send request to</p> required <code>message</code> <code>Message</code> <p>Message to send</p> required <p>Returns:</p> Type Description <code>Message</code> <p>Response message if successful</p> Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def request(\n    self,\n    topic: Topic,\n    message: Message,\n) -&gt; Message:\n    \"\"\"Send a request and wait for a response.\n\n    Args:\n        topic: Topic to send request to\n        message: Message to send\n\n    Returns:\n        Response message if successful\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.shutdown","title":"<code>shutdown()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Gracefully shutdown communication channels.</p> Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def shutdown(self) -&gt; None:\n    \"\"\"Gracefully shutdown communication channels.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.comms.base.BaseCommunication.subscribe","title":"<code>subscribe(topic, callback)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Subscribe to a topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>Topic to subscribe to</p> required <code>callback</code> <code>Callable[[Message], Coroutine[Any, Any, None]]</code> <p>Function to call when a message is received</p> required Source code in <code>aiperf/common/comms/base.py</code> <pre><code>@abstractmethod\nasync def subscribe(\n    self,\n    topic: Topic,\n    callback: Callable[[Message], Coroutine[Any, Any, None]],\n) -&gt; None:\n    \"\"\"Subscribe to a topic.\n\n    Args:\n        topic: Topic to subscribe to\n        callback: Function to call when a message is received\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperfcommoncommsclient_enums","title":"aiperf.common.comms.client_enums","text":""},{"location":"api/#aiperf.common.comms.client_enums.ClientType","title":"<code>ClientType = PubClientType | SubClientType | PushClientType | PullClientType | ReqClientType | RepClientType</code>  <code>module-attribute</code>","text":"<p>Union of all client types.</p>"},{"location":"api/#aiperf.common.comms.client_enums.PubClientType","title":"<code>PubClientType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Enum for specifying the client type for publishing messages. Includes a helper method for retrieving the appropriate client type based on the topic.</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>class PubClientType(CaseInsensitiveStrEnum):\n    \"\"\"\n    Enum for specifying the client type for publishing messages. Includes a helper method\n    for retrieving the appropriate client type based on the topic.\n    \"\"\"\n\n    CONTROLLER = \"controller_pub\"\n    COMPONENT = \"component_pub\"\n\n    @classmethod\n    def from_topic(cls, topic: Topic) -&gt; \"PubClientType\":\n        \"\"\"Determine the appropriate ClientType based on topic.\n\n        Args:\n            topic: The topic to communicate on\n\n        Returns:\n            The appropriate ClientType for the given topic\n        \"\"\"\n        match topic:\n            case (\n                Topic.HEARTBEAT\n                | Topic.REGISTRATION\n                | Topic.STATUS\n                | Topic.RESPONSE\n                | Topic.CREDITS_COMPLETE\n                | Topic.PROFILE_PROGRESS\n                | Topic.PROFILE_RESULTS\n                | Topic.PROFILE_STATS\n            ):\n                return cls.COMPONENT\n            case Topic.COMMAND:\n                return cls.CONTROLLER\n            case _:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"No client type found for topic {topic}\",\n                )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.PubClientType.from_topic","title":"<code>from_topic(topic)</code>  <code>classmethod</code>","text":"<p>Determine the appropriate ClientType based on topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>The topic to communicate on</p> required <p>Returns:</p> Type Description <code>PubClientType</code> <p>The appropriate ClientType for the given topic</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>@classmethod\ndef from_topic(cls, topic: Topic) -&gt; \"PubClientType\":\n    \"\"\"Determine the appropriate ClientType based on topic.\n\n    Args:\n        topic: The topic to communicate on\n\n    Returns:\n        The appropriate ClientType for the given topic\n    \"\"\"\n    match topic:\n        case (\n            Topic.HEARTBEAT\n            | Topic.REGISTRATION\n            | Topic.STATUS\n            | Topic.RESPONSE\n            | Topic.CREDITS_COMPLETE\n            | Topic.PROFILE_PROGRESS\n            | Topic.PROFILE_RESULTS\n            | Topic.PROFILE_STATS\n        ):\n            return cls.COMPONENT\n        case Topic.COMMAND:\n            return cls.CONTROLLER\n        case _:\n            raise CommunicationError(\n                CommunicationErrorReason.CLIENT_NOT_FOUND,\n                f\"No client type found for topic {topic}\",\n            )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.PullClientType","title":"<code>PullClientType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Enum for specifying the client type for pulling messages. Includes a helper method for retrieving the appropriate client type based on the topic.</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>class PullClientType(CaseInsensitiveStrEnum):\n    \"\"\"\n    Enum for specifying the client type for pulling messages. Includes a helper method\n    for retrieving the appropriate client type based on the topic.\n    \"\"\"\n\n    INFERENCE_RESULTS = \"inference_results_pull\"\n    CREDIT_DROP = \"credit_drop_pull\"\n    CREDIT_RETURN = \"credit_return_pull\"\n\n    @classmethod\n    def from_message_type(cls, message_type: MessageType) -&gt; \"PullClientType\":\n        \"\"\"Determine the appropriate ClientType based on message type.\n\n        Args:\n            message_type: The message type to communicate on\n\n        Returns:\n            The appropriate ClientType for the given message type\n        \"\"\"\n        match message_type:\n            case MessageType.CREDIT_DROP:\n                return cls.CREDIT_DROP\n            case MessageType.CREDIT_RETURN:\n                return cls.CREDIT_RETURN\n            case MessageType.INFERENCE_RESULTS:\n                return cls.INFERENCE_RESULTS\n            case _:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"No client type found for message type {message_type}\",\n                )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.PullClientType.from_message_type","title":"<code>from_message_type(message_type)</code>  <code>classmethod</code>","text":"<p>Determine the appropriate ClientType based on message type.</p> <p>Parameters:</p> Name Type Description Default <code>message_type</code> <code>MessageType</code> <p>The message type to communicate on</p> required <p>Returns:</p> Type Description <code>PullClientType</code> <p>The appropriate ClientType for the given message type</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>@classmethod\ndef from_message_type(cls, message_type: MessageType) -&gt; \"PullClientType\":\n    \"\"\"Determine the appropriate ClientType based on message type.\n\n    Args:\n        message_type: The message type to communicate on\n\n    Returns:\n        The appropriate ClientType for the given message type\n    \"\"\"\n    match message_type:\n        case MessageType.CREDIT_DROP:\n            return cls.CREDIT_DROP\n        case MessageType.CREDIT_RETURN:\n            return cls.CREDIT_RETURN\n        case MessageType.INFERENCE_RESULTS:\n            return cls.INFERENCE_RESULTS\n        case _:\n            raise CommunicationError(\n                CommunicationErrorReason.CLIENT_NOT_FOUND,\n                f\"No client type found for message type {message_type}\",\n            )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.PushClientType","title":"<code>PushClientType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Enum for specifying the client type for pushing messages. Includes a helper method for retrieving the appropriate client type based on the topic.</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>class PushClientType(CaseInsensitiveStrEnum):\n    \"\"\"\n    Enum for specifying the client type for pushing messages. Includes a helper method\n    for retrieving the appropriate client type based on the topic.\n    \"\"\"\n\n    INFERENCE_RESULTS = \"inference_results_push\"\n    CREDIT_DROP = \"credit_drop_push\"\n    CREDIT_RETURN = \"credit_return_push\"\n\n    @classmethod\n    def from_topic(cls, topic: Topic) -&gt; \"PushClientType\":\n        \"\"\"Determine the appropriate ClientType based on communication type and topic.\n\n        Args:\n            topic: The topic to communicate on\n\n        Returns:\n            The appropriate ClientType for the given topic\n        \"\"\"\n        match topic:\n            case Topic.CREDIT_DROP:\n                return cls.CREDIT_DROP\n            case Topic.CREDIT_RETURN:\n                return cls.CREDIT_RETURN\n            case Topic.INFERENCE_RESULTS:\n                return cls.INFERENCE_RESULTS\n            case _:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"No client type found for topic {topic}\",\n                )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.PushClientType.from_topic","title":"<code>from_topic(topic)</code>  <code>classmethod</code>","text":"<p>Determine the appropriate ClientType based on communication type and topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>The topic to communicate on</p> required <p>Returns:</p> Type Description <code>PushClientType</code> <p>The appropriate ClientType for the given topic</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>@classmethod\ndef from_topic(cls, topic: Topic) -&gt; \"PushClientType\":\n    \"\"\"Determine the appropriate ClientType based on communication type and topic.\n\n    Args:\n        topic: The topic to communicate on\n\n    Returns:\n        The appropriate ClientType for the given topic\n    \"\"\"\n    match topic:\n        case Topic.CREDIT_DROP:\n            return cls.CREDIT_DROP\n        case Topic.CREDIT_RETURN:\n            return cls.CREDIT_RETURN\n        case Topic.INFERENCE_RESULTS:\n            return cls.INFERENCE_RESULTS\n        case _:\n            raise CommunicationError(\n                CommunicationErrorReason.CLIENT_NOT_FOUND,\n                f\"No client type found for topic {topic}\",\n            )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.RepClientType","title":"<code>RepClientType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Enum for specifying the client type for responding to messages. Includes a helper method for retrieving the appropriate client type based on the topic.</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>class RepClientType(CaseInsensitiveStrEnum):\n    \"\"\"\n    Enum for specifying the client type for responding to messages. Includes a helper method\n    for retrieving the appropriate client type based on the topic.\n    \"\"\"\n\n    CONVERSATION_DATA = \"conversation_data_rep\"\n\n    @classmethod\n    def from_topic(cls, topic: Topic) -&gt; \"RepClientType\":\n        \"\"\"Determine the appropriate ClientType based on topic.\n\n        Args:\n            topic: The topic to communicate on\n\n        Returns:\n            The appropriate ClientType for the given topic\n        \"\"\"\n        match topic:\n            case Topic.CONVERSATION_DATA:\n                return cls.CONVERSATION_DATA\n            case _:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"No client type found for topic {topic}\",\n                )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.RepClientType.from_topic","title":"<code>from_topic(topic)</code>  <code>classmethod</code>","text":"<p>Determine the appropriate ClientType based on topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>The topic to communicate on</p> required <p>Returns:</p> Type Description <code>RepClientType</code> <p>The appropriate ClientType for the given topic</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>@classmethod\ndef from_topic(cls, topic: Topic) -&gt; \"RepClientType\":\n    \"\"\"Determine the appropriate ClientType based on topic.\n\n    Args:\n        topic: The topic to communicate on\n\n    Returns:\n        The appropriate ClientType for the given topic\n    \"\"\"\n    match topic:\n        case Topic.CONVERSATION_DATA:\n            return cls.CONVERSATION_DATA\n        case _:\n            raise CommunicationError(\n                CommunicationErrorReason.CLIENT_NOT_FOUND,\n                f\"No client type found for topic {topic}\",\n            )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.ReqClientType","title":"<code>ReqClientType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Enum for specifying the client type for requesting messages. Includes a helper method for retrieving the appropriate client type based on the topic.</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>class ReqClientType(CaseInsensitiveStrEnum):\n    \"\"\"\n    Enum for specifying the client type for requesting messages. Includes a helper method\n    for retrieving the appropriate client type based on the topic.\n    \"\"\"\n\n    CONVERSATION_DATA = \"conversation_data_req\"\n\n    @classmethod\n    def from_topic(cls, topic: Topic) -&gt; \"ReqClientType\":\n        \"\"\"Determine the appropriate ClientType based on topic.\n\n        Args:\n            topic: The topic to communicate on\n\n        Returns:\n            The appropriate ClientType for the given topic\n        \"\"\"\n        match topic:\n            case Topic.CONVERSATION_DATA:\n                return cls.CONVERSATION_DATA\n            case _:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"No client type found for topic {topic}\",\n                )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.ReqClientType.from_topic","title":"<code>from_topic(topic)</code>  <code>classmethod</code>","text":"<p>Determine the appropriate ClientType based on topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>The topic to communicate on</p> required <p>Returns:</p> Type Description <code>ReqClientType</code> <p>The appropriate ClientType for the given topic</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>@classmethod\ndef from_topic(cls, topic: Topic) -&gt; \"ReqClientType\":\n    \"\"\"Determine the appropriate ClientType based on topic.\n\n    Args:\n        topic: The topic to communicate on\n\n    Returns:\n        The appropriate ClientType for the given topic\n    \"\"\"\n    match topic:\n        case Topic.CONVERSATION_DATA:\n            return cls.CONVERSATION_DATA\n        case _:\n            raise CommunicationError(\n                CommunicationErrorReason.CLIENT_NOT_FOUND,\n                f\"No client type found for topic {topic}\",\n            )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.SubClientType","title":"<code>SubClientType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Enum for specifying the client type for subscribing to messages. Includes a helper method for retrieving the appropriate client type based on the topic.</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>class SubClientType(CaseInsensitiveStrEnum):\n    \"\"\"\n    Enum for specifying the client type for subscribing to messages. Includes a helper method\n    for retrieving the appropriate client type based on the topic.\n    \"\"\"\n\n    CONTROLLER = \"controller_sub\"\n    COMPONENT = \"component_sub\"\n\n    @classmethod\n    def from_topic(cls, topic: Topic) -&gt; \"SubClientType\":\n        \"\"\"Determine the appropriate ClientType based on topic.\n\n        Args:\n            topic: The topic to communicate on\n\n        Returns:\n            The appropriate ClientType for the given topic\n        \"\"\"\n        match topic:\n            case (\n                Topic.HEARTBEAT\n                | Topic.REGISTRATION\n                | Topic.STATUS\n                | Topic.RESPONSE\n                | Topic.CREDITS_COMPLETE\n                | Topic.PROFILE_PROGRESS\n                | Topic.PROFILE_RESULTS\n                | Topic.PROFILE_STATS\n            ):\n                return cls.COMPONENT\n            case Topic.COMMAND:\n                return cls.CONTROLLER\n            case _:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"No client type found for topic {topic}\",\n                )\n</code></pre>"},{"location":"api/#aiperf.common.comms.client_enums.SubClientType.from_topic","title":"<code>from_topic(topic)</code>  <code>classmethod</code>","text":"<p>Determine the appropriate ClientType based on topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>The topic to communicate on</p> required <p>Returns:</p> Type Description <code>SubClientType</code> <p>The appropriate ClientType for the given topic</p> Source code in <code>aiperf/common/comms/client_enums.py</code> <pre><code>@classmethod\ndef from_topic(cls, topic: Topic) -&gt; \"SubClientType\":\n    \"\"\"Determine the appropriate ClientType based on topic.\n\n    Args:\n        topic: The topic to communicate on\n\n    Returns:\n        The appropriate ClientType for the given topic\n    \"\"\"\n    match topic:\n        case (\n            Topic.HEARTBEAT\n            | Topic.REGISTRATION\n            | Topic.STATUS\n            | Topic.RESPONSE\n            | Topic.CREDITS_COMPLETE\n            | Topic.PROFILE_PROGRESS\n            | Topic.PROFILE_RESULTS\n            | Topic.PROFILE_STATS\n        ):\n            return cls.COMPONENT\n        case Topic.COMMAND:\n            return cls.CONTROLLER\n        case _:\n            raise CommunicationError(\n                CommunicationErrorReason.CLIENT_NOT_FOUND,\n                f\"No client type found for topic {topic}\",\n            )\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientsbase","title":"aiperf.common.comms.zmq.clients.base","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient","title":"<code>BaseZMQClient</code>","text":"<p>               Bases: <code>AIPerfTaskMixin</code></p> <p>Base class for all ZMQ clients.</p> <p>This class provides a common interface for all ZMQ clients in the AIPerf framework. It inherits from the :class:<code>AIPerfTaskMixin</code>, allowing derived classes to implement specific hooks.</p> Source code in <code>aiperf/common/comms/zmq/clients/base.py</code> <pre><code>@supports_hooks(\n    AIPerfHook.ON_INIT,\n    AIPerfHook.ON_STOP,\n    AIPerfHook.ON_CLEANUP,\n    AIPerfHook.AIPERF_TASK,\n)\nclass BaseZMQClient(AIPerfTaskMixin):\n    \"\"\"Base class for all ZMQ clients.\n\n    This class provides a common interface for all ZMQ clients in the AIPerf\n    framework. It inherits from the :class:`AIPerfTaskMixin`, allowing derived\n    classes to implement specific hooks.\n    \"\"\"\n\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        socket_type: zmq.SocketType,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Base class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_type (SocketType): The type of ZMQ socket (PUB or SUB).\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        self.logger = logging.getLogger(__name__)\n        self.stop_event: asyncio.Event = asyncio.Event()\n        self.initialized_event: asyncio.Event = asyncio.Event()\n        self.context: zmq.asyncio.Context = context\n        self.address: str = address\n        self.bind: bool = bind\n        self.socket_type: zmq.SocketType = socket_type\n        self._socket: zmq.asyncio.Socket | None = None\n        self.socket_ops: dict = socket_ops or {}\n        self.client_id: str = f\"{self.socket_type.name}_client_{uuid.uuid4().hex[:8]}\"\n        super().__init__()\n\n    @property\n    def is_initialized(self) -&gt; bool:\n        \"\"\"Check if the client is initialized.\"\"\"\n        return self.initialized_event.is_set()\n\n    @property\n    def is_shutdown(self) -&gt; bool:\n        \"\"\"Check if the client is shutdown.\"\"\"\n        return self.stop_event.is_set()\n\n    @property\n    def socket_type_name(self) -&gt; str:\n        \"\"\"Get the name of the socket type.\"\"\"\n        return self.socket_type.name\n\n    @property\n    def socket(self) -&gt; zmq.asyncio.Socket:\n        \"\"\"Get the zmq socket for the client.\n\n        Raises:\n            CommunicationError: If the client is not initialized\n        \"\"\"\n        if not self._socket:\n            raise CommunicationError(\n                CommunicationErrorReason.NOT_INITIALIZED_ERROR,\n                \"Communication channels are not initialized\",\n            )\n        return self._socket\n\n    def _ensure_initialized(self) -&gt; None:\n        \"\"\"Ensure the communication channels are initialized and not shutdown.\n\n        Raises:\n            CommunicationError: If the communication channels are not initialized\n                or shutdown\n        \"\"\"\n        if not self.is_initialized:\n            raise CommunicationError(\n                CommunicationErrorReason.NOT_INITIALIZED_ERROR,\n                \"Communication channels are not initialized\",\n            )\n        if self.is_shutdown:\n            raise asyncio.CancelledError()\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize the communication.\n\n        This method will:\n        - Create the zmq socket\n        - Bind or connect the socket to the address\n        - Set the socket options\n        - Run the AIPerfHook.ON_INIT hooks\n        \"\"\"\n        try:\n            self._socket = self.context.socket(self.socket_type)\n            if self.bind:\n                self.logger.debug(\n                    \"ZMQ %s socket initialized and bound to %s (%s)\",\n                    self.socket_type_name,\n                    self.address,\n                    self.client_id,\n                )\n                self._socket.bind(self.address)\n            else:\n                self.logger.debug(\n                    \"ZMQ %s socket initialized and connected to %s (%s)\",\n                    self.socket_type_name,\n                    self.address,\n                    self.client_id,\n                )\n                self._socket.connect(self.address)\n\n            # TODO: Make these easier to configure by an end user\n\n            # Use reasonable timeouts\n            self._socket.setsockopt(zmq.RCVTIMEO, 30000)  # 30 seconds\n            self._socket.setsockopt(zmq.SNDTIMEO, 30000)  # 30 seconds\n\n            # Add performance-oriented socket options\n            self._socket.setsockopt(zmq.TCP_KEEPALIVE, 1)\n            self._socket.setsockopt(zmq.TCP_KEEPALIVE_IDLE, 60)\n            self._socket.setsockopt(zmq.TCP_KEEPALIVE_INTVL, 10)\n            self._socket.setsockopt(zmq.TCP_KEEPALIVE_CNT, 3)\n            self._socket.setsockopt(zmq.IMMEDIATE, 1)  # Don't queue messages\n            self._socket.setsockopt(zmq.LINGER, 0)  # Don't wait on close\n\n            # Set additional socket options requested by the caller\n            for key, val in self.socket_ops.items():\n                self._socket.setsockopt(key, val)\n\n            await self.run_hooks(AIPerfHook.ON_INIT)\n\n            self.initialized_event.set()\n            self.logger.debug(\n                \"ZMQ %s socket initialized and connected to %s (%s)\",\n                self.socket_type_name,\n                self.address,\n                self.client_id,\n            )\n\n        except AIPerfError:\n            raise  # re-raise it up the stack\n        except Exception as e:\n            raise CommunicationError(\n                CommunicationErrorReason.INITIALIZATION_ERROR,\n                f\"Failed to initialize ZMQ socket: {e}\",\n            ) from e\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Shutdown the communication.\n\n        This method will:\n        - Close the zmq socket\n        - Run the AIPerfHook.ON_CLEANUP hooks\n        \"\"\"\n        if self.is_shutdown:\n            return\n\n        if not self.stop_event.is_set():\n            self.stop_event.set()\n\n        # Cancel all registered tasks\n        for task in self.registered_tasks.values():\n            task.cancel()\n\n        try:\n            if self._socket:\n                self._socket.close()\n                self.logger.debug(\n                    \"ZMQ %s socket closed (%s)\", self.socket_type_name, self.client_id\n                )\n\n        except Exception as e:\n            self.logger.error(\n                \"Exception shutting down ZMQ socket: %s (%s)\", e, self.client_id\n            )\n            raise CommunicationError(\n                CommunicationErrorReason.SHUTDOWN_ERROR,\n                f\"Failed to shutdown ZMQ socket: {e}\",\n            ) from e\n\n        finally:\n            self._socket = None\n\n            try:\n                await self.run_hooks(AIPerfHook.ON_STOP)\n                await self.run_hooks(AIPerfHook.ON_CLEANUP)\n\n            except asyncio.CancelledError:\n                return\n\n            except AIPerfError:\n                raise  # re-raise it up the stack\n\n            except Exception as e:\n                self.logger.error(\n                    \"Exception cleaning up ZMQ socket: %s (%s)\", e, self.client_id\n                )\n                raise CommunicationError(\n                    CommunicationErrorReason.CLEANUP_ERROR,\n                    f\"Failed to cleanup ZMQ socket: {e}\",\n                ) from e\n\n            # Wait for all tasks to complete\n            with contextlib.suppress(asyncio.CancelledError):\n                await asyncio.gather(*self.registered_tasks.values())\n\n            self.registered_tasks.clear()\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.is_initialized","title":"<code>is_initialized</code>  <code>property</code>","text":"<p>Check if the client is initialized.</p>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.is_shutdown","title":"<code>is_shutdown</code>  <code>property</code>","text":"<p>Check if the client is shutdown.</p>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.socket","title":"<code>socket</code>  <code>property</code>","text":"<p>Get the zmq socket for the client.</p> <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If the client is not initialized</p>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.socket_type_name","title":"<code>socket_type_name</code>  <code>property</code>","text":"<p>Get the name of the socket type.</p>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.__init__","title":"<code>__init__(context, socket_type, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Base class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_type</code> <code>SocketType</code> <p>The type of ZMQ socket (PUB or SUB).</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/base.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    socket_type: zmq.SocketType,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Base class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_type (SocketType): The type of ZMQ socket (PUB or SUB).\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    self.logger = logging.getLogger(__name__)\n    self.stop_event: asyncio.Event = asyncio.Event()\n    self.initialized_event: asyncio.Event = asyncio.Event()\n    self.context: zmq.asyncio.Context = context\n    self.address: str = address\n    self.bind: bool = bind\n    self.socket_type: zmq.SocketType = socket_type\n    self._socket: zmq.asyncio.Socket | None = None\n    self.socket_ops: dict = socket_ops or {}\n    self.client_id: str = f\"{self.socket_type.name}_client_{uuid.uuid4().hex[:8]}\"\n    super().__init__()\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.initialize","title":"<code>initialize()</code>  <code>async</code>","text":"<p>Initialize the communication.</p> <p>This method will: - Create the zmq socket - Bind or connect the socket to the address - Set the socket options - Run the AIPerfHook.ON_INIT hooks</p> Source code in <code>aiperf/common/comms/zmq/clients/base.py</code> <pre><code>async def initialize(self) -&gt; None:\n    \"\"\"Initialize the communication.\n\n    This method will:\n    - Create the zmq socket\n    - Bind or connect the socket to the address\n    - Set the socket options\n    - Run the AIPerfHook.ON_INIT hooks\n    \"\"\"\n    try:\n        self._socket = self.context.socket(self.socket_type)\n        if self.bind:\n            self.logger.debug(\n                \"ZMQ %s socket initialized and bound to %s (%s)\",\n                self.socket_type_name,\n                self.address,\n                self.client_id,\n            )\n            self._socket.bind(self.address)\n        else:\n            self.logger.debug(\n                \"ZMQ %s socket initialized and connected to %s (%s)\",\n                self.socket_type_name,\n                self.address,\n                self.client_id,\n            )\n            self._socket.connect(self.address)\n\n        # TODO: Make these easier to configure by an end user\n\n        # Use reasonable timeouts\n        self._socket.setsockopt(zmq.RCVTIMEO, 30000)  # 30 seconds\n        self._socket.setsockopt(zmq.SNDTIMEO, 30000)  # 30 seconds\n\n        # Add performance-oriented socket options\n        self._socket.setsockopt(zmq.TCP_KEEPALIVE, 1)\n        self._socket.setsockopt(zmq.TCP_KEEPALIVE_IDLE, 60)\n        self._socket.setsockopt(zmq.TCP_KEEPALIVE_INTVL, 10)\n        self._socket.setsockopt(zmq.TCP_KEEPALIVE_CNT, 3)\n        self._socket.setsockopt(zmq.IMMEDIATE, 1)  # Don't queue messages\n        self._socket.setsockopt(zmq.LINGER, 0)  # Don't wait on close\n\n        # Set additional socket options requested by the caller\n        for key, val in self.socket_ops.items():\n            self._socket.setsockopt(key, val)\n\n        await self.run_hooks(AIPerfHook.ON_INIT)\n\n        self.initialized_event.set()\n        self.logger.debug(\n            \"ZMQ %s socket initialized and connected to %s (%s)\",\n            self.socket_type_name,\n            self.address,\n            self.client_id,\n        )\n\n    except AIPerfError:\n        raise  # re-raise it up the stack\n    except Exception as e:\n        raise CommunicationError(\n            CommunicationErrorReason.INITIALIZATION_ERROR,\n            f\"Failed to initialize ZMQ socket: {e}\",\n        ) from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.base.BaseZMQClient.shutdown","title":"<code>shutdown()</code>  <code>async</code>","text":"<p>Shutdown the communication.</p> <p>This method will: - Close the zmq socket - Run the AIPerfHook.ON_CLEANUP hooks</p> Source code in <code>aiperf/common/comms/zmq/clients/base.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Shutdown the communication.\n\n    This method will:\n    - Close the zmq socket\n    - Run the AIPerfHook.ON_CLEANUP hooks\n    \"\"\"\n    if self.is_shutdown:\n        return\n\n    if not self.stop_event.is_set():\n        self.stop_event.set()\n\n    # Cancel all registered tasks\n    for task in self.registered_tasks.values():\n        task.cancel()\n\n    try:\n        if self._socket:\n            self._socket.close()\n            self.logger.debug(\n                \"ZMQ %s socket closed (%s)\", self.socket_type_name, self.client_id\n            )\n\n    except Exception as e:\n        self.logger.error(\n            \"Exception shutting down ZMQ socket: %s (%s)\", e, self.client_id\n        )\n        raise CommunicationError(\n            CommunicationErrorReason.SHUTDOWN_ERROR,\n            f\"Failed to shutdown ZMQ socket: {e}\",\n        ) from e\n\n    finally:\n        self._socket = None\n\n        try:\n            await self.run_hooks(AIPerfHook.ON_STOP)\n            await self.run_hooks(AIPerfHook.ON_CLEANUP)\n\n        except asyncio.CancelledError:\n            return\n\n        except AIPerfError:\n            raise  # re-raise it up the stack\n\n        except Exception as e:\n            self.logger.error(\n                \"Exception cleaning up ZMQ socket: %s (%s)\", e, self.client_id\n            )\n            raise CommunicationError(\n                CommunicationErrorReason.CLEANUP_ERROR,\n                f\"Failed to cleanup ZMQ socket: {e}\",\n            ) from e\n\n        # Wait for all tasks to complete\n        with contextlib.suppress(asyncio.CancelledError):\n            await asyncio.gather(*self.registered_tasks.values())\n\n        self.registered_tasks.clear()\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientsdealer_req","title":"aiperf.common.comms.zmq.clients.dealer_req","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.dealer_req.ZMQDealerReqClient","title":"<code>ZMQDealerReqClient</code>","text":"<p>               Bases: <code>BaseZMQClient</code></p> Source code in <code>aiperf/common/comms/zmq/clients/dealer_req.py</code> <pre><code>class ZMQDealerReqClient(BaseZMQClient):\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Dealer (Req) client class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        super().__init__(context, zmq.SocketType.DEALER, address, bind, socket_ops)\n\n    async def request(\n        self,\n        request_data: Message,\n    ) -&gt; Message:\n        \"\"\"Send a request and wait for a response.\n\n        Args:\n            request_data: Request data (must be a Message object)\n\n        Returns:\n            ResponseData object\n        \"\"\"\n        self._ensure_initialized()\n\n        # Generate request ID if not provided\n        if not request_data.request_id:\n            request_data.request_id = uuid.uuid4().hex\n\n        request_json = request_data.model_dump_json()\n\n        try:\n            # Send request\n            await self._socket.send_string(request_json)\n\n            # Wait for response with timeout\n            response_json = await self._socket.recv_string()\n            response = Message.from_json(response_json)\n            return response\n\n        except Exception as e:\n            raise CommunicationError(\n                CommunicationErrorReason.REQUEST_ERROR,\n                f\"Exception sending request: {e.__class__.__name__} {e}\",\n            ) from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.dealer_req.ZMQDealerReqClient.__init__","title":"<code>__init__(context, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Dealer (Req) client class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/dealer_req.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Dealer (Req) client class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    super().__init__(context, zmq.SocketType.DEALER, address, bind, socket_ops)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.dealer_req.ZMQDealerReqClient.request","title":"<code>request(request_data)</code>  <code>async</code>","text":"<p>Send a request and wait for a response.</p> <p>Parameters:</p> Name Type Description Default <code>request_data</code> <code>Message</code> <p>Request data (must be a Message object)</p> required <p>Returns:</p> Type Description <code>Message</code> <p>ResponseData object</p> Source code in <code>aiperf/common/comms/zmq/clients/dealer_req.py</code> <pre><code>async def request(\n    self,\n    request_data: Message,\n) -&gt; Message:\n    \"\"\"Send a request and wait for a response.\n\n    Args:\n        request_data: Request data (must be a Message object)\n\n    Returns:\n        ResponseData object\n    \"\"\"\n    self._ensure_initialized()\n\n    # Generate request ID if not provided\n    if not request_data.request_id:\n        request_data.request_id = uuid.uuid4().hex\n\n    request_json = request_data.model_dump_json()\n\n    try:\n        # Send request\n        await self._socket.send_string(request_json)\n\n        # Wait for response with timeout\n        response_json = await self._socket.recv_string()\n        response = Message.from_json(response_json)\n        return response\n\n    except Exception as e:\n        raise CommunicationError(\n            CommunicationErrorReason.REQUEST_ERROR,\n            f\"Exception sending request: {e.__class__.__name__} {e}\",\n        ) from e\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientspub","title":"aiperf.common.comms.zmq.clients.pub","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.pub.ZMQPubClient","title":"<code>ZMQPubClient</code>","text":"<p>               Bases: <code>BaseZMQClient</code></p> Source code in <code>aiperf/common/comms/zmq/clients/pub.py</code> <pre><code>class ZMQPubClient(BaseZMQClient):\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Publisher class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        super().__init__(context, zmq.SocketType.PUB, address, bind, socket_ops)\n\n    async def publish(self, topic: str, message: Message) -&gt; None:\n        \"\"\"Publish a message to a topic. Fairly straightforward, just dumps the message\n        and sends it over the socket.\n\n        Args:\n            topic: Topic to publish to\n            message: Message to publish (must be a Message object)\n\n        Raises:\n            CommunicationError: If the client is not initialized\n                or the message was not published successfully\n        \"\"\"\n        self._ensure_initialized()\n\n        try:\n            message_json = message.model_dump_json()\n\n            # Publish message\n            await self.socket.send_multipart([topic.encode(), message_json.encode()])\n\n        except Exception as e:\n            raise CommunicationError(\n                CommunicationErrorReason.PUBLISH_ERROR,\n                f\"Failed to publish message to topic {topic}: {e}\",\n            ) from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.pub.ZMQPubClient.__init__","title":"<code>__init__(context, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Publisher class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/pub.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Publisher class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    super().__init__(context, zmq.SocketType.PUB, address, bind, socket_ops)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.pub.ZMQPubClient.publish","title":"<code>publish(topic, message)</code>  <code>async</code>","text":"<p>Publish a message to a topic. Fairly straightforward, just dumps the message and sends it over the socket.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>str</code> <p>Topic to publish to</p> required <code>message</code> <code>Message</code> <p>Message to publish (must be a Message object)</p> required <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If the client is not initialized or the message was not published successfully</p> Source code in <code>aiperf/common/comms/zmq/clients/pub.py</code> <pre><code>async def publish(self, topic: str, message: Message) -&gt; None:\n    \"\"\"Publish a message to a topic. Fairly straightforward, just dumps the message\n    and sends it over the socket.\n\n    Args:\n        topic: Topic to publish to\n        message: Message to publish (must be a Message object)\n\n    Raises:\n        CommunicationError: If the client is not initialized\n            or the message was not published successfully\n    \"\"\"\n    self._ensure_initialized()\n\n    try:\n        message_json = message.model_dump_json()\n\n        # Publish message\n        await self.socket.send_multipart([topic.encode(), message_json.encode()])\n\n    except Exception as e:\n        raise CommunicationError(\n            CommunicationErrorReason.PUBLISH_ERROR,\n            f\"Failed to publish message to topic {topic}: {e}\",\n        ) from e\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientspull","title":"aiperf.common.comms.zmq.clients.pull","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.pull.ZMQPullClient","title":"<code>ZMQPullClient</code>","text":"<p>               Bases: <code>BaseZMQClient</code></p> Source code in <code>aiperf/common/comms/zmq/clients/pull.py</code> <pre><code>class ZMQPullClient(BaseZMQClient):\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Puller class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        super().__init__(context, zmq.SocketType.PULL, address, bind, socket_ops)\n        self._pull_callbacks: dict[\n            MessageType, list[Callable[[Message], Coroutine[Any, Any, None]]]\n        ] = {}\n\n    @aiperf_task\n    async def _pull_receiver(self) -&gt; None:\n        \"\"\"Background task for receiving data from the pull socket.\n\n        This method is a coroutine that will run indefinitely until the client is\n        shutdown. It will wait for messages from the socket and handle them.\n        \"\"\"\n        if not self.is_initialized:\n            await self.initialized_event.wait()\n\n        while not self.is_shutdown:\n            try:\n                message_json = await self.socket.recv_string()\n                logger.debug(\"Received message from pull socket: %s\", message_json)\n                _ = asyncio.create_task(self._process_message(message_json))\n\n            except zmq.Again:\n                pass\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(\n                    \"Exception receiving data from pull socket: %s %s\",\n                    type(e).__name__,\n                    e,\n                )\n                await asyncio.sleep(0.1)\n\n    async def _process_message(self, message_json: str) -&gt; None:\n        \"\"\"Process a message from the pull socket.\n\n        This method is called by the background task when a message is received from\n        the pull socket. It will deserialize the message and call the appropriate\n        callback function.\n        \"\"\"\n        message = Message.from_json(message_json)\n\n        # Call callbacks with Message object\n        if message.message_type in self._pull_callbacks:\n            _ = asyncio.create_task(\n                call_all_functions(self._pull_callbacks[message.message_type], message)\n            )\n        else:\n            logger.debug(\n                \"Pull message received on topic without callback %s\",\n                message.message_type,\n            )\n\n    async def register_pull_callback(\n        self,\n        message_type: MessageType,\n        callback: Callable[[Message], Coroutine[Any, Any, None]],\n    ) -&gt; None:\n        \"\"\"Register a ZMQ Pull data callback for a given message type.\n\n        Note that more than one callback can be registered for a given message type.\n\n        Args:\n            message_type: The message type to register the callback for.\n            callback: The function to call when data is received.\n\n        Raises:\n            CommunicationError: If the client is not initialized\n        \"\"\"\n        self._ensure_initialized()\n\n        # Register callback\n        if message_type not in self._pull_callbacks:\n            self._pull_callbacks[message_type] = []\n        self._pull_callbacks[message_type].append(callback)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.pull.ZMQPullClient.__init__","title":"<code>__init__(context, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Puller class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/pull.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Puller class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    super().__init__(context, zmq.SocketType.PULL, address, bind, socket_ops)\n    self._pull_callbacks: dict[\n        MessageType, list[Callable[[Message], Coroutine[Any, Any, None]]]\n    ] = {}\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.pull.ZMQPullClient.register_pull_callback","title":"<code>register_pull_callback(message_type, callback)</code>  <code>async</code>","text":"<p>Register a ZMQ Pull data callback for a given message type.</p> <p>Note that more than one callback can be registered for a given message type.</p> <p>Parameters:</p> Name Type Description Default <code>message_type</code> <code>MessageType</code> <p>The message type to register the callback for.</p> required <code>callback</code> <code>Callable[[Message], Coroutine[Any, Any, None]]</code> <p>The function to call when data is received.</p> required <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If the client is not initialized</p> Source code in <code>aiperf/common/comms/zmq/clients/pull.py</code> <pre><code>async def register_pull_callback(\n    self,\n    message_type: MessageType,\n    callback: Callable[[Message], Coroutine[Any, Any, None]],\n) -&gt; None:\n    \"\"\"Register a ZMQ Pull data callback for a given message type.\n\n    Note that more than one callback can be registered for a given message type.\n\n    Args:\n        message_type: The message type to register the callback for.\n        callback: The function to call when data is received.\n\n    Raises:\n        CommunicationError: If the client is not initialized\n    \"\"\"\n    self._ensure_initialized()\n\n    # Register callback\n    if message_type not in self._pull_callbacks:\n        self._pull_callbacks[message_type] = []\n    self._pull_callbacks[message_type].append(callback)\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientspush","title":"aiperf.common.comms.zmq.clients.push","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.push.ZMQPushClient","title":"<code>ZMQPushClient</code>","text":"<p>               Bases: <code>BaseZMQClient</code></p> Source code in <code>aiperf/common/comms/zmq/clients/push.py</code> <pre><code>class ZMQPushClient(BaseZMQClient):\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Pusher class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        super().__init__(context, zmq.SocketType.PUSH, address, bind, socket_ops)\n\n    async def push(self, message: Message) -&gt; None:\n        \"\"\"Push data to a target.\n\n        Args:\n            message: Message to be sent must be a Message object\n\n        Raises:\n            CommunicationError: If the client is not initialized\n                or the data was not pushed successfully\n        \"\"\"\n        self._ensure_initialized()\n\n        try:\n            # Serialize data directly using Pydantic's built-in method\n            data_json = message.model_dump_json()\n\n            # Send data\n            await self.socket.send_string(data_json)\n            logger.debug(\"Pushed json data: %s\", data_json)\n\n        except zmq.Again:\n            # Queue is full, yield control briefly and retry pushing the message.\n            await asyncio.sleep(0.1)\n            await self.push(message)\n\n        except Exception as e:\n            raise CommunicationError(\n                CommunicationErrorReason.PUSH_ERROR, f\"Failed to push data: {e}\"\n            ) from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.push.ZMQPushClient.__init__","title":"<code>__init__(context, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Pusher class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/push.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Pusher class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    super().__init__(context, zmq.SocketType.PUSH, address, bind, socket_ops)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.push.ZMQPushClient.push","title":"<code>push(message)</code>  <code>async</code>","text":"<p>Push data to a target.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>Message to be sent must be a Message object</p> required <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If the client is not initialized or the data was not pushed successfully</p> Source code in <code>aiperf/common/comms/zmq/clients/push.py</code> <pre><code>async def push(self, message: Message) -&gt; None:\n    \"\"\"Push data to a target.\n\n    Args:\n        message: Message to be sent must be a Message object\n\n    Raises:\n        CommunicationError: If the client is not initialized\n            or the data was not pushed successfully\n    \"\"\"\n    self._ensure_initialized()\n\n    try:\n        # Serialize data directly using Pydantic's built-in method\n        data_json = message.model_dump_json()\n\n        # Send data\n        await self.socket.send_string(data_json)\n        logger.debug(\"Pushed json data: %s\", data_json)\n\n    except zmq.Again:\n        # Queue is full, yield control briefly and retry pushing the message.\n        await asyncio.sleep(0.1)\n        await self.push(message)\n\n    except Exception as e:\n        raise CommunicationError(\n            CommunicationErrorReason.PUSH_ERROR, f\"Failed to push data: {e}\"\n        ) from e\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientsrouter_rep","title":"aiperf.common.comms.zmq.clients.router_rep","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.router_rep.ZMQRouterRepClient","title":"<code>ZMQRouterRepClient</code>","text":"<p>               Bases: <code>BaseZMQClient</code></p> Source code in <code>aiperf/common/comms/zmq/clients/router_rep.py</code> <pre><code>class ZMQRouterRepClient(BaseZMQClient):\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Router (Rep) client class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        super().__init__(context, zmq.SocketType.ROUTER, address, bind, socket_ops)\n\n        self._request_handlers: dict[\n            MessageType,\n            tuple[str, Callable[[Message], Coroutine[Any, Any, Message | None]]],\n        ] = {}\n        self._response_futures: dict[str, asyncio.Future[Message | None]] = {}\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        self._request_handlers.clear()\n\n    def register_request_handler(\n        self,\n        service_id: str,\n        message_type: MessageType,\n        handler: Callable[[Message], Coroutine[Any, Any, Message | None]],\n    ) -&gt; None:\n        \"\"\"Register a request handler. Anytime a request is received that matches the\n        message type, the handler will be called. The handler should return a response\n        message. If the handler returns None, the request will be ignored.\n\n        Note that there is a limit of 1 to 1 mapping between message type and handler.\n\n        Args:\n            service_id: The service ID to register the handler for\n            message_type: The message type to register the handler for\n            handler: The handler to register\n        \"\"\"\n        self._request_handlers[message_type] = (service_id, handler)\n\n    async def _handle_request(self, request_id: str, request_json: str) -&gt; None:\n        \"\"\"Handle a request.\n\n        This method will:\n        - Parse the request JSON to create a RequestData object\n        - Call the handler for the message type\n        - Set the response future\n        \"\"\"\n        request: Message = Message.from_json(request_json)\n        message_type = request.message_type\n\n        try:\n            _, handler = self._request_handlers[message_type]\n            response = await handler(request)\n\n        except Exception as e:\n            self.logger.error(\"Exception calling handler for %s: %s\", message_type, e)\n            response = ErrorMessage(\n                request_id=request.request_id,\n                error=str(e),\n            )\n\n        self._response_futures[request_id].set_result(response)\n\n    @aiperf_task\n    async def _rep_router_receiver(self) -&gt; None:\n        \"\"\"Background task for receiving requests and sending responses.\n\n        This method is a coroutine that will run indefinitely until the client is\n        shutdown. It will wait for requests from the socket and send responses in\n        an asynchronous manner.\n        \"\"\"\n        if not self.is_initialized:\n            await self.initialized_event.wait()\n\n        while not self.is_shutdown:\n            try:\n                # Receive request\n                try:\n                    request_id, request_json = await self.socket.recv_multipart()\n                except zmq.Again:\n                    # This means we timed out waiting for a request.\n                    # We can continue to the next iteration of the loop.\n                    continue\n\n                # Create a new response future for this request that will be resolved\n                # when the handler returns a response.\n                self._response_futures[request_id] = asyncio.Future()\n\n                # Handle the request in a new task.\n                asyncio.create_task(self._handle_request(request_id, request_json))\n\n                # Wait for the response asynchronously.\n                response = await self._response_futures[request_id]\n                if response is not None:\n                    # Send the response back to the client.\n                    await self.socket.send_multipart(\n                        [request_id, response.model_dump_json().encode()]\n                    )\n                else:\n                    # If the response is None, we send an error message back to the client.\n                    self.logger.warning(\"No response for request %s\", request_id)\n                    await self.socket.send_multipart([request_id, b\"ERROR\"])\n\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                self.logger.error(\"Exception receiving request: %s\", e)\n                await asyncio.sleep(0.1)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.router_rep.ZMQRouterRepClient.__init__","title":"<code>__init__(context, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Router (Rep) client class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/router_rep.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Router (Rep) client class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    super().__init__(context, zmq.SocketType.ROUTER, address, bind, socket_ops)\n\n    self._request_handlers: dict[\n        MessageType,\n        tuple[str, Callable[[Message], Coroutine[Any, Any, Message | None]]],\n    ] = {}\n    self._response_futures: dict[str, asyncio.Future[Message | None]] = {}\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.router_rep.ZMQRouterRepClient.register_request_handler","title":"<code>register_request_handler(service_id, message_type, handler)</code>","text":"<p>Register a request handler. Anytime a request is received that matches the message type, the handler will be called. The handler should return a response message. If the handler returns None, the request will be ignored.</p> <p>Note that there is a limit of 1 to 1 mapping between message type and handler.</p> <p>Parameters:</p> Name Type Description Default <code>service_id</code> <code>str</code> <p>The service ID to register the handler for</p> required <code>message_type</code> <code>MessageType</code> <p>The message type to register the handler for</p> required <code>handler</code> <code>Callable[[Message], Coroutine[Any, Any, Message | None]]</code> <p>The handler to register</p> required Source code in <code>aiperf/common/comms/zmq/clients/router_rep.py</code> <pre><code>def register_request_handler(\n    self,\n    service_id: str,\n    message_type: MessageType,\n    handler: Callable[[Message], Coroutine[Any, Any, Message | None]],\n) -&gt; None:\n    \"\"\"Register a request handler. Anytime a request is received that matches the\n    message type, the handler will be called. The handler should return a response\n    message. If the handler returns None, the request will be ignored.\n\n    Note that there is a limit of 1 to 1 mapping between message type and handler.\n\n    Args:\n        service_id: The service ID to register the handler for\n        message_type: The message type to register the handler for\n        handler: The handler to register\n    \"\"\"\n    self._request_handlers[message_type] = (service_id, handler)\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqclientssub","title":"aiperf.common.comms.zmq.clients.sub","text":""},{"location":"api/#aiperf.common.comms.zmq.clients.sub.ZMQSubClient","title":"<code>ZMQSubClient</code>","text":"<p>               Bases: <code>BaseZMQClient</code></p> Source code in <code>aiperf/common/comms/zmq/clients/sub.py</code> <pre><code>class ZMQSubClient(BaseZMQClient):\n    def __init__(\n        self,\n        context: zmq.asyncio.Context,\n        address: str,\n        bind: bool,\n        socket_ops: dict | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ZMQ Subscriber class.\n\n        Args:\n            context (zmq.asyncio.Context): The ZMQ context.\n            address (str): The address to bind or connect to.\n            bind (bool): Whether to bind or connect the socket.\n            socket_ops (dict, optional): Additional socket options to set.\n        \"\"\"\n        super().__init__(context, zmq.SocketType.SUB, address, bind, socket_ops)\n        self._subscribers: dict[str, list[Callable[[Message], Any]]] = {}\n\n    async def subscribe(self, topic: str, callback: Callable[[Message], Any]) -&gt; None:\n        \"\"\"Subscribe to a topic.\n\n        Args:\n            topic: Topic to subscribe to\n            callback: Function to call when a message is received (receives Message object)\n\n        Raises:\n            Exception if subscription was not successful, None otherwise\n        \"\"\"\n        self._ensure_initialized()\n\n        try:\n            # Subscribe to topic\n            self.socket.subscribe(topic.encode())\n\n            # Register callback\n            if topic not in self._subscribers:\n                self._subscribers[topic] = []\n            self._subscribers[topic].append(callback)\n\n            self.logger.debug(\n                \"Subscribed to topic: %s, %s\", topic, self._subscribers[topic]\n            )\n\n        except Exception as e:\n            self.logger.error(\"Exception subscribing to topic %s: %s\", topic, e)\n            raise CommunicationError(\n                CommunicationErrorReason.SUBSCRIBE_ERROR,\n                f\"Failed to subscribe to topic {topic}: {e}\",\n            ) from e\n\n    async def _handle_message(self, topic_bytes: bytes, message_bytes: bytes) -&gt; None:\n        \"\"\"Handle a message from a subscribed topic.\"\"\"\n        topic = topic_bytes.decode()\n        message_json = message_bytes.decode()\n        self.logger.debug(\n            \"Received message from topic: '%s', message: %s\",\n            topic,\n            message_json,\n        )\n\n        message = Message.from_json(message_json)\n\n        # Call callbacks with the parsed message object\n        if topic in self._subscribers:\n            await call_all_functions(self._subscribers[topic], message)\n\n    @aiperf_task\n    async def _sub_receiver(self) -&gt; None:\n        \"\"\"Background task for receiving messages from subscribed topics.\n\n        This method is a coroutine that will run indefinitely until the client is\n        shutdown. It will wait for messages from the socket and handle them.\n        \"\"\"\n        if not self.is_initialized:\n            self.logger.debug(\n                \"Sub client %s waiting for initialization\", self.client_id\n            )\n            await self.initialized_event.wait()\n            self.logger.debug(\"Sub client %s initialized\", self.client_id)\n\n        while not self.is_shutdown:\n            try:\n                # Receive message\n                (\n                    topic_bytes,\n                    message_bytes,\n                ) = await self.socket.recv_multipart()\n                asyncio.create_task(self._handle_message(topic_bytes, message_bytes))\n\n            except asyncio.CancelledError:\n                break\n            except zmq.Again:\n                # Handle ZMQ timeout or interruption\n                self.logger.debug(\n                    \"ZMQ recv timeout due to no messages. trying again @ %s\",\n                    self.address,\n                )\n                await asyncio.sleep(0.001)\n            except Exception as e:\n                self.logger.error(\n                    \"Exception receiving message from subscription: %s, %s\",\n                    e,\n                    type(e),\n                )\n                await asyncio.sleep(0.1)\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.sub.ZMQSubClient.__init__","title":"<code>__init__(context, address, bind, socket_ops=None)</code>","text":"<p>Initialize the ZMQ Subscriber class.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>The ZMQ context.</p> required <code>address</code> <code>str</code> <p>The address to bind or connect to.</p> required <code>bind</code> <code>bool</code> <p>Whether to bind or connect the socket.</p> required <code>socket_ops</code> <code>dict</code> <p>Additional socket options to set.</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/clients/sub.py</code> <pre><code>def __init__(\n    self,\n    context: zmq.asyncio.Context,\n    address: str,\n    bind: bool,\n    socket_ops: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ZMQ Subscriber class.\n\n    Args:\n        context (zmq.asyncio.Context): The ZMQ context.\n        address (str): The address to bind or connect to.\n        bind (bool): Whether to bind or connect the socket.\n        socket_ops (dict, optional): Additional socket options to set.\n    \"\"\"\n    super().__init__(context, zmq.SocketType.SUB, address, bind, socket_ops)\n    self._subscribers: dict[str, list[Callable[[Message], Any]]] = {}\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.clients.sub.ZMQSubClient.subscribe","title":"<code>subscribe(topic, callback)</code>  <code>async</code>","text":"<p>Subscribe to a topic.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>str</code> <p>Topic to subscribe to</p> required <code>callback</code> <code>Callable[[Message], Any]</code> <p>Function to call when a message is received (receives Message object)</p> required Source code in <code>aiperf/common/comms/zmq/clients/sub.py</code> <pre><code>async def subscribe(self, topic: str, callback: Callable[[Message], Any]) -&gt; None:\n    \"\"\"Subscribe to a topic.\n\n    Args:\n        topic: Topic to subscribe to\n        callback: Function to call when a message is received (receives Message object)\n\n    Raises:\n        Exception if subscription was not successful, None otherwise\n    \"\"\"\n    self._ensure_initialized()\n\n    try:\n        # Subscribe to topic\n        self.socket.subscribe(topic.encode())\n\n        # Register callback\n        if topic not in self._subscribers:\n            self._subscribers[topic] = []\n        self._subscribers[topic].append(callback)\n\n        self.logger.debug(\n            \"Subscribed to topic: %s, %s\", topic, self._subscribers[topic]\n        )\n\n    except Exception as e:\n        self.logger.error(\"Exception subscribing to topic %s: %s\", topic, e)\n        raise CommunicationError(\n            CommunicationErrorReason.SUBSCRIBE_ERROR,\n            f\"Failed to subscribe to topic {topic}: {e}\",\n        ) from e\n</code></pre>"},{"location":"api/#aiperfcommoncommszmqzmq_comms","title":"aiperf.common.comms.zmq.zmq_comms","text":""},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication","title":"<code>BaseZMQCommunication</code>","text":"<p>               Bases: <code>BaseCommunication</code>, <code>ABC</code></p> <p>ZeroMQ-based implementation of the Communication interface.</p> <p>Uses ZeroMQ for publish/subscribe and request/reply patterns to facilitate communication between AIPerf components.</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>class BaseZMQCommunication(BaseCommunication, ABC):\n    \"\"\"ZeroMQ-based implementation of the Communication interface.\n\n    Uses ZeroMQ for publish/subscribe and request/reply patterns to\n    facilitate communication between AIPerf components.\n    \"\"\"\n\n    def __init__(\n        self,\n        config: BaseZMQCommunicationConfig | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize ZMQ communication.\n\n        Args:\n            config: ZMQCommunicationConfig object with configuration parameters\n        \"\"\"\n        self.stop_event: asyncio.Event = asyncio.Event()\n        self.initialized_event: asyncio.Event = asyncio.Event()\n        self.config = config or ZMQIPCConfig()\n\n        self._context: zmq.asyncio.Context | None = None\n        self.clients: dict[ClientType, ZMQClient] = {}\n\n        logger.debug(\n            \"ZMQ communication using protocol: %s\",\n            type(self.config).__name__,\n        )\n\n    @property\n    def context(self) -&gt; zmq.asyncio.Context:\n        \"\"\"Get the ZeroMQ context.\n\n        Returns:\n            ZeroMQ context\n        \"\"\"\n        if not self._context:\n            raise CommunicationError(\n                CommunicationErrorReason.INITIALIZATION_ERROR,\n                \"Communication channels are not initialized\",\n            )\n        return self._context\n\n    @property\n    def is_initialized(self) -&gt; bool:\n        \"\"\"Check if communication channels are initialized.\n\n        Returns:\n            True if communication channels are initialized, False otherwise\n        \"\"\"\n        return self.initialized_event.is_set()\n\n    @property\n    def is_shutdown(self) -&gt; bool:\n        \"\"\"Check if communication channels are shutdown.\n\n        Returns:\n            True if communication channels are shutdown, False otherwise\n        \"\"\"\n        return self.stop_event.is_set()\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize communication channels.\n\n        Returns:\n            True if initialization was successful, False otherwise\n        \"\"\"\n        if self.is_initialized:\n            return\n\n        # Increase the number of IO threads to 2\n        self._context = zmq.asyncio.Context(io_threads=2)\n        self.initialized_event.set()\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Gracefully shutdown communication channels.\n\n        This method will wait for all clients to shutdown before shutting down\n        the context.\n\n        Returns:\n            True if shutdown was successful, False otherwise\n        \"\"\"\n        if self.is_shutdown:\n            return\n\n        try:\n            if not self.stop_event.is_set():\n                self.stop_event.set()\n\n            await asyncio.gather(\n                *(client.shutdown() for client in self.clients.values())\n            )\n\n            if self.context:\n                self.context.term()\n\n            self._context = None\n\n        except asyncio.CancelledError:\n            pass\n\n        except Exception as e:\n            raise CommunicationError(\n                CommunicationErrorReason.SHUTDOWN_ERROR,\n                \"Failed to shutdown ZMQ communication\",\n            ) from e\n\n        finally:\n            self.clients = {}\n            self._context = None\n\n    def _ensure_initialized(self) -&gt; None:\n        \"\"\"Ensure the communication channels are initialized.\n\n        Raises:\n            CommunicationError: If the communication channels are not initialized\n                or shutdown\n            asyncio.CancelledError: If the communication channels are shutdown\n        \"\"\"\n        if not self.is_initialized:\n            raise CommunicationError(\n                CommunicationErrorReason.INITIALIZATION_ERROR,\n                \"Communication channels are not initialized\",\n            )\n        if self.is_shutdown:\n            raise asyncio.CancelledError()\n\n    def _create_pub_client(self, client_type: PubClientType) -&gt; ZMQPubClient:\n        \"\"\"Create a ZMQ publisher client based on the client type.\n\n        Args:\n            client_type: The type of client to create\n\n        Returns:\n            ZMQPubClient instance\n\n        Raises:\n            CommunicationError: If the client type is invalid\n        \"\"\"\n        match client_type:\n            case PubClientType.CONTROLLER:\n                return ZMQPubClient(\n                    self.context,\n                    self.config.controller_pub_sub_address,\n                    bind=True,\n                )\n\n            case PubClientType.COMPONENT:\n                return ZMQPubClient(\n                    self.context,\n                    self.config.component_pub_sub_address,\n                    bind=False,\n                )\n\n            case _:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"Invalid client type: {client_type}\",\n                )\n\n    def _create_sub_client(self, client_type: SubClientType) -&gt; ZMQSubClient:\n        \"\"\"Create a ZMQ subscriber client based on the client type.\n\n        Args:\n            client_type: The type of client to create\n\n        Returns:\n            ZMQSubClient instance\n\n        Raises:\n            CommunicationError: If the client type is invalid\n        \"\"\"\n        match client_type:\n            case SubClientType.CONTROLLER:\n                return ZMQSubClient(\n                    self.context,\n                    self.config.controller_pub_sub_address,\n                    bind=False,\n                )\n\n            case SubClientType.COMPONENT:\n                return ZMQSubClient(\n                    self.context,\n                    self.config.component_pub_sub_address,\n                    bind=True,\n                )\n\n            case _:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"Invalid client type: {client_type}\",\n                )\n\n    def _create_push_client(self, client_type: PushClientType) -&gt; ZMQPushClient:\n        \"\"\"Create a ZMQ push client based on the client type.\n\n        Args:\n            client_type: The type of client to create\n\n        Returns:\n            ZMQPushClient instance\n\n        Raises:\n            CommunicationError: If the client type is invalid\n        \"\"\"\n        match client_type:\n            case PushClientType.INFERENCE_RESULTS:\n                return ZMQPushClient(\n                    self.context,\n                    self.config.inference_push_pull_address,\n                    bind=False,  # Workers are the pushers\n                    socket_ops={zmq.SNDHWM: 0},  # Unlimited send queue\n                )\n\n            case PushClientType.CREDIT_DROP:\n                return ZMQPushClient(\n                    self.context,\n                    self.config.credit_drop_address,\n                    bind=True,\n                )\n\n            case PushClientType.CREDIT_RETURN:\n                return ZMQPushClient(\n                    self.context,\n                    self.config.credit_return_address,\n                    bind=False,\n                )\n\n            case _:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"Invalid client type: {client_type}\",\n                )\n\n    def _create_pull_client(self, client_type: PullClientType) -&gt; ZMQPullClient:\n        \"\"\"Create a ZMQ pull client based on the client type.\n\n        Args:\n            client_type: The type of client to create\n\n        Returns:\n            ZMQPullClient instance\n\n        Raises:\n            CommunicationError: If the client type is invalid\n        \"\"\"\n        match client_type:\n            case PullClientType.INFERENCE_RESULTS:\n                return ZMQPullClient(\n                    self.context,\n                    self.config.inference_push_pull_address,\n                    bind=True,  # Records manager is the pull\n                    socket_ops={\n                        zmq.RCVBUF: 1024 * 1024 * 32,  # 1GB OS buffer\n                        zmq.RCVHWM: 0,  # Unlimited ZMQ queue\n                    },\n                )\n\n            case PullClientType.CREDIT_DROP:\n                return ZMQPullClient(\n                    self.context,\n                    self.config.credit_drop_address,\n                    bind=False,\n                )\n\n            case PullClientType.CREDIT_RETURN:\n                return ZMQPullClient(\n                    self.context,\n                    self.config.credit_return_address,\n                    bind=True,\n                )\n\n            case _:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"Invalid client type: {client_type}\",\n                )\n\n    def _create_req_client(self, client_type: ReqClientType) -&gt; ZMQDealerReqClient:\n        \"\"\"Create a ZMQ request client based on the client type.\n\n        Args:\n            client_type: The type of client to create\n\n        Returns:\n            ZMQReqClient instance\n\n        Raises:\n            CommunicationError: If the client type is invalid\n        \"\"\"\n        match client_type:\n            case ReqClientType.CONVERSATION_DATA:\n                return ZMQDealerReqClient(\n                    self.context,\n                    self.config.conversation_data_address,\n                    bind=False,  # Worker manager is the request\n                )\n            case _:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"Invalid client type: {client_type}\",\n                )\n\n    def _create_rep_client(self, client_type: RepClientType) -&gt; ZMQRouterRepClient:\n        \"\"\"Create a ZMQ reply client based on the client type.\n\n        Args:\n            client_type: The type of client to create\n\n        Returns:\n            ZMQRepClient instance\n\n        Raises:\n            CommunicationError: If the client type is invalid\n        \"\"\"\n        match client_type:\n            case RepClientType.CONVERSATION_DATA:\n                return ZMQRouterRepClient(\n                    self.context,\n                    self.config.conversation_data_address,\n                    bind=True,  # Data manager is the reply\n                )\n\n            case _:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"Invalid client type: {client_type}\",\n                )\n\n    async def create_clients(self, *types: ClientType) -&gt; None:\n        \"\"\"Create and initialize ZMQ clients based on the client types.\n\n        Args:\n            types: List of ClientType enums indicating the types of clients to\n            create and initialize\n\n        Raises:\n            CommunicationError: If the clients were not created\n                successfully\n        \"\"\"\n\n        for client_type in types:\n            if client_type in self.clients:\n                continue\n\n            if isinstance(client_type, PubClientType):\n                client = self._create_pub_client(client_type)\n\n            elif isinstance(client_type, SubClientType):\n                client = self._create_sub_client(client_type)\n\n            elif isinstance(client_type, PushClientType):\n                client = self._create_push_client(client_type)\n\n            elif isinstance(client_type, PullClientType):\n                client = self._create_pull_client(client_type)\n\n            elif isinstance(client_type, ReqClientType):\n                client = self._create_req_client(client_type)\n\n            elif isinstance(client_type, RepClientType):\n                client = self._create_rep_client(client_type)\n\n            else:\n                raise CommunicationError(\n                    CommunicationErrorReason.CLIENT_NOT_FOUND,\n                    f\"Invalid client type: {client_type}\",\n                )\n\n            await client.initialize()\n\n            self.clients[client_type] = client\n\n    async def publish(self, topic: Topic, message: Message) -&gt; None:\n        \"\"\"Publish a message to a topic. If the client type is not found, it will\n        be created.\n\n        Args:\n            topic: The topic to publish the message to\n            message: The message to publish\n\n        Raises:\n            CommunicationError: If the message was not published successfully\n        \"\"\"\n\n        self._ensure_initialized()\n        client_type = PubClientType.from_topic(topic)\n\n        if client_type not in self.clients:\n            logger.debug(\n                \"Client type %r not found for pub topic %r, creating client\",\n                client_type,\n                topic,\n            )\n            await self.create_clients(client_type)\n\n        try:\n            await cast(ZMQPubClient, self.clients[client_type]).publish(topic, message)\n        except Exception as e:\n            logger.error(\n                \"Exception publishing message to topic: %s, message: %s, error: %s\",\n                topic,\n                message,\n                e,\n            )\n            raise CommunicationError(\n                CommunicationErrorReason.PUBLISH_ERROR,\n                f\"Failed to publish message to topic: {topic}, message: {message}, error: {e}\",\n            ) from e\n\n    async def subscribe(\n        self,\n        topic: Topic,\n        callback: Callable[[Message], Coroutine[Any, Any, None]],\n    ) -&gt; None:\n        \"\"\"Subscribe to a topic. If the proper ZMQ client type is not found, it\n        will be created.\n\n        Args:\n            topic: The topic to subscribe to\n            callback: The callback to call when a message is received\n\n        Raises:\n            CommunicationError: If there was an error subscribing to the\n                topic, or if the communication channels are not initialized\n                or shutdown\n        \"\"\"\n\n        self._ensure_initialized()\n\n        client_type = SubClientType.from_topic(topic)\n\n        if client_type not in self.clients:\n            logger.debug(\n                \"Client type %r not found for sub topic %r, creating client\",\n                client_type,\n                topic,\n            )\n            await self.create_clients(client_type)\n\n        try:\n            await cast(ZMQSubClient, self.clients[client_type]).subscribe(\n                topic, callback\n            )\n        except Exception as e:\n            logger.error(f\"Exception subscribing to topic: {e}\")\n            raise CommunicationError(\n                CommunicationErrorReason.SUBSCRIBE_ERROR,\n                f\"Failed to subscribe to topic: {topic}, error: {e}\",\n            ) from e\n\n    async def request(\n        self,\n        topic: Topic,\n        message: Message,\n    ) -&gt; Message:\n        \"\"\"Request a message from a target. If the proper ZMQ client type is not\n        found, it will be created.\n\n        Args:\n            topic: The topic to request from\n            message: The message to request\n\n        Returns:\n            The response from the target\n\n        Raises:\n            CommunicationError: If there was an error requesting from the\n                target, or if the communication channels are not initialized\n                or shutdown\n        \"\"\"\n\n        self._ensure_initialized()\n\n        client_type = ReqClientType.from_topic(topic)\n\n        if client_type not in self.clients:\n            logger.debug(\n                \"Client type %r not found for req topic %r, creating client\",\n                client_type,\n                topic,\n            )\n            await self.create_clients(client_type)\n\n        try:\n            return await cast(ZMQDealerReqClient, self.clients[client_type]).request(\n                message\n            )\n        except Exception as e:\n            logger.error(f\"Exception requesting from {topic}: {e}\")\n            raise CommunicationError(\n                CommunicationErrorReason.REQUEST_ERROR,\n                f\"Failed to request from topic: {topic}, error: {e}\",\n            ) from e\n\n    async def register_request_handler(\n        self,\n        service_id: str,\n        topic: Topic,\n        message_type: MessageType,\n        handler: Callable[[Message], Coroutine[Any, Any, Message | None]],\n    ) -&gt; None:\n        \"\"\"Register a request handler for a topic.\n\n        Args:\n            service_id: The service ID to register the handler for\n            topic: The topic to register the handler for\n            message_type: The message type to register the handler for\n            handler: The handler to register\n        \"\"\"\n\n        self._ensure_initialized()\n\n        client_type = RepClientType.from_topic(topic)\n\n        if client_type not in self.clients:\n            logger.debug(\n                \"Client type %r not found for req topic %r, creating client\",\n                client_type,\n                topic,\n            )\n            await self.create_clients(client_type)\n\n        try:\n            cast(\n                ZMQRouterRepClient, self.clients[client_type]\n            ).register_request_handler(service_id, message_type, handler)\n        except Exception as e:\n            logger.error(f\"Exception registering request handler for {topic}: {e}\")\n            raise CommunicationError(\n                CommunicationErrorReason.REQUEST_ERROR,\n                f\"Failed to register request handler for topic: {topic}, error: {e}\",\n            ) from e\n\n    async def push(self, topic: Topic, message: Message) -&gt; None:\n        \"\"\"Push a message to a topic. If the proper ZMQ client type is not found,\n        it will be created.\n\n        Args:\n            topic: The topic to push the message to\n            message: The message to push\n\n        Raises:\n            CommunicationError: If there was an error pushing the message, or if the\n                communication channels are not initialized or shutdown\n        \"\"\"\n\n        self._ensure_initialized()\n\n        client_type = PushClientType.from_topic(topic)\n\n        if client_type not in self.clients:\n            logger.debug(\n                \"Client type %r not found for push, creating client\",\n                client_type,\n            )\n            await self.create_clients(client_type)\n\n        try:\n            await cast(ZMQPushClient, self.clients[client_type]).push(message)\n        except Exception as e:\n            logger.error(f\"Exception pushing data: {e}\")\n            raise CommunicationError(\n                CommunicationErrorReason.PUSH_ERROR,\n                f\"Failed to push data to topic: {topic}, error: {e}\",\n            ) from e\n\n    async def register_pull_callback(\n        self,\n        message_type: MessageType,\n        callback: Callable[[Message], Coroutine[Any, Any, None]],\n    ) -&gt; None:\n        \"\"\"Register a callback for a pull client.\n\n        Args:\n            message_type: The message type to register the callback for\n            callback: The callback to register\n\n        Raises:\n            CommunicationError: If there was an error registering the callback, or if\n                the communication channels are not initialized\n        \"\"\"\n\n        logger.debug(f\"Pulling data for {message_type}\")\n\n        self._ensure_initialized()\n\n        client_type = PullClientType.from_message_type(message_type)\n\n        if client_type not in self.clients:\n            logger.debug(\n                \"Client type %r not found for pull, creating client\",\n                client_type,\n            )\n            await self.create_clients(client_type)\n\n        # Only adds to the callback list, does not block, and does not raise an exception\n        await cast(ZMQPullClient, self.clients[client_type]).register_pull_callback(\n            message_type, callback\n        )\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.context","title":"<code>context</code>  <code>property</code>","text":"<p>Get the ZeroMQ context.</p> <p>Returns:</p> Type Description <code>Context</code> <p>ZeroMQ context</p>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.is_initialized","title":"<code>is_initialized</code>  <code>property</code>","text":"<p>Check if communication channels are initialized.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if communication channels are initialized, False otherwise</p>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.is_shutdown","title":"<code>is_shutdown</code>  <code>property</code>","text":"<p>Check if communication channels are shutdown.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if communication channels are shutdown, False otherwise</p>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.__init__","title":"<code>__init__(config=None)</code>","text":"<p>Initialize ZMQ communication.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>BaseZMQCommunicationConfig | None</code> <p>ZMQCommunicationConfig object with configuration parameters</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>def __init__(\n    self,\n    config: BaseZMQCommunicationConfig | None = None,\n) -&gt; None:\n    \"\"\"Initialize ZMQ communication.\n\n    Args:\n        config: ZMQCommunicationConfig object with configuration parameters\n    \"\"\"\n    self.stop_event: asyncio.Event = asyncio.Event()\n    self.initialized_event: asyncio.Event = asyncio.Event()\n    self.config = config or ZMQIPCConfig()\n\n    self._context: zmq.asyncio.Context | None = None\n    self.clients: dict[ClientType, ZMQClient] = {}\n\n    logger.debug(\n        \"ZMQ communication using protocol: %s\",\n        type(self.config).__name__,\n    )\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.create_clients","title":"<code>create_clients(*types)</code>  <code>async</code>","text":"<p>Create and initialize ZMQ clients based on the client types.</p> <p>Parameters:</p> Name Type Description Default <code>types</code> <code>ClientType</code> <p>List of ClientType enums indicating the types of clients to</p> <code>()</code> <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If the clients were not created successfully</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def create_clients(self, *types: ClientType) -&gt; None:\n    \"\"\"Create and initialize ZMQ clients based on the client types.\n\n    Args:\n        types: List of ClientType enums indicating the types of clients to\n        create and initialize\n\n    Raises:\n        CommunicationError: If the clients were not created\n            successfully\n    \"\"\"\n\n    for client_type in types:\n        if client_type in self.clients:\n            continue\n\n        if isinstance(client_type, PubClientType):\n            client = self._create_pub_client(client_type)\n\n        elif isinstance(client_type, SubClientType):\n            client = self._create_sub_client(client_type)\n\n        elif isinstance(client_type, PushClientType):\n            client = self._create_push_client(client_type)\n\n        elif isinstance(client_type, PullClientType):\n            client = self._create_pull_client(client_type)\n\n        elif isinstance(client_type, ReqClientType):\n            client = self._create_req_client(client_type)\n\n        elif isinstance(client_type, RepClientType):\n            client = self._create_rep_client(client_type)\n\n        else:\n            raise CommunicationError(\n                CommunicationErrorReason.CLIENT_NOT_FOUND,\n                f\"Invalid client type: {client_type}\",\n            )\n\n        await client.initialize()\n\n        self.clients[client_type] = client\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.initialize","title":"<code>initialize()</code>  <code>async</code>","text":"<p>Initialize communication channels.</p> <p>Returns:</p> Type Description <code>None</code> <p>True if initialization was successful, False otherwise</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def initialize(self) -&gt; None:\n    \"\"\"Initialize communication channels.\n\n    Returns:\n        True if initialization was successful, False otherwise\n    \"\"\"\n    if self.is_initialized:\n        return\n\n    # Increase the number of IO threads to 2\n    self._context = zmq.asyncio.Context(io_threads=2)\n    self.initialized_event.set()\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.publish","title":"<code>publish(topic, message)</code>  <code>async</code>","text":"<p>Publish a message to a topic. If the client type is not found, it will be created.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>The topic to publish the message to</p> required <code>message</code> <code>Message</code> <p>The message to publish</p> required <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If the message was not published successfully</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def publish(self, topic: Topic, message: Message) -&gt; None:\n    \"\"\"Publish a message to a topic. If the client type is not found, it will\n    be created.\n\n    Args:\n        topic: The topic to publish the message to\n        message: The message to publish\n\n    Raises:\n        CommunicationError: If the message was not published successfully\n    \"\"\"\n\n    self._ensure_initialized()\n    client_type = PubClientType.from_topic(topic)\n\n    if client_type not in self.clients:\n        logger.debug(\n            \"Client type %r not found for pub topic %r, creating client\",\n            client_type,\n            topic,\n        )\n        await self.create_clients(client_type)\n\n    try:\n        await cast(ZMQPubClient, self.clients[client_type]).publish(topic, message)\n    except Exception as e:\n        logger.error(\n            \"Exception publishing message to topic: %s, message: %s, error: %s\",\n            topic,\n            message,\n            e,\n        )\n        raise CommunicationError(\n            CommunicationErrorReason.PUBLISH_ERROR,\n            f\"Failed to publish message to topic: {topic}, message: {message}, error: {e}\",\n        ) from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.push","title":"<code>push(topic, message)</code>  <code>async</code>","text":"<p>Push a message to a topic. If the proper ZMQ client type is not found, it will be created.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>The topic to push the message to</p> required <code>message</code> <code>Message</code> <p>The message to push</p> required <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If there was an error pushing the message, or if the communication channels are not initialized or shutdown</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def push(self, topic: Topic, message: Message) -&gt; None:\n    \"\"\"Push a message to a topic. If the proper ZMQ client type is not found,\n    it will be created.\n\n    Args:\n        topic: The topic to push the message to\n        message: The message to push\n\n    Raises:\n        CommunicationError: If there was an error pushing the message, or if the\n            communication channels are not initialized or shutdown\n    \"\"\"\n\n    self._ensure_initialized()\n\n    client_type = PushClientType.from_topic(topic)\n\n    if client_type not in self.clients:\n        logger.debug(\n            \"Client type %r not found for push, creating client\",\n            client_type,\n        )\n        await self.create_clients(client_type)\n\n    try:\n        await cast(ZMQPushClient, self.clients[client_type]).push(message)\n    except Exception as e:\n        logger.error(f\"Exception pushing data: {e}\")\n        raise CommunicationError(\n            CommunicationErrorReason.PUSH_ERROR,\n            f\"Failed to push data to topic: {topic}, error: {e}\",\n        ) from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.register_pull_callback","title":"<code>register_pull_callback(message_type, callback)</code>  <code>async</code>","text":"<p>Register a callback for a pull client.</p> <p>Parameters:</p> Name Type Description Default <code>message_type</code> <code>MessageType</code> <p>The message type to register the callback for</p> required <code>callback</code> <code>Callable[[Message], Coroutine[Any, Any, None]]</code> <p>The callback to register</p> required <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If there was an error registering the callback, or if the communication channels are not initialized</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def register_pull_callback(\n    self,\n    message_type: MessageType,\n    callback: Callable[[Message], Coroutine[Any, Any, None]],\n) -&gt; None:\n    \"\"\"Register a callback for a pull client.\n\n    Args:\n        message_type: The message type to register the callback for\n        callback: The callback to register\n\n    Raises:\n        CommunicationError: If there was an error registering the callback, or if\n            the communication channels are not initialized\n    \"\"\"\n\n    logger.debug(f\"Pulling data for {message_type}\")\n\n    self._ensure_initialized()\n\n    client_type = PullClientType.from_message_type(message_type)\n\n    if client_type not in self.clients:\n        logger.debug(\n            \"Client type %r not found for pull, creating client\",\n            client_type,\n        )\n        await self.create_clients(client_type)\n\n    # Only adds to the callback list, does not block, and does not raise an exception\n    await cast(ZMQPullClient, self.clients[client_type]).register_pull_callback(\n        message_type, callback\n    )\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.register_request_handler","title":"<code>register_request_handler(service_id, topic, message_type, handler)</code>  <code>async</code>","text":"<p>Register a request handler for a topic.</p> <p>Parameters:</p> Name Type Description Default <code>service_id</code> <code>str</code> <p>The service ID to register the handler for</p> required <code>topic</code> <code>Topic</code> <p>The topic to register the handler for</p> required <code>message_type</code> <code>MessageType</code> <p>The message type to register the handler for</p> required <code>handler</code> <code>Callable[[Message], Coroutine[Any, Any, Message | None]]</code> <p>The handler to register</p> required Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def register_request_handler(\n    self,\n    service_id: str,\n    topic: Topic,\n    message_type: MessageType,\n    handler: Callable[[Message], Coroutine[Any, Any, Message | None]],\n) -&gt; None:\n    \"\"\"Register a request handler for a topic.\n\n    Args:\n        service_id: The service ID to register the handler for\n        topic: The topic to register the handler for\n        message_type: The message type to register the handler for\n        handler: The handler to register\n    \"\"\"\n\n    self._ensure_initialized()\n\n    client_type = RepClientType.from_topic(topic)\n\n    if client_type not in self.clients:\n        logger.debug(\n            \"Client type %r not found for req topic %r, creating client\",\n            client_type,\n            topic,\n        )\n        await self.create_clients(client_type)\n\n    try:\n        cast(\n            ZMQRouterRepClient, self.clients[client_type]\n        ).register_request_handler(service_id, message_type, handler)\n    except Exception as e:\n        logger.error(f\"Exception registering request handler for {topic}: {e}\")\n        raise CommunicationError(\n            CommunicationErrorReason.REQUEST_ERROR,\n            f\"Failed to register request handler for topic: {topic}, error: {e}\",\n        ) from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.request","title":"<code>request(topic, message)</code>  <code>async</code>","text":"<p>Request a message from a target. If the proper ZMQ client type is not found, it will be created.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>The topic to request from</p> required <code>message</code> <code>Message</code> <p>The message to request</p> required <p>Returns:</p> Type Description <code>Message</code> <p>The response from the target</p> <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If there was an error requesting from the target, or if the communication channels are not initialized or shutdown</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def request(\n    self,\n    topic: Topic,\n    message: Message,\n) -&gt; Message:\n    \"\"\"Request a message from a target. If the proper ZMQ client type is not\n    found, it will be created.\n\n    Args:\n        topic: The topic to request from\n        message: The message to request\n\n    Returns:\n        The response from the target\n\n    Raises:\n        CommunicationError: If there was an error requesting from the\n            target, or if the communication channels are not initialized\n            or shutdown\n    \"\"\"\n\n    self._ensure_initialized()\n\n    client_type = ReqClientType.from_topic(topic)\n\n    if client_type not in self.clients:\n        logger.debug(\n            \"Client type %r not found for req topic %r, creating client\",\n            client_type,\n            topic,\n        )\n        await self.create_clients(client_type)\n\n    try:\n        return await cast(ZMQDealerReqClient, self.clients[client_type]).request(\n            message\n        )\n    except Exception as e:\n        logger.error(f\"Exception requesting from {topic}: {e}\")\n        raise CommunicationError(\n            CommunicationErrorReason.REQUEST_ERROR,\n            f\"Failed to request from topic: {topic}, error: {e}\",\n        ) from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.shutdown","title":"<code>shutdown()</code>  <code>async</code>","text":"<p>Gracefully shutdown communication channels.</p> <p>This method will wait for all clients to shutdown before shutting down the context.</p> <p>Returns:</p> Type Description <code>None</code> <p>True if shutdown was successful, False otherwise</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Gracefully shutdown communication channels.\n\n    This method will wait for all clients to shutdown before shutting down\n    the context.\n\n    Returns:\n        True if shutdown was successful, False otherwise\n    \"\"\"\n    if self.is_shutdown:\n        return\n\n    try:\n        if not self.stop_event.is_set():\n            self.stop_event.set()\n\n        await asyncio.gather(\n            *(client.shutdown() for client in self.clients.values())\n        )\n\n        if self.context:\n            self.context.term()\n\n        self._context = None\n\n    except asyncio.CancelledError:\n        pass\n\n    except Exception as e:\n        raise CommunicationError(\n            CommunicationErrorReason.SHUTDOWN_ERROR,\n            \"Failed to shutdown ZMQ communication\",\n        ) from e\n\n    finally:\n        self.clients = {}\n        self._context = None\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.BaseZMQCommunication.subscribe","title":"<code>subscribe(topic, callback)</code>  <code>async</code>","text":"<p>Subscribe to a topic. If the proper ZMQ client type is not found, it will be created.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>Topic</code> <p>The topic to subscribe to</p> required <code>callback</code> <code>Callable[[Message], Coroutine[Any, Any, None]]</code> <p>The callback to call when a message is received</p> required <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If there was an error subscribing to the topic, or if the communication channels are not initialized or shutdown</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def subscribe(\n    self,\n    topic: Topic,\n    callback: Callable[[Message], Coroutine[Any, Any, None]],\n) -&gt; None:\n    \"\"\"Subscribe to a topic. If the proper ZMQ client type is not found, it\n    will be created.\n\n    Args:\n        topic: The topic to subscribe to\n        callback: The callback to call when a message is received\n\n    Raises:\n        CommunicationError: If there was an error subscribing to the\n            topic, or if the communication channels are not initialized\n            or shutdown\n    \"\"\"\n\n    self._ensure_initialized()\n\n    client_type = SubClientType.from_topic(topic)\n\n    if client_type not in self.clients:\n        logger.debug(\n            \"Client type %r not found for sub topic %r, creating client\",\n            client_type,\n            topic,\n        )\n        await self.create_clients(client_type)\n\n    try:\n        await cast(ZMQSubClient, self.clients[client_type]).subscribe(\n            topic, callback\n        )\n    except Exception as e:\n        logger.error(f\"Exception subscribing to topic: {e}\")\n        raise CommunicationError(\n            CommunicationErrorReason.SUBSCRIBE_ERROR,\n            f\"Failed to subscribe to topic: {topic}, error: {e}\",\n        ) from e\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQIPCCommunication","title":"<code>ZMQIPCCommunication</code>","text":"<p>               Bases: <code>BaseZMQCommunication</code></p> <p>ZeroMQ-based implementation of the Communication interface using IPC transport.</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>@CommunicationFactory.register(CommunicationBackend.ZMQ_IPC)\nclass ZMQIPCCommunication(BaseZMQCommunication):\n    \"\"\"ZeroMQ-based implementation of the Communication interface using IPC transport.\"\"\"\n\n    def __init__(self, config: ZMQIPCConfig | None = None) -&gt; None:\n        \"\"\"Initialize ZMQ IPC communication.\n\n        Args:\n            config: ZMQIPCConfig object with configuration parameters\n        \"\"\"\n        super().__init__(config or ZMQIPCConfig())\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize communication channels.\n\n        This method will create the IPC socket directory if needed.\n\n        Raises:\n            CommunicationError: If the communication channels are not initialized\n                or shutdown\n        \"\"\"\n        await super().initialize()\n        self._setup_ipc_directory()\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Gracefully shutdown communication channels.\n\n        This method will wait for all clients to shutdown before shutting down\n        the context.\n\n        Raises:\n            CommunicationError: If there was an error shutting down the communication\n                channels\n        \"\"\"\n        await super().shutdown()\n        self._cleanup_ipc_sockets()\n\n    def _setup_ipc_directory(self) -&gt; None:\n        \"\"\"Create IPC socket directory if using IPC transport.\"\"\"\n        self._ipc_socket_dir = Path(self.config.path)\n        self._ipc_socket_dir.mkdir(parents=True, exist_ok=True)\n        logger.debug(f\"Created IPC socket directory: {self._ipc_socket_dir}\")\n\n    def _cleanup_ipc_sockets(self) -&gt; None:\n        \"\"\"Clean up IPC socket files.\"\"\"\n        if self._ipc_socket_dir and self._ipc_socket_dir.exists():\n            # Remove all .ipc files in the directory\n            ipc_files = glob.glob(str(self._ipc_socket_dir / \"*.ipc\"))\n            for ipc_file in ipc_files:\n                try:\n                    if os.path.exists(ipc_file):\n                        os.unlink(ipc_file)\n                        logger.debug(f\"Removed IPC socket file: {ipc_file}\")\n                except OSError as e:\n                    if e.errno != errno.ENOENT:\n                        logger.warning(\n                            \"Failed to remove IPC socket file %s: %s\",\n                            ipc_file,\n                            e,\n                        )\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQIPCCommunication.__init__","title":"<code>__init__(config=None)</code>","text":"<p>Initialize ZMQ IPC communication.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ZMQIPCConfig | None</code> <p>ZMQIPCConfig object with configuration parameters</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>def __init__(self, config: ZMQIPCConfig | None = None) -&gt; None:\n    \"\"\"Initialize ZMQ IPC communication.\n\n    Args:\n        config: ZMQIPCConfig object with configuration parameters\n    \"\"\"\n    super().__init__(config or ZMQIPCConfig())\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQIPCCommunication.initialize","title":"<code>initialize()</code>  <code>async</code>","text":"<p>Initialize communication channels.</p> <p>This method will create the IPC socket directory if needed.</p> <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If the communication channels are not initialized or shutdown</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def initialize(self) -&gt; None:\n    \"\"\"Initialize communication channels.\n\n    This method will create the IPC socket directory if needed.\n\n    Raises:\n        CommunicationError: If the communication channels are not initialized\n            or shutdown\n    \"\"\"\n    await super().initialize()\n    self._setup_ipc_directory()\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQIPCCommunication.shutdown","title":"<code>shutdown()</code>  <code>async</code>","text":"<p>Gracefully shutdown communication channels.</p> <p>This method will wait for all clients to shutdown before shutting down the context.</p> <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If there was an error shutting down the communication channels</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Gracefully shutdown communication channels.\n\n    This method will wait for all clients to shutdown before shutting down\n    the context.\n\n    Raises:\n        CommunicationError: If there was an error shutting down the communication\n            channels\n    \"\"\"\n    await super().shutdown()\n    self._cleanup_ipc_sockets()\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQInprocCommunication","title":"<code>ZMQInprocCommunication</code>","text":"<p>               Bases: <code>ZMQIPCCommunication</code></p> <p>ZeroMQ-based implementation of the Communication interface using in-process transport. Note that communications between workers is still done over IPC sockets, which is why this class inherits from ZMQIPCCommunication.</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>@CommunicationFactory.register(CommunicationBackend.ZMQ_INPROC)\nclass ZMQInprocCommunication(ZMQIPCCommunication):\n    \"\"\"ZeroMQ-based implementation of the Communication interface using in-process\n    transport. Note that communications between workers is still done over IPC sockets,\n    which is why this class inherits from ZMQIPCCommunication.\"\"\"\n\n    def __init__(self, config: ZMQInprocConfig | None = None) -&gt; None:\n        \"\"\"Initialize ZMQ in-process communication.\n\n        Args:\n            config: ZMQInprocConfig object with configuration parameters\n        \"\"\"\n        super().__init__(config or ZMQInprocConfig())\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQInprocCommunication.__init__","title":"<code>__init__(config=None)</code>","text":"<p>Initialize ZMQ in-process communication.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ZMQInprocConfig | None</code> <p>ZMQInprocConfig object with configuration parameters</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>def __init__(self, config: ZMQInprocConfig | None = None) -&gt; None:\n    \"\"\"Initialize ZMQ in-process communication.\n\n    Args:\n        config: ZMQInprocConfig object with configuration parameters\n    \"\"\"\n    super().__init__(config or ZMQInprocConfig())\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQTCPCommunication","title":"<code>ZMQTCPCommunication</code>","text":"<p>               Bases: <code>BaseZMQCommunication</code></p> <p>ZeroMQ-based implementation of the Communication interface using TCP transport.</p> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>@CommunicationFactory.register(CommunicationBackend.ZMQ_TCP)\nclass ZMQTCPCommunication(BaseZMQCommunication):\n    \"\"\"ZeroMQ-based implementation of the Communication interface using TCP transport.\"\"\"\n\n    def __init__(self, config: ZMQTCPTransportConfig | None = None) -&gt; None:\n        \"\"\"Initialize ZMQ TCP communication.\n\n        Args:\n            config: ZMQTCPTransportConfig object with configuration parameters\n        \"\"\"\n        super().__init__(config or ZMQTCPTransportConfig())\n</code></pre>"},{"location":"api/#aiperf.common.comms.zmq.zmq_comms.ZMQTCPCommunication.__init__","title":"<code>__init__(config=None)</code>","text":"<p>Initialize ZMQ TCP communication.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ZMQTCPTransportConfig | None</code> <p>ZMQTCPTransportConfig object with configuration parameters</p> <code>None</code> Source code in <code>aiperf/common/comms/zmq/zmq_comms.py</code> <pre><code>def __init__(self, config: ZMQTCPTransportConfig | None = None) -&gt; None:\n    \"\"\"Initialize ZMQ TCP communication.\n\n    Args:\n        config: ZMQTCPTransportConfig object with configuration parameters\n    \"\"\"\n    super().__init__(config or ZMQTCPTransportConfig())\n</code></pre>"},{"location":"api/#aiperfcommonconfigbase_config","title":"aiperf.common.config.base_config","text":""},{"location":"api/#aiperf.common.config.base_config.BaseConfig","title":"<code>BaseConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>aiperf/common/config/base_config.py</code> <pre><code>class BaseConfig(BaseModel):\n    def serialize_to_yaml(self, verbose: bool = False, indent: int = 4) -&gt; str:\n        \"\"\"\n        Serialize a Pydantic model to a YAML string.\n\n        Args:\n            verbose: Whether to include verbose comments in the YAML output.\n            indent: The per-level indentation to use.\n        \"\"\"\n        # Dump model to dict with context (flags propagate recursively)\n        context = {\n            \"verbose\": verbose,\n        }\n\n        data = self.model_dump(context=context)\n\n        # Attach comments recursively\n        commented_data = self._attach_comments(\n            data=data,\n            model=self,\n            context=context,\n            indent=indent,\n        )\n\n        # Dump to YAML\n        yaml = YAML(pure=True)\n        yaml.indent(mapping=indent, sequence=indent, offset=indent)\n\n        stream = io.StringIO()\n        yaml.dump(commented_data, stream)\n        return stream.getvalue()\n\n    @staticmethod\n    def _attach_comments(\n        data: Any,\n        model: BaseModel,\n        context: dict,\n        indent: int,\n        indent_level: int = 0,\n    ) -&gt; Any:\n        \"\"\"\n        Recursively convert dicts to ruamel.yaml CommentedMap and attach comments from\n        Pydantic field descriptions, or based on context (e.g., verbose flag).\n\n        Args:\n            data: The raw data to convert to a CommentedMap.\n            model: The Pydantic model that contains the field descriptions.\n            context: The Pydantic serializer context which contains the serializer flags.\n            indent: The per-level indentation to use for the comments.\n            indent_level: The current level of indentation. The actual indentation is\n                `indent * indent_level`.\n\n        Returns:\n            The data with comments attached.\n        \"\"\"\n        if isinstance(data, dict):\n            # Create a CommentedMap to store the commented data. This is a special type of\n            # dict provided by the ruamel.yaml library that preserves the order of the keys and\n            # allows for comments to be attached to the keys.\n            commented_map = CommentedMap()\n\n            for field_name, value in data.items():\n                field = model.__class__.model_fields.get(field_name)\n\n                if not BaseConfig._should_add_field_to_template(field):\n                    continue\n\n                if BaseConfig._is_a_nested_config(field, value):\n                    # Recursively process nested models\n                    commented_map[field_name] = BaseConfig._attach_comments(\n                        value,\n                        getattr(model, field_name),\n                        context=context,\n                        indent=indent,\n                        indent_level=indent_level + 1,\n                    )\n\n                    commented_map.yaml_set_comment_before_after_key(\n                        field_name,\n                        before=\"\\n\",\n                        indent=indent * (indent_level + 1),\n                    )\n                else:\n                    # Attach the value to the commented map\n                    commented_map[field_name] = BaseConfig._preprocess_value(value)\n\n                # Attach comment if verbose and description exists\n                if context.get(\"verbose\") and field and field.description:\n                    # Set the comment before the key, with the specified indentation\n                    commented_map.yaml_set_comment_before_after_key(\n                        field_name,\n                        before=\"\\n\" + field.description,\n                        indent=indent * indent_level,\n                    )\n\n            return commented_map\n\n    @staticmethod\n    def _should_add_field_to_template(field: Any) -&gt; bool:\n        # Check if the field should be added to the template based on json_schema_extra\n        # and the add_to_template flag.\n        # If add_to_template is False, we skip adding the field to the template.\n        # If add_to_template is True or not present, we include the field in the template.\n        if field and field.json_schema_extra:\n            return field.json_schema_extra.get(ADD_TO_TEMPLATE, True)\n        else:\n            return True\n\n    @staticmethod\n    def _is_a_nested_config(field: Any, value: Any) -&gt; bool:\n        return (\n            isinstance(value, dict)\n            and field\n            and issubclass(field.annotation, BaseModel)\n        )\n\n    @staticmethod\n    def _preprocess_value(value: Any) -&gt; Any:\n        \"\"\"\n        Preprocess the value before serialization.\n        \"\"\"\n\n        if isinstance(value, Enum):\n            return str(value.value).lower()\n        elif isinstance(value, Path):\n            return str(value)\n        else:\n            return value\n</code></pre>"},{"location":"api/#aiperf.common.config.base_config.BaseConfig.serialize_to_yaml","title":"<code>serialize_to_yaml(verbose=False, indent=4)</code>","text":"<p>Serialize a Pydantic model to a YAML string.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>Whether to include verbose comments in the YAML output.</p> <code>False</code> <code>indent</code> <code>int</code> <p>The per-level indentation to use.</p> <code>4</code> Source code in <code>aiperf/common/config/base_config.py</code> <pre><code>def serialize_to_yaml(self, verbose: bool = False, indent: int = 4) -&gt; str:\n    \"\"\"\n    Serialize a Pydantic model to a YAML string.\n\n    Args:\n        verbose: Whether to include verbose comments in the YAML output.\n        indent: The per-level indentation to use.\n    \"\"\"\n    # Dump model to dict with context (flags propagate recursively)\n    context = {\n        \"verbose\": verbose,\n    }\n\n    data = self.model_dump(context=context)\n\n    # Attach comments recursively\n    commented_data = self._attach_comments(\n        data=data,\n        model=self,\n        context=context,\n        indent=indent,\n    )\n\n    # Dump to YAML\n    yaml = YAML(pure=True)\n    yaml.indent(mapping=indent, sequence=indent, offset=indent)\n\n    stream = io.StringIO()\n    yaml.dump(commented_data, stream)\n    return stream.getvalue()\n</code></pre>"},{"location":"api/#aiperfcommonconfigconfig_defaults","title":"aiperf.common.config.config_defaults","text":""},{"location":"api/#aiperfcommonconfigconfig_validators","title":"aiperf.common.config.config_validators","text":""},{"location":"api/#aiperf.common.config.config_validators.parse_file","title":"<code>parse_file(value)</code>","text":"<p>Parses the given string value and returns a Path object if the value represents a valid file, directory, or a specific synthetic/payload format. Returns None if the input value is empty. Args:     value (str): The string value to parse. Returns:     Optional[Path]: A Path object if the value is valid, or None if the value is empty. Raises:     ValueError: If the value is not a valid file or directory and does not match                 the synthetic/payload format.</p> Source code in <code>aiperf/common/config/config_validators.py</code> <pre><code>def parse_file(value: str | None) -&gt; Path | None:\n    \"\"\"\n    Parses the given string value and returns a Path object if the value represents\n    a valid file, directory, or a specific synthetic/payload format. Returns None if\n    the input value is empty.\n    Args:\n        value (str): The string value to parse.\n    Returns:\n        Optional[Path]: A Path object if the value is valid, or None if the value is empty.\n    Raises:\n        ValueError: If the value is not a valid file or directory and does not match\n                    the synthetic/payload format.\n    \"\"\"\n\n    if not value:\n        return None\n    elif not isinstance(value, str):\n        raise ValueError(f\"Expected a string, but got {type(value).__name__}\")\n    elif value.startswith(\"synthetic:\") or value.startswith(\"payload\"):\n        return Path(value)\n    else:\n        path = Path(value)\n        if path.is_file() or path.is_dir():\n            return path\n        else:\n            raise ValueError(f\"'{value}' is not a valid file or directory\")\n</code></pre>"},{"location":"api/#aiperf.common.config.config_validators.parse_goodput","title":"<code>parse_goodput(goodputs)</code>","text":"<p>Parses and validates a dictionary of goodput values, ensuring that all values are non-negative integers or floats, and converts them to floats. Args:     goodputs (Dict[str, Any]): A dictionary where keys are target metric names         (strings) and values are the corresponding goodput values. Returns:     Dict[str, float]: A dictionary with the same keys as the input, but with         all values converted to floats. Raises:     ValueError: If any value in the input dictionary is not an integer or float,         or if any value is negative.</p> Source code in <code>aiperf/common/config/config_validators.py</code> <pre><code>def parse_goodput(goodputs: dict[str, Any]) -&gt; dict[str, float]:\n    \"\"\"\n    Parses and validates a dictionary of goodput values, ensuring that all values\n    are non-negative integers or floats, and converts them to floats.\n    Args:\n        goodputs (Dict[str, Any]): A dictionary where keys are target metric names\n            (strings) and values are the corresponding goodput values.\n    Returns:\n        Dict[str, float]: A dictionary with the same keys as the input, but with\n            all values converted to floats.\n    Raises:\n        ValueError: If any value in the input dictionary is not an integer or float,\n            or if any value is negative.\n    \"\"\"\n\n    constraints = {}\n    for target_metric, target_value in goodputs.items():\n        if isinstance(target_value, (int | float)):\n            if target_value &lt; 0:\n                raise ValueError(\n                    f\"User Config: Goodput values must be non-negative ({target_metric}: {target_value})\"\n                )\n\n            constraints[target_metric] = float(target_value)\n        else:\n            raise ValueError(\"User Config: Goodput values must be integers or floats\")\n\n    return constraints\n</code></pre>"},{"location":"api/#aiperf.common.config.config_validators.parse_str_or_list","title":"<code>parse_str_or_list(input)</code>","text":"<p>Parses the input to ensure it is either a string or a list. If the input is a string, it splits the string by commas and trims any whitespace around each element, returning the result as a list. If the input is already a list, it is returned as-is. If the input is neither a string nor a list, a ValueError is raised. Args:     input (Any): The input to be parsed. Expected to be a string or a list. Returns:     list: A list of strings derived from the input. Raises:     ValueError: If the input is neither a string nor a list.</p> Source code in <code>aiperf/common/config/config_validators.py</code> <pre><code>def parse_str_or_list(input: Any) -&gt; list[Any]:\n    \"\"\"\n    Parses the input to ensure it is either a string or a list. If the input is a string,\n    it splits the string by commas and trims any whitespace around each element, returning\n    the result as a list. If the input is already a list, it is returned as-is. If the input\n    is neither a string nor a list, a ValueError is raised.\n    Args:\n        input (Any): The input to be parsed. Expected to be a string or a list.\n    Returns:\n        list: A list of strings derived from the input.\n    Raises:\n        ValueError: If the input is neither a string nor a list.\n    \"\"\"\n\n    if type(input) is str:\n        output = [input.strip() for input in input.split(\",\")]\n    elif type(input) is list:\n        output = input\n    else:\n        raise ValueError(f\"User Config: {input} - must be a string or list\")\n\n    return output\n</code></pre>"},{"location":"api/#aiperf.common.config.config_validators.parse_str_or_list_of_positive_values","title":"<code>parse_str_or_list_of_positive_values(input)</code>","text":"<p>Parses the input to ensure it is a list of positive integers or floats. This function first converts the input into a list using <code>parse_str_or_list</code>. It then validates that each value in the list is either an integer or a float and that all values are strictly greater than zero. If any value fails this validation, a <code>ValueError</code> is raised. Args:     input (Any): The input to be parsed. It can be a string or a list. Returns:     List[Any]: A list of positive integers or floats. Raises:     ValueError: If any value in the parsed list is not a positive integer or float.</p> Source code in <code>aiperf/common/config/config_validators.py</code> <pre><code>def parse_str_or_list_of_positive_values(input: Any) -&gt; list[Any]:\n    \"\"\"\n    Parses the input to ensure it is a list of positive integers or floats.\n    This function first converts the input into a list using `parse_str_or_list`.\n    It then validates that each value in the list is either an integer or a float\n    and that all values are strictly greater than zero. If any value fails this\n    validation, a `ValueError` is raised.\n    Args:\n        input (Any): The input to be parsed. It can be a string or a list.\n    Returns:\n        List[Any]: A list of positive integers or floats.\n    Raises:\n        ValueError: If any value in the parsed list is not a positive integer or float.\n    \"\"\"\n\n    output = parse_str_or_list(input)\n\n    for value in output:\n        if not isinstance(value, (int | float)) or value &lt;= 0:\n            raise ValueError(\n                f\"User Config: {output} - all values {value} must be a positive integer or float\"\n            )\n\n    return output\n</code></pre>"},{"location":"api/#aiperfcommonconfigendpointendpoint_config","title":"aiperf.common.config.endpoint.endpoint_config","text":""},{"location":"api/#aiperf.common.config.endpoint.endpoint_config.EndPointConfig","title":"<code>EndPointConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining endpoint related settings.</p> Source code in <code>aiperf/common/config/endpoint/endpoint_config.py</code> <pre><code>class EndPointConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining endpoint related settings.\n    \"\"\"\n\n    model_selection_strategy: Annotated[\n        ModelSelectionStrategy,\n        Field(\n            description=\"When multiple models are specified, this is how a specific model should be assigned to a prompt. \\\n            \\nround_robin: nth prompt in the list gets assigned to n-mod len(models). \\\n            \\nrandom: assignment is uniformly random\",\n        ),\n    ] = EndPointDefaults.MODEL_SELECTION_STRATEGY\n\n    backend: Annotated[\n        RequestPayloadType,\n        Field(\n            description=\"When benchmarking Triton, this is the backend of the model.\",\n        ),\n    ] = EndPointDefaults.BACKEND\n\n    custom: Annotated[\n        str,\n        Field(\n            description=\"Set a custom endpoint that differs from the OpenAI defaults.\",\n        ),\n    ] = EndPointDefaults.CUSTOM\n\n    type: Annotated[\n        str,\n        Field(\n            description=\"The type to send requests to on the server.\",\n        ),\n    ] = EndPointDefaults.TYPE\n\n    streaming: Annotated[\n        bool,\n        Field(\n            description=\"An option to enable the use of the streaming API.\",\n        ),\n    ] = EndPointDefaults.STREAMING\n\n    server_metrics_urls: Annotated[\n        list[str],\n        Field(\n            description=\"The list of Triton server metrics URLs. \\\n            \\nThese are used for Telemetry metric reporting with Triton.\",\n        ),\n        BeforeValidator(parse_str_or_list),\n    ] = EndPointDefaults.SERVER_METRICS_URLS\n\n    url: Annotated[\n        str,\n        Field(\n            description=\"URL of the endpoint to target for benchmarking.\",\n        ),\n    ] = EndPointDefaults.URL\n\n    grpc_method: Annotated[\n        str,\n        Field(\n            description=\"A fully-qualified gRPC method name in \"\n            \"'&lt;package&gt;.&lt;service&gt;/&lt;method&gt;' format.\"\n            \"\\nThe option is only supported by dynamic gRPC service kind and is\"\n            \"\\nrequired to identify the RPC to use when sending requests to the server.\",\n        ),\n    ] = EndPointDefaults.GRPC_METHOD\n</code></pre>"},{"location":"api/#aiperfcommonconfiginputaudio_config","title":"aiperf.common.config.input.audio_config","text":""},{"location":"api/#aiperf.common.config.input.audio_config.AudioConfig","title":"<code>AudioConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining audio related settings.</p> Source code in <code>aiperf/common/config/input/audio_config.py</code> <pre><code>class AudioConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining audio related settings.\n    \"\"\"\n\n    batch_size: Annotated[\n        int,\n        Field(\n            ge=0,\n            description=\"The batch size of audio requests GenAI-Perf should send.\\\n            \\nThis is currently supported with the OpenAI `multimodal` endpoint type\",\n        ),\n    ] = AudioDefaults.BATCH_SIZE\n\n    length: AudioLengthConfig = AudioLengthConfig()\n\n    format: Annotated[\n        AudioFormat,\n        Field(\n            description=\"The format of the audio files (wav or mp3).\",\n        ),\n    ] = AudioDefaults.FORMAT\n\n    depths: Annotated[\n        list[int],\n        Field(\n            min_length=1,\n            description=\"A list of audio bit depths to randomly select from in bits.\",\n        ),\n        BeforeValidator(parse_str_or_list_of_positive_values),\n    ] = AudioDefaults.DEPTHS\n\n    sample_rates: Annotated[\n        list[float],\n        Field(\n            min_length=1,\n            description=\"A list of audio sample rates to randomly select from in kHz.\",\n        ),\n        BeforeValidator(parse_str_or_list_of_positive_values),\n    ] = AudioDefaults.SAMPLE_RATES\n\n    num_channels: Annotated[\n        int,\n        Field(\n            ge=1,\n            le=2,\n            description=\"The number of audio channels to use for the audio data generation.\",\n        ),\n    ] = AudioDefaults.NUM_CHANNELS\n</code></pre>"},{"location":"api/#aiperf.common.config.input.audio_config.AudioLengthConfig","title":"<code>AudioLengthConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining audio length related settings.</p> Source code in <code>aiperf/common/config/input/audio_config.py</code> <pre><code>class AudioLengthConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining audio length related settings.\n    \"\"\"\n\n    mean: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"The mean length of the audio in seconds.\",\n        ),\n    ] = AudioDefaults.LENGTH_MEAN\n\n    stddev: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"The standard deviation of the length of the audio in seconds.\",\n        ),\n    ] = AudioDefaults.LENGTH_STDDEV\n</code></pre>"},{"location":"api/#aiperfcommonconfiginputimage_config","title":"aiperf.common.config.input.image_config","text":""},{"location":"api/#aiperf.common.config.input.image_config.ImageConfig","title":"<code>ImageConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining image related settings.</p> Source code in <code>aiperf/common/config/input/image_config.py</code> <pre><code>class ImageConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining image related settings.\n    \"\"\"\n\n    width: ImageWidthConfig = ImageWidthConfig()\n    height: ImageHeightConfig = ImageHeightConfig()\n    batch_size: Annotated[\n        int,\n        Field(\n            ge=0,\n            description=\"The image batch size of the requests AI-Perf should send.\\\n            \\nThis is currently supported with the image retrieval endpoint type.\",\n        ),\n    ] = ImageDefaults.BATCH_SIZE\n\n    format: Annotated[\n        ImageFormat,\n        Field(\n            description=\"The compression format of the images.\",\n        ),\n    ] = ImageDefaults.FORMAT\n</code></pre>"},{"location":"api/#aiperf.common.config.input.image_config.ImageHeightConfig","title":"<code>ImageHeightConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining image height related settings.</p> Source code in <code>aiperf/common/config/input/image_config.py</code> <pre><code>class ImageHeightConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining image height related settings.\n    \"\"\"\n\n    mean: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"The mean height of images when generating synthetic image data.\",\n        ),\n    ] = ImageDefaults.HEIGHT_MEAN\n\n    stddev: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"The standard deviation of height of images when generating synthetic image data.\",\n        ),\n    ] = ImageDefaults.HEIGHT_STDDEV\n</code></pre>"},{"location":"api/#aiperf.common.config.input.image_config.ImageWidthConfig","title":"<code>ImageWidthConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining image width related settings.</p> Source code in <code>aiperf/common/config/input/image_config.py</code> <pre><code>class ImageWidthConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining image width related settings.\n    \"\"\"\n\n    mean: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"The mean width of images when generating synthetic image data.\",\n        ),\n    ] = ImageDefaults.WIDTH_MEAN\n\n    stddev: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"The standard deviation of width of images when generating synthetic image data.\",\n        ),\n    ] = ImageDefaults.WIDTH_STDDEV\n</code></pre>"},{"location":"api/#aiperfcommonconfiginputinput_config","title":"aiperf.common.config.input.input_config","text":""},{"location":"api/#aiperf.common.config.input.input_config.InputConfig","title":"<code>InputConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining input related settings.</p> Source code in <code>aiperf/common/config/input/input_config.py</code> <pre><code>class InputConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining input related settings.\n    \"\"\"\n\n    batch_size: Annotated[\n        int,\n        Field(\n            description=\"The batch size of text requests GenAI-Perf should send.\\\n            \\nThis is currently supported with the embeddings and rankings endpoint types\",\n        ),\n    ] = InputDefaults.BATCH_SIZE\n\n    extra: Annotated[\n        Any,\n        Field(\n            description=\"Provide additional inputs to include with every request.\\\n            \\nInputs should be in an 'input_name:value' format.\",\n        ),\n    ] = InputDefaults.EXTRA\n\n    goodput: Annotated[\n        dict[str, Any],\n        Field(\n            description=\"An option to provide constraints in order to compute goodput.\\\n            \\nSpecify goodput constraints as 'key:value' pairs,\\\n            \\nwhere the key is a valid metric name, and the value is a number representing\\\n            \\neither milliseconds or a throughput value per second.\\\n            \\nFor example:\\\n            \\n  request_latency:300\\\n            \\n  output_token_throughput_per_user:600\",\n        ),\n        BeforeValidator(parse_goodput),\n    ] = InputDefaults.GOODPUT\n\n    header: Annotated[\n        Any,\n        Field(\n            description=\"Adds a custom header to the requests.\\\n            \\nHeaders must be specified as 'Header:Value' pairs.\",\n        ),\n    ] = InputDefaults.HEADER\n\n    file: Annotated[\n        Any,\n        Field(\n            description=\"The file or directory containing the content to use for profiling.\\\n            \\nExample:\\\n            \\n  text: \\\"Your prompt here\\\"\\\n            \\n\\nTo use synthetic files for a converter that needs multiple files,\\\n            \\nprefix the path with 'synthetic:' followed by a comma-separated list of file names.\\\n            \\nThe synthetic filenames should not have extensions.\\\n            \\nExample:\\\n            \\n  synthetic: queries,passages\",\n        ),\n        BeforeValidator(parse_file),\n    ] = InputDefaults.FILE\n\n    num_dataset_entries: Annotated[\n        int,\n        Field(\n            ge=1,\n            description=\"The number of unique payloads to sample from.\\\n            \\nThese will be reused until benchmarking is complete.\",\n        ),\n    ] = InputDefaults.NUM_DATASET_ENTRIES\n\n    random_seed: Annotated[\n        int,\n        Field(\n            description=\"The seed used to generate random values.\",\n        ),\n    ] = InputDefaults.RANDOM_SEED\n\n    audio: AudioConfig = AudioConfig()\n    image: ImageConfig = ImageConfig()\n    prompt: PromptConfig = PromptConfig()\n    sessions: SessionsConfig = SessionsConfig()\n</code></pre>"},{"location":"api/#aiperfcommonconfiginputprompt_config","title":"aiperf.common.config.input.prompt_config","text":""},{"location":"api/#aiperf.common.config.input.prompt_config.InputTokensConfig","title":"<code>InputTokensConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining input token related settings.</p> Source code in <code>aiperf/common/config/input/prompt_config.py</code> <pre><code>class InputTokensConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining input token related settings.\n    \"\"\"\n\n    mean: Annotated[\n        int,\n        Field(\n            ge=0,\n            description=\"The mean of number of tokens in the generated prompts when using synthetic data.\",\n        ),\n    ] = InputTokensDefaults.MEAN\n\n    stddev: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"The standard deviation of number of tokens in the generated prompts when using synthetic data.\",\n        ),\n    ] = InputTokensDefaults.STDDEV\n</code></pre>"},{"location":"api/#aiperf.common.config.input.prompt_config.OutputTokensConfig","title":"<code>OutputTokensConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining output token related settings.</p> Source code in <code>aiperf/common/config/input/prompt_config.py</code> <pre><code>class OutputTokensConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining output token related settings.\n    \"\"\"\n\n    mean: Annotated[\n        int,\n        Field(\n            ge=0,\n            description=\"The mean number of tokens in each output.\",\n        ),\n    ] = OutputTokensDefaults.MEAN\n\n    deterministic: Annotated[\n        bool,\n        Field(\n            description=(\n                \"This can be set to improve the precision of the mean by setting the\\n\"\n                \"minimum number of tokens equal to the requested number of tokens.\\n\"\n                \"This is currently supported with Triton.\"\n            ),\n        ),\n    ] = OutputTokensDefaults.DETERMINISTIC\n\n    stddev: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"The standard deviation of the number of tokens in each output.\",\n        ),\n    ] = OutputTokensDefaults.STDDEV\n</code></pre>"},{"location":"api/#aiperf.common.config.input.prompt_config.PrefixPromptConfig","title":"<code>PrefixPromptConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining prefix prompt related settings.</p> Source code in <code>aiperf/common/config/input/prompt_config.py</code> <pre><code>class PrefixPromptConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining prefix prompt related settings.\n    \"\"\"\n\n    pool_size: Annotated[\n        int,\n        Field(\n            ge=0,\n            description=(\n                \"The total size of the prefix prompt pool to select prefixes from.\\n\"\n                \"If this value is not zero, these are prompts that are prepended to input prompts.\\n\"\n                \"This is useful for benchmarking models that use a K-V cache.\"\n            ),\n        ),\n    ] = PrefixPromptDefaults.POOL_SIZE\n\n    length: Annotated[\n        int,\n        Field(\n            ge=0,\n            description=(\n                \"The number of tokens in each prefix prompt.\\n\"\n                'This is only used if \"num\" is greater than zero.\\n'\n                \"Note that due to the prefix and user prompts being concatenated,\\n\"\n                \"the number of tokens in the final prompt may be off by one.\"\n            ),\n        ),\n    ] = PrefixPromptDefaults.LENGTH\n</code></pre>"},{"location":"api/#aiperf.common.config.input.prompt_config.PromptConfig","title":"<code>PromptConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining prompt related settings.</p> Source code in <code>aiperf/common/config/input/prompt_config.py</code> <pre><code>class PromptConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining prompt related settings.\n    \"\"\"\n\n    input_tokens: InputTokensConfig = InputTokensConfig()\n    output_tokens: OutputTokensConfig = OutputTokensConfig()\n    prefix_prompt: PrefixPromptConfig = PrefixPromptConfig()\n</code></pre>"},{"location":"api/#aiperfcommonconfiginputsessions_config","title":"aiperf.common.config.input.sessions_config","text":""},{"location":"api/#aiperf.common.config.input.sessions_config.SessionTurnDelayConfig","title":"<code>SessionTurnDelayConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining session turn delay related settings.</p> Source code in <code>aiperf/common/config/input/sessions_config.py</code> <pre><code>class SessionTurnDelayConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining session turn delay related settings.\n    \"\"\"\n\n    mean: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"The mean delay (in ms) between turns in a session\",\n        ),\n    ] = SessionTurnDelayDefaults.MEAN\n\n    stddev: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"The standard deviation (in ms) of the delay between turns in a session\",\n        ),\n    ] = SessionTurnDelayDefaults.STDDEV\n\n    ratio: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"A ratio to scale multi-turn delays when using a payload file\",\n        ),\n    ] = SessionTurnDelayDefaults.RATIO\n</code></pre>"},{"location":"api/#aiperf.common.config.input.sessions_config.SessionTurnsConfig","title":"<code>SessionTurnsConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining session turns related settings.</p> Source code in <code>aiperf/common/config/input/sessions_config.py</code> <pre><code>class SessionTurnsConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining session turns related settings.\n    \"\"\"\n\n    mean: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"The mean number of turns in a session\",\n        ),\n    ] = SessionTurnsDefaults.MEAN\n\n    stddev: Annotated[\n        float,\n        Field(\n            ge=0,\n            description=\"The standard deviation of the number of turns in a session\",\n        ),\n    ] = SessionTurnsDefaults.STDDEV\n</code></pre>"},{"location":"api/#aiperf.common.config.input.sessions_config.SessionsConfig","title":"<code>SessionsConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining sessions related settings.</p> Source code in <code>aiperf/common/config/input/sessions_config.py</code> <pre><code>class SessionsConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining sessions related settings.\n    \"\"\"\n\n    num: Annotated[\n        int,\n        Field(\n            ge=0,\n            description=\"The number of sessions to simulate\",\n        ),\n    ] = SessionsDefaults.NUM\n\n    turns: SessionTurnsConfig = SessionTurnsConfig()\n    turn_delay: SessionTurnDelayConfig = SessionTurnDelayConfig()\n</code></pre>"},{"location":"api/#aiperfcommonconfigloader","title":"aiperf.common.config.loader","text":""},{"location":"api/#aiperf.common.config.loader.load_service_config","title":"<code>load_service_config()</code>","text":"<p>Load the service configuration.</p> Source code in <code>aiperf/common/config/loader.py</code> <pre><code>def load_service_config() -&gt; ServiceConfig:\n    \"\"\"Load the service configuration.\"\"\"\n    # TODO: implement\n    return ServiceConfig()\n</code></pre>"},{"location":"api/#aiperfcommonconfigoutputoutput_config","title":"aiperf.common.config.output.output_config","text":""},{"location":"api/#aiperf.common.config.output.output_config.OutputConfig","title":"<code>OutputConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining output related settings.</p> Source code in <code>aiperf/common/config/output/output_config.py</code> <pre><code>class OutputConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining output related settings.\n    \"\"\"\n\n    artifact_directory: Annotated[\n        Path,\n        Field(\n            description=\"The directory to store all the (output) artifacts generated by\\nAI-Perf.\",\n        ),\n    ] = OutputDefaults.ARTIFACT_DIRECTORY\n</code></pre>"},{"location":"api/#aiperfcommonconfigservice_config","title":"aiperf.common.config.service_config","text":""},{"location":"api/#aiperf.common.config.service_config.ServiceConfig","title":"<code>ServiceConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base configuration for all services.</p> <p>This class provides the common configuration parameters needed by all services.</p> Source code in <code>aiperf/common/config/service_config.py</code> <pre><code>class ServiceConfig(BaseModel):\n    \"\"\"Base configuration for all services.\n\n    This class provides the common configuration parameters needed by all services.\n    \"\"\"\n\n    # TODO: this needs to be cleaned up and finalized\n\n    service_run_type: ServiceRunType = Field(\n        default=ServiceRunType.MULTIPROCESSING,\n        description=\"Type of service run (MULTIPROCESSING, KUBERNETES)\",\n    )\n    comm_backend: CommunicationBackend = Field(\n        default=CommunicationBackend.ZMQ_IPC,\n        description=\"Communication backend to use\",\n    )\n    comm_config: BaseZMQCommunicationConfig | None = Field(\n        default=None,\n        description=\"Communication configuration\",\n    )\n    heartbeat_timeout: float = Field(\n        default=60.0,\n        description=\"Time in seconds after which a service is considered dead if no \"\n        \"heartbeat received\",\n    )\n    registration_timeout: float = Field(\n        default=60.0,\n        description=\"Time in seconds to wait for all required services to register\",\n    )\n    command_timeout: float = Field(\n        default=10.0,\n        description=\"Default timeout for command responses\",\n    )\n    heartbeat_interval: float = Field(\n        default=10.0,\n        description=\"Interval in seconds between heartbeat messages\",\n    )\n    min_workers: int = Field(\n        default=100,\n        description=\"Minimum number of idle workers to maintain\",\n    )\n    max_workers: int = Field(\n        default=100,\n        description=\"Maximum number of workers to create\",\n    )\n    target_idle_workers: int = Field(\n        default=10,\n        description=\"Target number of idle workers to maintain\",\n    )\n</code></pre>"},{"location":"api/#aiperfcommonconfigtokenizertokenizer_config","title":"aiperf.common.config.tokenizer.tokenizer_config","text":""},{"location":"api/#aiperf.common.config.tokenizer.tokenizer_config.TokenizerConfig","title":"<code>TokenizerConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining tokenizer related settings.</p> Source code in <code>aiperf/common/config/tokenizer/tokenizer_config.py</code> <pre><code>class TokenizerConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining tokenizer related settings.\n    \"\"\"\n\n    name: Annotated[\n        str,\n        Field(\n            description=(\n                \"The HuggingFace tokenizer to use to interpret token metrics \"\n                \"from prompts and responses. The value can be the \"\n                \"name of a tokenizer or the filepath of the tokenizer. \"\n                \"The default value is the model name.\"\n            ),\n        ),\n    ] = TokenizerDefaults.NAME\n\n    revision: Annotated[\n        str,\n        Field(\n            description=(\n                \"The specific model version to use. \"\n                \"It can be a branch name, tag name, or commit ID.\"\n            ),\n        ),\n    ] = TokenizerDefaults.REVISION\n\n    trust_remote_code: Annotated[\n        bool,\n        Field(\n            description=(\n                \"Allows custom tokenizer to be downloaded and executed. \"\n                \"This carries security risks and should only be used for repositories you trust. \"\n                \"This is only necessary for custom tokenizers stored in HuggingFace Hub.\"\n            ),\n        ),\n    ] = TokenizerDefaults.TRUST_REMOTE_CODE\n</code></pre>"},{"location":"api/#aiperfcommonconfiguser_config","title":"aiperf.common.config.user_config","text":""},{"location":"api/#aiperf.common.config.user_config.UserConfig","title":"<code>UserConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> <p>A configuration class for defining top-level user settings.</p> Source code in <code>aiperf/common/config/user_config.py</code> <pre><code>class UserConfig(BaseConfig):\n    \"\"\"\n    A configuration class for defining top-level user settings.\n    \"\"\"\n\n    model_names: Annotated[\n        list[str],\n        Field(\n            description=\"Model name(s) to be benchmarked. Can be a comma-separated list or a single model name.\",\n        ),\n        BeforeValidator(parse_str_or_list),\n    ] = UserDefaults.MODEL_NAMES\n\n    verbose: Annotated[\n        bool,\n        Field(\n            description=\"Enable verbose output.\",\n            json_schema_extra={ADD_TO_TEMPLATE: False},\n        ),\n    ] = UserDefaults.VERBOSE\n\n    template_filename: Annotated[\n        str,\n        Field(\n            description=\"Path to the template file.\",\n            json_schema_extra={ADD_TO_TEMPLATE: False},\n        ),\n    ] = UserDefaults.TEMPLATE_FILENAME\n\n    endpoint: EndPointConfig = EndPointConfig()\n    input: InputConfig = InputConfig()\n    output: OutputConfig = OutputConfig()\n    tokenizer: TokenizerConfig = TokenizerConfig()\n</code></pre>"},{"location":"api/#aiperfcommonconfigzmq_config","title":"aiperf.common.config.zmq_config","text":""},{"location":"api/#aiperf.common.config.zmq_config.BaseZMQCommunicationConfig","title":"<code>BaseZMQCommunicationConfig</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Configuration for ZMQ communication.</p> Source code in <code>aiperf/common/config/zmq_config.py</code> <pre><code>class BaseZMQCommunicationConfig(BaseModel, ABC):\n    \"\"\"Configuration for ZMQ communication.\"\"\"\n\n    @property\n    @abstractmethod\n    def controller_pub_sub_address(self) -&gt; str:\n        \"\"\"Get the controller pub/sub address based on protocol configuration.\"\"\"\n        ...\n\n    @property\n    @abstractmethod\n    def component_pub_sub_address(self) -&gt; str:\n        \"\"\"Get the component pub/sub address based on protocol configuration.\"\"\"\n        ...\n\n    @property\n    @abstractmethod\n    def inference_push_pull_address(self) -&gt; str:\n        \"\"\"Get the inference push/pull address based on protocol configuration.\"\"\"\n        ...\n\n    @property\n    @abstractmethod\n    def records_address(self) -&gt; str:\n        \"\"\"Get the records address based on protocol configuration.\"\"\"\n        ...\n\n    @property\n    @abstractmethod\n    def conversation_data_address(self) -&gt; str:\n        \"\"\"Get the conversation data address based on protocol configuration.\"\"\"\n        ...\n\n    @property\n    @abstractmethod\n    def credit_drop_address(self) -&gt; str:\n        \"\"\"Get the credit drop address based on protocol configuration.\"\"\"\n        ...\n\n    @property\n    @abstractmethod\n    def credit_return_address(self) -&gt; str:\n        \"\"\"Get the credit return address based on protocol configuration.\"\"\"\n        ...\n</code></pre>"},{"location":"api/#aiperf.common.config.zmq_config.BaseZMQCommunicationConfig.component_pub_sub_address","title":"<code>component_pub_sub_address</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Get the component pub/sub address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.BaseZMQCommunicationConfig.controller_pub_sub_address","title":"<code>controller_pub_sub_address</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Get the controller pub/sub address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.BaseZMQCommunicationConfig.conversation_data_address","title":"<code>conversation_data_address</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Get the conversation data address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.BaseZMQCommunicationConfig.credit_drop_address","title":"<code>credit_drop_address</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Get the credit drop address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.BaseZMQCommunicationConfig.credit_return_address","title":"<code>credit_return_address</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Get the credit return address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.BaseZMQCommunicationConfig.inference_push_pull_address","title":"<code>inference_push_pull_address</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Get the inference push/pull address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.BaseZMQCommunicationConfig.records_address","title":"<code>records_address</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Get the records address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQIPCConfig","title":"<code>ZMQIPCConfig</code>","text":"<p>               Bases: <code>BaseZMQCommunicationConfig</code></p> <p>Configuration for IPC transport.</p> Source code in <code>aiperf/common/config/zmq_config.py</code> <pre><code>class ZMQIPCConfig(BaseZMQCommunicationConfig):\n    \"\"\"Configuration for IPC transport.\"\"\"\n\n    path: str = Field(default=\"/tmp/aiperf\", description=\"Path for IPC sockets\")\n\n    @property\n    def controller_pub_sub_address(self) -&gt; str:\n        \"\"\"Get the controller pub/sub address based on protocol configuration.\"\"\"\n        return f\"ipc://{self.path}/controller_pub_sub.ipc\"\n\n    @property\n    def component_pub_sub_address(self) -&gt; str:\n        \"\"\"Get the component pub/sub address based on protocol configuration.\"\"\"\n        return f\"ipc://{self.path}/component_pub_sub.ipc\"\n\n    @property\n    def inference_push_pull_address(self) -&gt; str:\n        \"\"\"Get the inference push/pull address based on protocol configuration.\"\"\"\n        return f\"ipc://{self.path}/inference_push_pull.ipc\"\n\n    @property\n    def records_address(self) -&gt; str:\n        \"\"\"Get the records address based on protocol configuration.\"\"\"\n        return f\"ipc://{self.path}/records.ipc\"\n\n    @property\n    def conversation_data_address(self) -&gt; str:\n        \"\"\"Get the conversation data address based on protocol configuration.\"\"\"\n        return f\"ipc://{self.path}/conversation_data.ipc\"\n\n    @property\n    def credit_drop_address(self) -&gt; str:\n        \"\"\"Get the credit drop address based on protocol configuration.\"\"\"\n        return f\"ipc://{self.path}/credit_drop.ipc\"\n\n    @property\n    def credit_return_address(self) -&gt; str:\n        \"\"\"Get the credit return address based on protocol configuration.\"\"\"\n        return f\"ipc://{self.path}/credit_return.ipc\"\n</code></pre>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQIPCConfig.component_pub_sub_address","title":"<code>component_pub_sub_address</code>  <code>property</code>","text":"<p>Get the component pub/sub address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQIPCConfig.controller_pub_sub_address","title":"<code>controller_pub_sub_address</code>  <code>property</code>","text":"<p>Get the controller pub/sub address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQIPCConfig.conversation_data_address","title":"<code>conversation_data_address</code>  <code>property</code>","text":"<p>Get the conversation data address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQIPCConfig.credit_drop_address","title":"<code>credit_drop_address</code>  <code>property</code>","text":"<p>Get the credit drop address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQIPCConfig.credit_return_address","title":"<code>credit_return_address</code>  <code>property</code>","text":"<p>Get the credit return address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQIPCConfig.inference_push_pull_address","title":"<code>inference_push_pull_address</code>  <code>property</code>","text":"<p>Get the inference push/pull address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQIPCConfig.records_address","title":"<code>records_address</code>  <code>property</code>","text":"<p>Get the records address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQInprocConfig","title":"<code>ZMQInprocConfig</code>","text":"<p>               Bases: <code>ZMQIPCConfig</code></p> <p>Configuration for in-process transport. Note that communications between workers is still done over IPC sockets.</p> Source code in <code>aiperf/common/config/zmq_config.py</code> <pre><code>class ZMQInprocConfig(ZMQIPCConfig):\n    \"\"\"Configuration for in-process transport. Note that communications between workers\n    is still done over IPC sockets.\"\"\"\n\n    name: str = Field(default=\"aiperf\", description=\"Name for in-process sockets\")\n\n    @property\n    def controller_pub_sub_address(self) -&gt; str:\n        \"\"\"Get the controller pub/sub address based on protocol configuration.\"\"\"\n        return f\"inproc://{self.name}_controller_pub_sub\"\n\n    @property\n    def component_pub_sub_address(self) -&gt; str:\n        \"\"\"Get the component pub/sub address based on protocol configuration.\"\"\"\n        return f\"inproc://{self.name}_component_pub_sub\"\n</code></pre>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQInprocConfig.component_pub_sub_address","title":"<code>component_pub_sub_address</code>  <code>property</code>","text":"<p>Get the component pub/sub address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQInprocConfig.controller_pub_sub_address","title":"<code>controller_pub_sub_address</code>  <code>property</code>","text":"<p>Get the controller pub/sub address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQTCPTransportConfig","title":"<code>ZMQTCPTransportConfig</code>","text":"<p>               Bases: <code>BaseZMQCommunicationConfig</code></p> <p>Configuration for TCP transport.</p> Source code in <code>aiperf/common/config/zmq_config.py</code> <pre><code>class ZMQTCPTransportConfig(BaseZMQCommunicationConfig):\n    \"\"\"Configuration for TCP transport.\"\"\"\n\n    host: str = Field(\n        default=\"0.0.0.0\",\n        description=\"Host address for TCP connections\",\n    )\n    controller_pub_sub_port: int = Field(\n        default=5555, description=\"Port for controller pub/sub messages\"\n    )\n    component_pub_sub_port: int = Field(\n        default=5556, description=\"Port for component pub/sub messages\"\n    )\n    inference_push_pull_port: int = Field(\n        default=5557, description=\"Port for inference push/pull messages\"\n    )\n    req_rep_port: int = Field(\n        default=5558, description=\"Port for sending and receiving requests\"\n    )\n    push_pull_port: int = Field(\n        default=5559, description=\"Port for pushing and pulling data\"\n    )\n    records_port: int = Field(default=5560, description=\"Port for record data\")\n    conversation_data_port: int = Field(\n        default=5561, description=\"Port for conversation data\"\n    )\n    credit_drop_port: int = Field(\n        default=5562, description=\"Port for credit drop operations\"\n    )\n    credit_return_port: int = Field(\n        default=5563, description=\"Port for credit return operations\"\n    )\n\n    @property\n    def controller_pub_sub_address(self) -&gt; str:\n        \"\"\"Get the controller pub/sub address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.host}:{self.controller_pub_sub_port}\"\n\n    @property\n    def component_pub_sub_address(self) -&gt; str:\n        \"\"\"Get the component pub/sub address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.host}:{self.component_pub_sub_port}\"\n\n    @property\n    def inference_push_pull_address(self) -&gt; str:\n        \"\"\"Get the inference push/pull address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.host}:{self.inference_push_pull_port}\"\n\n    @property\n    def records_address(self) -&gt; str:\n        \"\"\"Get the records address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.host}:{self.records_port}\"\n\n    @property\n    def conversation_data_address(self) -&gt; str:\n        \"\"\"Get the conversation data address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.host}:{self.conversation_data_port}\"\n\n    @property\n    def credit_drop_address(self) -&gt; str:\n        \"\"\"Get the credit drop address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.host}:{self.credit_drop_port}\"\n\n    @property\n    def credit_return_address(self) -&gt; str:\n        \"\"\"Get the credit return address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.host}:{self.credit_return_port}\"\n</code></pre>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQTCPTransportConfig.component_pub_sub_address","title":"<code>component_pub_sub_address</code>  <code>property</code>","text":"<p>Get the component pub/sub address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQTCPTransportConfig.controller_pub_sub_address","title":"<code>controller_pub_sub_address</code>  <code>property</code>","text":"<p>Get the controller pub/sub address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQTCPTransportConfig.conversation_data_address","title":"<code>conversation_data_address</code>  <code>property</code>","text":"<p>Get the conversation data address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQTCPTransportConfig.credit_drop_address","title":"<code>credit_drop_address</code>  <code>property</code>","text":"<p>Get the credit drop address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQTCPTransportConfig.credit_return_address","title":"<code>credit_return_address</code>  <code>property</code>","text":"<p>Get the credit return address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQTCPTransportConfig.inference_push_pull_address","title":"<code>inference_push_pull_address</code>  <code>property</code>","text":"<p>Get the inference push/pull address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.config.zmq_config.ZMQTCPTransportConfig.records_address","title":"<code>records_address</code>  <code>property</code>","text":"<p>Get the records address based on protocol configuration.</p>"},{"location":"api/#aiperfcommonconstants","title":"aiperf.common.constants","text":""},{"location":"api/#aiperfcommonenums","title":"aiperf.common.enums","text":""},{"location":"api/#aiperf.common.enums.CaseInsensitiveStrEnum","title":"<code>CaseInsensitiveStrEnum</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>CaseInsensitiveStrEnum is a custom enumeration class that extends <code>str</code> and <code>Enum</code> to provide case-insensitive lookup functionality for its members.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class CaseInsensitiveStrEnum(str, Enum):\n    \"\"\"\n    CaseInsensitiveStrEnum is a custom enumeration class that extends `str` and `Enum` to provide case-insensitive\n    lookup functionality for its members.\n    \"\"\"\n\n    def __str__(self) -&gt; str:\n        return self.value\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}.{self.name}\"\n\n    def __eq__(self, other: Any) -&gt; bool:\n        if isinstance(other, str):\n            return self.value.lower() == other.lower()\n        return super().__eq__(other)\n\n    def __hash__(self) -&gt; int:\n        return hash(self.value.lower())\n\n    @classmethod\n    def _missing_(cls, value):\n        \"\"\"\n        Handles cases where a value is not directly found in the enumeration.\n\n        This method is called when an attempt is made to access an enumeration\n        member using a value that does not directly match any of the defined\n        members. It provides custom logic to handle such cases.\n\n        Returns:\n            The matching enumeration member if a case-insensitive match is found\n            for string values; otherwise, returns None.\n        \"\"\"\n        if isinstance(value, str):\n            for member in cls:\n                if member.value.lower() == value.lower():\n                    return member\n        return None\n</code></pre>"},{"location":"api/#aiperf.common.enums.CommandType","title":"<code>CommandType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>List of commands that the SystemController can send to component services.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class CommandType(CaseInsensitiveStrEnum):\n    \"\"\"List of commands that the SystemController can send to component services.\"\"\"\n\n    PROFILE_CONFIGURE = \"profile_configure\"\n    \"\"\"A command sent to configure a service in preparation for a profile run. This will\n    override the current configuration.\"\"\"\n\n    PROFILE_START = \"profile_start\"\n    \"\"\"A command sent to indicate that a service should begin profiling using the\n    current configuration.\"\"\"\n\n    PROFILE_STOP = \"profile_stop\"\n    \"\"\"A command sent to indicate that a service should stop doing profile related\n    work, as the profile run is complete.\"\"\"\n\n    PROFILE_CANCEL = \"profile_cancel\"\n    \"\"\"A command sent to cancel a profile run. This will stop the current profile run and\n    process the partial results.\"\"\"\n\n    SHUTDOWN = \"shutdown\"\n    \"\"\"A command sent to shutdown a service. This will stop the service gracefully\n    no matter what state it is in.\"\"\"\n\n    PROCESS_RECORDS = \"process_records\"\n    \"\"\"A command sent to process records. This will process the records and return\n    the services to their pre-record processing state.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.CommandType.PROCESS_RECORDS","title":"<code>PROCESS_RECORDS = 'process_records'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A command sent to process records. This will process the records and return the services to their pre-record processing state.</p>"},{"location":"api/#aiperf.common.enums.CommandType.PROFILE_CANCEL","title":"<code>PROFILE_CANCEL = 'profile_cancel'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A command sent to cancel a profile run. This will stop the current profile run and process the partial results.</p>"},{"location":"api/#aiperf.common.enums.CommandType.PROFILE_CONFIGURE","title":"<code>PROFILE_CONFIGURE = 'profile_configure'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A command sent to configure a service in preparation for a profile run. This will override the current configuration.</p>"},{"location":"api/#aiperf.common.enums.CommandType.PROFILE_START","title":"<code>PROFILE_START = 'profile_start'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A command sent to indicate that a service should begin profiling using the current configuration.</p>"},{"location":"api/#aiperf.common.enums.CommandType.PROFILE_STOP","title":"<code>PROFILE_STOP = 'profile_stop'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A command sent to indicate that a service should stop doing profile related work, as the profile run is complete.</p>"},{"location":"api/#aiperf.common.enums.CommandType.SHUTDOWN","title":"<code>SHUTDOWN = 'shutdown'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A command sent to shutdown a service. This will stop the service gracefully no matter what state it is in.</p>"},{"location":"api/#aiperf.common.enums.CommunicationBackend","title":"<code>CommunicationBackend</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Supported communication backends.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class CommunicationBackend(CaseInsensitiveStrEnum):\n    \"\"\"Supported communication backends.\"\"\"\n\n    ZMQ_TCP = \"zmq_tcp\"\n    \"\"\"ZeroMQ backend using TCP sockets.\"\"\"\n\n    ZMQ_IPC = \"zmq_ipc\"\n    \"\"\"ZeroMQ backend using IPC sockets.\"\"\"\n\n    ZMQ_INPROC = \"zmq_inproc\"\n    \"\"\"ZeroMQ backend using in-process communication.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.CommunicationBackend.ZMQ_INPROC","title":"<code>ZMQ_INPROC = 'zmq_inproc'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZeroMQ backend using in-process communication.</p>"},{"location":"api/#aiperf.common.enums.CommunicationBackend.ZMQ_IPC","title":"<code>ZMQ_IPC = 'zmq_ipc'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZeroMQ backend using IPC sockets.</p>"},{"location":"api/#aiperf.common.enums.CommunicationBackend.ZMQ_TCP","title":"<code>ZMQ_TCP = 'zmq_tcp'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZeroMQ backend using TCP sockets.</p>"},{"location":"api/#aiperf.common.enums.InferenceClientType","title":"<code>InferenceClientType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Inference client types.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class InferenceClientType(CaseInsensitiveStrEnum):\n    \"\"\"Inference client types.\"\"\"\n\n    GRPC = \"grpc\"\n    HTTP = \"http\"\n    OPENAI = \"openai\"\n    DYNAMO = \"dynamo\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.MessageType","title":"<code>MessageType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>The various types of messages that can be sent between services.</p> <p>The message type is used to determine what Pydantic model the message maps to, based on the message_type field in the message model.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class MessageType(CaseInsensitiveStrEnum):\n    \"\"\"The various types of messages that can be sent between services.\n\n    The message type is used to determine what Pydantic model the message maps to,\n    based on the message_type field in the message model.\n    \"\"\"\n\n    UNKNOWN = \"unknown\"\n    \"\"\"A placeholder value for when the message type is not known.\"\"\"\n\n    REGISTRATION = \"registration\"\n    \"\"\"A message sent by a component service to register itself with the\n    system controller.\"\"\"\n\n    HEARTBEAT = \"heartbeat\"\n    \"\"\"A message sent by a component service to the system controller to indicate it\n    is still running.\"\"\"\n\n    COMMAND = \"command\"\n    \"\"\"A message sent by the system controller to a component service to command it\n    to do something.\"\"\"\n\n    RESPONSE = \"response\"\n    \"\"\"A message sent by a component service to the system controller to respond\n    to a command.\"\"\"\n\n    STATUS = \"status\"\n    \"\"\"A notification sent by a component service to the system controller to\n    report its status.\"\"\"\n\n    ERROR = \"error\"\n    \"\"\"A generic error message.\"\"\"\n\n    SERVICE_ERROR = \"service_error\"\n    \"\"\"A message sent by a component service to the system controller to\n    report an error.\"\"\"\n\n    CREDIT_DROP = \"credit_drop\"\n    \"\"\"A message sent by the Timing Manager service to allocate credits\n    for a worker.\"\"\"\n\n    CREDIT_RETURN = \"credit_return\"\n    \"\"\"A message sent by the Worker services to return credits to the credit pool.\"\"\"\n\n    CREDITS_COMPLETE = \"credits_complete\"\n    \"\"\"A message sent by the Timing Manager services to signify all requests have completed.\"\"\"\n\n    CONVERSATION_REQUEST = \"conversation_request\"\n    \"\"\"A message sent by one service to another to request a conversation.\"\"\"\n\n    CONVERSATION_RESPONSE = \"conversation_response\"\n    \"\"\"A message sent by one service to another to respond to a conversation request.\"\"\"\n\n    INFERENCE_RESULTS = \"inference_results\"\n    \"\"\"A message containing inference results from a worker.\"\"\"\n\n    # Sweep run messages\n\n    SWEEP_CONFIGURE = \"sweep_configure\"\n    \"\"\"A message sent to configure a sweep run.\"\"\"\n\n    SWEEP_BEGIN = \"sweep_begin\"\n    \"\"\"A message sent to indicate that a sweep has begun.\"\"\"\n\n    SWEEP_PROGRESS = \"sweep_progress\"\n    \"\"\"A message containing sweep run progress.\"\"\"\n\n    SWEEP_END = \"sweep_end\"\n    \"\"\"A message sent to indicate that a sweep has ended.\"\"\"\n\n    SWEEP_RESULTS = \"sweep_results\"\n    \"\"\"A message containing sweep run results.\"\"\"\n\n    SWEEP_ERROR = \"sweep_error\"\n    \"\"\"A message containing an error from a sweep run.\"\"\"\n\n    # Profile run messages\n\n    PROFILE_PROGRESS = \"profile_progress\"\n    \"\"\"A message containing profile run progress.\"\"\"\n\n    PROFILE_STATS = \"profile_stats\"\n    \"\"\"A message containing profile run stats such as error rates, etc.\"\"\"\n\n    PROFILE_RESULTS = \"profile_results\"\n    \"\"\"A message containing profile run results.\"\"\"\n\n    PROFILE_ERROR = \"profile_error\"\n    \"\"\"A message containing an error from a profile run.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.MessageType.COMMAND","title":"<code>COMMAND = 'command'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by the system controller to a component service to command it to do something.</p>"},{"location":"api/#aiperf.common.enums.MessageType.CONVERSATION_REQUEST","title":"<code>CONVERSATION_REQUEST = 'conversation_request'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by one service to another to request a conversation.</p>"},{"location":"api/#aiperf.common.enums.MessageType.CONVERSATION_RESPONSE","title":"<code>CONVERSATION_RESPONSE = 'conversation_response'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by one service to another to respond to a conversation request.</p>"},{"location":"api/#aiperf.common.enums.MessageType.CREDITS_COMPLETE","title":"<code>CREDITS_COMPLETE = 'credits_complete'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by the Timing Manager services to signify all requests have completed.</p>"},{"location":"api/#aiperf.common.enums.MessageType.CREDIT_DROP","title":"<code>CREDIT_DROP = 'credit_drop'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by the Timing Manager service to allocate credits for a worker.</p>"},{"location":"api/#aiperf.common.enums.MessageType.CREDIT_RETURN","title":"<code>CREDIT_RETURN = 'credit_return'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by the Worker services to return credits to the credit pool.</p>"},{"location":"api/#aiperf.common.enums.MessageType.ERROR","title":"<code>ERROR = 'error'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A generic error message.</p>"},{"location":"api/#aiperf.common.enums.MessageType.HEARTBEAT","title":"<code>HEARTBEAT = 'heartbeat'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by a component service to the system controller to indicate it is still running.</p>"},{"location":"api/#aiperf.common.enums.MessageType.INFERENCE_RESULTS","title":"<code>INFERENCE_RESULTS = 'inference_results'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message containing inference results from a worker.</p>"},{"location":"api/#aiperf.common.enums.MessageType.PROFILE_ERROR","title":"<code>PROFILE_ERROR = 'profile_error'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message containing an error from a profile run.</p>"},{"location":"api/#aiperf.common.enums.MessageType.PROFILE_PROGRESS","title":"<code>PROFILE_PROGRESS = 'profile_progress'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message containing profile run progress.</p>"},{"location":"api/#aiperf.common.enums.MessageType.PROFILE_RESULTS","title":"<code>PROFILE_RESULTS = 'profile_results'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message containing profile run results.</p>"},{"location":"api/#aiperf.common.enums.MessageType.PROFILE_STATS","title":"<code>PROFILE_STATS = 'profile_stats'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message containing profile run stats such as error rates, etc.</p>"},{"location":"api/#aiperf.common.enums.MessageType.REGISTRATION","title":"<code>REGISTRATION = 'registration'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by a component service to register itself with the system controller.</p>"},{"location":"api/#aiperf.common.enums.MessageType.RESPONSE","title":"<code>RESPONSE = 'response'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by a component service to the system controller to respond to a command.</p>"},{"location":"api/#aiperf.common.enums.MessageType.SERVICE_ERROR","title":"<code>SERVICE_ERROR = 'service_error'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent by a component service to the system controller to report an error.</p>"},{"location":"api/#aiperf.common.enums.MessageType.STATUS","title":"<code>STATUS = 'status'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A notification sent by a component service to the system controller to report its status.</p>"},{"location":"api/#aiperf.common.enums.MessageType.SWEEP_BEGIN","title":"<code>SWEEP_BEGIN = 'sweep_begin'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent to indicate that a sweep has begun.</p>"},{"location":"api/#aiperf.common.enums.MessageType.SWEEP_CONFIGURE","title":"<code>SWEEP_CONFIGURE = 'sweep_configure'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent to configure a sweep run.</p>"},{"location":"api/#aiperf.common.enums.MessageType.SWEEP_END","title":"<code>SWEEP_END = 'sweep_end'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message sent to indicate that a sweep has ended.</p>"},{"location":"api/#aiperf.common.enums.MessageType.SWEEP_ERROR","title":"<code>SWEEP_ERROR = 'sweep_error'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message containing an error from a sweep run.</p>"},{"location":"api/#aiperf.common.enums.MessageType.SWEEP_PROGRESS","title":"<code>SWEEP_PROGRESS = 'sweep_progress'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message containing sweep run progress.</p>"},{"location":"api/#aiperf.common.enums.MessageType.SWEEP_RESULTS","title":"<code>SWEEP_RESULTS = 'sweep_results'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A message containing sweep run results.</p>"},{"location":"api/#aiperf.common.enums.MessageType.UNKNOWN","title":"<code>UNKNOWN = 'unknown'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A placeholder value for when the message type is not known.</p>"},{"location":"api/#aiperf.common.enums.MetricTimeType","title":"<code>MetricTimeType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Defines the time types for metrics.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class MetricTimeType(Enum):\n    \"\"\"Defines the time types for metrics.\"\"\"\n\n    NANOSECONDS = 9\n    MILLISECONDS = 3\n    SECONDS = 0\n</code></pre>"},{"location":"api/#aiperf.common.enums.Modality","title":"<code>Modality</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Modality of the model. Can be used to determine the type of data to send to the model in conjunction with the ModelSelectionStrategy.MODALITY_AWARE.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class Modality(CaseInsensitiveStrEnum):\n    \"\"\"Modality of the model. Can be used to determine the type of data to send to the model in\n    conjunction with the ModelSelectionStrategy.MODALITY_AWARE.\"\"\"\n\n    TEXT = \"text\"\n    IMAGE = \"image\"\n    AUDIO = \"audio\"\n    VIDEO = \"video\"\n    MULTIMODAL = \"multimodal\"\n    CUSTOM = \"custom\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.ModelSelectionStrategy","title":"<code>ModelSelectionStrategy</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Strategy for selecting the model to use for the request.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class ModelSelectionStrategy(CaseInsensitiveStrEnum):\n    \"\"\"Strategy for selecting the model to use for the request.\"\"\"\n\n    ROUND_ROBIN = \"round_robin\"\n    RANDOM = \"random\"\n    MODALITY_AWARE = \"modality_aware\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.PromptSource","title":"<code>PromptSource</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Source of prompts for the model.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class PromptSource(CaseInsensitiveStrEnum):\n    \"\"\"Source of prompts for the model.\"\"\"\n\n    SYNTHETIC = \"synthetic\"\n    FILE = \"file\"\n    PAYLOAD = \"payload\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.RequestPayloadType","title":"<code>RequestPayloadType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Request payload types.</p> <p>These determine the format of the request payload to send to the model.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class RequestPayloadType(CaseInsensitiveStrEnum):\n    \"\"\"Request payload types.\n\n    These determine the format of the request payload to send to the model.\n    \"\"\"\n\n    OPENAI_CHAT_COMPLETIONS = \"openai_chat_completions\"\n    OPENAI_COMPLETIONS = \"openai_completions\"\n    OPENAI_EMBEDDINGS = \"openai_embeddings\"\n    OPENAI_MULTIMODAL = \"openai_multimodal\"\n    OPENAI_RESPONSES = \"openai_responses\"\n\n    HUGGINGFACE_GENERATE = \"huggingface_generate\"\n    HUGGINGFACE_RANKINGS = \"huggingface_rankings\"\n\n    IMAGE_RETRIEVAL = \"image_retrieval\"\n    DYNAMIC_GRPC = \"dynamic_grpc\"\n    NVCLIP = \"nvclip\"\n\n    RANKINGS = \"rankings\"\n    TEMPLATE = \"template\"\n\n    TENSORRTLLM = \"tensorrtllm\"\n    VLLM = \"vllm\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.ResponsePayloadType","title":"<code>ResponsePayloadType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Response payload types.</p> <p>These determine the format of the response payload that the model will return.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class ResponsePayloadType(CaseInsensitiveStrEnum):\n    \"\"\"Response payload types.\n\n    These determine the format of the response payload that the model will return.\n    \"\"\"\n\n    HUGGINGFACE_GENERATE = \"huggingface_generate\"\n    HUGGINGFACE_RANKINGS = \"huggingface_rankings\"\n\n    OPENAI_CHAT_COMPLETIONS = \"openai_chat_completions\"\n    OPENAI_COMPLETIONS = \"openai_completions\"\n    OPENAI_EMBEDDINGS = \"openai_embeddings\"\n    OPENAI_MULTIMODAL = \"openai_multimodal\"\n    OPENAI_RESPONSES = \"openai_responses\"\n\n    RANKINGS = \"rankings\"\n    IMAGE_RETRIEVAL = \"image_retrieval\"\n\n    TRITON = \"triton\"\n    TRITON_GENERATE = \"triton_generate\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.ServiceRegistrationStatus","title":"<code>ServiceRegistrationStatus</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Defines the various states a service can be in during registration with the SystemController.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class ServiceRegistrationStatus(CaseInsensitiveStrEnum):\n    \"\"\"Defines the various states a service can be in during registration with\n    the SystemController.\"\"\"\n\n    UNREGISTERED = \"unregistered\"\n    \"\"\"The service is not registered with the SystemController. This is the\n    initial state.\"\"\"\n\n    WAITING = \"waiting\"\n    \"\"\"The service is waiting for the SystemController to register it.\n    This is a temporary state that should be followed by REGISTERED.\"\"\"\n\n    REGISTERED = \"registered\"\n    \"\"\"The service is registered with the SystemController.\"\"\"\n\n    TIMEOUT = \"timeout\"\n    \"\"\"The service registration timed out.\"\"\"\n\n    ERROR = \"error\"\n    \"\"\"The service registration failed.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.ServiceRegistrationStatus.ERROR","title":"<code>ERROR = 'error'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service registration failed.</p>"},{"location":"api/#aiperf.common.enums.ServiceRegistrationStatus.REGISTERED","title":"<code>REGISTERED = 'registered'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is registered with the SystemController.</p>"},{"location":"api/#aiperf.common.enums.ServiceRegistrationStatus.TIMEOUT","title":"<code>TIMEOUT = 'timeout'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service registration timed out.</p>"},{"location":"api/#aiperf.common.enums.ServiceRegistrationStatus.UNREGISTERED","title":"<code>UNREGISTERED = 'unregistered'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is not registered with the SystemController. This is the initial state.</p>"},{"location":"api/#aiperf.common.enums.ServiceRegistrationStatus.WAITING","title":"<code>WAITING = 'waiting'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is waiting for the SystemController to register it. This is a temporary state that should be followed by REGISTERED.</p>"},{"location":"api/#aiperf.common.enums.ServiceRunType","title":"<code>ServiceRunType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>The different ways the SystemController should run the component services.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class ServiceRunType(CaseInsensitiveStrEnum):\n    \"\"\"The different ways the SystemController should run the component services.\"\"\"\n\n    MULTIPROCESSING = \"process\"\n    \"\"\"Run each service as a separate process.\n    This is the default way for single-node deployments.\"\"\"\n\n    KUBERNETES = \"k8s\"\n    \"\"\"Run each service as a separate Kubernetes pod.\n    This is the default way for multi-node deployments.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.ServiceRunType.KUBERNETES","title":"<code>KUBERNETES = 'k8s'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Run each service as a separate Kubernetes pod. This is the default way for multi-node deployments.</p>"},{"location":"api/#aiperf.common.enums.ServiceRunType.MULTIPROCESSING","title":"<code>MULTIPROCESSING = 'process'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Run each service as a separate process. This is the default way for single-node deployments.</p>"},{"location":"api/#aiperf.common.enums.ServiceState","title":"<code>ServiceState</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>States a service can be in throughout its lifecycle.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class ServiceState(CaseInsensitiveStrEnum):\n    \"\"\"States a service can be in throughout its lifecycle.\"\"\"\n\n    UNKNOWN = \"unknown\"\n\n    INITIALIZING = \"initializing\"\n    \"\"\"The service is currently initializing. This is a temporary state that should be\n    followed by READY.\"\"\"\n\n    READY = \"ready\"\n    \"\"\"The service has initialized and is ready to be configured or started.\"\"\"\n\n    STARTING = \"starting\"\n    \"\"\"The service is starting. This is a temporary state that should be followed\n    by RUNNING.\"\"\"\n\n    RUNNING = \"running\"\n\n    STOPPING = \"stopping\"\n    \"\"\"The service is stopping. This is a temporary state that should be followed\n    by STOPPED.\"\"\"\n\n    STOPPED = \"stopped\"\n\n    ERROR = \"error\"\n    \"\"\"The service is currently in an error state.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.ServiceState.ERROR","title":"<code>ERROR = 'error'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is currently in an error state.</p>"},{"location":"api/#aiperf.common.enums.ServiceState.INITIALIZING","title":"<code>INITIALIZING = 'initializing'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is currently initializing. This is a temporary state that should be followed by READY.</p>"},{"location":"api/#aiperf.common.enums.ServiceState.READY","title":"<code>READY = 'ready'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service has initialized and is ready to be configured or started.</p>"},{"location":"api/#aiperf.common.enums.ServiceState.STARTING","title":"<code>STARTING = 'starting'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is starting. This is a temporary state that should be followed by RUNNING.</p>"},{"location":"api/#aiperf.common.enums.ServiceState.STOPPING","title":"<code>STOPPING = 'stopping'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The service is stopping. This is a temporary state that should be followed by STOPPED.</p>"},{"location":"api/#aiperf.common.enums.ServiceType","title":"<code>ServiceType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Types of services in the AIPerf system.</p> <p>This is used to identify the service type when registering with the SystemController. It can also be used for tracking purposes if multiple instances of the same service type are running.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class ServiceType(CaseInsensitiveStrEnum):\n    \"\"\"Types of services in the AIPerf system.\n\n    This is used to identify the service type when registering with the\n    SystemController. It can also be used for tracking purposes if multiple\n    instances of the same service type are running.\n    \"\"\"\n\n    SYSTEM_CONTROLLER = \"system_controller\"\n    DATASET_MANAGER = \"dataset_manager\"\n    TIMING_MANAGER = \"timing_manager\"\n    RECORDS_MANAGER = \"records_manager\"\n    POST_PROCESSOR_MANAGER = \"post_processor_manager\"\n    WORKER_MANAGER = \"worker_manager\"\n    MULTI_WORKER_PROCESS = \"multi_worker_process\"\n    WORKER = \"worker\"\n    TEST = \"test_service\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.SystemState","title":"<code>SystemState</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>State of the system as a whole.</p> <p>This is used to track the state of the system as a whole, and is used to determine what actions to take when a signal is received.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class SystemState(CaseInsensitiveStrEnum):\n    \"\"\"State of the system as a whole.\n\n    This is used to track the state of the system as a whole, and is used to\n    determine what actions to take when a signal is received.\n    \"\"\"\n\n    INITIALIZING = \"initializing\"\n    \"\"\"The system is initializing. This is the initial state.\"\"\"\n\n    CONFIGURING = \"configuring\"\n    \"\"\"The system is configuring services.\"\"\"\n\n    READY = \"ready\"\n    \"\"\"The system is ready to start profiling. This is a temporary state that should be\n    followed by PROFILING.\"\"\"\n\n    PROFILING = \"profiling\"\n    \"\"\"The system is running a profiling run.\"\"\"\n\n    PROCESSING = \"processing\"\n    \"\"\"The system is processing results.\"\"\"\n\n    STOPPING = \"stopping\"\n    \"\"\"The system is stopping.\"\"\"\n\n    SHUTDOWN = \"shutdown\"\n    \"\"\"The system is shutting down. This is the final state.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.enums.SystemState.CONFIGURING","title":"<code>CONFIGURING = 'configuring'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The system is configuring services.</p>"},{"location":"api/#aiperf.common.enums.SystemState.INITIALIZING","title":"<code>INITIALIZING = 'initializing'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The system is initializing. This is the initial state.</p>"},{"location":"api/#aiperf.common.enums.SystemState.PROCESSING","title":"<code>PROCESSING = 'processing'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The system is processing results.</p>"},{"location":"api/#aiperf.common.enums.SystemState.PROFILING","title":"<code>PROFILING = 'profiling'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The system is running a profiling run.</p>"},{"location":"api/#aiperf.common.enums.SystemState.READY","title":"<code>READY = 'ready'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The system is ready to start profiling. This is a temporary state that should be followed by PROFILING.</p>"},{"location":"api/#aiperf.common.enums.SystemState.SHUTDOWN","title":"<code>SHUTDOWN = 'shutdown'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The system is shutting down. This is the final state.</p>"},{"location":"api/#aiperf.common.enums.SystemState.STOPPING","title":"<code>STOPPING = 'stopping'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The system is stopping.</p>"},{"location":"api/#aiperf.common.enums.Topic","title":"<code>Topic</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Communication topics for the main messaging bus. Right now, there is some overlap between Topic and MessageType.</p> <p>NOTE: If you add a new topic, you must also add handlers for it in the ClientType enums so the system knows what type of client to use for that topic.</p> Source code in <code>aiperf/common/enums.py</code> <pre><code>class Topic(CaseInsensitiveStrEnum):\n    \"\"\"Communication topics for the main messaging bus.\n    Right now, there is some overlap between Topic and MessageType.\n\n    NOTE: If you add a new topic, you must also add handlers for it in the\n    ClientType enums so the system knows what type of client to use for that topic.\n    \"\"\"\n\n    CREDIT_DROP = \"credit_drop\"\n    CREDIT_RETURN = \"credit_return\"\n    CREDITS_COMPLETE = \"credits_complete\"\n    PROFILE_PROGRESS = \"profile_progress\"\n    PROFILE_STATS = \"profile_stats\"\n    PROFILE_RESULTS = \"profile_results\"\n    REGISTRATION = \"registration\"\n    COMMAND = \"command\"\n    RESPONSE = \"response\"\n    STATUS = \"status\"\n    HEARTBEAT = \"heartbeat\"\n    INFERENCE_RESULTS = \"inference_results\"\n    CONVERSATION_DATA = \"conversation_data\"\n</code></pre>"},{"location":"api/#aiperfcommonexceptions","title":"aiperf.common.exceptions","text":""},{"location":"api/#aiperf.common.exceptions.AIPerfError","title":"<code>AIPerfError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base class for all exceptions raised by AIPerf.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class AIPerfError(Exception):\n    \"\"\"Base class for all exceptions raised by AIPerf.\"\"\"\n\n    def __str__(self) -&gt; str:\n        return f\"{self.__class__.__name__}: {super().__str__()}\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.AIPerfMultiError","title":"<code>AIPerfMultiError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Exception raised when running multiple tasks and one or more fail.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class AIPerfMultiError(AIPerfError):\n    \"\"\"Exception raised when running multiple tasks and one or more fail.\"\"\"\n\n    def __init__(self, message: str, exceptions: list[Exception]) -&gt; None:\n        super().__init__(f\"{message}: {','.join([str(e) for e in exceptions])}\")\n        self.exceptions = exceptions\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.CommunicationError","title":"<code>CommunicationError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Base class for all communication exceptions.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class CommunicationError(AIPerfError):\n    \"\"\"Base class for all communication exceptions.\"\"\"\n\n    def __init__(self, reason: CommunicationErrorReason, message: str) -&gt; None:\n        super().__init__(f\"Communication Error {reason.name}: {message}\")\n        self.reason = reason\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ConfigError","title":"<code>ConfigError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Base class for all exceptions raised by configuration errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ConfigError(AIPerfError):\n    \"\"\"Base class for all exceptions raised by configuration errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ConfigLoadError","title":"<code>ConfigLoadError</code>","text":"<p>               Bases: <code>ConfigError</code></p> <p>Exception raised for configuration load errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ConfigLoadError(ConfigError):\n    \"\"\"Exception raised for configuration load errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ConfigParseError","title":"<code>ConfigParseError</code>","text":"<p>               Bases: <code>ConfigError</code></p> <p>Exception raised for configuration parse errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ConfigParseError(ConfigError):\n    \"\"\"Exception raised for configuration parse errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ConfigValidationError","title":"<code>ConfigValidationError</code>","text":"<p>               Bases: <code>ConfigError</code></p> <p>Exception raised for configuration validation errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ConfigValidationError(ConfigError):\n    \"\"\"Exception raised for configuration validation errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.FactoryCreationError","title":"<code>FactoryCreationError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Exception raised when a factory encounters an error while creating a class.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class FactoryCreationError(AIPerfError):\n    \"\"\"Exception raised when a factory encounters an error while creating a class.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.GeneratorConfigurationError","title":"<code>GeneratorConfigurationError</code>","text":"<p>               Bases: <code>GeneratorError</code></p> <p>Exception raised for data generator configuration errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class GeneratorConfigurationError(GeneratorError):\n    \"\"\"Exception raised for data generator configuration errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.GeneratorError","title":"<code>GeneratorError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Base class for all exceptions raised by data generator modules.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class GeneratorError(AIPerfError):\n    \"\"\"Base class for all exceptions raised by data generator modules.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.GeneratorInitializationError","title":"<code>GeneratorInitializationError</code>","text":"<p>               Bases: <code>GeneratorError</code></p> <p>Exception raised for data generator initialization errors.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class GeneratorInitializationError(GeneratorError):\n    \"\"\"Exception raised for data generator initialization errors.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.MetricTypeError","title":"<code>MetricTypeError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Exception raised when a metric type encounters an error while creating a class.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class MetricTypeError(AIPerfError):\n    \"\"\"Exception raised when a metric type encounters an error while creating a class.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.ServiceError","title":"<code>ServiceError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Base class for all exceptions raised by services.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class ServiceError(AIPerfError):\n    \"\"\"Base class for all exceptions raised by services.\"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        service_type: ServiceType,\n        service_id: str,\n    ) -&gt; None:\n        super().__init__(\n            f\"{message} for service of type {service_type} with id {service_id}\"\n        )\n        self.service_type = service_type\n        self.service_id = service_id\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.TokenizerError","title":"<code>TokenizerError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Base class for tokenizer exceptions.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class TokenizerError(AIPerfError):\n    \"\"\"Base class for tokenizer exceptions.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.TokenizerInitializationError","title":"<code>TokenizerInitializationError</code>","text":"<p>               Bases: <code>TokenizerError</code></p> <p>Exception raised for errors during tokenizer initialization.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class TokenizerInitializationError(TokenizerError):\n    \"\"\"Exception raised for errors during tokenizer initialization.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.exceptions.UnsupportedHookError","title":"<code>UnsupportedHookError</code>","text":"<p>               Bases: <code>AIPerfError</code></p> <p>Exception raised when a hook is defined on a class that does not support it.</p> Source code in <code>aiperf/common/exceptions.py</code> <pre><code>class UnsupportedHookError(AIPerfError):\n    \"\"\"Exception raised when a hook is defined on a class that does not support it.\"\"\"\n</code></pre>"},{"location":"api/#aiperfcommonfactories","title":"aiperf.common.factories","text":""},{"location":"api/#aiperf.common.factories.CommunicationFactory","title":"<code>CommunicationFactory</code>","text":"<p>               Bases: <code>FactoryMixin['CommunicationBackend', 'BaseCommunication']</code></p> <p>Factory for registering and creating BaseCommunication instances based on the specified communication backend.</p> <p>Example: ```python     # Register a new communication backend     @CommunicationFactory.register(CommunicationBackend.ZMQ_TCP)     class ZMQCommunication(BaseCommunication):         pass</p> <pre><code># Create a new communication instance\ncommunication = CommunicationFactory.create_instance(\n    CommunicationBackend.ZMQ_TCP,\n    config=ZMQTCPCommunicationConfig(\n        host=\"localhost\", port=5555, timeout=10.0),\n)\n</code></pre> Source code in <code>aiperf/common/factories.py</code> <pre><code>class CommunicationFactory(FactoryMixin[\"CommunicationBackend\", \"BaseCommunication\"]):\n    \"\"\"Factory for registering and creating BaseCommunication instances based on the specified communication backend.\n\n    Example:\n    ```python\n        # Register a new communication backend\n        @CommunicationFactory.register(CommunicationBackend.ZMQ_TCP)\n        class ZMQCommunication(BaseCommunication):\n            pass\n\n        # Create a new communication instance\n        communication = CommunicationFactory.create_instance(\n            CommunicationBackend.ZMQ_TCP,\n            config=ZMQTCPCommunicationConfig(\n                host=\"localhost\", port=5555, timeout=10.0),\n        )\n    \"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.factories.DataExporterFactory","title":"<code>DataExporterFactory</code>","text":"<p>               Bases: <code>FactoryMixin['DataExporterType', 'DataExporterProtocol']</code></p> <p>Factory for registering and creating DataExporterInterface instances.</p> <p>Example:</p> <pre><code>    # Iterate over all registered data exporter types\n    for exporter_class in DataExporterFactory.get_all_classes():\n        exporter = exporter_class(endpoint_config)\n\n        exporter.export(records)\n</code></pre> Source code in <code>aiperf/common/factories.py</code> <pre><code>class DataExporterFactory(FactoryMixin[\"DataExporterType\", \"DataExporterProtocol\"]):\n    \"\"\"Factory for registering and creating DataExporterInterface instances.\n\n    Example:\n    ```python\n        # Iterate over all registered data exporter types\n        for exporter_class in DataExporterFactory.get_all_classes():\n            exporter = exporter_class(endpoint_config)\n\n            exporter.export(records)\n    ```\n    \"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.factories.FactoryMixin","title":"<code>FactoryMixin</code>","text":"<p>               Bases: <code>Generic[ClassEnumT, ClassProtocolT]</code></p> <p>Defines a mixin for all factories, which supports registering and creating instances of classes.</p> <p>This mixin is used to create a factory for a given class type and protocol.</p> <p>Example:</p> <pre><code>    # Define a new enum for the expected implementation types\n    # This is optional, but recommended for type safety.\n    class DatasetLoaderType(CaseInsensitiveStrEnum):\n        FILE = \"file\"\n        S3 = \"s3\"\n\n    # Define a new class protocol.\n    class DatasetLoaderProtocol(Protocol):\n        def load(self) -&gt; Dataset:\n            pass\n\n    # Create a new factory for a given class type and protocol.\n    class DatasetFactory(FactoryMixin[DatasetLoaderType, DatasetLoaderProtocol]):\n        pass\n\n    # Register a new class type mapping to its corresponding class. It should implement the class protocol.\n    @DatasetFactory.register(DatasetLoaderType.FILE)\n    class FileDatasetLoader:\n        def __init__(self, filename: str):\n            self.filename = filename\n\n        def load(self) -&gt; Dataset:\n            return Dataset.from_file(self.filename)\n\n    DatasetConfig = {\n        \"type\": DatasetLoaderType.FILE,\n        \"filename\": \"data.csv\"\n    }\n\n    # Create a new instance of the class.\n    if DatasetConfig[\"type\"] == DatasetLoaderType.FILE:\n        dataset_instance = DatasetFactory.create_instance(DatasetLoaderType.FILE, filename=DatasetConfig[\"filename\"])\n    else:\n        raise ValueError(f\"Unsupported dataset loader type: {DatasetConfig['type']}\")\n\n    dataset_instance.load()\n</code></pre> Source code in <code>aiperf/common/factories.py</code> <pre><code>class FactoryMixin(Generic[ClassEnumT, ClassProtocolT]):\n    \"\"\"Defines a mixin for all factories, which supports registering and creating instances of classes.\n\n    This mixin is used to create a factory for a given class type and protocol.\n\n    Example:\n    ```python\n        # Define a new enum for the expected implementation types\n        # This is optional, but recommended for type safety.\n        class DatasetLoaderType(CaseInsensitiveStrEnum):\n            FILE = \"file\"\n            S3 = \"s3\"\n\n        # Define a new class protocol.\n        class DatasetLoaderProtocol(Protocol):\n            def load(self) -&gt; Dataset:\n                pass\n\n        # Create a new factory for a given class type and protocol.\n        class DatasetFactory(FactoryMixin[DatasetLoaderType, DatasetLoaderProtocol]):\n            pass\n\n        # Register a new class type mapping to its corresponding class. It should implement the class protocol.\n        @DatasetFactory.register(DatasetLoaderType.FILE)\n        class FileDatasetLoader:\n            def __init__(self, filename: str):\n                self.filename = filename\n\n            def load(self) -&gt; Dataset:\n                return Dataset.from_file(self.filename)\n\n        DatasetConfig = {\n            \"type\": DatasetLoaderType.FILE,\n            \"filename\": \"data.csv\"\n        }\n\n        # Create a new instance of the class.\n        if DatasetConfig[\"type\"] == DatasetLoaderType.FILE:\n            dataset_instance = DatasetFactory.create_instance(DatasetLoaderType.FILE, filename=DatasetConfig[\"filename\"])\n        else:\n            raise ValueError(f\"Unsupported dataset loader type: {DatasetConfig['type']}\")\n\n        dataset_instance.load()\n    ```\n    \"\"\"\n\n    logger = logging.getLogger(__name__)\n\n    _registry: dict[ClassEnumT | str, type[ClassProtocolT]]\n    _override_priorities: dict[ClassEnumT | str, int]\n\n    def __init_subclass__(cls) -&gt; None:\n        cls._registry = {}\n        cls._override_priorities = {}\n        super().__init_subclass__()\n\n    @classmethod\n    def register(\n        cls, class_type: ClassEnumT | str, override_priority: int = 0\n    ) -&gt; Callable:\n        \"\"\"Register a new class type mapping to its corresponding class.\n\n        Args:\n            class_type: The type of class to register\n            override_priority: The priority of the override. The higher the priority,\n                the more precedence the override has when multiple classes are registered\n                for the same class type. Built-in classes have a priority of 0.\n\n        Returns:\n            Decorator for the class that implements the class protocol\n        \"\"\"\n\n        def decorator(class_cls: type[ClassProtocolT]) -&gt; type[ClassProtocolT]:\n            existing_priority = cls._override_priorities.get(class_type, -1)\n            if class_type in cls._registry and existing_priority &gt;= override_priority:\n                # TODO: Will logging be initialized before this method is called?\n                cls.logger.warning(\n                    \"%r class %s already registered with same or higher priority \"\n                    \"(%s). The new registration of class %s with priority \"\n                    \"%s will be ignored.\",\n                    class_type,\n                    cls._registry[class_type].__name__,\n                    existing_priority,\n                    class_cls.__name__,\n                    override_priority,\n                )\n                return class_cls\n\n            if class_type not in cls._registry:\n                cls.logger.debug(\n                    \"%r class %s registered with priority %s.\",\n                    class_type,\n                    class_cls.__name__,\n                    override_priority,\n                )\n            else:\n                cls.logger.debug(\n                    \"%r class %s with priority %s overrides \"\n                    \"already registered class %s with lower priority (%s).\",\n                    class_type,\n                    class_cls.__name__,\n                    override_priority,\n                    cls._registry[class_type].__name__,\n                    existing_priority,\n                )\n            cls._registry[class_type] = class_cls\n            cls._override_priorities[class_type] = override_priority\n            return class_cls\n\n        return decorator\n\n    @classmethod\n    def create_instance(\n        cls,\n        class_type: ClassEnumT | str,\n        *args: Any,\n        **kwargs: Any,\n    ) -&gt; ClassProtocolT:\n        \"\"\"Create a new class instance.\n\n        Args:\n            class_type: The type of class to create\n            *args: Positional arguments for the class\n            **kwargs: Keyword arguments for the class\n\n        Returns:\n            The created class instance\n\n        Raises:\n            FactoryCreationError: If the class type is not registered or there is an error creating the instance\n        \"\"\"\n        if class_type not in cls._registry:\n            raise FactoryCreationError(f\"No implementation found for {class_type!r}.\")\n        try:\n            return cls._registry[class_type](*args, **kwargs)\n        except Exception as e:\n            raise FactoryCreationError(\n                f\"Error creating {class_type!r} instance: {e}\"\n            ) from e\n\n    @classmethod\n    def get_class_from_type(cls, class_type: ClassEnumT | str) -&gt; type[ClassProtocolT]:\n        \"\"\"Get the class from a class type.\n\n        Args:\n            class_type: The class type to get the class from\n\n        Returns:\n            The class for the given class type\n\n        Raises:\n            TypeError: If the class type is not registered\n        \"\"\"\n        if class_type not in cls._registry:\n            raise TypeError(\n                f\"No class found for {class_type!r}. Please register the class first.\"\n            )\n        return cls._registry[class_type]\n\n    @classmethod\n    def get_all_classes(cls) -&gt; list[type[ClassProtocolT]]:\n        \"\"\"Get all registered classes.\n\n        Returns:\n            A list of all registered class types implementing the expected protocol\n        \"\"\"\n        return list(cls._registry.values())\n</code></pre>"},{"location":"api/#aiperf.common.factories.FactoryMixin.create_instance","title":"<code>create_instance(class_type, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a new class instance.</p> <p>Parameters:</p> Name Type Description Default <code>class_type</code> <code>ClassEnumT | str</code> <p>The type of class to create</p> required <code>*args</code> <code>Any</code> <p>Positional arguments for the class</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments for the class</p> <code>{}</code> <p>Returns:</p> Type Description <code>ClassProtocolT</code> <p>The created class instance</p> <p>Raises:</p> Type Description <code>FactoryCreationError</code> <p>If the class type is not registered or there is an error creating the instance</p> Source code in <code>aiperf/common/factories.py</code> <pre><code>@classmethod\ndef create_instance(\n    cls,\n    class_type: ClassEnumT | str,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; ClassProtocolT:\n    \"\"\"Create a new class instance.\n\n    Args:\n        class_type: The type of class to create\n        *args: Positional arguments for the class\n        **kwargs: Keyword arguments for the class\n\n    Returns:\n        The created class instance\n\n    Raises:\n        FactoryCreationError: If the class type is not registered or there is an error creating the instance\n    \"\"\"\n    if class_type not in cls._registry:\n        raise FactoryCreationError(f\"No implementation found for {class_type!r}.\")\n    try:\n        return cls._registry[class_type](*args, **kwargs)\n    except Exception as e:\n        raise FactoryCreationError(\n            f\"Error creating {class_type!r} instance: {e}\"\n        ) from e\n</code></pre>"},{"location":"api/#aiperf.common.factories.FactoryMixin.get_all_classes","title":"<code>get_all_classes()</code>  <code>classmethod</code>","text":"<p>Get all registered classes.</p> <p>Returns:</p> Type Description <code>list[type[ClassProtocolT]]</code> <p>A list of all registered class types implementing the expected protocol</p> Source code in <code>aiperf/common/factories.py</code> <pre><code>@classmethod\ndef get_all_classes(cls) -&gt; list[type[ClassProtocolT]]:\n    \"\"\"Get all registered classes.\n\n    Returns:\n        A list of all registered class types implementing the expected protocol\n    \"\"\"\n    return list(cls._registry.values())\n</code></pre>"},{"location":"api/#aiperf.common.factories.FactoryMixin.get_class_from_type","title":"<code>get_class_from_type(class_type)</code>  <code>classmethod</code>","text":"<p>Get the class from a class type.</p> <p>Parameters:</p> Name Type Description Default <code>class_type</code> <code>ClassEnumT | str</code> <p>The class type to get the class from</p> required <p>Returns:</p> Type Description <code>type[ClassProtocolT]</code> <p>The class for the given class type</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the class type is not registered</p> Source code in <code>aiperf/common/factories.py</code> <pre><code>@classmethod\ndef get_class_from_type(cls, class_type: ClassEnumT | str) -&gt; type[ClassProtocolT]:\n    \"\"\"Get the class from a class type.\n\n    Args:\n        class_type: The class type to get the class from\n\n    Returns:\n        The class for the given class type\n\n    Raises:\n        TypeError: If the class type is not registered\n    \"\"\"\n    if class_type not in cls._registry:\n        raise TypeError(\n            f\"No class found for {class_type!r}. Please register the class first.\"\n        )\n    return cls._registry[class_type]\n</code></pre>"},{"location":"api/#aiperf.common.factories.FactoryMixin.register","title":"<code>register(class_type, override_priority=0)</code>  <code>classmethod</code>","text":"<p>Register a new class type mapping to its corresponding class.</p> <p>Parameters:</p> Name Type Description Default <code>class_type</code> <code>ClassEnumT | str</code> <p>The type of class to register</p> required <code>override_priority</code> <code>int</code> <p>The priority of the override. The higher the priority, the more precedence the override has when multiple classes are registered for the same class type. Built-in classes have a priority of 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>Callable</code> <p>Decorator for the class that implements the class protocol</p> Source code in <code>aiperf/common/factories.py</code> <pre><code>@classmethod\ndef register(\n    cls, class_type: ClassEnumT | str, override_priority: int = 0\n) -&gt; Callable:\n    \"\"\"Register a new class type mapping to its corresponding class.\n\n    Args:\n        class_type: The type of class to register\n        override_priority: The priority of the override. The higher the priority,\n            the more precedence the override has when multiple classes are registered\n            for the same class type. Built-in classes have a priority of 0.\n\n    Returns:\n        Decorator for the class that implements the class protocol\n    \"\"\"\n\n    def decorator(class_cls: type[ClassProtocolT]) -&gt; type[ClassProtocolT]:\n        existing_priority = cls._override_priorities.get(class_type, -1)\n        if class_type in cls._registry and existing_priority &gt;= override_priority:\n            # TODO: Will logging be initialized before this method is called?\n            cls.logger.warning(\n                \"%r class %s already registered with same or higher priority \"\n                \"(%s). The new registration of class %s with priority \"\n                \"%s will be ignored.\",\n                class_type,\n                cls._registry[class_type].__name__,\n                existing_priority,\n                class_cls.__name__,\n                override_priority,\n            )\n            return class_cls\n\n        if class_type not in cls._registry:\n            cls.logger.debug(\n                \"%r class %s registered with priority %s.\",\n                class_type,\n                class_cls.__name__,\n                override_priority,\n            )\n        else:\n            cls.logger.debug(\n                \"%r class %s with priority %s overrides \"\n                \"already registered class %s with lower priority (%s).\",\n                class_type,\n                class_cls.__name__,\n                override_priority,\n                cls._registry[class_type].__name__,\n                existing_priority,\n            )\n        cls._registry[class_type] = class_cls\n        cls._override_priorities[class_type] = override_priority\n        return class_cls\n\n    return decorator\n</code></pre>"},{"location":"api/#aiperf.common.factories.PostProcessorFactory","title":"<code>PostProcessorFactory</code>","text":"<p>               Bases: <code>FactoryMixin['PostProcessorType', 'PostProcessorProtocol']</code></p> <p>Factory for registering and creating PostProcessor instances based on the specified post-processor type.</p> <p>Example: ```python     # Register a new post-processor type     @PostProcessorFactory.register(PostProcessorType.METRIC_SUMMARY)     class MetricSummary:         pass</p> <pre><code># Create a new post-processor instance\npost_processor = PostProcessorFactory.create_instance(\n    PostProcessorType.METRIC_SUMMARY,\n)\n</code></pre> Source code in <code>aiperf/common/factories.py</code> <pre><code>class PostProcessorFactory(FactoryMixin[\"PostProcessorType\", \"PostProcessorProtocol\"]):\n    \"\"\"Factory for registering and creating PostProcessor instances based on the specified post-processor type.\n\n    Example:\n    ```python\n        # Register a new post-processor type\n        @PostProcessorFactory.register(PostProcessorType.METRIC_SUMMARY)\n        class MetricSummary:\n            pass\n\n        # Create a new post-processor instance\n        post_processor = PostProcessorFactory.create_instance(\n            PostProcessorType.METRIC_SUMMARY,\n        )\n    \"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.factories.ServiceFactory","title":"<code>ServiceFactory</code>","text":"<p>               Bases: <code>FactoryMixin['ServiceType', 'BaseService']</code></p> <p>Factory for registering and creating BaseService instances based on the specified service type.</p> <p>Example:</p> <pre><code>    # Register a new service type\n    @ServiceFactory.register(ServiceType.DATASET_MANAGER)\n    class DatasetManager(BaseService):\n        pass\n\n    # Create a new service instance in a separate process\n    service_class = ServiceFactory.get_class_from_type(service_type)\n\n    process = Process(\n        target=bootstrap_and_run_service,\n        name=f\"{service_type}_process\",\n        args=(service_class, self.config),\n        daemon=False,\n    )\n</code></pre> Source code in <code>aiperf/common/factories.py</code> <pre><code>class ServiceFactory(FactoryMixin[\"ServiceType\", \"BaseService\"]):\n    \"\"\"Factory for registering and creating BaseService instances based on the specified service type.\n\n    Example:\n    ```python\n        # Register a new service type\n        @ServiceFactory.register(ServiceType.DATASET_MANAGER)\n        class DatasetManager(BaseService):\n            pass\n\n        # Create a new service instance in a separate process\n        service_class = ServiceFactory.get_class_from_type(service_type)\n\n        process = Process(\n            target=bootstrap_and_run_service,\n            name=f\"{service_type}_process\",\n            args=(service_class, self.config),\n            daemon=False,\n        )\n    ```\n    \"\"\"\n</code></pre>"},{"location":"api/#aiperfcommonhooks","title":"aiperf.common.hooks","text":"<p>This module provides an extensive hook system for AIPerf. It is designed to be used as a mixin for classes that support hooks. It provides a simple interface for registering and running hooks.</p> <p>Classes should inherit from the :class:<code>HooksMixin</code>, and specify the supported hook types by decorating the class with the :func:<code>supports_hooks</code> decorator.</p> <p>The hook functions are registered by decorating functions with the various hook decorators such as :func:<code>on_init</code>, :func:<code>on_start</code>, :func:<code>on_stop</code>, etc.</p> <p>The hooks are run by calling the :meth:<code>HooksMixin.run_hooks</code> or :meth:<code>HooksMixin.run_hooks_async</code> methods on the class.</p> <p>More than one hook can be registered for a given hook type, and classes that inherit from classes with existing hooks will inherit the hooks from the base classes as well.</p>"},{"location":"api/#aiperf.common.hooks.AIPERF_HOOK_TYPE","title":"<code>AIPERF_HOOK_TYPE = '__aiperf_hook_type__'</code>  <code>module-attribute</code>","text":"<p>Constant attribute name that marks a function's hook type.</p>"},{"location":"api/#aiperf.common.hooks.HookType","title":"<code>HookType = AIPerfHook | str</code>  <code>module-attribute</code>","text":"<p>Type alias for valid hook types. This is a union of the AIPerfHook enum and any user-defined custom strings.</p>"},{"location":"api/#aiperf.common.hooks.AIPerfHook","title":"<code>AIPerfHook</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum for the various AIPerf hooks.</p> <p>Note: If you add a new hook, you must also add it to the @supports_hooks decorator of the class you wish to use the hook in.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>class AIPerfHook(Enum):\n    \"\"\"Enum for the various AIPerf hooks.\n\n    Note: If you add a new hook, you must also add it to the @supports_hooks\n    decorator of the class you wish to use the hook in.\n    \"\"\"\n\n    ON_INIT = \"__aiperf_on_init__\"\n    ON_RUN = \"__aiperf_on_run__\"\n    ON_CONFIGURE = \"__aiperf_on_configure__\"\n    ON_START = \"__aiperf_on_start__\"\n    ON_STOP = \"__aiperf_on_stop__\"\n    ON_CLEANUP = \"__aiperf_on_cleanup__\"\n\n    ON_SET_STATE = \"__aiperf_on_set_state__\"\n\n    AIPERF_TASK = \"__aiperf_task__\"\n</code></pre>"},{"location":"api/#aiperf.common.hooks.AIPerfTaskMixin","title":"<code>AIPerfTaskMixin</code>","text":"<p>               Bases: <code>HooksMixin</code></p> <p>Mixin to add task support to a class. It abstracts away the details of the :class:<code>AIPerfTask</code> and provides a simple interface for registering and running tasks. It hooks into the :meth:<code>HooksMixin.on_init</code> and :meth:<code>HooksMixin.on_stop</code> hooks to start and stop the tasks.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>@supports_hooks(AIPerfHook.AIPERF_TASK, AIPerfHook.ON_INIT, AIPerfHook.ON_STOP)\nclass AIPerfTaskMixin(HooksMixin):\n    \"\"\"Mixin to add task support to a class. It abstracts away the details of the\n    :class:`AIPerfTask` and provides a simple interface for registering and running tasks.\n    It hooks into the :meth:`HooksMixin.on_init` and :meth:`HooksMixin.on_stop` hooks to\n    start and stop the tasks.\n    \"\"\"\n\n    # TODO: Once we create a Mixin for `self.stop_event`, we can avoid\n    # having the user to call `while not self.stop_event.is_set()`\n\n    def __init__(self):\n        super().__init__()\n        self.registered_tasks: dict[str, asyncio.Task] = {}\n\n    @on_init\n    async def _start_tasks(self):\n        \"\"\"Start all the registered tasks in the background.\"\"\"\n        for hook in self.get_hooks(AIPerfHook.AIPERF_TASK):\n            if inspect.iscoroutinefunction(hook):\n                task = asyncio.create_task(hook())\n            else:\n                task = asyncio.create_task(asyncio.to_thread(hook))\n            self.registered_tasks[hook.__name__] = task\n\n    @on_stop\n    async def _stop_tasks(self):\n        \"\"\"Stop all the background tasks. This will wait for all the tasks to complete.\"\"\"\n        for task in self.registered_tasks.values():\n            task.cancel()\n\n        # Wait for all tasks to complete\n        with contextlib.suppress(asyncio.CancelledError):\n            await asyncio.gather(*self.registered_tasks.values())\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HookSystem","title":"<code>HookSystem</code>","text":"<p>System for managing hooks.</p> <p>This class is responsible for managing the hooks for a class. It will store the hooks in a dictionary, and provide methods to register and run the hooks.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>class HookSystem:\n    \"\"\"\n    System for managing hooks.\n\n    This class is responsible for managing the hooks for a class. It will\n    store the hooks in a dictionary, and provide methods to register and run\n    the hooks.\n    \"\"\"\n\n    def __init__(self, supported_hooks: set[HookType]):\n        \"\"\"\n        Initialize the hook system.\n\n        Args:\n            supported_hooks: The hook types that the class supports.\n        \"\"\"\n\n        self.supported_hooks: set[HookType] = supported_hooks\n        self._hooks: dict[HookType, list[Callable]] = {}\n\n    def register_hook(self, hook_type: HookType, func: Callable):\n        \"\"\"Register a hook function for a given hook type.\n\n        Args:\n            hook_type: The hook type to register the function for.\n            func: The function to register.\n        \"\"\"\n        if hook_type not in self.supported_hooks:\n            raise UnsupportedHookError(f\"Hook {hook_type} is not supported by class.\")\n\n        self._hooks.setdefault(hook_type, []).append(func)\n\n    def get_hooks(self, hook_type: HookType) -&gt; list[Callable]:\n        \"\"\"Get all the registered hooks for the given hook type.\n\n        Args:\n            hook_type: The hook type to get the hooks for.\n\n        Returns:\n            A list of the hooks for the given hook type.\n        \"\"\"\n        return self._hooks.get(hook_type, [])\n\n    async def run_hooks(self, hook_type: HookType, *args, **kwargs):\n        \"\"\"\n        Run all the hooks for a given hook type serially. This will wait for each\n        hook to complete before running the next one.\n\n        Args:\n            hook_type: The hook type to run.\n            *args: The arguments to pass to the hooks.\n            **kwargs: The keyword arguments to pass to the hooks.\n        \"\"\"\n        if hook_type not in self.supported_hooks:\n            raise UnsupportedHookError(f\"Hook {hook_type} is not supported by class.\")\n\n        exceptions: list[Exception] = []\n        for func in self.get_hooks(hook_type):\n            try:\n                if inspect.iscoroutinefunction(func):\n                    await func(*args, **kwargs)\n                else:\n                    await asyncio.to_thread(func, *args, **kwargs)\n            except Exception as e:\n                logger.error(f\"Error running hook {func.__name__}: {e}\")\n                exceptions.append(e)\n\n        if exceptions:\n            raise AIPerfMultiError(\"Errors running hooks\", exceptions)\n\n    async def run_hooks_async(self, hook_type: HookType, *args, **kwargs):\n        \"\"\"\n        Run all the hooks for a given hook type concurrently. This will run all\n        the hooks at the same time and return when all the hooks have completed.\n\n        Args:\n            hook_type: The hook type to run.\n            *args: The arguments to pass to the hooks.\n            **kwargs: The keyword arguments to pass to the hooks.\n        \"\"\"\n        if hook_type not in self.supported_hooks:\n            raise UnsupportedHookError(f\"Hook {hook_type} is not supported by class.\")\n\n        coroutines: list[Awaitable] = []\n        for func in self.get_hooks(hook_type):\n            if inspect.iscoroutinefunction(func):\n                coroutines.append(func(*args, **kwargs))\n            else:\n                coroutines.append(asyncio.to_thread(func, *args, **kwargs))\n\n        if coroutines:\n            results = await asyncio.gather(*coroutines, return_exceptions=True)\n\n            exceptions = [result for result in results if isinstance(result, Exception)]\n            if exceptions:\n                raise AIPerfMultiError(\"Errors running hooks\", exceptions)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HookSystem.__init__","title":"<code>__init__(supported_hooks)</code>","text":"<p>Initialize the hook system.</p> <p>Parameters:</p> Name Type Description Default <code>supported_hooks</code> <code>set[HookType]</code> <p>The hook types that the class supports.</p> required Source code in <code>aiperf/common/hooks.py</code> <pre><code>def __init__(self, supported_hooks: set[HookType]):\n    \"\"\"\n    Initialize the hook system.\n\n    Args:\n        supported_hooks: The hook types that the class supports.\n    \"\"\"\n\n    self.supported_hooks: set[HookType] = supported_hooks\n    self._hooks: dict[HookType, list[Callable]] = {}\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HookSystem.get_hooks","title":"<code>get_hooks(hook_type)</code>","text":"<p>Get all the registered hooks for the given hook type.</p> <p>Parameters:</p> Name Type Description Default <code>hook_type</code> <code>HookType</code> <p>The hook type to get the hooks for.</p> required <p>Returns:</p> Type Description <code>list[Callable]</code> <p>A list of the hooks for the given hook type.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def get_hooks(self, hook_type: HookType) -&gt; list[Callable]:\n    \"\"\"Get all the registered hooks for the given hook type.\n\n    Args:\n        hook_type: The hook type to get the hooks for.\n\n    Returns:\n        A list of the hooks for the given hook type.\n    \"\"\"\n    return self._hooks.get(hook_type, [])\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HookSystem.register_hook","title":"<code>register_hook(hook_type, func)</code>","text":"<p>Register a hook function for a given hook type.</p> <p>Parameters:</p> Name Type Description Default <code>hook_type</code> <code>HookType</code> <p>The hook type to register the function for.</p> required <code>func</code> <code>Callable</code> <p>The function to register.</p> required Source code in <code>aiperf/common/hooks.py</code> <pre><code>def register_hook(self, hook_type: HookType, func: Callable):\n    \"\"\"Register a hook function for a given hook type.\n\n    Args:\n        hook_type: The hook type to register the function for.\n        func: The function to register.\n    \"\"\"\n    if hook_type not in self.supported_hooks:\n        raise UnsupportedHookError(f\"Hook {hook_type} is not supported by class.\")\n\n    self._hooks.setdefault(hook_type, []).append(func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HookSystem.run_hooks","title":"<code>run_hooks(hook_type, *args, **kwargs)</code>  <code>async</code>","text":"<p>Run all the hooks for a given hook type serially. This will wait for each hook to complete before running the next one.</p> <p>Parameters:</p> Name Type Description Default <code>hook_type</code> <code>HookType</code> <p>The hook type to run.</p> required <code>*args</code> <p>The arguments to pass to the hooks.</p> <code>()</code> <code>**kwargs</code> <p>The keyword arguments to pass to the hooks.</p> <code>{}</code> Source code in <code>aiperf/common/hooks.py</code> <pre><code>async def run_hooks(self, hook_type: HookType, *args, **kwargs):\n    \"\"\"\n    Run all the hooks for a given hook type serially. This will wait for each\n    hook to complete before running the next one.\n\n    Args:\n        hook_type: The hook type to run.\n        *args: The arguments to pass to the hooks.\n        **kwargs: The keyword arguments to pass to the hooks.\n    \"\"\"\n    if hook_type not in self.supported_hooks:\n        raise UnsupportedHookError(f\"Hook {hook_type} is not supported by class.\")\n\n    exceptions: list[Exception] = []\n    for func in self.get_hooks(hook_type):\n        try:\n            if inspect.iscoroutinefunction(func):\n                await func(*args, **kwargs)\n            else:\n                await asyncio.to_thread(func, *args, **kwargs)\n        except Exception as e:\n            logger.error(f\"Error running hook {func.__name__}: {e}\")\n            exceptions.append(e)\n\n    if exceptions:\n        raise AIPerfMultiError(\"Errors running hooks\", exceptions)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HookSystem.run_hooks_async","title":"<code>run_hooks_async(hook_type, *args, **kwargs)</code>  <code>async</code>","text":"<p>Run all the hooks for a given hook type concurrently. This will run all the hooks at the same time and return when all the hooks have completed.</p> <p>Parameters:</p> Name Type Description Default <code>hook_type</code> <code>HookType</code> <p>The hook type to run.</p> required <code>*args</code> <p>The arguments to pass to the hooks.</p> <code>()</code> <code>**kwargs</code> <p>The keyword arguments to pass to the hooks.</p> <code>{}</code> Source code in <code>aiperf/common/hooks.py</code> <pre><code>async def run_hooks_async(self, hook_type: HookType, *args, **kwargs):\n    \"\"\"\n    Run all the hooks for a given hook type concurrently. This will run all\n    the hooks at the same time and return when all the hooks have completed.\n\n    Args:\n        hook_type: The hook type to run.\n        *args: The arguments to pass to the hooks.\n        **kwargs: The keyword arguments to pass to the hooks.\n    \"\"\"\n    if hook_type not in self.supported_hooks:\n        raise UnsupportedHookError(f\"Hook {hook_type} is not supported by class.\")\n\n    coroutines: list[Awaitable] = []\n    for func in self.get_hooks(hook_type):\n        if inspect.iscoroutinefunction(func):\n            coroutines.append(func(*args, **kwargs))\n        else:\n            coroutines.append(asyncio.to_thread(func, *args, **kwargs))\n\n    if coroutines:\n        results = await asyncio.gather(*coroutines, return_exceptions=True)\n\n        exceptions = [result for result in results if isinstance(result, Exception)]\n        if exceptions:\n            raise AIPerfMultiError(\"Errors running hooks\", exceptions)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HooksMixin","title":"<code>HooksMixin</code>","text":"<p>Mixin to add hook support to a class. It abstracts away the details of the :class:<code>HookSystem</code> and provides a simple interface for registering and running hooks.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>class HooksMixin:\n    \"\"\"\n    Mixin to add hook support to a class. It abstracts away the details of the\n    :class:`HookSystem` and provides a simple interface for registering and running hooks.\n    \"\"\"\n\n    # Class attributes that are set by the :func:`supports_hooks` decorator\n    supported_hooks: set[HookType] = set()\n\n    def __init__(self):\n        \"\"\"\n        Initialize the hook system and register all functions that are decorated with a hook decorator.\n        \"\"\"\n        # Initialize the hook system\n        self._hook_system = HookSystem(self.supported_hooks)\n\n        # Register all functions that are decorated with a hook decorator\n        # Iterate through MRO in reverse order to ensure base class hooks are registered first\n        for cls in reversed(self.__class__.__mro__):\n            # Skip object and other non-hook classes\n            if not issubclass(cls, HooksMixin):\n                continue\n\n            # Get methods defined directly in this class (not inherited)\n            for _, attr in cls.__dict__.items():\n                if callable(attr) and hasattr(attr, AIPERF_HOOK_TYPE):\n                    # Get the hook type from the function\n                    hook_type = getattr(attr, AIPERF_HOOK_TYPE)\n                    # Bind the method to the instance\n                    bound_method = attr.__get__(self, cls)\n                    # Register the function with the hook type\n                    self.register_hook(hook_type, bound_method)\n\n    def register_hook(self, hook_type: HookType, func: Callable):\n        \"\"\"Register a hook function for a given hook type.\n\n        Args:\n            hook_type: The hook type to register the function for.\n            func: The function to register.\n        \"\"\"\n        self._hook_system.register_hook(hook_type, func)\n\n    async def run_hooks(self, hook_type: HookType, *args, **kwargs):\n        \"\"\"Run all the hooks serially. See :meth:`HookSystem.run_hooks`.\"\"\"\n        await self._hook_system.run_hooks(hook_type, *args, **kwargs)\n\n    async def run_hooks_async(self, hook_type: HookType, *args, **kwargs):\n        \"\"\"Run all the hooks concurrently. See :meth:`HookSystem.run_hooks_async`.\"\"\"\n        await self._hook_system.run_hooks_async(hook_type, *args, **kwargs)\n\n    def get_hooks(self, hook_type: HookType) -&gt; list[Callable]:\n        \"\"\"Get all the registered hooks for the given hook type. See :meth:`HookSystem.get_hooks`.\"\"\"\n        return self._hook_system.get_hooks(hook_type)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HooksMixin.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the hook system and register all functions that are decorated with a hook decorator.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initialize the hook system and register all functions that are decorated with a hook decorator.\n    \"\"\"\n    # Initialize the hook system\n    self._hook_system = HookSystem(self.supported_hooks)\n\n    # Register all functions that are decorated with a hook decorator\n    # Iterate through MRO in reverse order to ensure base class hooks are registered first\n    for cls in reversed(self.__class__.__mro__):\n        # Skip object and other non-hook classes\n        if not issubclass(cls, HooksMixin):\n            continue\n\n        # Get methods defined directly in this class (not inherited)\n        for _, attr in cls.__dict__.items():\n            if callable(attr) and hasattr(attr, AIPERF_HOOK_TYPE):\n                # Get the hook type from the function\n                hook_type = getattr(attr, AIPERF_HOOK_TYPE)\n                # Bind the method to the instance\n                bound_method = attr.__get__(self, cls)\n                # Register the function with the hook type\n                self.register_hook(hook_type, bound_method)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HooksMixin.get_hooks","title":"<code>get_hooks(hook_type)</code>","text":"<p>Get all the registered hooks for the given hook type. See :meth:<code>HookSystem.get_hooks</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def get_hooks(self, hook_type: HookType) -&gt; list[Callable]:\n    \"\"\"Get all the registered hooks for the given hook type. See :meth:`HookSystem.get_hooks`.\"\"\"\n    return self._hook_system.get_hooks(hook_type)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HooksMixin.register_hook","title":"<code>register_hook(hook_type, func)</code>","text":"<p>Register a hook function for a given hook type.</p> <p>Parameters:</p> Name Type Description Default <code>hook_type</code> <code>HookType</code> <p>The hook type to register the function for.</p> required <code>func</code> <code>Callable</code> <p>The function to register.</p> required Source code in <code>aiperf/common/hooks.py</code> <pre><code>def register_hook(self, hook_type: HookType, func: Callable):\n    \"\"\"Register a hook function for a given hook type.\n\n    Args:\n        hook_type: The hook type to register the function for.\n        func: The function to register.\n    \"\"\"\n    self._hook_system.register_hook(hook_type, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HooksMixin.run_hooks","title":"<code>run_hooks(hook_type, *args, **kwargs)</code>  <code>async</code>","text":"<p>Run all the hooks serially. See :meth:<code>HookSystem.run_hooks</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>async def run_hooks(self, hook_type: HookType, *args, **kwargs):\n    \"\"\"Run all the hooks serially. See :meth:`HookSystem.run_hooks`.\"\"\"\n    await self._hook_system.run_hooks(hook_type, *args, **kwargs)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.HooksMixin.run_hooks_async","title":"<code>run_hooks_async(hook_type, *args, **kwargs)</code>  <code>async</code>","text":"<p>Run all the hooks concurrently. See :meth:<code>HookSystem.run_hooks_async</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>async def run_hooks_async(self, hook_type: HookType, *args, **kwargs):\n    \"\"\"Run all the hooks concurrently. See :meth:`HookSystem.run_hooks_async`.\"\"\"\n    await self._hook_system.run_hooks_async(hook_type, *args, **kwargs)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.aiperf_task","title":"<code>aiperf_task(func)</code>","text":"<p>Decorator to indicate that the function is a task function. It will be started and stopped automatically by the base class lifecycle. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def aiperf_task(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to indicate that the function is a task function. It will be started\n    and stopped automatically by the base class lifecycle.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.AIPERF_TASK, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.hook_decorator","title":"<code>hook_decorator(hook_type, func)</code>","text":"<p>Generic decorator to specify that the function should be called during a specific hook.</p> <p>Parameters:</p> Name Type Description Default <code>hook_type</code> <code>HookType</code> <p>The hook type to decorate the function with.</p> required <code>func</code> <code>Callable</code> <p>The function to decorate.</p> required <p>Returns:     The decorated function.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def hook_decorator(hook_type: HookType, func: Callable) -&gt; Callable:\n    \"\"\"Generic decorator to specify that the function should be called during\n    a specific hook.\n\n    Args:\n        hook_type: The hook type to decorate the function with.\n        func: The function to decorate.\n    Returns:\n        The decorated function.\n    \"\"\"\n    setattr(func, AIPERF_HOOK_TYPE, hook_type)\n    return func\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_cleanup","title":"<code>on_cleanup(func)</code>","text":"<p>Decorator to specify that the function should be called during cleanup. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_cleanup(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called during cleanup.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_CLEANUP, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_configure","title":"<code>on_configure(func)</code>","text":"<p>Decorator to specify that the function should be called during the service configuration. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_configure(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called during the service configuration.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_CONFIGURE, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_init","title":"<code>on_init(func)</code>","text":"<p>Decorator to specify that the function should be called during initialization. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_init(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called during initialization.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_INIT, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_run","title":"<code>on_run(func)</code>","text":"<p>Decorator to specify that the function should be called during run. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_run(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called during run.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_RUN, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_set_state","title":"<code>on_set_state(func)</code>","text":"<p>Decorator to specify that the function should be called when the service state is set. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_set_state(\n    func: Callable,\n) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called when the service state is set.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_SET_STATE, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_start","title":"<code>on_start(func)</code>","text":"<p>Decorator to specify that the function should be called during start. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_start(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called during start.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_START, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.on_stop","title":"<code>on_stop(func)</code>","text":"<p>Decorator to specify that the function should be called during stop. See :func:<code>aiperf.common.hooks.hook_decorator</code>.</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def on_stop(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to specify that the function should be called during stop.\n    See :func:`aiperf.common.hooks.hook_decorator`.\"\"\"\n    return hook_decorator(AIPerfHook.ON_STOP, func)\n</code></pre>"},{"location":"api/#aiperf.common.hooks.supports_hooks","title":"<code>supports_hooks(*supported_hook_types)</code>","text":"<p>Decorator to indicate that a class supports hooks and sets the supported hook types.</p> <p>Parameters:</p> Name Type Description Default <code>supported_hook_types</code> <code>HookType</code> <p>The hook types that the class supports.</p> <code>()</code> <p>Returns:</p> Type Description <code>Callable[[type], type]</code> <p>The decorated class</p> Source code in <code>aiperf/common/hooks.py</code> <pre><code>def supports_hooks(\n    *supported_hook_types: HookType,\n) -&gt; Callable[[type], type]:\n    \"\"\"Decorator to indicate that a class supports hooks and sets the\n    supported hook types.\n\n    Args:\n        supported_hook_types: The hook types that the class supports.\n\n    Returns:\n        The decorated class\n    \"\"\"\n\n    def decorator(cls: type) -&gt; type:\n        # Ensure the class inherits from HooksMixin\n        if not issubclass(cls, HooksMixin):\n            raise TypeError(f\"Class {cls.__name__} does not inherit from HooksMixin.\")\n\n        # Inherit any hooks defined by base classes in the MRO (Method Resolution Order).\n        base_hooks = [\n            base.supported_hooks\n            for base in cls.__mro__[1:]  # Skip this class itself (cls)\n            if issubclass(\n                base, HooksMixin\n            )  # Only include classes that inherit from HooksMixin\n        ]\n\n        # Set the supported hooks to be the union of the existing base hooks and the new supported hook types.\n        cls.supported_hooks = set.union(*base_hooks, set(supported_hook_types))\n        return cls\n\n    return decorator\n</code></pre>"},{"location":"api/#aiperfcommoninterfaces","title":"aiperf.common.interfaces","text":""},{"location":"api/#aiperf.common.interfaces.DataExporterProtocol","title":"<code>DataExporterProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for data exporters. Any class implementing this protocol must provide an <code>export</code> method that takes a list of Record objects and handles exporting them appropriately.</p> Source code in <code>aiperf/common/interfaces.py</code> <pre><code>class DataExporterProtocol(Protocol):\n    \"\"\"\n    Protocol for data exporters.\n    Any class implementing this protocol must provide an `export` method\n    that takes a list of Record objects and handles exporting them appropriately.\n    \"\"\"\n\n    def export(self, records: list[Record]) -&gt; None: ...\n</code></pre>"},{"location":"api/#aiperf.common.interfaces.PostProcessorProtocol","title":"<code>PostProcessorProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>PostProcessorProtocol is a protocol that defines the API for post-processors. It requires an <code>process</code> method that takes a list of records and returns a result.</p> Source code in <code>aiperf/common/interfaces.py</code> <pre><code>class PostProcessorProtocol(Protocol):\n    \"\"\"\n    PostProcessorProtocol is a protocol that defines the API for post-processors.\n    It requires an `process` method that takes a list of records and returns a result.\n    \"\"\"\n\n    def process(self, records: dict) -&gt; dict:\n        \"\"\"\n        Execute the post-processing logic on the given payload.\n\n        :param payload: The input data to be processed.\n        :return: The processed data as a dictionary.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/#aiperf.common.interfaces.PostProcessorProtocol.process","title":"<code>process(records)</code>","text":"<p>Execute the post-processing logic on the given payload.</p> <p>:param payload: The input data to be processed. :return: The processed data as a dictionary.</p> Source code in <code>aiperf/common/interfaces.py</code> <pre><code>def process(self, records: dict) -&gt; dict:\n    \"\"\"\n    Execute the post-processing logic on the given payload.\n\n    :param payload: The input data to be processed.\n    :return: The processed data as a dictionary.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperfcommonmessages","title":"aiperf.common.messages","text":""},{"location":"api/#aiperf.common.messages.BaseMessage","title":"<code>BaseMessage</code>","text":"<p>               Bases: <code>Message</code></p> <p>Base message model with common fields for all messages.</p> <p>Each message model should inherit from this class, set the message_type field, and define its own additional fields.</p> <p>Optionally, the @exclude_if_none decorator can be used to specify which fields should be excluded from the serialized message if they are None.</p> <p>Example:</p> <pre><code>@exclude_if_none([\"some_field\"])\nclass ExampleMessage(BaseMessage):\n    some_field: int | None = Field(default=None)\n    other_field: int = Field(default=1)\n</code></pre> Source code in <code>aiperf/common/messages.py</code> <pre><code>@exclude_if_none([\"request_ns\", \"request_id\"])\nclass BaseMessage(Message):\n    \"\"\"Base message model with common fields for all messages.\n\n    Each message model should inherit from this class, set the message_type field,\n    and define its own additional fields.\n\n    Optionally, the @exclude_if_none decorator can be used to specify which fields\n    should be excluded from the serialized message if they are None.\n\n    Example:\n    ```python\n    @exclude_if_none([\"some_field\"])\n    class ExampleMessage(BaseMessage):\n        some_field: int | None = Field(default=None)\n        other_field: int = Field(default=1)\n    ```\n    \"\"\"\n\n    _exclude_if_none_fields: ClassVar[set[str]] = set()\n    \"\"\"Set of field names that should be excluded from the serialized message if they\n    are None. This is set by the @exclude_if_none decorator.\n    \"\"\"\n\n    request_ns: int | None = Field(\n        default=None,\n        description=\"Timestamp of the request\",\n    )\n\n    request_id: str | None = Field(\n        default=None,\n        description=\"ID of the request\",\n    )\n\n    @model_serializer\n    def _serialize_message(self) -&gt; dict[str, Any]:\n        \"\"\"Serialize the message to a dictionary.\n\n        This method overrides the default serializer to exclude fields that have a\n        value of None and have the EXCLUDE_IF_NONE json_schema_extra key set to True.\n        \"\"\"\n        return {\n            k: v\n            for k, v in self\n            if not (k in self._exclude_if_none_fields and v is None)\n        }\n</code></pre>"},{"location":"api/#aiperf.common.messages.BaseServiceErrorMessage","title":"<code>BaseServiceErrorMessage</code>","text":"<p>               Bases: <code>BaseServiceMessage</code></p> <p>Base message containing error data.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class BaseServiceErrorMessage(BaseServiceMessage):\n    \"\"\"Base message containing error data.\"\"\"\n\n    message_type: Literal[MessageType.SERVICE_ERROR] = MessageType.SERVICE_ERROR\n\n    error: str | None = Field(\n        default=None,\n        description=\"Error information\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.BaseServiceMessage","title":"<code>BaseServiceMessage</code>","text":"<p>               Bases: <code>BaseMessage</code></p> <p>Base message that is sent from a service. Requires a service_id field to specify the service that sent the message.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class BaseServiceMessage(BaseMessage):\n    \"\"\"Base message that is sent from a service. Requires a service_id field to specify\n    the service that sent the message.\"\"\"\n\n    service_id: str = Field(\n        ...,\n        description=\"ID of the service sending the message\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.BaseStatusMessage","title":"<code>BaseStatusMessage</code>","text":"<p>               Bases: <code>BaseServiceMessage</code></p> <p>Base message containing status data. This message is sent by a service to the system controller to report its status.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class BaseStatusMessage(BaseServiceMessage):\n    \"\"\"Base message containing status data.\n    This message is sent by a service to the system controller to report its status.\n    \"\"\"\n\n    # override request_ns to be auto-filled if not provided\n    request_ns: int | None = Field(\n        default=time.time_ns(),\n        description=\"Timestamp of the request\",\n    )\n    state: ServiceState = Field(\n        ...,\n        description=\"Current state of the service\",\n    )\n    service_type: ServiceType = Field(\n        ...,\n        description=\"Type of service\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.CommandMessage","title":"<code>CommandMessage</code>","text":"<p>               Bases: <code>BaseServiceMessage</code></p> <p>Message containing command data. This message is sent by the system controller to a service to command it to do something.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class CommandMessage(BaseServiceMessage):\n    \"\"\"Message containing command data.\n    This message is sent by the system controller to a service to command it to do something.\n    \"\"\"\n\n    message_type: Literal[MessageType.COMMAND] = MessageType.COMMAND\n\n    command: CommandType = Field(\n        ...,\n        description=\"Command to execute\",\n    )\n    command_id: str = Field(\n        default_factory=lambda: str(uuid.uuid4()),\n        description=\"Unique identifier for this command. If not provided, a random UUID will be generated.\",\n    )\n    require_response: bool = Field(\n        default=False,\n        description=\"Whether a response is required for this command\",\n    )\n    # TODO: should we allow a service_type as well to send to all services of a given type?\n    target_service_type: ServiceType | None = Field(\n        default=None,\n        description=\"Type of the service to send the command to. \"\n        \"If both `target_service_type` and `target_service_id` are None, the command is \"\n        \"sent to all services.\",\n    )\n    target_service_id: str | None = Field(\n        default=None,\n        description=\"ID of the target service to send the command to. \"\n        \"If both `target_service_type` and `target_service_id` are None, the command is \"\n        \"sent to all services.\",\n    )\n    data: SerializeAsAny[ProcessRecordsCommandData | BaseModel | None] = Field(\n        default=None,\n        description=\"Data to send with the command\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.ConversationRequestMessage","title":"<code>ConversationRequestMessage</code>","text":"<p>               Bases: <code>BaseServiceMessage</code></p> <p>Message for a conversation request.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class ConversationRequestMessage(BaseServiceMessage):\n    \"\"\"Message for a conversation request.\"\"\"\n\n    message_type: Literal[MessageType.CONVERSATION_REQUEST] = (\n        MessageType.CONVERSATION_REQUEST\n    )\n\n    conversation_id: str = Field(..., description=\"The ID of the conversation\")\n</code></pre>"},{"location":"api/#aiperf.common.messages.ConversationResponseMessage","title":"<code>ConversationResponseMessage</code>","text":"<p>               Bases: <code>BaseServiceMessage</code></p> <p>Message for a conversation response.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class ConversationResponseMessage(BaseServiceMessage):\n    \"\"\"Message for a conversation response.\"\"\"\n\n    message_type: Literal[MessageType.CONVERSATION_RESPONSE] = (\n        MessageType.CONVERSATION_RESPONSE\n    )\n\n    conversation_id: str = Field(..., description=\"The ID of the conversation\")\n    conversation_data: list[dict[str, Any]] = Field(\n        ..., description=\"The data of the conversation\"\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.CreditDropMessage","title":"<code>CreditDropMessage</code>","text":"<p>               Bases: <code>BaseServiceMessage</code></p> <p>Message indicating that a credit has been dropped. This message is sent by the timing manager to a workers to indicate that credit(s) have been dropped.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class CreditDropMessage(BaseServiceMessage):\n    \"\"\"Message indicating that a credit has been dropped.\n    This message is sent by the timing manager to a workers to indicate that credit(s)\n    have been dropped.\n    \"\"\"\n\n    message_type: Literal[MessageType.CREDIT_DROP] = MessageType.CREDIT_DROP\n\n    amount: int = Field(\n        ...,\n        description=\"Amount of credits that have been dropped\",\n    )\n    credit_drop_ns: int = Field(\n        default_factory=time.time_ns, description=\"Timestamp of the credit drop\"\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.CreditReturnMessage","title":"<code>CreditReturnMessage</code>","text":"<p>               Bases: <code>BaseServiceMessage</code></p> <p>Message indicating that a credit has been returned. This message is sent by a worker to the timing manager to indicate that work has been completed.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class CreditReturnMessage(BaseServiceMessage):\n    \"\"\"Message indicating that a credit has been returned.\n    This message is sent by a worker to the timing manager to indicate that work has\n    been completed.\n    \"\"\"\n\n    message_type: Literal[MessageType.CREDIT_RETURN] = MessageType.CREDIT_RETURN\n\n    amount: int = Field(\n        ...,\n        description=\"Amount of credits being returned\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.CreditsCompleteMessage","title":"<code>CreditsCompleteMessage</code>","text":"<p>               Bases: <code>BaseServiceMessage</code></p> <p>Credits complete message sent to System controller to signify all requests have completed.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class CreditsCompleteMessage(BaseServiceMessage):\n    \"\"\"Credits complete message sent to System controller to signify all requests have completed.\"\"\"\n\n    message_type: Literal[MessageType.CREDITS_COMPLETE] = MessageType.CREDITS_COMPLETE\n    cancelled: bool = Field(\n        default=False,\n        description=\"Whether the profile run was cancelled\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.ErrorMessage","title":"<code>ErrorMessage</code>","text":"<p>               Bases: <code>BaseMessage</code></p> <p>Message containing error data.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class ErrorMessage(BaseMessage):\n    \"\"\"Message containing error data.\"\"\"\n\n    message_type: Literal[MessageType.ERROR] = MessageType.ERROR\n\n    error: str | None = Field(\n        default=None,\n        description=\"Error information\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.HeartbeatMessage","title":"<code>HeartbeatMessage</code>","text":"<p>               Bases: <code>BaseStatusMessage</code></p> <p>Message containing heartbeat data. This message is sent by a service to the system controller to indicate that it is still running.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class HeartbeatMessage(BaseStatusMessage):\n    \"\"\"Message containing heartbeat data.\n    This message is sent by a service to the system controller to indicate that it is\n    still running.\n    \"\"\"\n\n    message_type: Literal[MessageType.HEARTBEAT] = MessageType.HEARTBEAT\n\n    state: ServiceState = ServiceState.RUNNING\n</code></pre>"},{"location":"api/#aiperf.common.messages.InferenceResultsMessage","title":"<code>InferenceResultsMessage</code>","text":"<p>               Bases: <code>BaseServiceMessage</code></p> <p>Message for a inference results.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class InferenceResultsMessage(BaseServiceMessage):\n    \"\"\"Message for a inference results.\"\"\"\n\n    message_type: Literal[MessageType.INFERENCE_RESULTS] = MessageType.INFERENCE_RESULTS\n\n    record: SerializeAsAny[RequestRecord] = Field(\n        ..., description=\"The inference results record\"\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.Message","title":"<code>Message</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for optimized message handling</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class Message(BaseModel):\n    \"\"\"Base class for optimized message handling\"\"\"\n\n    _message_type_lookup: ClassVar[dict[MessageType, type[\"Message\"]]] = {}\n\n    def __init_subclass__(cls, **kwargs: dict[str, Any]):\n        super().__init_subclass__(**kwargs)\n        if hasattr(cls, \"message_type\"):\n            cls._message_type_lookup[cls.message_type] = cls\n\n    message_type: MessageType | Any = Field(\n        ...,\n        description=\"Type of the message\",\n    )\n\n    @classmethod\n    def __get_validators__(cls):\n        yield cls.from_json\n\n    @classmethod\n    def from_json(cls, json_str: str) -&gt; \"Message\":\n        \"\"\"Fast deserialization without full validation\"\"\"\n        data = json.loads(json_str)\n        message_type = data.get(\"message_type\")\n        if not message_type:\n            raise ValueError(\"Missing message_type\")\n\n        # Use cached message type lookup\n        message_class = cls._message_type_lookup[message_type]\n        if not message_class:\n            raise ValueError(f\"Unknown message type: {message_type}\")\n\n        return message_class(**data)\n\n    def to_json(self) -&gt; str:\n        \"\"\"Fast serialization without full validation\"\"\"\n        return json.dumps(self.__dict__)\n</code></pre>"},{"location":"api/#aiperf.common.messages.Message.from_json","title":"<code>from_json(json_str)</code>  <code>classmethod</code>","text":"<p>Fast deserialization without full validation</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>@classmethod\ndef from_json(cls, json_str: str) -&gt; \"Message\":\n    \"\"\"Fast deserialization without full validation\"\"\"\n    data = json.loads(json_str)\n    message_type = data.get(\"message_type\")\n    if not message_type:\n        raise ValueError(\"Missing message_type\")\n\n    # Use cached message type lookup\n    message_class = cls._message_type_lookup[message_type]\n    if not message_class:\n        raise ValueError(f\"Unknown message type: {message_type}\")\n\n    return message_class(**data)\n</code></pre>"},{"location":"api/#aiperf.common.messages.Message.to_json","title":"<code>to_json()</code>","text":"<p>Fast serialization without full validation</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Fast serialization without full validation\"\"\"\n    return json.dumps(self.__dict__)\n</code></pre>"},{"location":"api/#aiperf.common.messages.ProcessRecordsCommandData","title":"<code>ProcessRecordsCommandData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Data to send with the process records command.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class ProcessRecordsCommandData(BaseModel):\n    \"\"\"Data to send with the process records command.\"\"\"\n\n    cancelled: bool = Field(\n        default=False,\n        description=\"Whether the profile run was cancelled\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.ProfileProgressMessage","title":"<code>ProfileProgressMessage</code>","text":"<p>               Bases: <code>BaseServiceMessage</code></p> <p>Message for profile progress.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class ProfileProgressMessage(BaseServiceMessage):\n    \"\"\"Message for profile progress.\"\"\"\n\n    message_type: Literal[MessageType.PROFILE_PROGRESS] = MessageType.PROFILE_PROGRESS\n\n    sweep_id: str | None = Field(\n        default=None, description=\"The ID of the current sweep\"\n    )\n    sweep_start_ns: int = Field(\n        ..., description=\"The start time of the sweep in nanoseconds\"\n    )\n    sweep_end_ns: int | None = Field(\n        default=None, description=\"The end time of the sweep in nanoseconds\"\n    )\n    total: int = Field(\n        ..., description=\"The total number of inference requests to be made\"\n    )\n    completed: int = Field(\n        ..., description=\"The number of inference requests completed\"\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.ProfileResultsMessage","title":"<code>ProfileResultsMessage</code>","text":"<p>               Bases: <code>BaseServiceMessage</code></p> <p>Message for profile results.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class ProfileResultsMessage(BaseServiceMessage):\n    \"\"\"Message for profile results.\"\"\"\n\n    message_type: Literal[MessageType.PROFILE_RESULTS] = MessageType.PROFILE_RESULTS\n\n    records: SerializeAsAny[list[Record]] = Field(\n        ..., description=\"The records of the profile results\"\n    )\n    total: int = Field(\n        ..., description=\"The total number of inference requests to be made\"\n    )\n    completed: int = Field(\n        ..., description=\"The number of inference requests completed\"\n    )\n    # TODO: Are these needed?\n    # begin_ns: int = Field(\n    #     ..., description=\"The start time of the profile run in nanoseconds\"\n    # )\n    # end_ns: int = Field(\n    #     ...,\n    #     description=\"The end time of the profile run in nanoseconds\"\n    # )\n    was_cancelled: bool = Field(\n        default=False,\n        description=\"Whether the profile run was cancelled early\",\n    )\n    errors_by_type: list[ErrorDetailsCount] = Field(\n        default_factory=list,\n        description=\"A list of the unique error details and their counts\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.ProfileStatsMessage","title":"<code>ProfileStatsMessage</code>","text":"<p>               Bases: <code>BaseServiceMessage</code></p> <p>Message for profile stats.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class ProfileStatsMessage(BaseServiceMessage):\n    \"\"\"Message for profile stats.\"\"\"\n\n    message_type: Literal[MessageType.PROFILE_STATS] = MessageType.PROFILE_STATS\n\n    error_count: int = Field(default=0, description=\"The number of errors encountered\")\n    completed: int = Field(default=0, description=\"The number of requests completed\")\n    worker_completed: dict[str, int] = Field(\n        default_factory=dict,\n        description=\"Per-worker request completion counts, keyed by worker service_id\",\n    )\n    worker_errors: dict[str, int] = Field(\n        default_factory=dict,\n        description=\"Per-worker error counts, keyed by worker service_id\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.messages.RegistrationMessage","title":"<code>RegistrationMessage</code>","text":"<p>               Bases: <code>BaseStatusMessage</code></p> <p>Message containing registration data. This message is sent by a service to the system controller to register itself.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class RegistrationMessage(BaseStatusMessage):\n    \"\"\"Message containing registration data.\n    This message is sent by a service to the system controller to register itself.\n    \"\"\"\n\n    message_type: Literal[MessageType.REGISTRATION] = MessageType.REGISTRATION\n\n    state: ServiceState = ServiceState.READY\n</code></pre>"},{"location":"api/#aiperf.common.messages.StatusMessage","title":"<code>StatusMessage</code>","text":"<p>               Bases: <code>BaseStatusMessage</code></p> <p>Message containing status data. This message is sent by a service to the system controller to report its status.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>class StatusMessage(BaseStatusMessage):\n    \"\"\"Message containing status data.\n    This message is sent by a service to the system controller to report its status.\n    \"\"\"\n\n    message_type: Literal[MessageType.STATUS] = MessageType.STATUS\n</code></pre>"},{"location":"api/#aiperf.common.messages.exclude_if_none","title":"<code>exclude_if_none(field_names)</code>","text":"<p>Decorator to set the _exclude_if_none_fields class attribute to the set of field names that should be excluded if they are None.</p> Source code in <code>aiperf/common/messages.py</code> <pre><code>def exclude_if_none(field_names: list[str]):\n    \"\"\"Decorator to set the _exclude_if_none_fields class attribute to the set of\n    field names that should be excluded if they are None.\n    \"\"\"\n\n    def decorator(model: type[\"BaseMessage\"]) -&gt; type[\"BaseMessage\"]:\n        model._exclude_if_none_fields.update(field_names)\n        return model\n\n    return decorator\n</code></pre>"},{"location":"api/#aiperfcommonmodels","title":"aiperf.common.models","text":""},{"location":"api/#aiperf.common.models.ServiceRunInfo","title":"<code>ServiceRunInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base model for tracking service run information.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class ServiceRunInfo(BaseModel):\n    \"\"\"Base model for tracking service run information.\"\"\"\n\n    service_type: ServiceType = Field(\n        ...,\n        description=\"The type of service\",\n    )\n    registration_status: ServiceRegistrationStatus = Field(\n        ...,\n        description=\"The registration status of the service\",\n    )\n    service_id: str = Field(\n        ...,\n        description=\"The ID of the service\",\n    )\n    first_seen: int | None = Field(\n        default_factory=time.time_ns,\n        description=\"The first time the service was seen\",\n    )\n    last_seen: int | None = Field(\n        default_factory=time.time_ns,\n        description=\"The last time the service was seen\",\n    )\n    state: ServiceState = Field(\n        default=ServiceState.UNKNOWN,\n        description=\"The current state of the service\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig","title":"<code>ZMQCommunicationConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for ZMQ communication.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class ZMQCommunicationConfig(BaseModel):\n    \"\"\"Configuration for ZMQ communication.\"\"\"\n\n    protocol_config: ZMQTCPTransportConfig = Field(\n        default_factory=ZMQTCPTransportConfig,\n        description=\"Configuration for the selected transport protocol\",\n    )\n    client_id: str | None = Field(\n        default=None, description=\"Client ID, will be generated if not provided\"\n    )\n\n    @property\n    def controller_pub_sub_address(self) -&gt; str:\n        \"\"\"Get the controller pub/sub address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.protocol_config.host}:{self.protocol_config.controller_pub_sub_port}\"\n\n    @property\n    def component_pub_sub_address(self) -&gt; str:\n        \"\"\"Get the component pub/sub address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.protocol_config.host}:{self.protocol_config.component_pub_sub_port}\"\n\n    @property\n    def inference_push_pull_address(self) -&gt; str:\n        \"\"\"Get the inference push/pull address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.protocol_config.host}:{self.protocol_config.inference_push_pull_port}\"\n\n    @property\n    def records_address(self) -&gt; str:\n        \"\"\"Get the records address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.protocol_config.host}:{self.protocol_config.records_port}\"\n\n    @property\n    def conversation_data_address(self) -&gt; str:\n        \"\"\"Get the conversation data address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.protocol_config.host}:{self.protocol_config.conversation_data_port}\"\n\n    @property\n    def credit_drop_address(self) -&gt; str:\n        \"\"\"Get the credit drop address based on protocol configuration.\"\"\"\n        return (\n            f\"tcp://{self.protocol_config.host}:{self.protocol_config.credit_drop_port}\"\n        )\n\n    @property\n    def credit_return_address(self) -&gt; str:\n        \"\"\"Get the credit return address based on protocol configuration.\"\"\"\n        return f\"tcp://{self.protocol_config.host}:{self.protocol_config.credit_return_port}\"\n</code></pre>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.component_pub_sub_address","title":"<code>component_pub_sub_address</code>  <code>property</code>","text":"<p>Get the component pub/sub address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.controller_pub_sub_address","title":"<code>controller_pub_sub_address</code>  <code>property</code>","text":"<p>Get the controller pub/sub address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.conversation_data_address","title":"<code>conversation_data_address</code>  <code>property</code>","text":"<p>Get the conversation data address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.credit_drop_address","title":"<code>credit_drop_address</code>  <code>property</code>","text":"<p>Get the credit drop address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.credit_return_address","title":"<code>credit_return_address</code>  <code>property</code>","text":"<p>Get the credit return address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.inference_push_pull_address","title":"<code>inference_push_pull_address</code>  <code>property</code>","text":"<p>Get the inference push/pull address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQCommunicationConfig.records_address","title":"<code>records_address</code>  <code>property</code>","text":"<p>Get the records address based on protocol configuration.</p>"},{"location":"api/#aiperf.common.models.ZMQTCPTransportConfig","title":"<code>ZMQTCPTransportConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for TCP transport.</p> Source code in <code>aiperf/common/models.py</code> <pre><code>class ZMQTCPTransportConfig(BaseModel):\n    \"\"\"Configuration for TCP transport.\"\"\"\n\n    host: str = Field(\n        default=\"0.0.0.0\",\n        description=\"Host address for TCP connections\",\n    )\n    controller_pub_sub_port: int = Field(\n        default=5555, description=\"Port for controller pub/sub messages\"\n    )\n    component_pub_sub_port: int = Field(\n        default=5556, description=\"Port for component pub/sub messages\"\n    )\n    inference_push_pull_port: int = Field(\n        default=5557, description=\"Port for inference push/pull messages\"\n    )\n    req_rep_port: int = Field(\n        default=5558, description=\"Port for sending and receiving requests\"\n    )\n    push_pull_port: int = Field(\n        default=5559, description=\"Port for pushing and pulling data\"\n    )\n    records_port: int = Field(default=5560, description=\"Port for record data\")\n    conversation_data_port: int = Field(\n        default=5561, description=\"Port for conversation data\"\n    )\n    credit_drop_port: int = Field(\n        default=5562, description=\"Port for credit drop operations\"\n    )\n    credit_return_port: int = Field(\n        default=5563, description=\"Port for credit return operations\"\n    )\n</code></pre>"},{"location":"api/#aiperfcommonrecord_models","title":"aiperf.common.record_models","text":""},{"location":"api/#aiperf.common.record_models.BaseClientConfig","title":"<code>BaseClientConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base configuration options for all clients.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class BaseClientConfig(BaseModel):\n    \"\"\"Base configuration options for all clients.\"\"\"\n</code></pre>"},{"location":"api/#aiperf.common.record_models.ErrorDetails","title":"<code>ErrorDetails</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Encapsulates details about an error.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class ErrorDetails(BaseModel):\n    \"\"\"Encapsulates details about an error.\"\"\"\n\n    code: int | None = Field(\n        default=None,\n        description=\"The error code.\",\n    )\n    type: str | None = Field(\n        default=None,\n        description=\"The error type.\",\n    )\n    message: str = Field(\n        ...,\n        description=\"The error message.\",\n    )\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Check if the error details are equal by comparing the code, type, and message.\"\"\"\n        if not isinstance(other, ErrorDetails):\n            return False\n        return (\n            self.code == other.code\n            and self.type == other.type\n            and self.message == other.message\n        )\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Hash the error details by hashing the code, type, and message.\"\"\"\n        return hash((self.code, self.type, self.message))\n</code></pre>"},{"location":"api/#aiperf.common.record_models.ErrorDetails.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Check if the error details are equal by comparing the code, type, and message.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Check if the error details are equal by comparing the code, type, and message.\"\"\"\n    if not isinstance(other, ErrorDetails):\n        return False\n    return (\n        self.code == other.code\n        and self.type == other.type\n        and self.message == other.message\n    )\n</code></pre>"},{"location":"api/#aiperf.common.record_models.ErrorDetails.__hash__","title":"<code>__hash__()</code>","text":"<p>Hash the error details by hashing the code, type, and message.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Hash the error details by hashing the code, type, and message.\"\"\"\n    return hash((self.code, self.type, self.message))\n</code></pre>"},{"location":"api/#aiperf.common.record_models.ErrorDetailsCount","title":"<code>ErrorDetailsCount</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Count of error details.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class ErrorDetailsCount(BaseModel):\n    \"\"\"Count of error details.\"\"\"\n\n    error_details: ErrorDetails\n    count: int = Field(\n        ...,\n        description=\"The count of the error details.\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.record_models.GenericHTTPClientConfig","title":"<code>GenericHTTPClientConfig</code>","text":"<p>               Bases: <code>BaseClientConfig</code></p> <p>Configuration options for a generic HTTP inference client.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class GenericHTTPClientConfig(BaseClientConfig):\n    \"\"\"Configuration options for a generic HTTP inference client.\"\"\"\n\n    url: str = Field(\n        default=f\"http://localhost:{os.getenv('AIPERF_PORT', 8080)}\",\n        description=\"The URL of the inference client.\",\n    )\n    protocol: str = Field(\n        default=\"http\", description=\"The protocol to use for the inference client.\"\n    )\n    ssl_options: dict[str, Any] | None = Field(\n        default=None,\n        description=\"The SSL options to use for the inference client.\",\n    )\n    timeout_ms: int = Field(\n        default=300000,\n        description=\"The timeout in milliseconds for the inference client.\",\n    )\n    headers: dict[str, str] = Field(\n        default_factory=dict,\n        description=\"The headers to use for the inference client.\",\n    )\n    api_key: str | None = Field(\n        default=None,\n        description=\"The API key to use for the inference client.\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.record_models.InferenceServerResponse","title":"<code>InferenceServerResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response from a inference client.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class InferenceServerResponse(BaseModel):\n    \"\"\"Response from a inference client.\"\"\"\n\n    perf_ns: int = Field(\n        ...,\n        description=\"The timestamp of the response in nanoseconds (perf_counter_ns).\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.record_models.Record","title":"<code>Record</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a record containing a request transaction and its associated response transactions. Attributes:     request: The input transaction for the record.     responses A list of response transactions corresponding to the request.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class Record(BaseModel):\n    \"\"\"\n    Represents a record containing a request transaction and its associated response transactions.\n    Attributes:\n        request: The input transaction for the record.\n        responses A list of response transactions corresponding to the request.\n    \"\"\"\n\n    request: Transaction = Field(description=\"The request transaction for the record\")\n    responses: list[Transaction] = Field(\n        description=\"A list of response transactions for the record\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.record_models.RequestRecord","title":"<code>RequestRecord</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Record of a request.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class RequestRecord(BaseModel):\n    \"\"\"Record of a request.\"\"\"\n\n    start_perf_ns: int = Field(\n        default_factory=time.perf_counter_ns,\n        description=\"The start time of the request in perf_counter_ns.\",\n    )\n    end_perf_ns: int | None = Field(\n        default=None,\n        description=\"The end time of the request in perf_counter_ns.\",\n    )\n    recv_start_perf_ns: int | None = Field(\n        default=None,\n        description=\"The start time of the response in perf_counter_ns.\",\n    )\n    status: int | None = Field(\n        default=None,\n        description=\"The HTTPstatus code of the request.\",\n    )\n    # Note: we need to use SerializeAsAny to allow for generic subclass support\n    responses: SerializeAsAny[\n        list[InferenceServerResponse | SSEMessage | TextResponse]\n    ] = Field(\n        default_factory=list,\n        description=\"The raw responses received from the request.\",\n    )\n    error: ErrorDetails | None = Field(\n        default=None,\n        description=\"The error details if the request failed.\",\n    )\n    sequence_end: bool = Field(\n        default=True, description=\"Whether the sequence has ended.\"\n    )\n    delayed: bool = Field(default=False, description=\"Whether the request was delayed.\")\n\n    # TODO: Most of these properties will be removed once we have proper record handling.\n\n    @property\n    def has_null_last_response(self) -&gt; bool:\n        \"\"\"Whether the last response received was null.\"\"\"\n        return len(self.responses) &gt; 0 and self.responses[-1] is None\n\n    @property\n    def has_error(self) -&gt; bool:\n        \"\"\"Check if the request record has an error.\"\"\"\n        return self.error is not None\n\n    @property\n    def valid(self) -&gt; bool:\n        \"\"\"Check if the request record is valid by ensuring that the start time\n        and response timestamps are within valid ranges.\n\n        Returns:\n            bool: True if the record is valid, False otherwise.\n        \"\"\"\n        return not self.has_error and (\n            0 &lt;= self.start_perf_ns &lt; sys.maxsize\n            and len(self.responses) &gt; 0\n            and all(0 &lt; response.perf_ns &lt; sys.maxsize for response in self.responses)\n        )\n\n    @property\n    def time_to_first_response_ns(self) -&gt; int | None:\n        \"\"\"Get the time to the first response in nanoseconds.\"\"\"\n        if not self.valid:\n            return None\n        return self.responses[0].perf_ns - self.recv_start_perf_ns\n\n    @property\n    def time_to_second_response_ns(self) -&gt; int | None:\n        \"\"\"Get the time to the second response in nanoseconds.\"\"\"\n        if not self.valid or len(self.responses) &lt; 2:\n            return None\n        # first_data = 0\n        # while first_data &lt; len(self.responses) - 1:\n        #     if self.responses[first_data].packets[-1].value == \"[DONE]\":\n        #         break\n        #     first_data += 1\n        return self.responses[1].perf_ns - self.responses[0].perf_ns\n\n    @property\n    def time_to_last_response_ns(self) -&gt; int | None:\n        \"\"\"Get the time to the last response in nanoseconds.\"\"\"\n        if not self.valid:\n            return None\n        if self.end_perf_ns is None or self.start_perf_ns is None:\n            return None\n        return self.end_perf_ns - self.recv_start_perf_ns\n\n    @property\n    def inter_token_latency_ns(self) -&gt; float | None:\n        \"\"\"Get the interval between responses in nanoseconds.\"\"\"\n        if not self.valid or len(self.responses) &lt; 2:\n            return None\n\n        if (\n            hasattr(self.responses[-1], \"packets\")\n            and self.responses[-1].packets[-1].value == \"[DONE]\"\n        ):\n            return (self.responses[-2].perf_ns - self.responses[0].perf_ns) / (\n                len(self.responses) - 2\n            )\n\n        return (self.responses[-1].perf_ns - self.responses[0].perf_ns) / (\n            len(self.responses) - 1\n        )\n\n    def token_latency_ns(self, index: int) -&gt; float | None:\n        \"\"\"Get the latency of a token in nanoseconds.\"\"\"\n        if not self.valid or len(self.responses) &lt; 1:\n            return None\n        if index == 0:\n            return self.responses[0].perf_ns - self.recv_start_perf_ns\n        return self.responses[index].perf_ns - self.responses[index - 1].perf_ns\n\n    def time_string(self) -&gt; str:\n        \"\"\"Return a string representation of the request record.\"\"\"\n        lt = [\n            # f\"start_perf_ns={self.start_perf_ns / 1000000:.3f}ms\",\n            f\"recv_start_perf_ns={(self.recv_start_perf_ns - self.start_perf_ns) / 1000000:.3f}ms\",\n            f\"end_perf_ns={(self.end_perf_ns - self.start_perf_ns) / 1000000:.3f}ms\",\n            f\"recv_duration={(self.end_perf_ns - self.recv_start_perf_ns) / 1000000:.3f}ms\",\n            f\"duration={(self.end_perf_ns - self.start_perf_ns) / 1000000:.3f}ms\",\n        ]\n        tt = [\n            f\"{self.token_latency_ns(i) / 1000000:.3f}ms\"\n            for i in range(len(self.responses))\n        ]\n        return f\"RequestRecord({', '.join(lt)}, [{', '.join(tt)}])\"\n</code></pre>"},{"location":"api/#aiperf.common.record_models.RequestRecord.has_error","title":"<code>has_error</code>  <code>property</code>","text":"<p>Check if the request record has an error.</p>"},{"location":"api/#aiperf.common.record_models.RequestRecord.has_null_last_response","title":"<code>has_null_last_response</code>  <code>property</code>","text":"<p>Whether the last response received was null.</p>"},{"location":"api/#aiperf.common.record_models.RequestRecord.inter_token_latency_ns","title":"<code>inter_token_latency_ns</code>  <code>property</code>","text":"<p>Get the interval between responses in nanoseconds.</p>"},{"location":"api/#aiperf.common.record_models.RequestRecord.time_to_first_response_ns","title":"<code>time_to_first_response_ns</code>  <code>property</code>","text":"<p>Get the time to the first response in nanoseconds.</p>"},{"location":"api/#aiperf.common.record_models.RequestRecord.time_to_last_response_ns","title":"<code>time_to_last_response_ns</code>  <code>property</code>","text":"<p>Get the time to the last response in nanoseconds.</p>"},{"location":"api/#aiperf.common.record_models.RequestRecord.time_to_second_response_ns","title":"<code>time_to_second_response_ns</code>  <code>property</code>","text":"<p>Get the time to the second response in nanoseconds.</p>"},{"location":"api/#aiperf.common.record_models.RequestRecord.valid","title":"<code>valid</code>  <code>property</code>","text":"<p>Check if the request record is valid by ensuring that the start time and response timestamps are within valid ranges.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the record is valid, False otherwise.</p>"},{"location":"api/#aiperf.common.record_models.RequestRecord.time_string","title":"<code>time_string()</code>","text":"<p>Return a string representation of the request record.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>def time_string(self) -&gt; str:\n    \"\"\"Return a string representation of the request record.\"\"\"\n    lt = [\n        # f\"start_perf_ns={self.start_perf_ns / 1000000:.3f}ms\",\n        f\"recv_start_perf_ns={(self.recv_start_perf_ns - self.start_perf_ns) / 1000000:.3f}ms\",\n        f\"end_perf_ns={(self.end_perf_ns - self.start_perf_ns) / 1000000:.3f}ms\",\n        f\"recv_duration={(self.end_perf_ns - self.recv_start_perf_ns) / 1000000:.3f}ms\",\n        f\"duration={(self.end_perf_ns - self.start_perf_ns) / 1000000:.3f}ms\",\n    ]\n    tt = [\n        f\"{self.token_latency_ns(i) / 1000000:.3f}ms\"\n        for i in range(len(self.responses))\n    ]\n    return f\"RequestRecord({', '.join(lt)}, [{', '.join(tt)}])\"\n</code></pre>"},{"location":"api/#aiperf.common.record_models.RequestRecord.token_latency_ns","title":"<code>token_latency_ns(index)</code>","text":"<p>Get the latency of a token in nanoseconds.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>def token_latency_ns(self, index: int) -&gt; float | None:\n    \"\"\"Get the latency of a token in nanoseconds.\"\"\"\n    if not self.valid or len(self.responses) &lt; 1:\n        return None\n    if index == 0:\n        return self.responses[0].perf_ns - self.recv_start_perf_ns\n    return self.responses[index].perf_ns - self.responses[index - 1].perf_ns\n</code></pre>"},{"location":"api/#aiperf.common.record_models.SSEEventType","title":"<code>SSEEventType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Event types in an SSE message. Many of these are custom and not defined by the SSE spec.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class SSEEventType(CaseInsensitiveStrEnum):\n    \"\"\"Event types in an SSE message. Many of these are custom and not defined by the SSE spec.\"\"\"\n\n    ERROR = \"error\"\n    LLM_METRICS = \"llm_metrics\"\n</code></pre>"},{"location":"api/#aiperf.common.record_models.SSEField","title":"<code>SSEField</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base model for a single field in an SSE message.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class SSEField(BaseModel):\n    \"\"\"Base model for a single field in an SSE message.\"\"\"\n\n    name: SSEFieldType | str = Field(\n        ...,\n        description=\"The name of the field. e.g. 'data', 'event', 'id', 'retry', 'comment'.\",\n    )\n    value: str | None = Field(\n        default=None,\n        description=\"The value of the field.\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.record_models.SSEFieldType","title":"<code>SSEFieldType</code>","text":"<p>               Bases: <code>CaseInsensitiveStrEnum</code></p> <p>Field types in an SSE message.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class SSEFieldType(CaseInsensitiveStrEnum):\n    \"\"\"Field types in an SSE message.\"\"\"\n\n    DATA = \"data\"\n    EVENT = \"event\"\n    ID = \"id\"\n    RETRY = \"retry\"\n    COMMENT = \"comment\"\n</code></pre>"},{"location":"api/#aiperf.common.record_models.SSEMessage","title":"<code>SSEMessage</code>","text":"<p>               Bases: <code>InferenceServerResponse</code></p> <p>Individual SSE message from an SSE stream. Delimited by </p> <p>.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class SSEMessage(InferenceServerResponse):\n    \"\"\"Individual SSE message from an SSE stream. Delimited by \\n\\n.\"\"\"\n\n    # Note: \"fields\" is a restricted keyword in pydantic\n    packets: list[SSEField] = Field(\n        default_factory=list,\n        description=\"The fields contained in the message.\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.record_models.TextResponse","title":"<code>TextResponse</code>","text":"<p>               Bases: <code>InferenceServerResponse</code></p> <p>Raw text response from a inference client including an optional content type.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class TextResponse(InferenceServerResponse):\n    \"\"\"Raw text response from a inference client including an optional content type.\"\"\"\n\n    content_type: str | None = Field(\n        default=None,\n        description=\"The content type of the response. e.g. 'text/plain', 'application/json'.\",\n    )\n    text: str = Field(\n        ...,\n        description=\"The text of the response.\",\n    )\n</code></pre>"},{"location":"api/#aiperf.common.record_models.Transaction","title":"<code>Transaction</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a request/response with a timestamp and associated payload.</p> <p>Attributes:</p> Name Type Description <code>timestamp</code> <code>int</code> <p>The time at which the transaction was recorded.</p> <code>payload</code> <code>Any</code> <p>The data or content of the transaction.</p> Source code in <code>aiperf/common/record_models.py</code> <pre><code>class Transaction(BaseModel):\n    \"\"\"\n    Represents a request/response with a timestamp and associated payload.\n\n    Attributes:\n        timestamp: The time at which the transaction was recorded.\n        payload: The data or content of the transaction.\n    \"\"\"\n\n    timestamp: int = Field(description=\"The timestamp of the transaction\")\n    payload: Any = Field(description=\"The payload of the transaction\")\n</code></pre>"},{"location":"api/#aiperfcommonservicebase_component_service","title":"aiperf.common.service.base_component_service","text":""},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService","title":"<code>BaseComponentService</code>","text":"<p>               Bases: <code>BaseService</code></p> <p>Base class for all Component services.</p> <p>This class provides a common interface for all Component services in the AIPerf framework such as the Timing Manager, Dataset Manager, etc.</p> <p>It extends the BaseService by: - Subscribing to the command topic - Processing command messages - Sending registration requests to the system controller - Sending heartbeat notifications to the system controller - Sending status notifications to the system controller - Helpers to create heartbeat, registration, and status messages - Request the appropriate communication clients for a component service</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>class BaseComponentService(BaseService):\n    \"\"\"Base class for all Component services.\n\n    This class provides a common interface for all Component services in the AIPerf\n    framework such as the Timing Manager, Dataset Manager, etc.\n\n    It extends the BaseService by:\n    - Subscribing to the command topic\n    - Processing command messages\n    - Sending registration requests to the system controller\n    - Sending heartbeat notifications to the system controller\n    - Sending status notifications to the system controller\n    - Helpers to create heartbeat, registration, and status messages\n    - Request the appropriate communication clients for a component service\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self._command_callbacks: dict[\n            CommandType, Callable[[CommandMessage], Awaitable[None]]\n        ] = {}\n\n    @property\n    def required_clients(self) -&gt; list[ClientType]:\n        \"\"\"The communication clients required by the service.\n\n        The component services subscribe to controller messages and publish\n        component messages.\n        \"\"\"\n        return [\n            *(super().required_clients or []),\n            PubClientType.COMPONENT,\n            SubClientType.CONTROLLER,\n        ]\n\n    @on_run\n    async def _on_run(self) -&gt; None:\n        \"\"\"Automatically subscribe to the command topic and register the service\n        with the system controller when the run hook is called.\n\n        This method will:\n        - Subscribe to the command topic\n        - Wait for the communication to be fully initialized\n        - Register the service with the system controller\n        \"\"\"\n        # Subscribe to the command topic\n        try:\n            await self.comms.subscribe(\n                Topic.COMMAND,\n                self.process_command_message,\n            )\n        except Exception as e:\n            raise self._service_error(\"Failed to subscribe to command topic\") from e\n\n        # TODO: Find a way to wait for the communication to be fully initialized\n        # FIXME: This is a hack to ensure the communication is fully initialized\n        await asyncio.sleep(1)\n\n        # Register the service\n        try:\n            await self.register()\n            await asyncio.sleep(0.5)\n        except Exception as e:\n            raise self._service_error(\"Failed to register service\") from e\n\n    @aiperf_task\n    async def _heartbeat_task(self) -&gt; None:\n        \"\"\"Starts a background task to send heartbeats at regular intervals. It\n        will continue to send heartbeats even if an error occurs until the stop\n        event is set.\n        \"\"\"\n        while not self.stop_event.is_set():\n            # Sleep first to avoid sending a heartbeat before the registration\n            # message has been published\n            await asyncio.sleep(self._heartbeat_interval)\n\n            try:\n                await self.send_heartbeat()\n            except Exception as e:\n                self.logger.warning(\"Exception sending heartbeat: %s\", e)\n                # continue to keep sending heartbeats regardless of the error\n\n        self.logger.debug(\"Heartbeat task stopped\")\n\n    async def send_heartbeat(self) -&gt; None:\n        \"\"\"Send a heartbeat notification to the system controller.\"\"\"\n        heartbeat_message = self.create_heartbeat_message()\n        self.logger.debug(\"Sending heartbeat: %s\", heartbeat_message)\n        try:\n            await self.comms.publish(\n                topic=Topic.HEARTBEAT,\n                message=heartbeat_message,\n            )\n        except Exception as e:\n            raise self._service_error(\"Failed to send heartbeat\") from e\n\n    async def register(self) -&gt; None:\n        \"\"\"Publish a registration request to the system controller.\n\n        This method should be called after the service has been initialized and is\n        ready to start processing messages.\n        \"\"\"\n        self.logger.debug(\n            \"Attempting to register service %s (%s) with system controller\",\n            self.service_type,\n            self.service_id,\n        )\n        try:\n            await self.comms.publish(\n                topic=Topic.REGISTRATION,\n                message=self.create_registration_message(),\n            )\n        except Exception as e:\n            raise self._service_error(\"Failed to register service\") from e\n\n    async def process_command_message(self, message: CommandMessage) -&gt; None:\n        \"\"\"Process a command message received from the controller.\n\n        This method will process the command message and execute the appropriate action.\n        \"\"\"\n        if message.target_service_id and message.target_service_id != self.service_id:\n            return  # Ignore commands meant for other services\n        if (\n            message.target_service_type\n            and message.target_service_type != self.service_type\n        ):\n            return  # Ignore commands meant for other services\n\n        cmd = message.command\n        if cmd == CommandType.PROFILE_START:\n            await self.start()\n\n        elif cmd == CommandType.SHUTDOWN:\n            self.logger.debug(\"%s received stop command\", self.service_id)\n            self.stop_event.set()\n\n        elif cmd == CommandType.PROFILE_CONFIGURE:\n            await self.run_hooks(AIPerfHook.ON_CONFIGURE, message)\n\n        elif cmd in self._command_callbacks:\n            await self._command_callbacks[cmd](message)\n\n        else:\n            self.logger.warning(\"%s received unknown command: %s\", self.service_id, cmd)\n\n    def register_command_callback(\n        self,\n        cmd: CommandType,\n        callback: Callable[[CommandMessage], Awaitable[None]],\n    ) -&gt; None:\n        \"\"\"Register a single callback for a command.\"\"\"\n        self._command_callbacks[cmd] = callback\n\n    @on_set_state\n    async def _on_set_state(self, state: ServiceState) -&gt; None:\n        \"\"\"Action to take when the service state is set.\n\n        This method will also publish the status message to the status topic if the\n        communications are initialized.\n        \"\"\"\n        if self._comms and self._comms.is_initialized:\n            await self.comms.publish(\n                topic=Topic.STATUS,\n                message=self.create_status_message(state),\n            )\n\n    def create_heartbeat_message(self) -&gt; HeartbeatMessage:\n        \"\"\"Create a heartbeat notification message.\"\"\"\n        return HeartbeatMessage(\n            service_id=self.service_id,\n            service_type=self.service_type,\n        )\n\n    def create_registration_message(self) -&gt; RegistrationMessage:\n        \"\"\"Create a registration request message.\"\"\"\n        return RegistrationMessage(\n            service_id=self.service_id,\n            service_type=self.service_type,\n        )\n\n    def create_status_message(self, state: ServiceState) -&gt; StatusMessage:\n        \"\"\"Create a status notification message.\"\"\"\n        return StatusMessage(\n            service_id=self.service_id,\n            state=state,\n            service_type=self.service_type,\n        )\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.required_clients","title":"<code>required_clients</code>  <code>property</code>","text":"<p>The communication clients required by the service.</p> <p>The component services subscribe to controller messages and publish component messages.</p>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.create_heartbeat_message","title":"<code>create_heartbeat_message()</code>","text":"<p>Create a heartbeat notification message.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>def create_heartbeat_message(self) -&gt; HeartbeatMessage:\n    \"\"\"Create a heartbeat notification message.\"\"\"\n    return HeartbeatMessage(\n        service_id=self.service_id,\n        service_type=self.service_type,\n    )\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.create_registration_message","title":"<code>create_registration_message()</code>","text":"<p>Create a registration request message.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>def create_registration_message(self) -&gt; RegistrationMessage:\n    \"\"\"Create a registration request message.\"\"\"\n    return RegistrationMessage(\n        service_id=self.service_id,\n        service_type=self.service_type,\n    )\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.create_status_message","title":"<code>create_status_message(state)</code>","text":"<p>Create a status notification message.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>def create_status_message(self, state: ServiceState) -&gt; StatusMessage:\n    \"\"\"Create a status notification message.\"\"\"\n    return StatusMessage(\n        service_id=self.service_id,\n        state=state,\n        service_type=self.service_type,\n    )\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.process_command_message","title":"<code>process_command_message(message)</code>  <code>async</code>","text":"<p>Process a command message received from the controller.</p> <p>This method will process the command message and execute the appropriate action.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>async def process_command_message(self, message: CommandMessage) -&gt; None:\n    \"\"\"Process a command message received from the controller.\n\n    This method will process the command message and execute the appropriate action.\n    \"\"\"\n    if message.target_service_id and message.target_service_id != self.service_id:\n        return  # Ignore commands meant for other services\n    if (\n        message.target_service_type\n        and message.target_service_type != self.service_type\n    ):\n        return  # Ignore commands meant for other services\n\n    cmd = message.command\n    if cmd == CommandType.PROFILE_START:\n        await self.start()\n\n    elif cmd == CommandType.SHUTDOWN:\n        self.logger.debug(\"%s received stop command\", self.service_id)\n        self.stop_event.set()\n\n    elif cmd == CommandType.PROFILE_CONFIGURE:\n        await self.run_hooks(AIPerfHook.ON_CONFIGURE, message)\n\n    elif cmd in self._command_callbacks:\n        await self._command_callbacks[cmd](message)\n\n    else:\n        self.logger.warning(\"%s received unknown command: %s\", self.service_id, cmd)\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.register","title":"<code>register()</code>  <code>async</code>","text":"<p>Publish a registration request to the system controller.</p> <p>This method should be called after the service has been initialized and is ready to start processing messages.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>async def register(self) -&gt; None:\n    \"\"\"Publish a registration request to the system controller.\n\n    This method should be called after the service has been initialized and is\n    ready to start processing messages.\n    \"\"\"\n    self.logger.debug(\n        \"Attempting to register service %s (%s) with system controller\",\n        self.service_type,\n        self.service_id,\n    )\n    try:\n        await self.comms.publish(\n            topic=Topic.REGISTRATION,\n            message=self.create_registration_message(),\n        )\n    except Exception as e:\n        raise self._service_error(\"Failed to register service\") from e\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.register_command_callback","title":"<code>register_command_callback(cmd, callback)</code>","text":"<p>Register a single callback for a command.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>def register_command_callback(\n    self,\n    cmd: CommandType,\n    callback: Callable[[CommandMessage], Awaitable[None]],\n) -&gt; None:\n    \"\"\"Register a single callback for a command.\"\"\"\n    self._command_callbacks[cmd] = callback\n</code></pre>"},{"location":"api/#aiperf.common.service.base_component_service.BaseComponentService.send_heartbeat","title":"<code>send_heartbeat()</code>  <code>async</code>","text":"<p>Send a heartbeat notification to the system controller.</p> Source code in <code>aiperf/common/service/base_component_service.py</code> <pre><code>async def send_heartbeat(self) -&gt; None:\n    \"\"\"Send a heartbeat notification to the system controller.\"\"\"\n    heartbeat_message = self.create_heartbeat_message()\n    self.logger.debug(\"Sending heartbeat: %s\", heartbeat_message)\n    try:\n        await self.comms.publish(\n            topic=Topic.HEARTBEAT,\n            message=heartbeat_message,\n        )\n    except Exception as e:\n        raise self._service_error(\"Failed to send heartbeat\") from e\n</code></pre>"},{"location":"api/#aiperfcommonservicebase_controller_service","title":"aiperf.common.service.base_controller_service","text":""},{"location":"api/#aiperf.common.service.base_controller_service.BaseControllerService","title":"<code>BaseControllerService</code>","text":"<p>               Bases: <code>BaseService</code></p> <p>Base class for all controller services, such as the System Controller.</p> <p>This class provides a common interface for all controller services in the AIPerf framework. It inherits from the BaseService class and implements the required methods for controller services.</p> <p>It extends the BaseService by: - Starting the service automatically when the run hook is called - Helpers to create command messages to be sent to a specific service - Request the appropriate communication clients for a controller service</p> Source code in <code>aiperf/common/service/base_controller_service.py</code> <pre><code>class BaseControllerService(BaseService):\n    \"\"\"Base class for all controller services, such as the System Controller.\n\n    This class provides a common interface for all controller services in the AIPerf\n    framework. It inherits from the BaseService class and implements the required\n    methods for controller services.\n\n    It extends the BaseService by:\n    - Starting the service automatically when the run hook is called\n    - Helpers to create command messages to be sent to a specific service\n    - Request the appropriate communication clients for a controller service\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n\n    @property\n    def required_clients(self) -&gt; list[ClientType]:\n        \"\"\"The communication clients required by the service.\n\n        The controller service subscribes to controller messages and publishes\n        to components.\n        \"\"\"\n        return [\n            *(super().required_clients or []),\n            PubClientType.CONTROLLER,\n            SubClientType.COMPONENT,\n        ]\n\n    @on_run\n    async def _on_run(self) -&gt; None:\n        \"\"\"Automatically start the service when the run hook is called.\"\"\"\n        await self.start()\n\n    def create_command_message(\n        self,\n        command: CommandType,\n        target_service_id: str | None,\n        data: BaseModel | None = None,\n        target_service_type: ServiceType | None = None,\n    ) -&gt; CommandMessage:\n        \"\"\"Create a command message to be sent to a specific service.\n\n        Args:\n            command: The command to send\n            target_service_id: The ID of the service to send the command to\n            target_service_type: The type of the service to send the command to\n            data: Optional data to send with the command.\n\n        Returns:\n            A command message\n        \"\"\"\n        return CommandMessage(\n            service_id=self.service_id,\n            command=command,\n            target_service_id=target_service_id,\n            target_service_type=target_service_type,\n            data=data,\n        )\n</code></pre>"},{"location":"api/#aiperf.common.service.base_controller_service.BaseControllerService.required_clients","title":"<code>required_clients</code>  <code>property</code>","text":"<p>The communication clients required by the service.</p> <p>The controller service subscribes to controller messages and publishes to components.</p>"},{"location":"api/#aiperf.common.service.base_controller_service.BaseControllerService.create_command_message","title":"<code>create_command_message(command, target_service_id, data=None, target_service_type=None)</code>","text":"<p>Create a command message to be sent to a specific service.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>CommandType</code> <p>The command to send</p> required <code>target_service_id</code> <code>str | None</code> <p>The ID of the service to send the command to</p> required <code>target_service_type</code> <code>ServiceType | None</code> <p>The type of the service to send the command to</p> <code>None</code> <code>data</code> <code>BaseModel | None</code> <p>Optional data to send with the command.</p> <code>None</code> <p>Returns:</p> Type Description <code>CommandMessage</code> <p>A command message</p> Source code in <code>aiperf/common/service/base_controller_service.py</code> <pre><code>def create_command_message(\n    self,\n    command: CommandType,\n    target_service_id: str | None,\n    data: BaseModel | None = None,\n    target_service_type: ServiceType | None = None,\n) -&gt; CommandMessage:\n    \"\"\"Create a command message to be sent to a specific service.\n\n    Args:\n        command: The command to send\n        target_service_id: The ID of the service to send the command to\n        target_service_type: The type of the service to send the command to\n        data: Optional data to send with the command.\n\n    Returns:\n        A command message\n    \"\"\"\n    return CommandMessage(\n        service_id=self.service_id,\n        command=command,\n        target_service_id=target_service_id,\n        target_service_type=target_service_type,\n        data=data,\n    )\n</code></pre>"},{"location":"api/#aiperfcommonservicebase_service","title":"aiperf.common.service.base_service","text":""},{"location":"api/#aiperf.common.service.base_service.BaseService","title":"<code>BaseService</code>","text":"<p>               Bases: <code>BaseServiceInterface</code>, <code>ABC</code>, <code>AIPerfTaskMixin</code></p> <p>Base class for all AIPerf services, providing common functionality for communication, state management, and lifecycle operations.</p> <p>This class provides the foundation for implementing the various services of the AIPerf system. Some of the abstract methods are implemented here, while others are still required to be implemented by derived classes.</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>@supports_hooks(\n    AIPerfHook.ON_INIT,\n    AIPerfHook.ON_RUN,\n    AIPerfHook.ON_CONFIGURE,\n    AIPerfHook.ON_START,\n    AIPerfHook.ON_STOP,\n    AIPerfHook.ON_CLEANUP,\n    AIPerfHook.ON_SET_STATE,\n    AIPerfHook.AIPERF_TASK,\n)\nclass BaseService(BaseServiceInterface, ABC, AIPerfTaskMixin):\n    \"\"\"Base class for all AIPerf services, providing common functionality for\n    communication, state management, and lifecycle operations.\n\n    This class provides the foundation for implementing the various services of the\n    AIPerf system. Some of the abstract methods are implemented here, while others\n    are still required to be implemented by derived classes.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        self.service_id: str = (\n            service_id or f\"{self.service_type}_{uuid.uuid4().hex[:8]}\"\n        )\n        self.service_config = service_config\n\n        self.logger = logging.getLogger(self.service_type)\n        self.logger.debug(\n            f\"Initializing {self.service_type} service (id: {self.service_id})\"\n        )\n\n        self._state: ServiceState = ServiceState.UNKNOWN\n        self._heartbeat_interval = self.service_config.heartbeat_interval\n\n        self.stop_event = asyncio.Event()\n        self.initialized_event = asyncio.Event()\n\n        self._comms: BaseCommunication | None = None\n\n        try:\n            import setproctitle\n\n            setproctitle.setproctitle(f\"aiperf {self.service_id}\")\n        except Exception:\n            # setproctitle is not available on all platforms, so we ignore the error\n            self.logger.debug(\"Failed to set process title, ignoring\")\n\n        super().__init__()\n        self.logger.debug(\"__init__ finished for %s\", self.__class__.__name__)\n\n    @property\n    def comms(self) -&gt; BaseCommunication:\n        \"\"\"\n        Get the communication object for the service.\n        Raises:\n            CommunicationError: If the communication is not initialized\n        \"\"\"\n        if not self._comms:\n            raise CommunicationError(\n                CommunicationErrorReason.INITIALIZATION_ERROR,\n                \"Communication channels are not initialized\",\n            )\n        return self._comms\n\n    @property\n    def state(self) -&gt; ServiceState:\n        \"\"\"The current state of the service.\"\"\"\n        return self._state\n\n    @property\n    def is_initialized(self) -&gt; bool:\n        \"\"\"Check if service is initialized.\n\n        Returns:\n            True if service is initialized, False otherwise\n        \"\"\"\n        return self.initialized_event.is_set()\n\n    @property\n    def is_shutdown(self) -&gt; bool:\n        \"\"\"Check if service is shutdown.\n\n        Returns:\n            True if service is shutdown, False otherwise\n        \"\"\"\n        return self.stop_event.is_set()\n\n    def _service_error(self, message: str) -&gt; ServiceError:\n        return ServiceError(\n            message=message,\n            service_type=self.service_type,\n            service_id=self.service_id,\n        )\n\n    # Note: Not using as a setter so it can be overridden by derived classes and still\n    # be async\n    async def set_state(self, state: ServiceState) -&gt; None:\n        \"\"\"Set the state of the service. This method implements\n        the `BaseServiceInterface.set_state` method.\n\n        This method will:\n        - Set the service state to the given state\n        - Call all registered `AIPerfHook.ON_SET_STATE` hooks\n        \"\"\"\n        self._state = state\n        await self.run_hooks(AIPerfHook.ON_SET_STATE, state)\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize the service communication and signal handlers. This method implements\n        the `BaseServiceInterface.initialize` method.\n\n        This method will:\n        - Set the service to `ServiceState.INITIALIZING` state\n        - Allow time for the event loop to start\n        - Initialize communication\n        - Call all registered `AIPerfHook.ON_INIT` hooks\n        - Set the service to `ServiceState.READY` state\n        - Set the initialized asyncio event\n        \"\"\"\n        self._state = ServiceState.INITIALIZING\n        # Allow time for the event loop to start\n        await asyncio.sleep(0.1)\n\n        # Initialize communication\n        self._comms = CommunicationFactory.create_instance(\n            self.service_config.comm_backend,\n            config=self.service_config.comm_config,\n        )\n\n        await self._comms.initialize()\n\n        if len(self.required_clients) &gt; 0:\n            # Create the communication clients ahead of time\n            self.logger.debug(\n                \"%s: Creating communication clients (%s)\",\n                self.service_type,\n                self.required_clients,\n            )\n\n            await self._comms.create_clients(*self.required_clients)\n\n        # Initialize any derived service components\n        await self.run_hooks(AIPerfHook.ON_INIT)\n        await self.set_state(ServiceState.READY)\n\n        self.initialized_event.set()\n\n    async def run_forever(self) -&gt; None:\n        \"\"\"Run the service in a loop until the stop event is set. This method implements\n        the `BaseServiceInterface.run_forever` method.\n\n        This method will:\n        - Call the initialize method to initialize the service\n        - Call all registered `AIPerfHook.RUN` hooks\n        - Wait for the stop event to be set\n        - Shuts down the service when the stop event is set\n\n        This method will be called as the main entry point for the service.\n        \"\"\"\n        try:\n            self.logger.debug(\n                \"Running %s service (id: %s)\", self.service_type, self.service_id\n            )\n\n            await self.initialize()\n            await self.run_hooks(AIPerfHook.ON_RUN)\n\n        except asyncio.CancelledError:\n            self.logger.debug(\"Service %s execution cancelled\", self.service_type)\n            return\n\n        except AIPerfError:\n            raise  # re-raise it up the stack\n\n        except Exception as e:\n            self.logger.exception(\"Service %s execution failed:\", self.service_type)\n            _ = await self.set_state(ServiceState.ERROR)\n            raise self._service_error(\"Service execution failed\") from e\n\n        await self._forever_loop()\n\n    async def _forever_loop(self) -&gt; None:\n        \"\"\"\n        This method will be called by the `run_forever` method to allow the service to run\n        indefinitely. This method is not expected to be overridden by derived classes.\n\n        This method will:\n        - Wait for the stop event to be set\n        - Shuts down the service when the stop event is set\n        \"\"\"\n        while not self.is_shutdown:\n            try:\n                self.logger.debug(\n                    \"Service %s waiting for stop event\", self.service_type\n                )\n                # Wait forever for the stop event to be set\n                await self.stop_event.wait()\n\n            except (SystemExit, asyncio.CancelledError):\n                pass\n\n            except Exception:\n                self.logger.exception(\n                    \"Caught unexpected exception in service %s execution\",\n                    self.service_type,\n                )\n\n            finally:\n                # Shutdown the service\n                try:\n                    await self.stop()\n                except Exception as e:\n                    raise self._service_error(\"Exception stopping service\") from e\n\n    async def start(self) -&gt; None:\n        \"\"\"Start the service and its components. This method implements\n        the `BaseServiceInterface.start` method.\n\n        This method should be called to start the service after it has been initialized\n        and configured.\n\n        This method will:\n        - Set the service to `ServiceState.STARTING` state\n        - Call all registered `AIPerfHook.ON_START` hooks\n        - Set the service to `ServiceState.RUNNING` state\n        \"\"\"\n\n        try:\n            self.logger.debug(\n                \"Starting %s service (id: %s)\", self.service_type, self.service_id\n            )\n            _ = await self.set_state(ServiceState.STARTING)\n\n            await self.run_hooks(AIPerfHook.ON_START)\n\n            _ = await self.set_state(ServiceState.RUNNING)\n\n        except asyncio.CancelledError:\n            self.logger.debug(\"Service %s execution cancelled\", self.service_type)\n            pass\n\n        except Exception as e:\n            self._state = ServiceState.ERROR\n            raise self._service_error(\"Failed to start service\") from e\n\n    async def stop(self) -&gt; None:\n        \"\"\"Stop the service and clean up its components. This method implements\n        the `BaseServiceInterface.stop` method.\n\n        This method will:\n        - Set the service to `ServiceState.STOPPING` state\n        - Call all registered `AIPerfHook.ON_STOP` hooks\n        - Shutdown the service communication component\n        - Call all registered `AIPerfHook.ON_CLEANUP` hooks\n        - Set the service to `ServiceState.STOPPED` state\n        \"\"\"\n        try:\n            if self.state == ServiceState.STOPPED:\n                self.logger.warning(\n                    \"Service %s state %s is already STOPPED, ignoring stop request\",\n                    self.service_type,\n                    self.state,\n                )\n                return\n\n            self._state = ServiceState.STOPPING\n\n            # Signal the run method to exit if it hasn't already\n            if not self.stop_event.is_set():\n                self.stop_event.set()\n\n            # Custom stop logic implemented by derived classes\n            with contextlib.suppress(asyncio.CancelledError):\n                await self.run_hooks(AIPerfHook.ON_STOP)\n\n            # Shutdown communication component\n            if self._comms and not self._comms.is_shutdown:\n                await self._comms.shutdown()\n\n            # Custom cleanup logic implemented by derived classes\n            with contextlib.suppress(asyncio.CancelledError):\n                await self.run_hooks(AIPerfHook.ON_CLEANUP)\n\n            # Set the state to STOPPED. Communications are shutdown, so we don't need to\n            # publish a status message\n            self._state = ServiceState.STOPPED\n            if self.service_type not in (\n                ServiceType.WORKER,\n                ServiceType.WORKER_MANAGER,\n            ):\n                self.logger.debug(\n                    \"Service %s (id: %s) stopped\", self.service_type, self.service_id\n                )\n\n        except Exception as e:\n            self._state = ServiceState.ERROR\n            raise self._service_error(\"Failed to stop service\") from e\n\n    async def configure(self, message: Message) -&gt; None:\n        \"\"\"Configure the service with the given configuration. This method implements\n        the `BaseServiceInterface.configure` method.\n\n        This method will:\n        - Call all registered AIPerfHook.ON_CONFIGURE hooks\n        \"\"\"\n        await self.run_hooks(AIPerfHook.ON_CONFIGURE, message)\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.comms","title":"<code>comms</code>  <code>property</code>","text":"<p>Get the communication object for the service. Raises:     CommunicationError: If the communication is not initialized</p>"},{"location":"api/#aiperf.common.service.base_service.BaseService.is_initialized","title":"<code>is_initialized</code>  <code>property</code>","text":"<p>Check if service is initialized.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if service is initialized, False otherwise</p>"},{"location":"api/#aiperf.common.service.base_service.BaseService.is_shutdown","title":"<code>is_shutdown</code>  <code>property</code>","text":"<p>Check if service is shutdown.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if service is shutdown, False otherwise</p>"},{"location":"api/#aiperf.common.service.base_service.BaseService.state","title":"<code>state</code>  <code>property</code>","text":"<p>The current state of the service.</p>"},{"location":"api/#aiperf.common.service.base_service.BaseService.configure","title":"<code>configure(message)</code>  <code>async</code>","text":"<p>Configure the service with the given configuration. This method implements the <code>BaseServiceInterface.configure</code> method.</p> <p>This method will: - Call all registered AIPerfHook.ON_CONFIGURE hooks</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>async def configure(self, message: Message) -&gt; None:\n    \"\"\"Configure the service with the given configuration. This method implements\n    the `BaseServiceInterface.configure` method.\n\n    This method will:\n    - Call all registered AIPerfHook.ON_CONFIGURE hooks\n    \"\"\"\n    await self.run_hooks(AIPerfHook.ON_CONFIGURE, message)\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.initialize","title":"<code>initialize()</code>  <code>async</code>","text":"<p>Initialize the service communication and signal handlers. This method implements the <code>BaseServiceInterface.initialize</code> method.</p> <p>This method will: - Set the service to <code>ServiceState.INITIALIZING</code> state - Allow time for the event loop to start - Initialize communication - Call all registered <code>AIPerfHook.ON_INIT</code> hooks - Set the service to <code>ServiceState.READY</code> state - Set the initialized asyncio event</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>async def initialize(self) -&gt; None:\n    \"\"\"Initialize the service communication and signal handlers. This method implements\n    the `BaseServiceInterface.initialize` method.\n\n    This method will:\n    - Set the service to `ServiceState.INITIALIZING` state\n    - Allow time for the event loop to start\n    - Initialize communication\n    - Call all registered `AIPerfHook.ON_INIT` hooks\n    - Set the service to `ServiceState.READY` state\n    - Set the initialized asyncio event\n    \"\"\"\n    self._state = ServiceState.INITIALIZING\n    # Allow time for the event loop to start\n    await asyncio.sleep(0.1)\n\n    # Initialize communication\n    self._comms = CommunicationFactory.create_instance(\n        self.service_config.comm_backend,\n        config=self.service_config.comm_config,\n    )\n\n    await self._comms.initialize()\n\n    if len(self.required_clients) &gt; 0:\n        # Create the communication clients ahead of time\n        self.logger.debug(\n            \"%s: Creating communication clients (%s)\",\n            self.service_type,\n            self.required_clients,\n        )\n\n        await self._comms.create_clients(*self.required_clients)\n\n    # Initialize any derived service components\n    await self.run_hooks(AIPerfHook.ON_INIT)\n    await self.set_state(ServiceState.READY)\n\n    self.initialized_event.set()\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.run_forever","title":"<code>run_forever()</code>  <code>async</code>","text":"<p>Run the service in a loop until the stop event is set. This method implements the <code>BaseServiceInterface.run_forever</code> method.</p> <p>This method will: - Call the initialize method to initialize the service - Call all registered <code>AIPerfHook.RUN</code> hooks - Wait for the stop event to be set - Shuts down the service when the stop event is set</p> <p>This method will be called as the main entry point for the service.</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>async def run_forever(self) -&gt; None:\n    \"\"\"Run the service in a loop until the stop event is set. This method implements\n    the `BaseServiceInterface.run_forever` method.\n\n    This method will:\n    - Call the initialize method to initialize the service\n    - Call all registered `AIPerfHook.RUN` hooks\n    - Wait for the stop event to be set\n    - Shuts down the service when the stop event is set\n\n    This method will be called as the main entry point for the service.\n    \"\"\"\n    try:\n        self.logger.debug(\n            \"Running %s service (id: %s)\", self.service_type, self.service_id\n        )\n\n        await self.initialize()\n        await self.run_hooks(AIPerfHook.ON_RUN)\n\n    except asyncio.CancelledError:\n        self.logger.debug(\"Service %s execution cancelled\", self.service_type)\n        return\n\n    except AIPerfError:\n        raise  # re-raise it up the stack\n\n    except Exception as e:\n        self.logger.exception(\"Service %s execution failed:\", self.service_type)\n        _ = await self.set_state(ServiceState.ERROR)\n        raise self._service_error(\"Service execution failed\") from e\n\n    await self._forever_loop()\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.set_state","title":"<code>set_state(state)</code>  <code>async</code>","text":"<p>Set the state of the service. This method implements the <code>BaseServiceInterface.set_state</code> method.</p> <p>This method will: - Set the service state to the given state - Call all registered <code>AIPerfHook.ON_SET_STATE</code> hooks</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>async def set_state(self, state: ServiceState) -&gt; None:\n    \"\"\"Set the state of the service. This method implements\n    the `BaseServiceInterface.set_state` method.\n\n    This method will:\n    - Set the service state to the given state\n    - Call all registered `AIPerfHook.ON_SET_STATE` hooks\n    \"\"\"\n    self._state = state\n    await self.run_hooks(AIPerfHook.ON_SET_STATE, state)\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.start","title":"<code>start()</code>  <code>async</code>","text":"<p>Start the service and its components. This method implements the <code>BaseServiceInterface.start</code> method.</p> <p>This method should be called to start the service after it has been initialized and configured.</p> <p>This method will: - Set the service to <code>ServiceState.STARTING</code> state - Call all registered <code>AIPerfHook.ON_START</code> hooks - Set the service to <code>ServiceState.RUNNING</code> state</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>async def start(self) -&gt; None:\n    \"\"\"Start the service and its components. This method implements\n    the `BaseServiceInterface.start` method.\n\n    This method should be called to start the service after it has been initialized\n    and configured.\n\n    This method will:\n    - Set the service to `ServiceState.STARTING` state\n    - Call all registered `AIPerfHook.ON_START` hooks\n    - Set the service to `ServiceState.RUNNING` state\n    \"\"\"\n\n    try:\n        self.logger.debug(\n            \"Starting %s service (id: %s)\", self.service_type, self.service_id\n        )\n        _ = await self.set_state(ServiceState.STARTING)\n\n        await self.run_hooks(AIPerfHook.ON_START)\n\n        _ = await self.set_state(ServiceState.RUNNING)\n\n    except asyncio.CancelledError:\n        self.logger.debug(\"Service %s execution cancelled\", self.service_type)\n        pass\n\n    except Exception as e:\n        self._state = ServiceState.ERROR\n        raise self._service_error(\"Failed to start service\") from e\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service.BaseService.stop","title":"<code>stop()</code>  <code>async</code>","text":"<p>Stop the service and clean up its components. This method implements the <code>BaseServiceInterface.stop</code> method.</p> <p>This method will: - Set the service to <code>ServiceState.STOPPING</code> state - Call all registered <code>AIPerfHook.ON_STOP</code> hooks - Shutdown the service communication component - Call all registered <code>AIPerfHook.ON_CLEANUP</code> hooks - Set the service to <code>ServiceState.STOPPED</code> state</p> Source code in <code>aiperf/common/service/base_service.py</code> <pre><code>async def stop(self) -&gt; None:\n    \"\"\"Stop the service and clean up its components. This method implements\n    the `BaseServiceInterface.stop` method.\n\n    This method will:\n    - Set the service to `ServiceState.STOPPING` state\n    - Call all registered `AIPerfHook.ON_STOP` hooks\n    - Shutdown the service communication component\n    - Call all registered `AIPerfHook.ON_CLEANUP` hooks\n    - Set the service to `ServiceState.STOPPED` state\n    \"\"\"\n    try:\n        if self.state == ServiceState.STOPPED:\n            self.logger.warning(\n                \"Service %s state %s is already STOPPED, ignoring stop request\",\n                self.service_type,\n                self.state,\n            )\n            return\n\n        self._state = ServiceState.STOPPING\n\n        # Signal the run method to exit if it hasn't already\n        if not self.stop_event.is_set():\n            self.stop_event.set()\n\n        # Custom stop logic implemented by derived classes\n        with contextlib.suppress(asyncio.CancelledError):\n            await self.run_hooks(AIPerfHook.ON_STOP)\n\n        # Shutdown communication component\n        if self._comms and not self._comms.is_shutdown:\n            await self._comms.shutdown()\n\n        # Custom cleanup logic implemented by derived classes\n        with contextlib.suppress(asyncio.CancelledError):\n            await self.run_hooks(AIPerfHook.ON_CLEANUP)\n\n        # Set the state to STOPPED. Communications are shutdown, so we don't need to\n        # publish a status message\n        self._state = ServiceState.STOPPED\n        if self.service_type not in (\n            ServiceType.WORKER,\n            ServiceType.WORKER_MANAGER,\n        ):\n            self.logger.debug(\n                \"Service %s (id: %s) stopped\", self.service_type, self.service_id\n            )\n\n    except Exception as e:\n        self._state = ServiceState.ERROR\n        raise self._service_error(\"Failed to stop service\") from e\n</code></pre>"},{"location":"api/#aiperfcommonservicebase_service_interface","title":"aiperf.common.service.base_service_interface","text":""},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface","title":"<code>BaseServiceInterface</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base interface for all services.</p> <p>This class provides the base foundation for which every service should provide. Some methods are required to be implemented by derived classes, while others are meant to be implemented by the base class.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>class BaseServiceInterface(ABC):\n    \"\"\"Base interface for all services.\n\n    This class provides the base foundation for which every service should provide. Some\n    methods are required to be implemented by derived classes, while others are\n    meant to be implemented by the base class.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def required_clients(self) -&gt; list[ClientType]:\n        \"\"\"The communication clients required by the service. If nothing is returned,\n        the service will be responsible for creating its own clients.\n\n        This property should be implemented by derived classes to specify the\n        communication clients that the service requires.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type/name of the service.\n\n        This property should be implemented by derived classes to specify the\n        type/name of the service.\"\"\"\n        # TODO: We can do this better by using a decorator to set the service type\n        pass\n\n    @abstractmethod\n    async def set_state(self, state: ServiceState) -&gt; None:\n        \"\"\"Set the state of the service.\n\n        This method will be implemented by the base class, and extra\n        functionality can be added by derived classes via the `@on_set_state`\n        decorator.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize the service.\n\n        This method will be implemented by the base class.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def start(self) -&gt; None:\n        \"\"\"Start the service. It should be called after the service has been initialized\n        and configured.\n\n        This method will be implemented by the base class, and extra\n        functionality can be added by derived classes via the `@on_start`\n        decorator.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def stop(self) -&gt; None:\n        \"\"\"Stop the service.\n\n        This method will be implemented by the base class, and extra\n        functionality can be added by derived classes via the `@on_stop`\n        decorator.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def configure(self, message: Message) -&gt; None:\n        \"\"\"Configure the service with the given configuration.\n\n        This method will be implemented by the base class, and extra\n        functionality can be added by derived classes via the `@on_configure`\n        decorator.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def run_forever(self) -&gt; None:\n        \"\"\"Run the service. This method will be the primary entry point for the service\n        and will be called by the bootstrap script. It should not return until the\n        service is completely shutdown.\n\n        This method will be implemented by the base class. Any additional\n        functionality can be added by derived classes via the `@on_run`\n        decorator.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def _forever_loop(self) -&gt; None:\n        \"\"\"Run the service in a loop until the stop event is set. This method will be\n        called by the `run` method to allow the service to run indefinitely.\n\n        This method will be implemented by the base class, and is not expected to be\n        overridden by derived classes.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.required_clients","title":"<code>required_clients</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The communication clients required by the service. If nothing is returned, the service will be responsible for creating its own clients.</p> <p>This property should be implemented by derived classes to specify the communication clients that the service requires.</p>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.service_type","title":"<code>service_type</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The type/name of the service.</p> <p>This property should be implemented by derived classes to specify the type/name of the service.</p>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.configure","title":"<code>configure(message)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Configure the service with the given configuration.</p> <p>This method will be implemented by the base class, and extra functionality can be added by derived classes via the <code>@on_configure</code> decorator.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>@abstractmethod\nasync def configure(self, message: Message) -&gt; None:\n    \"\"\"Configure the service with the given configuration.\n\n    This method will be implemented by the base class, and extra\n    functionality can be added by derived classes via the `@on_configure`\n    decorator.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.initialize","title":"<code>initialize()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Initialize the service.</p> <p>This method will be implemented by the base class.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>@abstractmethod\nasync def initialize(self) -&gt; None:\n    \"\"\"Initialize the service.\n\n    This method will be implemented by the base class.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.run_forever","title":"<code>run_forever()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Run the service. This method will be the primary entry point for the service and will be called by the bootstrap script. It should not return until the service is completely shutdown.</p> <p>This method will be implemented by the base class. Any additional functionality can be added by derived classes via the <code>@on_run</code> decorator.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>@abstractmethod\nasync def run_forever(self) -&gt; None:\n    \"\"\"Run the service. This method will be the primary entry point for the service\n    and will be called by the bootstrap script. It should not return until the\n    service is completely shutdown.\n\n    This method will be implemented by the base class. Any additional\n    functionality can be added by derived classes via the `@on_run`\n    decorator.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.set_state","title":"<code>set_state(state)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Set the state of the service.</p> <p>This method will be implemented by the base class, and extra functionality can be added by derived classes via the <code>@on_set_state</code> decorator.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>@abstractmethod\nasync def set_state(self, state: ServiceState) -&gt; None:\n    \"\"\"Set the state of the service.\n\n    This method will be implemented by the base class, and extra\n    functionality can be added by derived classes via the `@on_set_state`\n    decorator.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.start","title":"<code>start()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Start the service. It should be called after the service has been initialized and configured.</p> <p>This method will be implemented by the base class, and extra functionality can be added by derived classes via the <code>@on_start</code> decorator.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>@abstractmethod\nasync def start(self) -&gt; None:\n    \"\"\"Start the service. It should be called after the service has been initialized\n    and configured.\n\n    This method will be implemented by the base class, and extra\n    functionality can be added by derived classes via the `@on_start`\n    decorator.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.common.service.base_service_interface.BaseServiceInterface.stop","title":"<code>stop()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Stop the service.</p> <p>This method will be implemented by the base class, and extra functionality can be added by derived classes via the <code>@on_stop</code> decorator.</p> Source code in <code>aiperf/common/service/base_service_interface.py</code> <pre><code>@abstractmethod\nasync def stop(self) -&gt; None:\n    \"\"\"Stop the service.\n\n    This method will be implemented by the base class, and extra\n    functionality can be added by derived classes via the `@on_stop`\n    decorator.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperfcommontokenizer","title":"aiperf.common.tokenizer","text":""},{"location":"api/#aiperf.common.tokenizer.Tokenizer","title":"<code>Tokenizer</code>","text":"<p>This class provides a simplified interface for using Huggingface tokenizers, with default arguments for common operations.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>class Tokenizer:\n    \"\"\"\n    This class provides a simplified interface for using Huggingface\n    tokenizers, with default arguments for common operations.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"\n        Initialize the tokenizer with default values for call, encode, and decode.\n        \"\"\"\n        self._tokenizer = None\n        self._call_args = {\"add_special_tokens\": False}\n        self._encode_args = {\"add_special_tokens\": False}\n        self._decode_args = {\"skip_special_tokens\": True}\n\n    @classmethod\n    def from_pretrained(\n        cls,\n        name: str,\n        trust_remote_code: bool = False,\n        revision: str = \"main\",\n    ) -&gt; \"Tokenizer\":\n        \"\"\"\n        Factory to load a tokenizer for the given pretrained model name.\n\n        Args:\n            name: The name or path of the pretrained tokenizer model.\n            trust_remote_code: Whether to trust remote code when loading the tokenizer.\n            revision: The specific model version to use.\n        \"\"\"\n        try:\n            tokenizer_cls = cls()\n            tokenizer_cls._tokenizer = AutoTokenizer.from_pretrained(\n                name, trust_remote_code=trust_remote_code, revision=revision\n            )\n        except Exception as e:\n            raise TokenizerInitializationError(e) from e\n        return tokenizer_cls\n\n    def __call__(self, text, **kwargs) -&gt; \"BatchEncoding\":\n        \"\"\"\n        Call the underlying Huggingface tokenizer with default arguments,\n        which can be overridden by kwargs.\n\n        Args:\n            text: The input text to tokenize.\n\n        Returns:\n            A BatchEncoding object containing the tokenized output.\n        \"\"\"\n        if self._tokenizer is None:\n            raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n        return self._tokenizer(text, **{**self._call_args, **kwargs})\n\n    def encode(self, text, **kwargs) -&gt; list[int]:\n        \"\"\"\n        Encode the input text into a list of token IDs.\n\n        This method calls the underlying Huggingface tokenizer's encode\n        method with default arguments, which can be overridden by kwargs.\n\n        Args:\n            text: The input text to encode.\n\n        Returns:\n            A list of token IDs.\n        \"\"\"\n        if self._tokenizer is None:\n            raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n        return self._tokenizer.encode(text, **{**self._encode_args, **kwargs})\n\n    def decode(self, token_ids, **kwargs) -&gt; str:\n        \"\"\"\n        Decode a list of token IDs back into a string.\n\n        This method calls the underlying Huggingface tokenizer's decode\n        method with default arguments, which can be overridden by kwargs.\n\n        Args:\n            token_ids: A list of token IDs to decode.\n\n        Returns:\n            The decoded string.\n        \"\"\"\n        if self._tokenizer is None:\n            raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n        return self._tokenizer.decode(token_ids, **{**self._decode_args, **kwargs})\n\n    def bos_token_id(self) -&gt; int:\n        \"\"\"\n        Return the beginning-of-sequence (BOS) token ID.\n        \"\"\"\n        if self._tokenizer is None:\n            raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n        return self._tokenizer.bos_token_id\n\n    def __repr__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the underlying tokenizer.\n\n        Returns:\n            The string representation of the tokenizer.\n        \"\"\"\n        return self._tokenizer.__repr__()\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Return a user-friendly string representation of the underlying tokenizer.\n\n        Returns:\n            The string representation of the tokenizer.\n        \"\"\"\n        return self._tokenizer.__str__()\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.__call__","title":"<code>__call__(text, **kwargs)</code>","text":"<p>Call the underlying Huggingface tokenizer with default arguments, which can be overridden by kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>The input text to tokenize.</p> required <p>Returns:</p> Type Description <code>BatchEncoding</code> <p>A BatchEncoding object containing the tokenized output.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def __call__(self, text, **kwargs) -&gt; \"BatchEncoding\":\n    \"\"\"\n    Call the underlying Huggingface tokenizer with default arguments,\n    which can be overridden by kwargs.\n\n    Args:\n        text: The input text to tokenize.\n\n    Returns:\n        A BatchEncoding object containing the tokenized output.\n    \"\"\"\n    if self._tokenizer is None:\n        raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n    return self._tokenizer(text, **{**self._call_args, **kwargs})\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the tokenizer with default values for call, encode, and decode.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"\n    Initialize the tokenizer with default values for call, encode, and decode.\n    \"\"\"\n    self._tokenizer = None\n    self._call_args = {\"add_special_tokens\": False}\n    self._encode_args = {\"add_special_tokens\": False}\n    self._decode_args = {\"skip_special_tokens\": True}\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the underlying tokenizer.</p> <p>Returns:</p> Type Description <code>str</code> <p>The string representation of the tokenizer.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"\n    Return a string representation of the underlying tokenizer.\n\n    Returns:\n        The string representation of the tokenizer.\n    \"\"\"\n    return self._tokenizer.__repr__()\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.__str__","title":"<code>__str__()</code>","text":"<p>Return a user-friendly string representation of the underlying tokenizer.</p> <p>Returns:</p> Type Description <code>str</code> <p>The string representation of the tokenizer.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Return a user-friendly string representation of the underlying tokenizer.\n\n    Returns:\n        The string representation of the tokenizer.\n    \"\"\"\n    return self._tokenizer.__str__()\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.bos_token_id","title":"<code>bos_token_id()</code>","text":"<p>Return the beginning-of-sequence (BOS) token ID.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def bos_token_id(self) -&gt; int:\n    \"\"\"\n    Return the beginning-of-sequence (BOS) token ID.\n    \"\"\"\n    if self._tokenizer is None:\n        raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n    return self._tokenizer.bos_token_id\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.decode","title":"<code>decode(token_ids, **kwargs)</code>","text":"<p>Decode a list of token IDs back into a string.</p> <p>This method calls the underlying Huggingface tokenizer's decode method with default arguments, which can be overridden by kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>token_ids</code> <p>A list of token IDs to decode.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The decoded string.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def decode(self, token_ids, **kwargs) -&gt; str:\n    \"\"\"\n    Decode a list of token IDs back into a string.\n\n    This method calls the underlying Huggingface tokenizer's decode\n    method with default arguments, which can be overridden by kwargs.\n\n    Args:\n        token_ids: A list of token IDs to decode.\n\n    Returns:\n        The decoded string.\n    \"\"\"\n    if self._tokenizer is None:\n        raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n    return self._tokenizer.decode(token_ids, **{**self._decode_args, **kwargs})\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.encode","title":"<code>encode(text, **kwargs)</code>","text":"<p>Encode the input text into a list of token IDs.</p> <p>This method calls the underlying Huggingface tokenizer's encode method with default arguments, which can be overridden by kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>The input text to encode.</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>A list of token IDs.</p> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>def encode(self, text, **kwargs) -&gt; list[int]:\n    \"\"\"\n    Encode the input text into a list of token IDs.\n\n    This method calls the underlying Huggingface tokenizer's encode\n    method with default arguments, which can be overridden by kwargs.\n\n    Args:\n        text: The input text to encode.\n\n    Returns:\n        A list of token IDs.\n    \"\"\"\n    if self._tokenizer is None:\n        raise TokenizerInitializationError(\"Tokenizer is not initialized.\")\n    return self._tokenizer.encode(text, **{**self._encode_args, **kwargs})\n</code></pre>"},{"location":"api/#aiperf.common.tokenizer.Tokenizer.from_pretrained","title":"<code>from_pretrained(name, trust_remote_code=False, revision='main')</code>  <code>classmethod</code>","text":"<p>Factory to load a tokenizer for the given pretrained model name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name or path of the pretrained tokenizer model.</p> required <code>trust_remote_code</code> <code>bool</code> <p>Whether to trust remote code when loading the tokenizer.</p> <code>False</code> <code>revision</code> <code>str</code> <p>The specific model version to use.</p> <code>'main'</code> Source code in <code>aiperf/common/tokenizer.py</code> <pre><code>@classmethod\ndef from_pretrained(\n    cls,\n    name: str,\n    trust_remote_code: bool = False,\n    revision: str = \"main\",\n) -&gt; \"Tokenizer\":\n    \"\"\"\n    Factory to load a tokenizer for the given pretrained model name.\n\n    Args:\n        name: The name or path of the pretrained tokenizer model.\n        trust_remote_code: Whether to trust remote code when loading the tokenizer.\n        revision: The specific model version to use.\n    \"\"\"\n    try:\n        tokenizer_cls = cls()\n        tokenizer_cls._tokenizer = AutoTokenizer.from_pretrained(\n            name, trust_remote_code=trust_remote_code, revision=revision\n        )\n    except Exception as e:\n        raise TokenizerInitializationError(e) from e\n    return tokenizer_cls\n</code></pre>"},{"location":"api/#aiperfcommonutils","title":"aiperf.common.utils","text":""},{"location":"api/#aiperf.common.utils.call_all_functions","title":"<code>call_all_functions(funcs, *args, **kwargs)</code>  <code>async</code>","text":"<p>Call all functions in the list with the given name.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <p>The object to call the functions on.</p> required <code>func_names</code> <p>The names of the functions to call.</p> required <code>*args</code> <p>The arguments to pass to the functions.</p> <code>()</code> <code>**kwargs</code> <p>The keyword arguments to pass to the functions.</p> <code>{}</code> <p>Raises:</p> Type Description <code>AIPerfMultiError</code> <p>If any of the functions raise an exception.</p> Source code in <code>aiperf/common/utils.py</code> <pre><code>async def call_all_functions(funcs: list[Callable], *args, **kwargs) -&gt; None:\n    \"\"\"Call all functions in the list with the given name.\n\n    Args:\n        obj: The object to call the functions on.\n        func_names: The names of the functions to call.\n        *args: The arguments to pass to the functions.\n        **kwargs: The keyword arguments to pass to the functions.\n\n    Raises:\n        AIPerfMultiError: If any of the functions raise an exception.\n    \"\"\"\n\n    exceptions = []\n    for func in funcs:\n        try:\n            if inspect.iscoroutinefunction(func):\n                await func(*args, **kwargs)\n            else:\n                func(*args, **kwargs)\n        except Exception as e:\n            # TODO: error handling, logging\n            traceback.print_exc()\n            exceptions.append(e)\n\n    if len(exceptions) &gt; 0:\n        raise AIPerfMultiError(\"Errors calling functions\", exceptions)\n</code></pre>"},{"location":"api/#aiperf.common.utils.call_all_functions_self","title":"<code>call_all_functions_self(self_, funcs, *args, **kwargs)</code>  <code>async</code>","text":"<p>Call all functions in the list with the given name.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <p>The object to call the functions on.</p> required <code>func_names</code> <p>The names of the functions to call.</p> required <code>*args</code> <p>The arguments to pass to the functions.</p> <code>()</code> <code>**kwargs</code> <p>The keyword arguments to pass to the functions.</p> <code>{}</code> <p>Raises:</p> Type Description <code>AIPerfMultiError</code> <p>If any of the functions raise an exception.</p> Source code in <code>aiperf/common/utils.py</code> <pre><code>async def call_all_functions_self(\n    self_: object, funcs: list[Callable], *args, **kwargs\n) -&gt; None:\n    \"\"\"Call all functions in the list with the given name.\n\n    Args:\n        obj: The object to call the functions on.\n        func_names: The names of the functions to call.\n        *args: The arguments to pass to the functions.\n        **kwargs: The keyword arguments to pass to the functions.\n\n    Raises:\n        AIPerfMultiError: If any of the functions raise an exception.\n    \"\"\"\n\n    exceptions = []\n    for func in funcs:\n        try:\n            if inspect.iscoroutinefunction(func):\n                await func(self_, *args, **kwargs)\n            else:\n                func(self_, *args, **kwargs)\n        except Exception as e:\n            # TODO: error handling, logging\n            traceback.print_exc()\n            exceptions.append(e)\n\n    if len(exceptions) &gt; 0:\n        raise AIPerfMultiError(\"Errors calling functions\", exceptions)\n</code></pre>"},{"location":"api/#aiperfdata_exporterconsole_exporter","title":"aiperf.data_exporter.console_exporter","text":""},{"location":"api/#aiperf.data_exporter.console_exporter.ConsoleExporter","title":"<code>ConsoleExporter</code>","text":"<p>A class that exports data to the console</p> Source code in <code>aiperf/data_exporter/console_exporter.py</code> <pre><code>@DataExporterFactory.register(DataExporterType.CONSOLE)\nclass ConsoleExporter:\n    \"\"\"A class that exports data to the console\"\"\"\n\n    STAT_COLUMN_KEYS = [\"avg\", \"min\", \"max\", \"p99\", \"p90\", \"p75\"]\n\n    def __init__(self, endpoint_config: EndPointConfig) -&gt; None:\n        self.endpoint_type = endpoint_config.type\n        self.streaming = endpoint_config.streaming\n\n    def export(self, records: list[Record], **kwargs) -&gt; None:\n        console = Console(**kwargs)\n        table = Table(title=self._get_title())\n        table.add_column(\"Metric\", justify=\"right\", style=\"cyan\")\n        for key in self.STAT_COLUMN_KEYS:\n            table.add_column(key, justify=\"right\", style=\"green\")\n        self._construct_table(table, records)\n        console.print(table)\n\n    def _construct_table(self, table: Table, records: list[Record]) -&gt; None:\n        for record in records:\n            if self._should_skip(record):\n                continue\n            table.add_row(*self._format_row(record))\n\n    def _should_skip(self, record: Record) -&gt; bool:\n        if self.endpoint_type == \"embeddings\":\n            return False\n\n        return record.streaming_only and not self.streaming\n\n    def _format_row(self, record: Record) -&gt; list[str]:\n        row = [f\"{record.name} ({record.unit})\"]\n        for stat in self.STAT_COLUMN_KEYS:\n            value = getattr(record, stat, None)\n            row.append(f\"{value:.2f}\" if value is not None else \"N/A\")\n        return row\n\n    def _get_title(self) -&gt; str:\n        type_titles = {\n            \"embeddings\": \"Embeddings Metrics\",\n            \"rankings\": \"Rankings Metrics\",\n            \"image_retrieval\": \"Image Retrieval Metrics\",\n            \"multimodal\": \"Multi-Modal Metrics\",\n        }\n        metric_title = type_titles.get(self.endpoint_type, \"LLM Metrics\")\n        return f\"NVIDIA AIPerf | {metric_title}\"\n</code></pre>"},{"location":"api/#aiperfdata_exporterexporter_manager","title":"aiperf.data_exporter.exporter_manager","text":""},{"location":"api/#aiperf.data_exporter.exporter_manager.ExporterManager","title":"<code>ExporterManager</code>","text":"<p>ExporterManager is responsible for exporting records using all registered data exporters.</p> Source code in <code>aiperf/data_exporter/exporter_manager.py</code> <pre><code>class ExporterManager:\n    \"\"\"\n    ExporterManager is responsible for exporting records using all\n    registered data exporters.\n    \"\"\"\n\n    def __init__(self, endpoint_config: EndPointConfig):\n        self.endpoint_config = endpoint_config\n        self.exporter_classes = DataExporterFactory.get_all_classes()\n\n    def export(self, records: list[Record]) -&gt; None:\n        for exporter_class in self.exporter_classes:\n            exporter = exporter_class(self.endpoint_config)\n            exporter.export(records)\n</code></pre>"},{"location":"api/#aiperfdata_exporterrecord","title":"aiperf.data_exporter.record","text":""},{"location":"api/#aiperfservicesdatasetdataset_manager","title":"aiperf.services.dataset.dataset_manager","text":""},{"location":"api/#aiperf.services.dataset.dataset_manager.DatasetManager","title":"<code>DatasetManager</code>","text":"<p>               Bases: <code>BaseComponentService</code></p> <p>The DatasetManager primary responsibility is to manage the data generation or acquisition. For synthetic generation, it contains the code to generate the prompts or tokens. It will have an API for dataset acquisition of a dataset if available in a remote repository or database.</p> Source code in <code>aiperf/services/dataset/dataset_manager.py</code> <pre><code>@ServiceFactory.register(ServiceType.DATASET_MANAGER)\nclass DatasetManager(BaseComponentService):\n    \"\"\"\n    The DatasetManager primary responsibility is to manage the data generation or acquisition.\n    For synthetic generation, it contains the code to generate the prompts or tokens.\n    It will have an API for dataset acquisition of a dataset if available in a remote repository or database.\n    \"\"\"\n\n    def __init__(\n        self,\n        service_config: ServiceConfig,\n        service_id: str | None = None,\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Initializing dataset manager\")\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.DATASET_MANAGER\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize dataset manager-specific components.\"\"\"\n        self.logger.debug(\"Initializing dataset manager\")\n        # TODO: Implement dataset manager initialization\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the dataset manager.\"\"\"\n        self.logger.debug(\"Starting dataset manager\")\n        # TODO: Implement dataset manager start\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the dataset manager.\"\"\"\n        self.logger.debug(\"Stopping dataset manager\")\n        # TODO: Implement dataset manager stop\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up dataset manager-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up dataset manager\")\n        # TODO: Implement dataset manager cleanup\n\n    @on_configure\n    async def _configure(self, message: Message) -&gt; None:\n        \"\"\"Configure the dataset manager.\"\"\"\n        self.logger.debug(f\"Configuring dataset manager with message: {message}\")\n</code></pre>"},{"location":"api/#aiperf.services.dataset.dataset_manager.DatasetManager.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.dataset.dataset_manager.main","title":"<code>main()</code>","text":"<p>Main entry point for the dataset manager.</p> Source code in <code>aiperf/services/dataset/dataset_manager.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the dataset manager.\"\"\"\n\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(DatasetManager)\n</code></pre>"},{"location":"api/#aiperfservicesdatasetgeneratoraudio","title":"aiperf.services.dataset.generator.audio","text":""},{"location":"api/#aiperf.services.dataset.generator.audio.AudioGenerator","title":"<code>AudioGenerator</code>","text":"<p>A class for generating synthetic audio data.</p> <p>This class provides methods to create audio samples with specified characteristics such as format (WAV, MP3), length, sampling rate, bit depth, and number of channels. It supports validation of audio parameters to ensure compatibility with chosen formats.</p> Source code in <code>aiperf/services/dataset/generator/audio.py</code> <pre><code>class AudioGenerator:\n    \"\"\"\n    A class for generating synthetic audio data.\n\n    This class provides methods to create audio samples with specified\n    characteristics such as format (WAV, MP3), length, sampling rate,\n    bit depth, and number of channels. It supports validation of audio\n    parameters to ensure compatibility with chosen formats.\n    \"\"\"\n\n    @staticmethod\n    def _sample_positive_normal(\n        mean: float, stddev: float, min_value: float = 0.1\n    ) -&gt; float:\n        \"\"\"\n        Sample from a normal distribution ensuring positive values without distorting the distribution.\n        Uses rejection sampling to maintain the proper shape of the distribution.\n\n        Args:\n            mean: Mean value for the normal distribution\n            stddev: Standard deviation for the normal distribution\n            min_value: Minimum acceptable value\n\n        Returns:\n            A positive sample from the normal distribution\n\n        Raises:\n            GeneratorConfigurationError: If mean is less than min_value\n        \"\"\"\n        if mean &lt; min_value:\n            raise GeneratorConfigurationError(\n                f\"Mean value ({mean}) must be greater than min_value ({min_value})\"\n            )\n\n        while True:\n            sample = np.random.normal(mean, stddev)\n            if sample &gt;= min_value:\n                return sample\n\n    @staticmethod\n    def _validate_sampling_rate(sampling_rate: int, audio_format: AudioFormat) -&gt; None:\n        \"\"\"\n        Validate sampling rate for the given output format.\n\n        Args:\n            sampling_rate: Sampling rate in Hz\n            audio_format: Audio format\n\n        Raises:\n            GeneratorConfigurationError: If sampling rate is not supported for the given format\n        \"\"\"\n        if (\n            audio_format == AudioFormat.MP3\n            and sampling_rate not in MP3_SUPPORTED_SAMPLE_RATES\n        ):\n            supported_rates = sorted(MP3_SUPPORTED_SAMPLE_RATES)\n            raise GeneratorConfigurationError(\n                f\"MP3 format only supports the following sample rates (in Hz): {supported_rates}. \"\n                f\"Got {sampling_rate} Hz. Please choose a supported rate from the list.\"\n            )\n\n    @staticmethod\n    def _validate_bit_depth(bit_depth: int) -&gt; None:\n        \"\"\"\n        Validate bit depth is supported.\n\n        Args:\n            bit_depth: Bit depth in bits\n\n        Raises:\n            GeneratorConfigurationError: If bit depth is not supported\n        \"\"\"\n        if bit_depth not in SUPPORTED_BIT_DEPTHS:\n            supported_depths = sorted(SUPPORTED_BIT_DEPTHS.keys())\n            raise GeneratorConfigurationError(\n                f\"Unsupported bit depth: {bit_depth}. \"\n                f\"Supported bit depths are: {supported_depths}\"\n            )\n\n    # TODO: uncomment when ConfigAudio is implemented\n    # @staticmethod\n    # def create_synthetic_audio(config: ConfigAudio) -&gt; str:\n    @staticmethod\n    def create_synthetic_audio(config) -&gt; str:\n        \"\"\"\n        Generate audio data with specified parameters.\n\n        Args:\n            config: ConfigAudio object containing audio generation parameters\n\n        Returns:\n            Data URI containing base64-encoded audio data with format specification\n\n        Raises:\n            GeneratorConfigurationError: If any of the following conditions are met:\n                - audio_length_mean is less than 0.1 seconds\n                - channels is not 1 (mono) or 2 (stereo)\n                - sampling rate is not supported for MP3 format\n                - bit depth is not supported (must be 8, 16, 24, or 32)\n                - audio format is not supported (must be 'wav' or 'mp3')\n        \"\"\"\n        if config.num_channels not in (1, 2):\n            raise GeneratorConfigurationError(\n                \"Only mono (1) and stereo (2) channels are supported\"\n            )\n\n        # Sample audio length (in seconds) using rejection sampling\n        audio_length = AudioGenerator._sample_positive_normal(\n            config.length.mean, config.length.stddev\n        )\n\n        # Randomly select sampling rate and bit depth\n        sampling_rate = int(\n            np.random.choice(config.sample_rates) * 1000\n        )  # Convert kHz to Hz\n        bit_depth = np.random.choice(config.depths)\n\n        # Validate sampling rate and bit depth\n        AudioGenerator._validate_sampling_rate(sampling_rate, config.format)\n        AudioGenerator._validate_bit_depth(bit_depth)\n\n        # Generate synthetic audio data (gaussian noise)\n        num_samples = int(audio_length * sampling_rate)\n        audio_data = np.random.normal(\n            0,\n            0.3,\n            (\n                (num_samples, config.num_channels)\n                if config.num_channels &gt; 1\n                else num_samples\n            ),\n        )\n\n        # Ensure the signal is within [-1, 1] range\n        audio_data = np.clip(audio_data, -1, 1)\n\n        # Scale to the appropriate bit depth range\n        max_val = 2 ** (bit_depth - 1) - 1\n        numpy_type, _ = SUPPORTED_BIT_DEPTHS[bit_depth]\n        audio_data = (audio_data * max_val).astype(numpy_type)\n\n        # Write audio using soundfile\n        output_buffer = io.BytesIO()\n\n        # Select appropriate subtype based on format\n        if config.format == AudioFormat.MP3:\n            subtype = \"MPEG_LAYER_III\"\n        elif config.format == AudioFormat.WAV:\n            _, subtype = SUPPORTED_BIT_DEPTHS[bit_depth]\n        else:\n            raise GeneratorConfigurationError(\n                f\"Unsupported audio format: {config.format.name}. \"\n                f\"Supported formats are: {AudioFormat.WAV.name}, {AudioFormat.MP3.name}\"\n            )\n\n        sf.write(\n            output_buffer,\n            audio_data,\n            sampling_rate,\n            format=config.format.name,\n            subtype=subtype,\n        )\n        audio_bytes = output_buffer.getvalue()\n\n        # Encode to base64 with data URI scheme: \"{format},{data}\"\n        base64_data = base64.b64encode(audio_bytes).decode(\"utf-8\")\n        return f\"{config.format.name.lower()},{base64_data}\"\n</code></pre>"},{"location":"api/#aiperf.services.dataset.generator.audio.AudioGenerator.create_synthetic_audio","title":"<code>create_synthetic_audio(config)</code>  <code>staticmethod</code>","text":"<p>Generate audio data with specified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <p>ConfigAudio object containing audio generation parameters</p> required <p>Returns:</p> Type Description <code>str</code> <p>Data URI containing base64-encoded audio data with format specification</p> <p>Raises:</p> Type Description <code>GeneratorConfigurationError</code> <p>If any of the following conditions are met: - audio_length_mean is less than 0.1 seconds - channels is not 1 (mono) or 2 (stereo) - sampling rate is not supported for MP3 format - bit depth is not supported (must be 8, 16, 24, or 32) - audio format is not supported (must be 'wav' or 'mp3')</p> Source code in <code>aiperf/services/dataset/generator/audio.py</code> <pre><code>@staticmethod\ndef create_synthetic_audio(config) -&gt; str:\n    \"\"\"\n    Generate audio data with specified parameters.\n\n    Args:\n        config: ConfigAudio object containing audio generation parameters\n\n    Returns:\n        Data URI containing base64-encoded audio data with format specification\n\n    Raises:\n        GeneratorConfigurationError: If any of the following conditions are met:\n            - audio_length_mean is less than 0.1 seconds\n            - channels is not 1 (mono) or 2 (stereo)\n            - sampling rate is not supported for MP3 format\n            - bit depth is not supported (must be 8, 16, 24, or 32)\n            - audio format is not supported (must be 'wav' or 'mp3')\n    \"\"\"\n    if config.num_channels not in (1, 2):\n        raise GeneratorConfigurationError(\n            \"Only mono (1) and stereo (2) channels are supported\"\n        )\n\n    # Sample audio length (in seconds) using rejection sampling\n    audio_length = AudioGenerator._sample_positive_normal(\n        config.length.mean, config.length.stddev\n    )\n\n    # Randomly select sampling rate and bit depth\n    sampling_rate = int(\n        np.random.choice(config.sample_rates) * 1000\n    )  # Convert kHz to Hz\n    bit_depth = np.random.choice(config.depths)\n\n    # Validate sampling rate and bit depth\n    AudioGenerator._validate_sampling_rate(sampling_rate, config.format)\n    AudioGenerator._validate_bit_depth(bit_depth)\n\n    # Generate synthetic audio data (gaussian noise)\n    num_samples = int(audio_length * sampling_rate)\n    audio_data = np.random.normal(\n        0,\n        0.3,\n        (\n            (num_samples, config.num_channels)\n            if config.num_channels &gt; 1\n            else num_samples\n        ),\n    )\n\n    # Ensure the signal is within [-1, 1] range\n    audio_data = np.clip(audio_data, -1, 1)\n\n    # Scale to the appropriate bit depth range\n    max_val = 2 ** (bit_depth - 1) - 1\n    numpy_type, _ = SUPPORTED_BIT_DEPTHS[bit_depth]\n    audio_data = (audio_data * max_val).astype(numpy_type)\n\n    # Write audio using soundfile\n    output_buffer = io.BytesIO()\n\n    # Select appropriate subtype based on format\n    if config.format == AudioFormat.MP3:\n        subtype = \"MPEG_LAYER_III\"\n    elif config.format == AudioFormat.WAV:\n        _, subtype = SUPPORTED_BIT_DEPTHS[bit_depth]\n    else:\n        raise GeneratorConfigurationError(\n            f\"Unsupported audio format: {config.format.name}. \"\n            f\"Supported formats are: {AudioFormat.WAV.name}, {AudioFormat.MP3.name}\"\n        )\n\n    sf.write(\n        output_buffer,\n        audio_data,\n        sampling_rate,\n        format=config.format.name,\n        subtype=subtype,\n    )\n    audio_bytes = output_buffer.getvalue()\n\n    # Encode to base64 with data URI scheme: \"{format},{data}\"\n    base64_data = base64.b64encode(audio_bytes).decode(\"utf-8\")\n    return f\"{config.format.name.lower()},{base64_data}\"\n</code></pre>"},{"location":"api/#aiperfservicesdatasetgeneratorimage","title":"aiperf.services.dataset.generator.image","text":""},{"location":"api/#aiperf.services.dataset.generator.image.ImageGenerator","title":"<code>ImageGenerator</code>","text":"<p>A class that generates images from source images.</p> <p>This class provides methods to create synthetic images by resizing source images (located in the 'assets/source_images' directory) to specified dimensions and converting them to a chosen image format (e.g., PNG, JPEG). The dimensions can be randomized based on mean and standard deviation values.</p> Source code in <code>aiperf/services/dataset/generator/image.py</code> <pre><code>class ImageGenerator:\n    \"\"\"A class that generates images from source images.\n\n    This class provides methods to create synthetic images by resizing\n    source images (located in the 'assets/source_images' directory)\n    to specified dimensions and converting them to a chosen image format (e.g., PNG, JPEG).\n    The dimensions can be randomized based on mean and standard deviation values.\n    \"\"\"\n\n    @classmethod\n    def create_synthetic_image(\n        cls,\n        image_width_mean: int,\n        image_width_stddev: int,\n        image_height_mean: int,\n        image_height_stddev: int,\n        image_format: ImageFormat | None = None,\n    ) -&gt; str:\n        \"\"\"Generate an image with the provided parameters.\n\n        Args:\n            image_width_mean: The mean width of the image.\n            image_width_stddev: The standard deviation of the image width.\n            image_height_mean: The mean height of the image.\n            image_height_stddev: The standard deviation of the image height.\n            image_format: The format of the image.\n\n        Returns:\n            A base64 encoded string of the generated image.\n        \"\"\"\n        if image_format is None:\n            image_format = random.choice(list(ImageFormat))\n        width = cls._sample_random_positive_integer(\n            image_width_mean, image_width_stddev\n        )\n        height = cls._sample_random_positive_integer(\n            image_height_mean, image_height_stddev\n        )\n\n        image = cls._sample_source_image()\n        image = image.resize(size=(width, height))\n        base64_image = utils.encode_image(image, image_format.name)\n\n        return f\"data:image/{image_format.name.lower()};base64,{base64_image}\"\n\n    @classmethod\n    def _sample_source_image(cls):\n        \"\"\"Sample one image among the source images.\n\n        Returns:\n            A PIL Image object randomly selected from the source images.\n        \"\"\"\n        filepath = Path(__file__).parent.resolve() / \"assets\" / \"source_images\" / \"*\"\n        filenames = glob.glob(str(filepath))\n        if not filenames:\n            raise ValueError(f\"No source images found in '{filepath}'\")\n        return Image.open(random.choice(filenames))\n\n    @classmethod\n    def _sample_random_positive_integer(cls, mean: int, stddev: int) -&gt; int:\n        \"\"\"Sample a random positive integer from a Gaussian distribution.\n\n        Args:\n            mean: The mean of the Gaussian distribution.\n            stddev: The standard deviation of the Gaussian distribution.\n\n        Returns:\n            A positive integer sampled from the distribution. If the sampled\n            number is zero, it returns 1.\n        \"\"\"\n        n = int(abs(random.gauss(mean, stddev)))\n        return n if n != 0 else 1  # avoid zero\n</code></pre>"},{"location":"api/#aiperf.services.dataset.generator.image.ImageGenerator.create_synthetic_image","title":"<code>create_synthetic_image(image_width_mean, image_width_stddev, image_height_mean, image_height_stddev, image_format=None)</code>  <code>classmethod</code>","text":"<p>Generate an image with the provided parameters.</p> <p>Parameters:</p> Name Type Description Default <code>image_width_mean</code> <code>int</code> <p>The mean width of the image.</p> required <code>image_width_stddev</code> <code>int</code> <p>The standard deviation of the image width.</p> required <code>image_height_mean</code> <code>int</code> <p>The mean height of the image.</p> required <code>image_height_stddev</code> <code>int</code> <p>The standard deviation of the image height.</p> required <code>image_format</code> <code>ImageFormat | None</code> <p>The format of the image.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A base64 encoded string of the generated image.</p> Source code in <code>aiperf/services/dataset/generator/image.py</code> <pre><code>@classmethod\ndef create_synthetic_image(\n    cls,\n    image_width_mean: int,\n    image_width_stddev: int,\n    image_height_mean: int,\n    image_height_stddev: int,\n    image_format: ImageFormat | None = None,\n) -&gt; str:\n    \"\"\"Generate an image with the provided parameters.\n\n    Args:\n        image_width_mean: The mean width of the image.\n        image_width_stddev: The standard deviation of the image width.\n        image_height_mean: The mean height of the image.\n        image_height_stddev: The standard deviation of the image height.\n        image_format: The format of the image.\n\n    Returns:\n        A base64 encoded string of the generated image.\n    \"\"\"\n    if image_format is None:\n        image_format = random.choice(list(ImageFormat))\n    width = cls._sample_random_positive_integer(\n        image_width_mean, image_width_stddev\n    )\n    height = cls._sample_random_positive_integer(\n        image_height_mean, image_height_stddev\n    )\n\n    image = cls._sample_source_image()\n    image = image.resize(size=(width, height))\n    base64_image = utils.encode_image(image, image_format.name)\n\n    return f\"data:image/{image_format.name.lower()};base64,{base64_image}\"\n</code></pre>"},{"location":"api/#aiperfservicesdatasetgeneratorprompt","title":"aiperf.services.dataset.generator.prompt","text":""},{"location":"api/#aiperf.services.dataset.generator.prompt.PromptGenerator","title":"<code>PromptGenerator</code>","text":"<p>A class for generating synthetic prompts from a text corpus.</p> <p>This class loads a text corpus (e.g., Shakespearean text), tokenizes it, and uses the tokenized corpus to generate synthetic prompts of specified lengths. It supports generating prompts with a target number of tokens (with optional randomization around a mean and standard deviation) and can reuse previously generated token blocks to optimize generation for certain use cases. It also allows for the creation of a pool of prefix prompts that can be randomly selected.</p> Source code in <code>aiperf/services/dataset/generator/prompt.py</code> <pre><code>class PromptGenerator:\n    \"\"\"A class for generating synthetic prompts from a text corpus.\n\n    This class loads a text corpus (e.g., Shakespearean text), tokenizes it,\n    and uses the tokenized corpus to generate synthetic prompts of specified\n    lengths. It supports generating prompts with a target number of tokens\n    (with optional randomization around a mean and standard deviation) and\n    can reuse previously generated token blocks to optimize generation for\n    certain use cases. It also allows for the creation of a pool of prefix\n    prompts that can be randomly selected.\n    \"\"\"\n\n    _tokenized_corpus = None\n    _corpus_length = 0\n    _prefix_prompts: list[str] = []\n    _cache: dict[int, list[int]] = {}\n\n    @classmethod\n    def create_synthetic_prompt(\n        cls,\n        tokenizer: Tokenizer,\n        prompt_tokens_mean: int = 550,\n        prompt_tokens_stddev: int = 250,\n        hash_ids: list[int] | None = None,\n        block_size: int = 512,\n    ) -&gt; str:\n        \"\"\"\n        Generate a synthetic prompt with a specific number of tokens.\n\n        Args:\n            tokenizer: Tokenizer instance.\n            prompt_tokens_mean: Mean number of tokens in the prompt.\n            prompt_tokens_stddev: Standard deviation for the number of tokens in the prompt.\n            hash_ids: Optional list of integers for token reuse.\n            block_size: Size of the token block for reuse.\n\n        Returns:\n            A synthetic prompt as a string.\n        \"\"\"\n        if cls._tokenized_corpus is None:\n            cls._initialize_corpus(tokenizer)\n\n        if hash_ids:\n            return cls._generate_prompt_with_token_reuse(\n                tokenizer, prompt_tokens_mean, hash_ids, block_size\n            )\n\n        num_prompt_tokens = max(\n            0, int(random.gauss(prompt_tokens_mean, prompt_tokens_stddev))\n        )\n\n        return cls._generate_prompt(tokenizer, num_prompt_tokens)\n\n    @classmethod\n    def _initialize_corpus(\n        cls, tokenizer: Tokenizer, corpus_file: str = DEFAULT_CORPUS_FILE\n    ) -&gt; None:\n        \"\"\"\n        Load and tokenize the corpus once, storing it for reuse.\n\n        Args:\n            tokenizer: Tokenizer for tokenizing the corpus.\n            corpus_file: Path to the corpus file.\n        \"\"\"\n        corpus_path = pathlib.Path(__file__).parent / corpus_file\n\n        with open(corpus_path) as f:\n            lines = f.readlines()\n\n        def tokenize_chunk(chunk):\n            cleaned_text = \" \".join(line.strip() for line in chunk if line.strip())\n            tokens = tokenizer.encode(cleaned_text)\n            return tokens\n\n        num_threads = os.cpu_count()\n        if num_threads is None:\n            num_threads = 4\n        chunk_size = len(lines) // num_threads\n        chunks = [lines[i : i + chunk_size] for i in range(0, len(lines), chunk_size)]\n\n        with ThreadPoolExecutor(max_workers=num_threads) as executor:\n            tokenized_chunks = list(executor.map(tokenize_chunk, chunks))\n\n        cls._tokenized_corpus = [token for chunk in tokenized_chunks for token in chunk]\n        cls._corpus_length = len(cls._tokenized_corpus)\n\n    @classmethod\n    def _generate_prompt_tokens(cls, num_tokens: int) -&gt; list[int]:\n        \"\"\"\n        Generate a prompt containing exactly `num_tokens` using the preloaded tokenized corpus.\n\n        Args:\n            num_tokens: Number of tokens required in the prompt.\n\n        Returns:\n            A synthetic prompt of tokens.\n\n        Raises:\n            GeneratorInitializationError: If the tokenized corpus is not initialized\n        \"\"\"\n        if not cls._tokenized_corpus:\n            raise GeneratorInitializationError(\"Tokenized corpus is not initialized.\")\n        if num_tokens &gt; cls._corpus_length:\n            logger.warning(\n                f\"Requested prompt length {num_tokens} is longer than the corpus. \"\n                f\"Returning a prompt of length {cls._corpus_length}.\"\n            )\n\n        start_idx = random.randrange(cls._corpus_length)\n\n        end_idx = start_idx + num_tokens\n        prompt_tokens = cls._tokenized_corpus[start_idx:end_idx]\n        if end_idx &gt; cls._corpus_length:\n            prompt_tokens += cls._tokenized_corpus[: end_idx - cls._corpus_length]\n\n        return prompt_tokens\n\n    @classmethod\n    def _generate_prompt(cls, tokenizer: Tokenizer, num_tokens: int) -&gt; str:\n        \"\"\"\n        Generate a prompt containing exactly `num_tokens` using the preloaded tokenized corpus.\n\n        Args:\n            tokenizer: Tokenizer instance.\n            num_tokens: Number of tokens required in the prompt.\n\n        Returns:\n            A synthetic prompt as a string.\n        \"\"\"\n        return tokenizer.decode(cls._generate_prompt_tokens(num_tokens))\n\n    @classmethod\n    def _generate_prompt_with_token_reuse(\n        cls,\n        tokenizer: Tokenizer,\n        num_tokens: int,\n        prompt_hash_list: list[int],\n        block_size: int,\n    ) -&gt; str:\n        \"\"\"\n        Generate a prompt containing exactly `num_tokens` by reusing previously generated prompts\n        stored in `_cache`. Each hash index in `prompt_hash_list` corresponds to a block of\n        `block_size` tokens. If a hash index is found in `_cache`, its stored prompt is reused.\n        Otherwise, a new prompt is generated using `_generate_prompt()` and stored in `_cache`.\n\n        Args:\n            tokenizer : Tokenizer\n                The tokenizer used to generate prompts.\n            num_tokens : int\n                The number of tokens required in the prompt.\n            prompt_hash_list : list[int]\n                A list of hash indices used for token reuse.\n            block_size : int\n                The number of tokens allocated per hash block (default 512).\n\n        Returns:\n            str: A synthetic prompt as a string.\n\n        Raises:\n            GeneratorConfigurationError: If the input parameters are not compatible.\n        \"\"\"\n        final_prompt: list[int] = []\n        size_to_use = block_size\n        last_hash_length = num_tokens - ((len(prompt_hash_list) - 1) * block_size)\n        if last_hash_length &lt;= 0 or block_size &lt; last_hash_length:\n            raise GeneratorConfigurationError(\n                f\"Input_length: {num_tokens}, Hash_ids: {prompt_hash_list}, Block_size: {block_size} \"\n                f\"are not compatible. The final hash id length: {last_hash_length} must be greater \"\n                f\"than 0 and less than or equal to {block_size}.\"\n            )\n        for index, hash_index in enumerate(prompt_hash_list):\n            if index == len(prompt_hash_list) - 1:\n                size_to_use = num_tokens - (index * block_size)\n            if hash_index not in cls._cache:\n                # To ensure that the prompt doesn't merge chunks, we pop the last token\n                # and insert the bos token at the beginning. Length is maintained and\n                # the prompt generates the expected number of tokens.\n                prompt_tokens = cls._generate_prompt_tokens(size_to_use)\n                prompt_tokens.pop(0)\n                prompt_tokens.insert(0, tokenizer.bos_token_id())\n                cls._cache[hash_index] = prompt_tokens\n            final_prompt.extend(cls._cache[hash_index])\n        prompt = tokenizer.decode(final_prompt, skip_special_tokens=False)\n\n        return prompt\n\n    @classmethod\n    def create_prefix_prompts_pool(\n        cls, tokenizer: Tokenizer, num_prompts: int, prompt_length: int\n    ) -&gt; None:\n        \"\"\"\n        Generate a pool of prefix prompts.\n\n        Args:\n            tokenizer: Tokenizer instance.\n            num_prompts: Number of prefix prompts to generate.\n            prompt_length: Number of tokens per prefix prompt.\n        \"\"\"\n        if cls._tokenized_corpus is None:\n            cls._initialize_corpus(tokenizer)\n\n        cls._prefix_prompts = [\n            cls._generate_prompt(tokenizer, prompt_length) for _ in range(num_prompts)\n        ]\n\n    @classmethod\n    def get_random_prefix_prompt(cls) -&gt; str:\n        \"\"\"\n        Fetch a random prefix prompt from the pool.\n\n        Returns:\n            A random prefix prompt.\n\n        Raises:\n            GeneratorInitializationError: If the prefix prompts pool is empty.\n        \"\"\"\n        if not cls._prefix_prompts:\n            raise GeneratorInitializationError(\n                \"Prefix prompts pool is empty. Call `create_prefix_prompts_pool` first.\"\n            )\n        return random.choice(cls._prefix_prompts)\n</code></pre>"},{"location":"api/#aiperf.services.dataset.generator.prompt.PromptGenerator.create_prefix_prompts_pool","title":"<code>create_prefix_prompts_pool(tokenizer, num_prompts, prompt_length)</code>  <code>classmethod</code>","text":"<p>Generate a pool of prefix prompts.</p> <p>Parameters:</p> Name Type Description Default <code>tokenizer</code> <code>Tokenizer</code> <p>Tokenizer instance.</p> required <code>num_prompts</code> <code>int</code> <p>Number of prefix prompts to generate.</p> required <code>prompt_length</code> <code>int</code> <p>Number of tokens per prefix prompt.</p> required Source code in <code>aiperf/services/dataset/generator/prompt.py</code> <pre><code>@classmethod\ndef create_prefix_prompts_pool(\n    cls, tokenizer: Tokenizer, num_prompts: int, prompt_length: int\n) -&gt; None:\n    \"\"\"\n    Generate a pool of prefix prompts.\n\n    Args:\n        tokenizer: Tokenizer instance.\n        num_prompts: Number of prefix prompts to generate.\n        prompt_length: Number of tokens per prefix prompt.\n    \"\"\"\n    if cls._tokenized_corpus is None:\n        cls._initialize_corpus(tokenizer)\n\n    cls._prefix_prompts = [\n        cls._generate_prompt(tokenizer, prompt_length) for _ in range(num_prompts)\n    ]\n</code></pre>"},{"location":"api/#aiperf.services.dataset.generator.prompt.PromptGenerator.create_synthetic_prompt","title":"<code>create_synthetic_prompt(tokenizer, prompt_tokens_mean=550, prompt_tokens_stddev=250, hash_ids=None, block_size=512)</code>  <code>classmethod</code>","text":"<p>Generate a synthetic prompt with a specific number of tokens.</p> <p>Parameters:</p> Name Type Description Default <code>tokenizer</code> <code>Tokenizer</code> <p>Tokenizer instance.</p> required <code>prompt_tokens_mean</code> <code>int</code> <p>Mean number of tokens in the prompt.</p> <code>550</code> <code>prompt_tokens_stddev</code> <code>int</code> <p>Standard deviation for the number of tokens in the prompt.</p> <code>250</code> <code>hash_ids</code> <code>list[int] | None</code> <p>Optional list of integers for token reuse.</p> <code>None</code> <code>block_size</code> <code>int</code> <p>Size of the token block for reuse.</p> <code>512</code> <p>Returns:</p> Type Description <code>str</code> <p>A synthetic prompt as a string.</p> Source code in <code>aiperf/services/dataset/generator/prompt.py</code> <pre><code>@classmethod\ndef create_synthetic_prompt(\n    cls,\n    tokenizer: Tokenizer,\n    prompt_tokens_mean: int = 550,\n    prompt_tokens_stddev: int = 250,\n    hash_ids: list[int] | None = None,\n    block_size: int = 512,\n) -&gt; str:\n    \"\"\"\n    Generate a synthetic prompt with a specific number of tokens.\n\n    Args:\n        tokenizer: Tokenizer instance.\n        prompt_tokens_mean: Mean number of tokens in the prompt.\n        prompt_tokens_stddev: Standard deviation for the number of tokens in the prompt.\n        hash_ids: Optional list of integers for token reuse.\n        block_size: Size of the token block for reuse.\n\n    Returns:\n        A synthetic prompt as a string.\n    \"\"\"\n    if cls._tokenized_corpus is None:\n        cls._initialize_corpus(tokenizer)\n\n    if hash_ids:\n        return cls._generate_prompt_with_token_reuse(\n            tokenizer, prompt_tokens_mean, hash_ids, block_size\n        )\n\n    num_prompt_tokens = max(\n        0, int(random.gauss(prompt_tokens_mean, prompt_tokens_stddev))\n    )\n\n    return cls._generate_prompt(tokenizer, num_prompt_tokens)\n</code></pre>"},{"location":"api/#aiperf.services.dataset.generator.prompt.PromptGenerator.get_random_prefix_prompt","title":"<code>get_random_prefix_prompt()</code>  <code>classmethod</code>","text":"<p>Fetch a random prefix prompt from the pool.</p> <p>Returns:</p> Type Description <code>str</code> <p>A random prefix prompt.</p> <p>Raises:</p> Type Description <code>GeneratorInitializationError</code> <p>If the prefix prompts pool is empty.</p> Source code in <code>aiperf/services/dataset/generator/prompt.py</code> <pre><code>@classmethod\ndef get_random_prefix_prompt(cls) -&gt; str:\n    \"\"\"\n    Fetch a random prefix prompt from the pool.\n\n    Returns:\n        A random prefix prompt.\n\n    Raises:\n        GeneratorInitializationError: If the prefix prompts pool is empty.\n    \"\"\"\n    if not cls._prefix_prompts:\n        raise GeneratorInitializationError(\n            \"Prefix prompts pool is empty. Call `create_prefix_prompts_pool` first.\"\n        )\n    return random.choice(cls._prefix_prompts)\n</code></pre>"},{"location":"api/#aiperfservicesdatasetgeneratorutils","title":"aiperf.services.dataset.generator.utils","text":""},{"location":"api/#aiperf.services.dataset.generator.utils.encode_image","title":"<code>encode_image(img, format)</code>","text":"<p>Encodes an image into base64 encoded string.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>Image</code> <p>The PIL Image object to encode.</p> required <code>format</code> <code>str</code> <p>The image format to use (e.g., \"JPEG\", \"PNG\").</p> required <p>Returns:</p> Type Description <code>str</code> <p>A base64 encoded string representation of the image.</p> Source code in <code>aiperf/services/dataset/generator/utils.py</code> <pre><code>def encode_image(img: Image, format: str) -&gt; str:\n    \"\"\"Encodes an image into base64 encoded string.\n\n    Args:\n        img: The PIL Image object to encode.\n        format: The image format to use (e.g., \"JPEG\", \"PNG\").\n\n    Returns:\n        A base64 encoded string representation of the image.\n    \"\"\"\n    # JPEG does not support P or RGBA mode (commonly used for PNG) so it needs\n    # to be converted to RGB before an image can be saved as JPEG format.\n    if format == \"JPEG\" and img.mode != \"RGB\":\n        img = img.convert(\"RGB\")\n\n    buffer = BytesIO()\n    img.save(buffer, format=format)\n    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n</code></pre>"},{"location":"api/#aiperfservicespost_processor_managerpost_processor_manager","title":"aiperf.services.post_processor_manager.post_processor_manager","text":""},{"location":"api/#aiperf.services.post_processor_manager.post_processor_manager.PostProcessorManager","title":"<code>PostProcessorManager</code>","text":"<p>               Bases: <code>BaseComponentService</code></p> <p>PostProcessorManager is primarily responsible for iterating over the records to generate metrics and other conclusions from the records.</p> Source code in <code>aiperf/services/post_processor_manager/post_processor_manager.py</code> <pre><code>@ServiceFactory.register(ServiceType.POST_PROCESSOR_MANAGER)\nclass PostProcessorManager(BaseComponentService):\n    \"\"\"PostProcessorManager is primarily responsible for iterating over the\n    records to generate metrics and other conclusions from the records.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Initializing post processor manager\")\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.POST_PROCESSOR_MANAGER\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize post processor manager-specific components.\"\"\"\n        self.logger.debug(\"Initializing post processor manager\")\n        # TODO: Implement post processor manager initialization\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the post processor manager.\"\"\"\n        self.logger.debug(\"Starting post processor manager\")\n        # TODO: Implement post processor manager start\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the post processor manager.\"\"\"\n        self.logger.debug(\"Stopping post processor manager\")\n        # TODO: Implement post processor manager stop\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up post processor manager-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up post processor manager\")\n        # TODO: Implement post processor manager cleanup\n\n    @on_configure\n    async def _configure(self, message: Message) -&gt; None:\n        \"\"\"Configure the post processor manager.\"\"\"\n        self.logger.debug(f\"Configuring post processor manager with message: {message}\")\n</code></pre>"},{"location":"api/#aiperf.services.post_processor_manager.post_processor_manager.PostProcessorManager.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.post_processor_manager.post_processor_manager.main","title":"<code>main()</code>","text":"<p>Main entry point for the post processor manager.</p> Source code in <code>aiperf/services/post_processor_manager/post_processor_manager.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the post processor manager.\"\"\"\n\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(PostProcessorManager)\n</code></pre>"},{"location":"api/#aiperfservicesrecords_managermetricsbase_metric","title":"aiperf.services.records_manager.metrics.base_metric","text":""},{"location":"api/#aiperf.services.records_manager.metrics.base_metric.BaseMetric","title":"<code>BaseMetric</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for all metricss with automatic subclass registration.</p> Source code in <code>aiperf/services/records_manager/metrics/base_metric.py</code> <pre><code>class BaseMetric(ABC):\n    \"Base class for all metricss with automatic subclass registration.\"\n\n    # Class attributes that subclasses must override\n    tag: ClassVar[str] = \"\"\n    unit: ClassVar[MetricTimeType] = MetricTimeType.NANOSECONDS\n    larger_is_better: ClassVar[bool] = True\n    header: ClassVar[str] = \"\"\n\n    metric_interfaces: dict[str, type[\"BaseMetric\"]] = {}\n\n    def __init_subclass__(cls, **kwargs):\n        \"\"\"\n        This method is called when a class is subclassed from Metric.\n        It automatically registers the subclass in the metric_interfaces\n        dictionary using the `tag` class attribute.\n        The `tag` attribute must be a non-empty string that uniquely identifies the\n        metric type. Only concrete (non-abstract) classes will be registered.\n        \"\"\"\n\n        super().__init_subclass__(**kwargs)\n\n        # Only register concrete classes (not abstract ones)\n        if inspect.isabstract(cls):\n            return\n\n        # Enforce that subclasses define a non-empty tag\n        if not cls.tag or not isinstance(cls.tag, str):\n            raise TypeError(\n                f\"Concrete metric class {cls.__name__} must define a non-empty 'tag' class attribute\"\n            )\n\n        # Check for duplicate tags\n        if cls.tag in cls.metric_interfaces:\n            raise ValueError(\n                f\"Metric tag '{cls.tag}' is already registered by {cls.metric_interfaces[cls.tag].__name__}\"\n            )\n\n        cls.metric_interfaces[cls.tag] = cls\n\n    @classmethod\n    def get_all(cls) -&gt; dict[str, type[\"BaseMetric\"]]:\n        \"\"\"\n        Returns the dictionary of all registered metric interfaces.\n\n        This method dynamically imports all metric type modules from the 'types'\n        directory to ensure all metric classes are registered via __init_subclass__.\n\n        Returns:\n            dict[str, type[Metric]]: Mapping of metric tags to their corresponding classes\n\n        Raises:\n            MetricTypeError: If there's an error importing metric type modules\n        \"\"\"\n        # Get the types directory path\n        types_dir = Path(__file__).parent / \"types\"\n\n        # Import all metric type modules to trigger registration\n        if types_dir.exists():\n            for python_file in types_dir.glob(\"*.py\"):\n                if python_file.name != \"__init__.py\":\n                    module_name = python_file.stem  # Get filename without extension\n                    try:\n                        importlib.import_module(\n                            f\"aiperf.services.records_manager.metrics.types.{module_name}\"\n                        )\n                    except ImportError as err:\n                        raise MetricTypeError(\n                            f\"Error importing metric type module '{module_name}'\"\n                        ) from err\n\n        return cls.metric_interfaces\n\n    @abstractmethod\n    def update_value(\n        self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n    ) -&gt; None:\n        \"\"\"\n        Updates the metric value based on the provided record and dictionary of other metrics.\n\n        Args:\n            record (Optional[Record]): The record to update the metric with.\n            metrics (Optional[dict[BaseMetric]]): A dictionary of other metrics that may be needed for calculation.\n        \"\"\"\n\n    @abstractmethod\n    def values(self) -&gt; Any:\n        \"\"\"\n        Returns the list of calculated metrics.\n        \"\"\"\n\n    @abstractmethod\n    def _check_record(self, record: Record) -&gt; None:\n        \"\"\"\n        Checks if the record is valid for metric calculation.\n\n        Raises:\n            ValueError: If the record does not meet the required conditions.\n        \"\"\"\n\n    def get_converted_metrics(self, unit: MetricTimeType) -&gt; list[Any]:\n        if not isinstance(unit, MetricTimeType):\n            raise MetricTypeError(\"Invalid metric time type for conversion.\")\n\n        scale_factor = self.unit.value - unit.value\n\n        return [metric / 10**scale_factor for metric in self.values()]\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.base_metric.BaseMetric.__init_subclass__","title":"<code>__init_subclass__(**kwargs)</code>","text":"<p>This method is called when a class is subclassed from Metric. It automatically registers the subclass in the metric_interfaces dictionary using the <code>tag</code> class attribute. The <code>tag</code> attribute must be a non-empty string that uniquely identifies the metric type. Only concrete (non-abstract) classes will be registered.</p> Source code in <code>aiperf/services/records_manager/metrics/base_metric.py</code> <pre><code>def __init_subclass__(cls, **kwargs):\n    \"\"\"\n    This method is called when a class is subclassed from Metric.\n    It automatically registers the subclass in the metric_interfaces\n    dictionary using the `tag` class attribute.\n    The `tag` attribute must be a non-empty string that uniquely identifies the\n    metric type. Only concrete (non-abstract) classes will be registered.\n    \"\"\"\n\n    super().__init_subclass__(**kwargs)\n\n    # Only register concrete classes (not abstract ones)\n    if inspect.isabstract(cls):\n        return\n\n    # Enforce that subclasses define a non-empty tag\n    if not cls.tag or not isinstance(cls.tag, str):\n        raise TypeError(\n            f\"Concrete metric class {cls.__name__} must define a non-empty 'tag' class attribute\"\n        )\n\n    # Check for duplicate tags\n    if cls.tag in cls.metric_interfaces:\n        raise ValueError(\n            f\"Metric tag '{cls.tag}' is already registered by {cls.metric_interfaces[cls.tag].__name__}\"\n        )\n\n    cls.metric_interfaces[cls.tag] = cls\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.base_metric.BaseMetric.get_all","title":"<code>get_all()</code>  <code>classmethod</code>","text":"<p>Returns the dictionary of all registered metric interfaces.</p> <p>This method dynamically imports all metric type modules from the 'types' directory to ensure all metric classes are registered via init_subclass.</p> <p>Returns:</p> Type Description <code>dict[str, type[BaseMetric]]</code> <p>dict[str, type[Metric]]: Mapping of metric tags to their corresponding classes</p> <p>Raises:</p> Type Description <code>MetricTypeError</code> <p>If there's an error importing metric type modules</p> Source code in <code>aiperf/services/records_manager/metrics/base_metric.py</code> <pre><code>@classmethod\ndef get_all(cls) -&gt; dict[str, type[\"BaseMetric\"]]:\n    \"\"\"\n    Returns the dictionary of all registered metric interfaces.\n\n    This method dynamically imports all metric type modules from the 'types'\n    directory to ensure all metric classes are registered via __init_subclass__.\n\n    Returns:\n        dict[str, type[Metric]]: Mapping of metric tags to their corresponding classes\n\n    Raises:\n        MetricTypeError: If there's an error importing metric type modules\n    \"\"\"\n    # Get the types directory path\n    types_dir = Path(__file__).parent / \"types\"\n\n    # Import all metric type modules to trigger registration\n    if types_dir.exists():\n        for python_file in types_dir.glob(\"*.py\"):\n            if python_file.name != \"__init__.py\":\n                module_name = python_file.stem  # Get filename without extension\n                try:\n                    importlib.import_module(\n                        f\"aiperf.services.records_manager.metrics.types.{module_name}\"\n                    )\n                except ImportError as err:\n                    raise MetricTypeError(\n                        f\"Error importing metric type module '{module_name}'\"\n                    ) from err\n\n    return cls.metric_interfaces\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.base_metric.BaseMetric.update_value","title":"<code>update_value(record=None, metrics=None)</code>  <code>abstractmethod</code>","text":"<p>Updates the metric value based on the provided record and dictionary of other metrics.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Optional[Record]</code> <p>The record to update the metric with.</p> <code>None</code> <code>metrics</code> <code>Optional[dict[BaseMetric]]</code> <p>A dictionary of other metrics that may be needed for calculation.</p> <code>None</code> Source code in <code>aiperf/services/records_manager/metrics/base_metric.py</code> <pre><code>@abstractmethod\ndef update_value(\n    self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n) -&gt; None:\n    \"\"\"\n    Updates the metric value based on the provided record and dictionary of other metrics.\n\n    Args:\n        record (Optional[Record]): The record to update the metric with.\n        metrics (Optional[dict[BaseMetric]]): A dictionary of other metrics that may be needed for calculation.\n    \"\"\"\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.base_metric.BaseMetric.values","title":"<code>values()</code>  <code>abstractmethod</code>","text":"<p>Returns the list of calculated metrics.</p> Source code in <code>aiperf/services/records_manager/metrics/base_metric.py</code> <pre><code>@abstractmethod\ndef values(self) -&gt; Any:\n    \"\"\"\n    Returns the list of calculated metrics.\n    \"\"\"\n</code></pre>"},{"location":"api/#aiperfservicesrecords_managermetricstypesbenchmark_duration_metric","title":"aiperf.services.records_manager.metrics.types.benchmark_duration_metric","text":""},{"location":"api/#aiperf.services.records_manager.metrics.types.benchmark_duration_metric.BenchmarkDurationMetric","title":"<code>BenchmarkDurationMetric</code>","text":"<p>               Bases: <code>BaseMetric</code></p> <p>Post-processor for calculating the Benchmark Duration metric.</p> Source code in <code>aiperf/services/records_manager/metrics/types/benchmark_duration_metric.py</code> <pre><code>class BenchmarkDurationMetric(BaseMetric):\n    \"\"\"\n    Post-processor for calculating the Benchmark Duration metric.\n    \"\"\"\n\n    tag = \"benchmark_duration\"\n    unit = MetricTimeType.NANOSECONDS\n    larger_is_better = False\n    header = \"Benchmark Duration\"\n    type = MetricType.METRIC_OF_METRICS\n\n    def __init__(self):\n        self.metric: float = 0.0\n\n    def update_value(\n        self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n    ) -&gt; None:\n        min_req_time = metrics[MinRequestMetric.tag].values()\n        max_res_time = metrics[MaxResponseMetric.tag].values()\n        benchmark_duration = max_res_time - min_req_time\n        self.metric = benchmark_duration\n\n    def values(self) -&gt; float:\n        \"\"\"\n        Returns the list of Time to First Token (BenchmarkDuration) metrics.\n        \"\"\"\n        return self.metric\n\n    def _check_record(self, record: Record) -&gt; None:\n        pass\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.types.benchmark_duration_metric.BenchmarkDurationMetric.values","title":"<code>values()</code>","text":"<p>Returns the list of Time to First Token (BenchmarkDuration) metrics.</p> Source code in <code>aiperf/services/records_manager/metrics/types/benchmark_duration_metric.py</code> <pre><code>def values(self) -&gt; float:\n    \"\"\"\n    Returns the list of Time to First Token (BenchmarkDuration) metrics.\n    \"\"\"\n    return self.metric\n</code></pre>"},{"location":"api/#aiperfservicesrecords_managermetricstypesmax_response_metric","title":"aiperf.services.records_manager.metrics.types.max_response_metric","text":""},{"location":"api/#aiperf.services.records_manager.metrics.types.max_response_metric.MaxResponseMetric","title":"<code>MaxResponseMetric</code>","text":"<p>               Bases: <code>BaseMetric</code></p> <p>Post-processor for calculating the maximum response time stamp metric from records.</p> Source code in <code>aiperf/services/records_manager/metrics/types/max_response_metric.py</code> <pre><code>class MaxResponseMetric(BaseMetric):\n    \"\"\"\n    Post-processor for calculating the maximum response time stamp metric from records.\n    \"\"\"\n\n    tag = \"max_response\"\n    unit = MetricTimeType.NANOSECONDS\n    type = MetricType.METRIC_OF_RECORDS\n    larger_is_better = False\n    header = \"Maximum Response Timestamp\"\n\n    def __init__(self):\n        self.metric: float = 0\n\n    def update_value(\n        self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n    ) -&gt; None:\n        \"\"\"\n        Adds a new record and calculates the maximum response timestamp metric.\n\n        \"\"\"\n        self._check_record(record)\n        if record.responses[-1].timestamp &gt; self.metric:\n            self.metric = record.responses[-1].timestamp\n\n    def values(self) -&gt; float:\n        \"\"\"\n        Returns the list of Time to First Token (TTFT) metrics.\n        \"\"\"\n        return self.metric\n\n    def _check_record(self, record: Record) -&gt; None:\n        \"\"\"\n        Checks if the record is valid for calculations.\n\n        \"\"\"\n        if not record.responses or not record.responses[-1].timestamp:\n            raise ValueError(\"Record must have valid responses with timestamps.\")\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.types.max_response_metric.MaxResponseMetric.update_value","title":"<code>update_value(record=None, metrics=None)</code>","text":"<p>Adds a new record and calculates the maximum response timestamp metric.</p> Source code in <code>aiperf/services/records_manager/metrics/types/max_response_metric.py</code> <pre><code>def update_value(\n    self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n) -&gt; None:\n    \"\"\"\n    Adds a new record and calculates the maximum response timestamp metric.\n\n    \"\"\"\n    self._check_record(record)\n    if record.responses[-1].timestamp &gt; self.metric:\n        self.metric = record.responses[-1].timestamp\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.types.max_response_metric.MaxResponseMetric.values","title":"<code>values()</code>","text":"<p>Returns the list of Time to First Token (TTFT) metrics.</p> Source code in <code>aiperf/services/records_manager/metrics/types/max_response_metric.py</code> <pre><code>def values(self) -&gt; float:\n    \"\"\"\n    Returns the list of Time to First Token (TTFT) metrics.\n    \"\"\"\n    return self.metric\n</code></pre>"},{"location":"api/#aiperfservicesrecords_managermetricstypesmin_request_metric","title":"aiperf.services.records_manager.metrics.types.min_request_metric","text":""},{"location":"api/#aiperf.services.records_manager.metrics.types.min_request_metric.MinRequestMetric","title":"<code>MinRequestMetric</code>","text":"<p>               Bases: <code>BaseMetric</code></p> <p>Post-processor for calculating the minimum request time stamp metric from records.</p> Source code in <code>aiperf/services/records_manager/metrics/types/min_request_metric.py</code> <pre><code>class MinRequestMetric(BaseMetric):\n    \"\"\"\n    Post-processor for calculating the minimum request time stamp metric from records.\n    \"\"\"\n\n    tag = \"min_request\"\n    unit = MetricTimeType.NANOSECONDS\n    type = MetricType.METRIC_OF_RECORDS\n    larger_is_better = False\n    header = \"Minimum Request Timestamp\"\n\n    def __init__(self):\n        self.metric: float = float(\"inf\")\n\n    def update_value(\n        self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n    ) -&gt; None:\n        \"\"\"\n        Adds a new record and calculates the minimum request timestamp metric.\n\n        \"\"\"\n        self._check_record(record)\n        if record.request.timestamp &lt; self.metric:\n            self.metric = record.request.timestamp\n\n    def values(self) -&gt; float:\n        \"\"\"\n        Returns the list of Time to First Token (TTFT) metrics.\n        \"\"\"\n        return self.metric\n\n    def _check_record(self, record: Record) -&gt; None:\n        \"\"\"\n        Checks if the record is valid for calculations.\n\n        \"\"\"\n        if not record.request or not record.request.timestamp:\n            raise ValueError(\"Record must have a valid request with a timestamp.\")\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.types.min_request_metric.MinRequestMetric.update_value","title":"<code>update_value(record=None, metrics=None)</code>","text":"<p>Adds a new record and calculates the minimum request timestamp metric.</p> Source code in <code>aiperf/services/records_manager/metrics/types/min_request_metric.py</code> <pre><code>def update_value(\n    self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n) -&gt; None:\n    \"\"\"\n    Adds a new record and calculates the minimum request timestamp metric.\n\n    \"\"\"\n    self._check_record(record)\n    if record.request.timestamp &lt; self.metric:\n        self.metric = record.request.timestamp\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.types.min_request_metric.MinRequestMetric.values","title":"<code>values()</code>","text":"<p>Returns the list of Time to First Token (TTFT) metrics.</p> Source code in <code>aiperf/services/records_manager/metrics/types/min_request_metric.py</code> <pre><code>def values(self) -&gt; float:\n    \"\"\"\n    Returns the list of Time to First Token (TTFT) metrics.\n    \"\"\"\n    return self.metric\n</code></pre>"},{"location":"api/#aiperfservicesrecords_managermetricstypesrequest_latency_metric","title":"aiperf.services.records_manager.metrics.types.request_latency_metric","text":""},{"location":"api/#aiperf.services.records_manager.metrics.types.request_latency_metric.RequestLatencyMetric","title":"<code>RequestLatencyMetric</code>","text":"<p>               Bases: <code>BaseMetric</code></p> <p>Post-processor for calculating Request Latency metrics from records.</p> Source code in <code>aiperf/services/records_manager/metrics/types/request_latency_metric.py</code> <pre><code>class RequestLatencyMetric(BaseMetric):\n    \"\"\"\n    Post-processor for calculating Request Latency metrics from records.\n    \"\"\"\n\n    tag = \"request_latency\"\n    unit = MetricTimeType.NANOSECONDS\n    type = MetricType.METRIC_OF_RECORDS\n    larger_is_better = False\n    header = \"Request Latency\"\n\n    def __init__(self):\n        self.metric: list[int] = []\n\n    def update_value(\n        self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n    ) -&gt; None:\n        \"\"\"\n        Adds a new record and calculates the Request Latencies metric.\n\n        This method extracts the request and last response timestamps, calculates the differences in time, and\n        appends the result to the metric list.\n        \"\"\"\n        self._check_record(record)\n        request_ts = record.request.timestamp\n        final_response_ts = record.responses[-1].timestamp\n        request_latency = final_response_ts - request_ts\n        self.metric.append(request_latency)\n\n    def values(self) -&gt; list[int]:\n        \"\"\"\n        Returns the list of Time to First Token (Request Latencies) metrics.\n        \"\"\"\n        return self.metric\n\n    def _check_record(self, record: Record) -&gt; None:\n        if not record.request or not record.request.timestamp:\n            raise ValueError(\"Record must have a valid request with a timestamp.\")\n        if len(record.responses) &lt; 1:\n            raise ValueError(\"Record must have at least one response.\")\n\n        request_ts = record.request.timestamp\n        response_ts = record.responses[-1].timestamp\n\n        if request_ts &lt; 0 or response_ts &lt; 0:\n            raise ValueError(\"Timestamps must be positive values.\")\n\n        if response_ts &lt; request_ts:\n            raise ValueError(\n                \"Response timestamp must be greater than or equal to request timestamp.\"\n            )\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.types.request_latency_metric.RequestLatencyMetric.update_value","title":"<code>update_value(record=None, metrics=None)</code>","text":"<p>Adds a new record and calculates the Request Latencies metric.</p> <p>This method extracts the request and last response timestamps, calculates the differences in time, and appends the result to the metric list.</p> Source code in <code>aiperf/services/records_manager/metrics/types/request_latency_metric.py</code> <pre><code>def update_value(\n    self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n) -&gt; None:\n    \"\"\"\n    Adds a new record and calculates the Request Latencies metric.\n\n    This method extracts the request and last response timestamps, calculates the differences in time, and\n    appends the result to the metric list.\n    \"\"\"\n    self._check_record(record)\n    request_ts = record.request.timestamp\n    final_response_ts = record.responses[-1].timestamp\n    request_latency = final_response_ts - request_ts\n    self.metric.append(request_latency)\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.types.request_latency_metric.RequestLatencyMetric.values","title":"<code>values()</code>","text":"<p>Returns the list of Time to First Token (Request Latencies) metrics.</p> Source code in <code>aiperf/services/records_manager/metrics/types/request_latency_metric.py</code> <pre><code>def values(self) -&gt; list[int]:\n    \"\"\"\n    Returns the list of Time to First Token (Request Latencies) metrics.\n    \"\"\"\n    return self.metric\n</code></pre>"},{"location":"api/#aiperfservicesrecords_managermetricstypesttft_metric","title":"aiperf.services.records_manager.metrics.types.ttft_metric","text":""},{"location":"api/#aiperf.services.records_manager.metrics.types.ttft_metric.TTFTMetric","title":"<code>TTFTMetric</code>","text":"<p>               Bases: <code>BaseMetric</code></p> <p>Post-processor for calculating Time to First Token (TTFT) metrics from records.</p> Source code in <code>aiperf/services/records_manager/metrics/types/ttft_metric.py</code> <pre><code>class TTFTMetric(BaseMetric):\n    \"\"\"\n    Post-processor for calculating Time to First Token (TTFT) metrics from records.\n    \"\"\"\n\n    tag = \"ttft\"\n    unit = MetricTimeType.NANOSECONDS\n    larger_is_better = False\n    header = \"Time to First Token (TTFT)\"\n    type = MetricType.METRIC_OF_RECORDS\n\n    def __init__(self):\n        self.metric: list[int] = []\n\n    def update_value(\n        self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n    ) -&gt; None:\n        \"\"\"\n        Adds a new record and calculates the Time To First Token (TTFT) metric.\n\n        This method extracts the timestamp from the request and the first response in the given\n        Record object, computes the difference (TTFT), and appends the result to the metric list.\n        \"\"\"\n        self._check_record(record)\n        request_ts = record.request.timestamp\n        response_ts = record.responses[0].timestamp\n        ttft = response_ts - request_ts\n        self.metric.append(ttft)\n\n    def values(self) -&gt; list[int]:\n        \"\"\"\n        Returns the list of Time to First Token (TTFT) metrics.\n        \"\"\"\n        return self.metric\n\n    def _check_record(self, record: Record) -&gt; None:\n        \"\"\"\n        Checks if the record is valid for TTFT calculation.\n\n        Raises:\n            ValueError: If the record does not have at least one response.\n        \"\"\"\n        if not record.request or not record.request.timestamp:\n            raise ValueError(\"Record must have a valid request with a timestamp.\")\n        if not record.responses or len(record.responses) &lt; 1:\n            raise ValueError(\n                \"Record must have at least one response to calculate TTFT.\"\n            )\n        if record.responses[0].timestamp &lt; record.request.timestamp:\n            raise ValueError(\n                \"Response timestamp must be greater than or equal to request timestamp.\"\n            )\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.types.ttft_metric.TTFTMetric.update_value","title":"<code>update_value(record=None, metrics=None)</code>","text":"<p>Adds a new record and calculates the Time To First Token (TTFT) metric.</p> <p>This method extracts the timestamp from the request and the first response in the given Record object, computes the difference (TTFT), and appends the result to the metric list.</p> Source code in <code>aiperf/services/records_manager/metrics/types/ttft_metric.py</code> <pre><code>def update_value(\n    self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n) -&gt; None:\n    \"\"\"\n    Adds a new record and calculates the Time To First Token (TTFT) metric.\n\n    This method extracts the timestamp from the request and the first response in the given\n    Record object, computes the difference (TTFT), and appends the result to the metric list.\n    \"\"\"\n    self._check_record(record)\n    request_ts = record.request.timestamp\n    response_ts = record.responses[0].timestamp\n    ttft = response_ts - request_ts\n    self.metric.append(ttft)\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.types.ttft_metric.TTFTMetric.values","title":"<code>values()</code>","text":"<p>Returns the list of Time to First Token (TTFT) metrics.</p> Source code in <code>aiperf/services/records_manager/metrics/types/ttft_metric.py</code> <pre><code>def values(self) -&gt; list[int]:\n    \"\"\"\n    Returns the list of Time to First Token (TTFT) metrics.\n    \"\"\"\n    return self.metric\n</code></pre>"},{"location":"api/#aiperfservicesrecords_managermetricstypesttst_metric","title":"aiperf.services.records_manager.metrics.types.ttst_metric","text":""},{"location":"api/#aiperf.services.records_manager.metrics.types.ttst_metric.TTSTMetric","title":"<code>TTSTMetric</code>","text":"<p>               Bases: <code>BaseMetric</code></p> <p>Post-processor for calculating Time to Second Token (TTST) metrics from records.</p> Source code in <code>aiperf/services/records_manager/metrics/types/ttst_metric.py</code> <pre><code>class TTSTMetric(BaseMetric):\n    \"\"\"\n    Post-processor for calculating Time to Second Token (TTST) metrics from records.\n    \"\"\"\n\n    tag = \"ttst\"\n    unit = MetricTimeType.NANOSECONDS\n    larger_is_better = False\n    header = \"Time to Second Token (TTST)\"\n    type = MetricType.METRIC_OF_RECORDS\n\n    def __init__(self):\n        self.metric: list[int] = []\n\n    def update_value(\n        self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n    ) -&gt; None:\n        \"\"\"\n        Adds a new record and calculates the Time To Second Token (TTST) metric.\n\n        This method extracts the timestamp from the first and second response in the given\n        Record object, computes the difference (TTST), and appends the result to the metric list.\n        \"\"\"\n        self._check_record(record)\n        first_reponse_ts = record.responses[0].timestamp\n        second_response_ts = record.responses[1].timestamp\n        ttst = second_response_ts - first_reponse_ts\n        self.metric.append(ttst)\n\n    def values(self) -&gt; list[int]:\n        \"\"\"\n        Returns the list of Time to First Token (TTST) metrics.\n        \"\"\"\n        return self.metric\n\n    def _check_record(self, record: Record) -&gt; None:\n        \"\"\"\n        Checks if the record is valid for TTST calculation.\n\n        Raises:\n            ValueError: If the record does not have at least two responses.\n        \"\"\"\n        if not record.request or not record.request.timestamp:\n            raise ValueError(\"Record must have a valid request with a timestamp.\")\n        if not record.responses or len(record.responses) &lt; 2:\n            raise ValueError(\n                \"Record must have at least two responses to calculate TTST.\"\n            )\n        if record.responses[1].timestamp &lt; record.responses[0].timestamp:\n            raise ValueError(\n                \"Second response timestamp must be greater than or equal to the first response timestamp.\"\n            )\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.types.ttst_metric.TTSTMetric.update_value","title":"<code>update_value(record=None, metrics=None)</code>","text":"<p>Adds a new record and calculates the Time To Second Token (TTST) metric.</p> <p>This method extracts the timestamp from the first and second response in the given Record object, computes the difference (TTST), and appends the result to the metric list.</p> Source code in <code>aiperf/services/records_manager/metrics/types/ttst_metric.py</code> <pre><code>def update_value(\n    self, record: Record | None = None, metrics: dict[\"BaseMetric\"] | None = None\n) -&gt; None:\n    \"\"\"\n    Adds a new record and calculates the Time To Second Token (TTST) metric.\n\n    This method extracts the timestamp from the first and second response in the given\n    Record object, computes the difference (TTST), and appends the result to the metric list.\n    \"\"\"\n    self._check_record(record)\n    first_reponse_ts = record.responses[0].timestamp\n    second_response_ts = record.responses[1].timestamp\n    ttst = second_response_ts - first_reponse_ts\n    self.metric.append(ttst)\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.metrics.types.ttst_metric.TTSTMetric.values","title":"<code>values()</code>","text":"<p>Returns the list of Time to First Token (TTST) metrics.</p> Source code in <code>aiperf/services/records_manager/metrics/types/ttst_metric.py</code> <pre><code>def values(self) -&gt; list[int]:\n    \"\"\"\n    Returns the list of Time to First Token (TTST) metrics.\n    \"\"\"\n    return self.metric\n</code></pre>"},{"location":"api/#aiperfservicesrecords_managerpost_processorsmetric_summary","title":"aiperf.services.records_manager.post_processors.metric_summary","text":""},{"location":"api/#aiperf.services.records_manager.post_processors.metric_summary.MetricSummary","title":"<code>MetricSummary</code>","text":"<p>MetricSummary is a post-processor that generates a summary of metrics from the records. It processes the records to extract relevant metrics and returns them in a structured format.</p> Source code in <code>aiperf/services/records_manager/post_processors/metric_summary.py</code> <pre><code>@PostProcessorFactory.register(PostProcessorType.METRIC_SUMMARY)\nclass MetricSummary:\n    \"\"\"\n    MetricSummary is a post-processor that generates a summary of metrics from the records.\n    It processes the records to extract relevant metrics and returns them in a structured format.\n    \"\"\"\n\n    def __init__(self):\n        self.logger = logging.getLogger(__name__)\n        self.logger.debug(\"Initializing MetricSummary post-processor\")\n\n        self._metrics = []\n        for metric_cls in BaseMetric.get_all().values():\n            self._metrics.append(metric_cls())\n\n    def process(self, records: list) -&gt; None:\n        \"\"\"\n        Process the records to generate a summary of metrics.\n\n        :param records: The input records to be processed.\n        :return: A dictionary containing the summarized metrics.\n        \"\"\"\n        for record in records:\n            for metric in self._metrics:\n                if metric.type == MetricType.METRIC_OF_RECORDS:\n                    metric.update_value(record=record)\n            for metric in self._metrics:\n                if metric.type == MetricType.METRIC_OF_METRICS:\n                    metric.update_value(metrics={m.tag: m for m in self._metrics})\n                elif metric.type == MetricType.METRIC_OF_BOTH:\n                    metric.update_value(\n                        record=record, metrics={m.tag: m for m in self._metrics}\n                    )\n\n        # TODO: Fix this after we add support for dependencies\n        # between metrics of metrics\n        # This is a workaround to ensure that metrics of metrics\n        # are updated after all records are processed\n        for metric in self._metrics:\n            if metric.type == MetricType.METRIC_OF_METRICS:\n                metric.update_value(metrics={m.tag: m for m in self._metrics})\n            elif metric.type == MetricType.METRIC_OF_BOTH:\n                metric.update_value(\n                    record=record, metrics={m.tag: m for m in self._metrics}\n                )\n\n    def get_metrics_summary(self) -&gt; dict:\n        metrics_summary = {}\n        for metric in self._metrics:\n            metrics_summary[metric.tag] = metric.values()\n\n        return metrics_summary\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.post_processors.metric_summary.MetricSummary.process","title":"<code>process(records)</code>","text":"<p>Process the records to generate a summary of metrics.</p> <p>:param records: The input records to be processed. :return: A dictionary containing the summarized metrics.</p> Source code in <code>aiperf/services/records_manager/post_processors/metric_summary.py</code> <pre><code>def process(self, records: list) -&gt; None:\n    \"\"\"\n    Process the records to generate a summary of metrics.\n\n    :param records: The input records to be processed.\n    :return: A dictionary containing the summarized metrics.\n    \"\"\"\n    for record in records:\n        for metric in self._metrics:\n            if metric.type == MetricType.METRIC_OF_RECORDS:\n                metric.update_value(record=record)\n        for metric in self._metrics:\n            if metric.type == MetricType.METRIC_OF_METRICS:\n                metric.update_value(metrics={m.tag: m for m in self._metrics})\n            elif metric.type == MetricType.METRIC_OF_BOTH:\n                metric.update_value(\n                    record=record, metrics={m.tag: m for m in self._metrics}\n                )\n\n    # TODO: Fix this after we add support for dependencies\n    # between metrics of metrics\n    # This is a workaround to ensure that metrics of metrics\n    # are updated after all records are processed\n    for metric in self._metrics:\n        if metric.type == MetricType.METRIC_OF_METRICS:\n            metric.update_value(metrics={m.tag: m for m in self._metrics})\n        elif metric.type == MetricType.METRIC_OF_BOTH:\n            metric.update_value(\n                record=record, metrics={m.tag: m for m in self._metrics}\n            )\n</code></pre>"},{"location":"api/#aiperfservicesrecords_managerrecords","title":"aiperf.services.records_manager.records","text":""},{"location":"api/#aiperf.services.records_manager.records.Records","title":"<code>Records</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A collection of records, each containing a request and a list of responses.</p> Source code in <code>aiperf/services/records_manager/records.py</code> <pre><code>class Records(BaseModel):\n    \"\"\"\n    A collection of records, each containing a request and a list of responses.\n    \"\"\"\n\n    records: list[Record] = Field(\n        default_factory=list,\n        description=\"A list of records, each containing a request and its responses.\",\n    )\n\n    def add_record(self, request: Transaction, responses: list[Transaction]) -&gt; None:\n        \"\"\"\n        Add a new record with the given request and responses.\n        \"\"\"\n        self.records.append(Record(request=request, responses=responses))\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.records.Records.add_record","title":"<code>add_record(request, responses)</code>","text":"<p>Add a new record with the given request and responses.</p> Source code in <code>aiperf/services/records_manager/records.py</code> <pre><code>def add_record(self, request: Transaction, responses: list[Transaction]) -&gt; None:\n    \"\"\"\n    Add a new record with the given request and responses.\n    \"\"\"\n    self.records.append(Record(request=request, responses=responses))\n</code></pre>"},{"location":"api/#aiperfservicesrecords_managerrecords_manager","title":"aiperf.services.records_manager.records_manager","text":""},{"location":"api/#aiperf.services.records_manager.records_manager.RecordsManager","title":"<code>RecordsManager</code>","text":"<p>               Bases: <code>BaseComponentService</code></p> <p>The RecordsManager service is primarily responsible for holding the results returned from the workers.</p> Source code in <code>aiperf/services/records_manager/records_manager.py</code> <pre><code>@ServiceFactory.register(ServiceType.RECORDS_MANAGER)\nclass RecordsManager(BaseComponentService):\n    \"\"\"\n    The RecordsManager service is primarily responsible for holding the\n    results returned from the workers.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Initializing records manager\")\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.RECORDS_MANAGER\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize records manager-specific components.\"\"\"\n        self.logger.debug(\"Initializing records manager\")\n        # TODO: Implement records manager initialization\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the records manager.\"\"\"\n        self.logger.debug(\"Starting records manager\")\n        # TODO: Implement records manager start\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the records manager.\"\"\"\n        self.logger.debug(\"Stopping records manager\")\n        # TODO: Implement records manager stop\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up records manager-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up records manager\")\n        # TODO: Implement records manager cleanup\n\n    @on_configure\n    async def _configure(self, message: Message) -&gt; None:\n        \"\"\"Configure the records manager.\"\"\"\n        self.logger.debug(f\"Configuring records manager with message: {message}\")\n</code></pre>"},{"location":"api/#aiperf.services.records_manager.records_manager.RecordsManager.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.records_manager.records_manager.main","title":"<code>main()</code>","text":"<p>Main entry point for the records manager.</p> Source code in <code>aiperf/services/records_manager/records_manager.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the records manager.\"\"\"\n\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(RecordsManager)\n</code></pre>"},{"location":"api/#aiperfservicesservice_managerbase","title":"aiperf.services.service_manager.base","text":""},{"location":"api/#aiperf.services.service_manager.base.BaseServiceManager","title":"<code>BaseServiceManager</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for service managers. It provides a common interface for managing services and a way to look up service information by service ID.</p> Source code in <code>aiperf/services/service_manager/base.py</code> <pre><code>class BaseServiceManager(ABC):\n    \"\"\"\n    Base class for service managers. It provides a common interface for\n    managing services and a way to look up service information by service ID.\n    \"\"\"\n\n    def __init__(\n        self, required_service_types: list[ServiceType], config: ServiceConfig\n    ):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.required_service_types = required_service_types\n        self.config = config\n\n        # Maps to track service information\n        self.service_map: dict[ServiceType, list[ServiceRunInfo]] = {}\n\n        # Create service ID map for component lookups\n        self.service_id_map: dict[str, ServiceRunInfo] = {}\n\n    @abstractmethod\n    async def run_all_services(self) -&gt; None:\n        \"\"\"Run all required services.\"\"\"\n        pass\n\n    @abstractmethod\n    async def shutdown_all_services(self) -&gt; None:\n        \"\"\"Shutdown all managed services.\"\"\"\n        pass\n\n    @abstractmethod\n    async def kill_all_services(self) -&gt; None:\n        \"\"\"Kill all managed services.\"\"\"\n        pass\n\n    @abstractmethod\n    async def wait_for_all_services_registration(\n        self, stop_event: asyncio.Event, timeout_seconds: int = 30\n    ) -&gt; None:\n        \"\"\"Wait for all required services to be registered.\"\"\"\n        pass\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.base.BaseServiceManager.kill_all_services","title":"<code>kill_all_services()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Kill all managed services.</p> Source code in <code>aiperf/services/service_manager/base.py</code> <pre><code>@abstractmethod\nasync def kill_all_services(self) -&gt; None:\n    \"\"\"Kill all managed services.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.base.BaseServiceManager.run_all_services","title":"<code>run_all_services()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Run all required services.</p> Source code in <code>aiperf/services/service_manager/base.py</code> <pre><code>@abstractmethod\nasync def run_all_services(self) -&gt; None:\n    \"\"\"Run all required services.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.base.BaseServiceManager.shutdown_all_services","title":"<code>shutdown_all_services()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Shutdown all managed services.</p> Source code in <code>aiperf/services/service_manager/base.py</code> <pre><code>@abstractmethod\nasync def shutdown_all_services(self) -&gt; None:\n    \"\"\"Shutdown all managed services.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.base.BaseServiceManager.wait_for_all_services_registration","title":"<code>wait_for_all_services_registration(stop_event, timeout_seconds=30)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Wait for all required services to be registered.</p> Source code in <code>aiperf/services/service_manager/base.py</code> <pre><code>@abstractmethod\nasync def wait_for_all_services_registration(\n    self, stop_event: asyncio.Event, timeout_seconds: int = 30\n) -&gt; None:\n    \"\"\"Wait for all required services to be registered.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#aiperfservicesservice_managerkubernetes","title":"aiperf.services.service_manager.kubernetes","text":""},{"location":"api/#aiperf.services.service_manager.kubernetes.KubernetesServiceManager","title":"<code>KubernetesServiceManager</code>","text":"<p>               Bases: <code>BaseServiceManager</code></p> <p>Service Manager for starting and stopping services in a Kubernetes cluster.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>class KubernetesServiceManager(BaseServiceManager):\n    \"\"\"\n    Service Manager for starting and stopping services in a Kubernetes cluster.\n    \"\"\"\n\n    def __init__(\n        self, required_service_types: list[ServiceType], config: ServiceConfig\n    ):\n        super().__init__(required_service_types, config)\n\n    async def run_all_services(self) -&gt; None:\n        \"\"\"Initialize all required services as Kubernetes pods.\"\"\"\n        self.logger.debug(\"Initializing all required services as Kubernetes pods\")\n        # TODO: Implement Kubernetes\n        raise NotImplementedError(\n            \"KubernetesServiceManager.initialize_all_services not implemented\"\n        )\n\n    async def shutdown_all_services(self) -&gt; None:\n        \"\"\"Stop all required services as Kubernetes pods.\"\"\"\n        self.logger.debug(\"Stopping all required services as Kubernetes pods\")\n        # TODO: Implement Kubernetes\n        raise NotImplementedError(\n            \"KubernetesServiceManager.stop_all_services not implemented\"\n        )\n\n    async def kill_all_services(self) -&gt; None:\n        \"\"\"Kill all required services as Kubernetes pods.\"\"\"\n        self.logger.debug(\"Killing all required services as Kubernetes pods\")\n        # TODO: Implement Kubernetes\n        raise NotImplementedError(\n            \"KubernetesServiceManager.kill_all_services not implemented\"\n        )\n\n    async def wait_for_all_services_registration(\n        self, stop_event: asyncio.Event, timeout_seconds: int = 30\n    ) -&gt; None:\n        \"\"\"Wait for all required services to be registered in Kubernetes.\"\"\"\n        self.logger.debug(\n            \"Waiting for all required services to be registered in Kubernetes\"\n        )\n        # TODO: Implement Kubernetes\n        raise NotImplementedError(\n            \"KubernetesServiceManager.wait_for_all_services_registration not implemented\"\n        )\n\n    async def wait_for_all_services_start(self) -&gt; None:\n        \"\"\"Wait for all required services to be started in Kubernetes.\"\"\"\n        self.logger.debug(\n            \"Waiting for all required services to be started in Kubernetes\"\n        )\n        # TODO: Implement Kubernetes\n        raise NotImplementedError(\n            \"KubernetesServiceManager.wait_for_all_services_start not implemented\"\n        )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.kubernetes.KubernetesServiceManager.kill_all_services","title":"<code>kill_all_services()</code>  <code>async</code>","text":"<p>Kill all required services as Kubernetes pods.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>async def kill_all_services(self) -&gt; None:\n    \"\"\"Kill all required services as Kubernetes pods.\"\"\"\n    self.logger.debug(\"Killing all required services as Kubernetes pods\")\n    # TODO: Implement Kubernetes\n    raise NotImplementedError(\n        \"KubernetesServiceManager.kill_all_services not implemented\"\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.kubernetes.KubernetesServiceManager.run_all_services","title":"<code>run_all_services()</code>  <code>async</code>","text":"<p>Initialize all required services as Kubernetes pods.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>async def run_all_services(self) -&gt; None:\n    \"\"\"Initialize all required services as Kubernetes pods.\"\"\"\n    self.logger.debug(\"Initializing all required services as Kubernetes pods\")\n    # TODO: Implement Kubernetes\n    raise NotImplementedError(\n        \"KubernetesServiceManager.initialize_all_services not implemented\"\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.kubernetes.KubernetesServiceManager.shutdown_all_services","title":"<code>shutdown_all_services()</code>  <code>async</code>","text":"<p>Stop all required services as Kubernetes pods.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>async def shutdown_all_services(self) -&gt; None:\n    \"\"\"Stop all required services as Kubernetes pods.\"\"\"\n    self.logger.debug(\"Stopping all required services as Kubernetes pods\")\n    # TODO: Implement Kubernetes\n    raise NotImplementedError(\n        \"KubernetesServiceManager.stop_all_services not implemented\"\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.kubernetes.KubernetesServiceManager.wait_for_all_services_registration","title":"<code>wait_for_all_services_registration(stop_event, timeout_seconds=30)</code>  <code>async</code>","text":"<p>Wait for all required services to be registered in Kubernetes.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>async def wait_for_all_services_registration(\n    self, stop_event: asyncio.Event, timeout_seconds: int = 30\n) -&gt; None:\n    \"\"\"Wait for all required services to be registered in Kubernetes.\"\"\"\n    self.logger.debug(\n        \"Waiting for all required services to be registered in Kubernetes\"\n    )\n    # TODO: Implement Kubernetes\n    raise NotImplementedError(\n        \"KubernetesServiceManager.wait_for_all_services_registration not implemented\"\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.kubernetes.KubernetesServiceManager.wait_for_all_services_start","title":"<code>wait_for_all_services_start()</code>  <code>async</code>","text":"<p>Wait for all required services to be started in Kubernetes.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>async def wait_for_all_services_start(self) -&gt; None:\n    \"\"\"Wait for all required services to be started in Kubernetes.\"\"\"\n    self.logger.debug(\n        \"Waiting for all required services to be started in Kubernetes\"\n    )\n    # TODO: Implement Kubernetes\n    raise NotImplementedError(\n        \"KubernetesServiceManager.wait_for_all_services_start not implemented\"\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.kubernetes.ServiceKubernetesRunInfo","title":"<code>ServiceKubernetesRunInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about a service running in a Kubernetes pod.</p> Source code in <code>aiperf/services/service_manager/kubernetes.py</code> <pre><code>class ServiceKubernetesRunInfo(BaseModel):\n    \"\"\"Information about a service running in a Kubernetes pod.\"\"\"\n\n    pod_name: str\n    node_name: str\n    namespace: str\n</code></pre>"},{"location":"api/#aiperfservicesservice_managermultiprocess","title":"aiperf.services.service_manager.multiprocess","text":""},{"location":"api/#aiperf.services.service_manager.multiprocess.MultiProcessRunInfo","title":"<code>MultiProcessRunInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about a service running as a multiprocessing process.</p> Source code in <code>aiperf/services/service_manager/multiprocess.py</code> <pre><code>class MultiProcessRunInfo(BaseModel):\n    \"\"\"Information about a service running as a multiprocessing process.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    process: Process | None = Field(default=None)\n    service_type: ServiceType = Field(\n        ...,\n        description=\"Type of service running in the process\",\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.multiprocess.MultiProcessServiceManager","title":"<code>MultiProcessServiceManager</code>","text":"<p>               Bases: <code>BaseServiceManager</code></p> <p>Service Manager for starting and stopping services as multiprocessing processes.</p> Source code in <code>aiperf/services/service_manager/multiprocess.py</code> <pre><code>class MultiProcessServiceManager(BaseServiceManager):\n    \"\"\"\n    Service Manager for starting and stopping services as multiprocessing processes.\n    \"\"\"\n\n    def __init__(\n        self,\n        required_service_types: list[ServiceType],\n        config: ServiceConfig,\n    ):\n        super().__init__(required_service_types, config)\n        self.multi_process_info: list[MultiProcessRunInfo] = []\n\n    async def run_all_services(self) -&gt; None:\n        \"\"\"Start all required services as multiprocessing processes.\"\"\"\n        self.logger.debug(\"Starting all required services as multiprocessing processes\")\n\n        # Create and start all service processes\n        for service_type in self.required_service_types:\n            service_class = ServiceFactory.get_class_from_type(service_type)\n\n            process = Process(\n                target=bootstrap_and_run_service,\n                name=f\"{service_type}_process\",\n                args=(service_class, self.config),\n                daemon=True,\n            )\n            if service_type == ServiceType.WORKER_MANAGER:\n                process.daemon = False  # Worker manager cannot be a daemon because it needs to be able to spawn worker processes\n\n            process.start()\n\n            self.logger.debug(\n                \"Service %s started as process (pid: %d)\",\n                service_type,\n                process.pid,\n            )\n\n            self.multi_process_info.append(\n                MultiProcessRunInfo(process=process, service_type=service_type)\n            )\n\n            # Sleep to allow the service to register\n            await asyncio.sleep(0.01)\n\n    async def shutdown_all_services(self) -&gt; None:\n        \"\"\"Stop all required services as multiprocessing processes.\"\"\"\n        self.logger.debug(\"Stopping all service processes\")\n\n        # Wait for all to finish in parallel\n        await asyncio.gather(\n            *[self._wait_for_process(info) for info in self.multi_process_info]\n        )\n\n    async def kill_all_services(self) -&gt; None:\n        \"\"\"Kill all required services as multiprocessing processes.\"\"\"\n        self.logger.debug(\"Killing all service processes\")\n\n        # Kill all processes\n        for info in self.multi_process_info:\n            if info.process:\n                info.process.kill()\n\n        # Wait for all to finish in parallel\n        await asyncio.gather(\n            *[self._wait_for_process(info) for info in self.multi_process_info]\n        )\n\n    async def wait_for_all_services_registration(\n        self, stop_event: asyncio.Event, timeout_seconds: int = 30\n    ) -&gt; None:\n        \"\"\"Wait for all required services to be registered.\n\n        Args:\n            stop_event: Event to check if operation should be cancelled\n            timeout_seconds: Maximum time to wait in seconds\n\n        Raises:\n            Exception if any service failed to register, None otherwise\n        \"\"\"\n        self.logger.debug(\"Waiting for all required services to register...\")\n\n        # Get the set of required service types for checking completion\n        required_types = set(self.required_service_types)\n\n        # TODO: Can this be done better by using asyncio.Event()?\n\n        async def _wait_for_registration():\n            while not stop_event.is_set():\n                # Get all registered service types from the id map\n                registered_types = {\n                    service_info.service_type\n                    for service_info in self.service_id_map.values()\n                    if service_info.registration_status\n                    == ServiceRegistrationStatus.REGISTERED\n                }\n\n                # Check if all required types are registered\n                if required_types.issubset(registered_types):\n                    return\n\n                # Wait a bit before checking again\n                await asyncio.sleep(0.5)\n\n        try:\n            await asyncio.wait_for(_wait_for_registration(), timeout=timeout_seconds)\n        except asyncio.TimeoutError:\n            # Log which services didn't register in time\n            registered_types = {\n                service_info.service_type\n                for service_info in self.service_id_map.values()\n                if service_info.registration_status\n                == ServiceRegistrationStatus.REGISTERED\n            }\n\n            for service_type in required_types - registered_types:\n                self.logger.warning(\n                    f\"Service {service_type} failed to register within timeout\"\n                )\n\n    async def _wait_for_process(self, info: MultiProcessRunInfo) -&gt; None:\n        \"\"\"Wait for a process to terminate with timeout handling.\"\"\"\n        if not info.process or not info.process.is_alive():\n            return\n\n        try:\n            info.process.terminate()\n            await asyncio.wait_for(\n                asyncio.to_thread(\n                    info.process.join, timeout=1.0\n                ),  # Add timeout to join\n                timeout=GRACEFUL_SHUTDOWN_TIMEOUT_SECONDS,  # Overall timeout\n            )\n            self.logger.debug(\n                \"Service %s process stopped (pid: %d)\",\n                info.service_type,\n                info.process.pid,\n            )\n        except asyncio.TimeoutError:\n            self.logger.warning(\n                \"Service %s process (pid: %d) did not terminate gracefully, killing\",\n                info.service_type,\n                info.process.pid,\n            )\n            info.process.kill()\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.multiprocess.MultiProcessServiceManager.kill_all_services","title":"<code>kill_all_services()</code>  <code>async</code>","text":"<p>Kill all required services as multiprocessing processes.</p> Source code in <code>aiperf/services/service_manager/multiprocess.py</code> <pre><code>async def kill_all_services(self) -&gt; None:\n    \"\"\"Kill all required services as multiprocessing processes.\"\"\"\n    self.logger.debug(\"Killing all service processes\")\n\n    # Kill all processes\n    for info in self.multi_process_info:\n        if info.process:\n            info.process.kill()\n\n    # Wait for all to finish in parallel\n    await asyncio.gather(\n        *[self._wait_for_process(info) for info in self.multi_process_info]\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.multiprocess.MultiProcessServiceManager.run_all_services","title":"<code>run_all_services()</code>  <code>async</code>","text":"<p>Start all required services as multiprocessing processes.</p> Source code in <code>aiperf/services/service_manager/multiprocess.py</code> <pre><code>async def run_all_services(self) -&gt; None:\n    \"\"\"Start all required services as multiprocessing processes.\"\"\"\n    self.logger.debug(\"Starting all required services as multiprocessing processes\")\n\n    # Create and start all service processes\n    for service_type in self.required_service_types:\n        service_class = ServiceFactory.get_class_from_type(service_type)\n\n        process = Process(\n            target=bootstrap_and_run_service,\n            name=f\"{service_type}_process\",\n            args=(service_class, self.config),\n            daemon=True,\n        )\n        if service_type == ServiceType.WORKER_MANAGER:\n            process.daemon = False  # Worker manager cannot be a daemon because it needs to be able to spawn worker processes\n\n        process.start()\n\n        self.logger.debug(\n            \"Service %s started as process (pid: %d)\",\n            service_type,\n            process.pid,\n        )\n\n        self.multi_process_info.append(\n            MultiProcessRunInfo(process=process, service_type=service_type)\n        )\n\n        # Sleep to allow the service to register\n        await asyncio.sleep(0.01)\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.multiprocess.MultiProcessServiceManager.shutdown_all_services","title":"<code>shutdown_all_services()</code>  <code>async</code>","text":"<p>Stop all required services as multiprocessing processes.</p> Source code in <code>aiperf/services/service_manager/multiprocess.py</code> <pre><code>async def shutdown_all_services(self) -&gt; None:\n    \"\"\"Stop all required services as multiprocessing processes.\"\"\"\n    self.logger.debug(\"Stopping all service processes\")\n\n    # Wait for all to finish in parallel\n    await asyncio.gather(\n        *[self._wait_for_process(info) for info in self.multi_process_info]\n    )\n</code></pre>"},{"location":"api/#aiperf.services.service_manager.multiprocess.MultiProcessServiceManager.wait_for_all_services_registration","title":"<code>wait_for_all_services_registration(stop_event, timeout_seconds=30)</code>  <code>async</code>","text":"<p>Wait for all required services to be registered.</p> <p>Parameters:</p> Name Type Description Default <code>stop_event</code> <code>Event</code> <p>Event to check if operation should be cancelled</p> required <code>timeout_seconds</code> <code>int</code> <p>Maximum time to wait in seconds</p> <code>30</code> Source code in <code>aiperf/services/service_manager/multiprocess.py</code> <pre><code>async def wait_for_all_services_registration(\n    self, stop_event: asyncio.Event, timeout_seconds: int = 30\n) -&gt; None:\n    \"\"\"Wait for all required services to be registered.\n\n    Args:\n        stop_event: Event to check if operation should be cancelled\n        timeout_seconds: Maximum time to wait in seconds\n\n    Raises:\n        Exception if any service failed to register, None otherwise\n    \"\"\"\n    self.logger.debug(\"Waiting for all required services to register...\")\n\n    # Get the set of required service types for checking completion\n    required_types = set(self.required_service_types)\n\n    # TODO: Can this be done better by using asyncio.Event()?\n\n    async def _wait_for_registration():\n        while not stop_event.is_set():\n            # Get all registered service types from the id map\n            registered_types = {\n                service_info.service_type\n                for service_info in self.service_id_map.values()\n                if service_info.registration_status\n                == ServiceRegistrationStatus.REGISTERED\n            }\n\n            # Check if all required types are registered\n            if required_types.issubset(registered_types):\n                return\n\n            # Wait a bit before checking again\n            await asyncio.sleep(0.5)\n\n    try:\n        await asyncio.wait_for(_wait_for_registration(), timeout=timeout_seconds)\n    except asyncio.TimeoutError:\n        # Log which services didn't register in time\n        registered_types = {\n            service_info.service_type\n            for service_info in self.service_id_map.values()\n            if service_info.registration_status\n            == ServiceRegistrationStatus.REGISTERED\n        }\n\n        for service_type in required_types - registered_types:\n            self.logger.warning(\n                f\"Service {service_type} failed to register within timeout\"\n            )\n</code></pre>"},{"location":"api/#aiperfservicessystem_controllersystem_controller","title":"aiperf.services.system_controller.system_controller","text":""},{"location":"api/#aiperf.services.system_controller.system_controller.SystemController","title":"<code>SystemController</code>","text":"<p>               Bases: <code>SignalHandlerMixin</code>, <code>BaseControllerService</code></p> <p>System Controller service.</p> <p>This service is responsible for managing the lifecycle of all other services. It will start, stop, and configure all other services.</p> Source code in <code>aiperf/services/system_controller/system_controller.py</code> <pre><code>@ServiceFactory.register(ServiceType.SYSTEM_CONTROLLER)\nclass SystemController(SignalHandlerMixin, BaseControllerService):\n    \"\"\"System Controller service.\n\n    This service is responsible for managing the lifecycle of all other services.\n    It will start, stop, and configure all other services.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Creating System Controller\")\n\n        self._system_state: SystemState = SystemState.INITIALIZING\n\n        # List of required service types, in no particular order\n        self.required_service_types: list[ServiceType] = [\n            ServiceType.DATASET_MANAGER,\n            ServiceType.TIMING_MANAGER,\n            ServiceType.WORKER_MANAGER,\n            ServiceType.RECORDS_MANAGER,\n            ServiceType.POST_PROCESSOR_MANAGER,\n        ]\n\n        self.service_manager: BaseServiceManager = None  # type: ignore - is set in _initialize\n        self.logger.debug(\"System Controller created\")\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.SYSTEM_CONTROLLER\n\n    async def _forever_loop(self) -&gt; None:\n        \"\"\"Run the system controller in a loop until the stop event is set.\"\"\"\n        try:\n            await super()._forever_loop()\n        except KeyboardInterrupt:\n            await self.send_command_to_service(\n                target_service_type=ServiceType.RECORDS_MANAGER,\n                target_service_id=None,\n                command=CommandType.PROCESS_RECORDS,\n                data=ProcessRecordsCommandData(cancelled=True),\n            )\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize system controller-specific components.\n\n        This method will:\n        - Initialize the service manager\n        - Subscribe to relevant messages\n        \"\"\"\n        self.logger.debug(\"Initializing System Controller\")\n\n        self.setup_signal_handlers(self._handle_signal)\n        self.logger.debug(\"Setup signal handlers\")\n\n        if self.service_config.service_run_type == ServiceRunType.MULTIPROCESSING:\n            self.service_manager = MultiProcessServiceManager(\n                self.required_service_types, self.service_config\n            )\n\n        elif self.service_config.service_run_type == ServiceRunType.KUBERNETES:\n            self.service_manager = KubernetesServiceManager(\n                self.required_service_types, self.service_config\n            )\n\n        else:\n            raise ConfigError(\n                f\"Unsupported service run type: {self.service_config.service_run_type}\"\n            )\n\n        # Subscribe to relevant messages\n        subscribe_callbacks = [\n            (Topic.REGISTRATION, self._process_registration_message),\n            (Topic.HEARTBEAT, self._process_heartbeat_message),\n            (Topic.STATUS, self._process_status_message),\n            (Topic.CREDITS_COMPLETE, self._process_credits_complete_message),\n            (Topic.PROFILE_STATS, self._process_profile_stats_message),\n            (Topic.PROFILE_RESULTS, self._process_profile_results_message),\n        ]\n        for topic, callback in subscribe_callbacks:\n            try:\n                await self.comms.subscribe(topic=topic, callback=callback)\n            except Exception as e:\n                self.logger.error(\"Failed to subscribe to topic %s: %s\", topic, e)\n                raise CommunicationError(\n                    CommunicationErrorReason.SUBSCRIBE_ERROR,\n                    f\"Failed to subscribe to topic {topic}: {e}\",\n                ) from e\n\n        # TODO: HACK:\n        # wait 1 second to ensure that the communication is initialized\n        await asyncio.sleep(1)\n\n        self._system_state = SystemState.CONFIGURING\n        await self._bootstrap_system()\n\n    async def _handle_signal(self, sig: int) -&gt; None:\n        \"\"\"Handle received signals by triggering graceful shutdown.\n\n        Args:\n            sig: The signal number received\n        \"\"\"\n        self.logger.debug(\"Received signal %s, initiating graceful shutdown\", sig)\n        if sig == signal.SIGINT:\n            await self.send_command_to_service(\n                target_service_id=None,\n                target_service_type=ServiceType.RECORDS_MANAGER,\n                command=CommandType.PROCESS_RECORDS,\n                data=ProcessRecordsCommandData(cancelled=True),\n            )\n        else:\n            self.stop_event.set()\n\n    async def _bootstrap_system(self) -&gt; None:\n        \"\"\"Bootstrap the system services.\n\n        This method will:\n        - Initialize all required services\n        - Wait for all required services to be registered\n        - Start all required services\n        \"\"\"\n        self.logger.debug(\"Starting System Controller\")\n\n        # Start all required services\n        try:\n            await self.service_manager.run_all_services()\n        except Exception as e:\n            raise self._service_error(\"Failed to initialize all services\") from e\n\n        try:\n            # Wait for all required services to be registered\n            await self.service_manager.wait_for_all_services_registration(\n                self.stop_event\n            )\n\n            if self.stop_event.is_set():\n                self.logger.debug(\n                    \"System Controller stopped before all services registered\"\n                )\n                return  # Don't continue with the rest of the initialization\n\n        except Exception as e:\n            raise self._service_error(\n                \"Not all required services registered within the timeout period\"\n            ) from e\n\n        self.logger.debug(\"All required services registered successfully\")\n\n        self.logger.info(\"AIPerf System is READY\")\n        self._system_state = SystemState.READY\n\n        await self.start_profiling_all_services()\n\n        if self.stop_event.is_set():\n            self.logger.debug(\"System Controller stopped before all services started\")\n            return  # Don't continue with the rest of the initialization\n\n        self.logger.debug(\"All required services started successfully\")\n        self.logger.info(\"AIPerf System is RUNNING\")\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the system controller and all running services.\n\n        This method will:\n        - Stop all running services\n        \"\"\"\n        self.logger.debug(\"Stopping System Controller\")\n        self.logger.info(\"AIPerf System is SHUTTING DOWN\")\n\n        self._system_state = SystemState.STOPPING\n\n        # Broadcast a stop command to all services\n        await self.send_command_to_service(\n            target_service_id=None,\n            command=CommandType.SHUTDOWN,\n        )\n\n        try:\n            await self.service_manager.shutdown_all_services()\n        except Exception as e:\n            raise self._service_error(\"Failed to stop all services\") from e\n\n        # TODO: This is a hack to give the services time to produce results\n        # await asyncio.sleep(3)\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up system controller-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up System Controller\")\n\n        self._system_state = SystemState.SHUTDOWN\n\n    async def start_profiling_all_services(self) -&gt; None:\n        \"\"\"Tell all services to start profiling.\"\"\"\n        self._system_state = SystemState.PROFILING\n\n        self.logger.debug(\"Starting services\")\n        for service_info in self.service_manager.service_id_map.values():\n            if service_info.state == ServiceState.READY:\n                try:\n                    await self.send_command_to_service(\n                        target_service_id=service_info.service_id,\n                        command=CommandType.PROFILE_START,\n                    )\n\n                except Exception as e:\n                    self.logger.warning(\"Failed to start service: %s\", e)\n                    # Continue to the next service\n                    # TODO: should we have some sort of retries?\n                    continue\n\n    async def _process_profile_stats_message(\n        self, message: ProfileStatsMessage\n    ) -&gt; None:\n        \"\"\"Process a profile stats message.\"\"\"\n        self.logger.debug(\"Received profile stats: %s\", message)\n\n    async def _process_profile_results_message(\n        self, message: ProfileResultsMessage\n    ) -&gt; None:\n        \"\"\"Process a profile results message.\"\"\"\n        self.logger.debug(\"Received profile results: %s\", message)\n        self.stop_event.set()\n\n    async def _process_registration_message(self, message: RegistrationMessage) -&gt; None:\n        \"\"\"Process a registration message from a service. It will\n        add the service to the service manager and send a configure command\n        to the service.\n\n        Args:\n            message: The registration message to process\n        \"\"\"\n        service_id = message.service_id\n        service_type = message.service_type\n\n        self.logger.debug(\n            f\"Processing registration from {service_type} with ID: {service_id}\"\n        )\n\n        service_info = ServiceRunInfo(\n            registration_status=ServiceRegistrationStatus.REGISTERED,\n            service_type=service_type,\n            service_id=service_id,\n            first_seen=time.time_ns(),\n            state=ServiceState.READY,\n            last_seen=time.time_ns(),\n        )\n\n        self.service_manager.service_id_map[service_id] = service_info\n        if service_type not in self.service_manager.service_map:\n            self.service_manager.service_map[service_type] = []\n        self.service_manager.service_map[service_type].append(service_info)\n\n        is_required = service_type in self.required_service_types\n        self.logger.debug(\n            f\"Registered {'required' if is_required else 'non-required'} \"\n            f\"service: {service_type} with ID: {service_id}\"\n        )\n\n        # Send configure command to the newly registered service\n        try:\n            await self.send_command_to_service(\n                target_service_id=service_id,\n                command=CommandType.PROFILE_CONFIGURE,\n                data=None,\n            )\n        except Exception as e:\n            raise self._service_error(\n                f\"Failed to send configure command to {service_type} (ID: {service_id})\"\n            ) from e\n\n        self.logger.debug(\n            f\"Sent configure command to {service_type} (ID: {service_id})\"\n        )\n\n    async def _process_heartbeat_message(self, message: HeartbeatMessage) -&gt; None:\n        \"\"\"Process a heartbeat message from a service. It will\n        update the last seen timestamp and state of the service.\n\n        Args:\n            message: The heartbeat message to process\n        \"\"\"\n        service_id = message.service_id\n        service_type = message.service_type\n        timestamp = message.request_ns\n\n        self.logger.debug(f\"Received heartbeat from {service_type} (ID: {service_id})\")\n\n        # Update the last heartbeat timestamp if the component exists\n        try:\n            service_info = self.service_manager.service_id_map[service_id]\n            service_info.last_seen = timestamp\n            service_info.state = message.state\n            self.logger.debug(f\"Updated heartbeat for {service_id} to {timestamp}\")\n        except Exception:\n            self.logger.warning(\n                f\"Received heartbeat from unknown service: {service_id} ({service_type})\"\n            )\n\n    async def _process_credits_complete_message(\n        self, message: CreditsCompleteMessage\n    ) -&gt; None:\n        \"\"\"Process a credits complete message from a service. It will\n        update the state of the service with the service manager.\n\n        Args:\n            message: The credits complete message to process\n        \"\"\"\n        service_id = message.service_id\n        self.logger.info(\"Received credits complete from %s\", service_id)\n\n    async def _process_status_message(self, message: StatusMessage) -&gt; None:\n        \"\"\"Process a status message from a service. It will\n        update the state of the service with the service manager.\n\n        Args:\n            message: The status message to process\n        \"\"\"\n        service_id = message.service_id\n        service_type = message.service_type\n        state = message.state\n\n        self.logger.debug(\n            f\"Received status update from {service_type} (ID: {service_id}): {state}\"\n        )\n\n        # Update the component state if the component exists\n        if service_id not in self.service_manager.service_id_map:\n            self.logger.debug(\n                f\"Received status update from un-registered service: {service_id} ({service_type})\"\n            )\n            return\n\n        service_info = self.service_manager.service_id_map.get(service_id)\n        if service_info is None:\n            return\n\n        service_info.state = message.state\n\n        self.logger.debug(f\"Updated state for {service_id} to {state}\")\n\n    async def send_command_to_service(\n        self,\n        target_service_id: str | None,\n        command: CommandType,\n        data: Any | None = None,\n        target_service_type: ServiceType | None = None,\n    ) -&gt; None:\n        \"\"\"Send a command to a specific service.\n\n        Args:\n            target_service_id: ID of the target service, or None to send to all services\n            target_service_type: Type of the target service, or None to send to all services\n            command: The command to send (from CommandType enum).\n            data: Optional data to send with the command.\n\n        Raises:\n            CommunicationError: If the communication is not initialized\n                or the command was not sent successfully\n        \"\"\"\n        if not self._comms:\n            self.logger.error(\"Cannot send command: Communication is not initialized\")\n            raise CommunicationError(\n                CommunicationErrorReason.INITIALIZATION_ERROR,\n                \"Communication channels are not initialized\",\n            )\n\n        # Create command message using the helper method\n        command_message = self.create_command_message(\n            command=command,\n            target_service_id=target_service_id,\n            target_service_type=target_service_type,\n            data=data,\n        )\n\n        # Publish command message\n        try:\n            await self.comms.publish(\n                topic=Topic.COMMAND,\n                message=command_message,\n            )\n        except Exception as e:\n            self.logger.error(\"Exception publishing command: %s\", e)\n            raise CommunicationError(\n                CommunicationErrorReason.PUBLISH_ERROR,\n                f\"Failed to publish command: {e}\",\n            ) from e\n</code></pre>"},{"location":"api/#aiperf.services.system_controller.system_controller.SystemController.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.system_controller.system_controller.SystemController.send_command_to_service","title":"<code>send_command_to_service(target_service_id, command, data=None, target_service_type=None)</code>  <code>async</code>","text":"<p>Send a command to a specific service.</p> <p>Parameters:</p> Name Type Description Default <code>target_service_id</code> <code>str | None</code> <p>ID of the target service, or None to send to all services</p> required <code>target_service_type</code> <code>ServiceType | None</code> <p>Type of the target service, or None to send to all services</p> <code>None</code> <code>command</code> <code>CommandType</code> <p>The command to send (from CommandType enum).</p> required <code>data</code> <code>Any | None</code> <p>Optional data to send with the command.</p> <code>None</code> <p>Raises:</p> Type Description <code>CommunicationError</code> <p>If the communication is not initialized or the command was not sent successfully</p> Source code in <code>aiperf/services/system_controller/system_controller.py</code> <pre><code>async def send_command_to_service(\n    self,\n    target_service_id: str | None,\n    command: CommandType,\n    data: Any | None = None,\n    target_service_type: ServiceType | None = None,\n) -&gt; None:\n    \"\"\"Send a command to a specific service.\n\n    Args:\n        target_service_id: ID of the target service, or None to send to all services\n        target_service_type: Type of the target service, or None to send to all services\n        command: The command to send (from CommandType enum).\n        data: Optional data to send with the command.\n\n    Raises:\n        CommunicationError: If the communication is not initialized\n            or the command was not sent successfully\n    \"\"\"\n    if not self._comms:\n        self.logger.error(\"Cannot send command: Communication is not initialized\")\n        raise CommunicationError(\n            CommunicationErrorReason.INITIALIZATION_ERROR,\n            \"Communication channels are not initialized\",\n        )\n\n    # Create command message using the helper method\n    command_message = self.create_command_message(\n        command=command,\n        target_service_id=target_service_id,\n        target_service_type=target_service_type,\n        data=data,\n    )\n\n    # Publish command message\n    try:\n        await self.comms.publish(\n            topic=Topic.COMMAND,\n            message=command_message,\n        )\n    except Exception as e:\n        self.logger.error(\"Exception publishing command: %s\", e)\n        raise CommunicationError(\n            CommunicationErrorReason.PUBLISH_ERROR,\n            f\"Failed to publish command: {e}\",\n        ) from e\n</code></pre>"},{"location":"api/#aiperf.services.system_controller.system_controller.SystemController.start_profiling_all_services","title":"<code>start_profiling_all_services()</code>  <code>async</code>","text":"<p>Tell all services to start profiling.</p> Source code in <code>aiperf/services/system_controller/system_controller.py</code> <pre><code>async def start_profiling_all_services(self) -&gt; None:\n    \"\"\"Tell all services to start profiling.\"\"\"\n    self._system_state = SystemState.PROFILING\n\n    self.logger.debug(\"Starting services\")\n    for service_info in self.service_manager.service_id_map.values():\n        if service_info.state == ServiceState.READY:\n            try:\n                await self.send_command_to_service(\n                    target_service_id=service_info.service_id,\n                    command=CommandType.PROFILE_START,\n                )\n\n            except Exception as e:\n                self.logger.warning(\"Failed to start service: %s\", e)\n                # Continue to the next service\n                # TODO: should we have some sort of retries?\n                continue\n</code></pre>"},{"location":"api/#aiperf.services.system_controller.system_controller.main","title":"<code>main()</code>","text":"<p>Main entry point for the system controller.</p> Source code in <code>aiperf/services/system_controller/system_controller.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the system controller.\"\"\"\n\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(SystemController)\n</code></pre>"},{"location":"api/#aiperfservicessystem_controllersystem_mixins","title":"aiperf.services.system_controller.system_mixins","text":""},{"location":"api/#aiperf.services.system_controller.system_mixins.SignalHandlerMixin","title":"<code>SignalHandlerMixin</code>","text":"<p>Mixin for services that need to handle system signals.</p> Source code in <code>aiperf/services/system_controller/system_mixins.py</code> <pre><code>class SignalHandlerMixin:\n    \"\"\"Mixin for services that need to handle system signals.\"\"\"\n\n    def __init__(self, *args, **kwargs) -&gt; None:\n        # Set to store signal handler tasks to prevent them from being garbage collected\n        self._signal_tasks = set()\n        self.logger = logging.getLogger(__name__)\n        super().__init__(*args, **kwargs)\n\n    def setup_signal_handlers(\n        self, callback: Callable[[int], Coroutine[Any, Any, None]]\n    ) -&gt; None:\n        \"\"\"This method will set up signal handlers for the SIGTERM and SIGINT signals\n        in order to trigger a graceful shutdown of the service.\n\n        Args:\n            callback: The callback to call when a signal is received\n        \"\"\"\n        loop = asyncio.get_running_loop()\n\n        def signal_handler(sig: int) -&gt; None:\n            # Create a task and store it so it doesn't get garbage collected\n            task = asyncio.create_task(callback(sig))\n\n            # Store the task somewhere to prevent it from being garbage collected\n            # before it completes\n            self._signal_tasks.add(task)\n            task.add_done_callback(self._signal_tasks.discard)\n\n        for sig in (signal.SIGTERM, signal.SIGINT):\n            loop.add_signal_handler(sig, lambda s=sig: signal_handler(s))\n</code></pre>"},{"location":"api/#aiperf.services.system_controller.system_mixins.SignalHandlerMixin.setup_signal_handlers","title":"<code>setup_signal_handlers(callback)</code>","text":"<p>This method will set up signal handlers for the SIGTERM and SIGINT signals in order to trigger a graceful shutdown of the service.</p> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[[int], Coroutine[Any, Any, None]]</code> <p>The callback to call when a signal is received</p> required Source code in <code>aiperf/services/system_controller/system_mixins.py</code> <pre><code>def setup_signal_handlers(\n    self, callback: Callable[[int], Coroutine[Any, Any, None]]\n) -&gt; None:\n    \"\"\"This method will set up signal handlers for the SIGTERM and SIGINT signals\n    in order to trigger a graceful shutdown of the service.\n\n    Args:\n        callback: The callback to call when a signal is received\n    \"\"\"\n    loop = asyncio.get_running_loop()\n\n    def signal_handler(sig: int) -&gt; None:\n        # Create a task and store it so it doesn't get garbage collected\n        task = asyncio.create_task(callback(sig))\n\n        # Store the task somewhere to prevent it from being garbage collected\n        # before it completes\n        self._signal_tasks.add(task)\n        task.add_done_callback(self._signal_tasks.discard)\n\n    for sig in (signal.SIGTERM, signal.SIGINT):\n        loop.add_signal_handler(sig, lambda s=sig: signal_handler(s))\n</code></pre>"},{"location":"api/#aiperfservicestiming_managertiming_manager","title":"aiperf.services.timing_manager.timing_manager","text":""},{"location":"api/#aiperf.services.timing_manager.timing_manager.TimingManager","title":"<code>TimingManager</code>","text":"<p>               Bases: <code>BaseComponentService</code></p> <p>The TimingManager service is responsible to generate the schedule and issuing timing credits for requests.</p> Source code in <code>aiperf/services/timing_manager/timing_manager.py</code> <pre><code>@ServiceFactory.register(ServiceType.TIMING_MANAGER)\nclass TimingManager(BaseComponentService):\n    \"\"\"\n    The TimingManager service is responsible to generate the schedule and issuing\n    timing credits for requests.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self._credit_lock = asyncio.Lock()\n        self._credits_available = 100\n        self.logger.debug(\"Initializing timing manager\")\n        self._credit_drop_task: asyncio.Task | None = None\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.TIMING_MANAGER\n\n    @property\n    def required_clients(self) -&gt; list[ClientType]:\n        \"\"\"The communication clients required by the service.\"\"\"\n        return [\n            *(super().required_clients or []),\n            PullClientType.CREDIT_RETURN,\n            PushClientType.CREDIT_DROP,\n        ]\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize timing manager-specific components.\"\"\"\n        self.logger.debug(\"Initializing timing manager\")\n        # TODO: Implement timing manager initialization\n\n    @on_configure\n    async def _configure(self, message: Message) -&gt; None:\n        \"\"\"Configure the timing manager.\"\"\"\n        self.logger.debug(f\"Configuring timing manager with message: {message}\")\n        # TODO: Implement timing manager configuration\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the timing manager.\"\"\"\n        self.logger.debug(\"Starting timing manager\")\n        # TODO: Implement timing manager start\n        await self.comms.register_pull_callback(\n            message_type=MessageType.CREDIT_RETURN,\n            callback=self._on_credit_return,\n        )\n        await self.set_state(ServiceState.RUNNING)\n        await asyncio.sleep(3)\n\n        self._credit_drop_task = asyncio.create_task(self._issue_credit_drops())\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the timing manager.\"\"\"\n        self.logger.debug(\"Stopping timing manager\")\n        # TODO: Implement timing manager stop\n        if self._credit_drop_task and not self._credit_drop_task.done():\n            self._credit_drop_task.cancel()\n            with contextlib.suppress(asyncio.CancelledError):\n                await self._credit_drop_task\n            self._credit_drop_task = None\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up timing manager-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up timing manager\")\n        # TODO: Implement timing manager cleanup\n\n    async def _issue_credit_drops(self) -&gt; None:\n        \"\"\"Issue credit drops to workers.\"\"\"\n        self.logger.debug(\"Issuing credit drops to workers\")\n        # TODO: Actually implement real credit drop logic\n        while not self.stop_event.is_set():\n            try:\n                await asyncio.sleep(0.1)\n\n                async with self._credit_lock:\n                    if self._credits_available &lt;= 0:\n                        self.logger.warning(\n                            \"No credits available, skipping credit drop\"\n                        )\n                        continue\n                    self.logger.debug(\"Issuing credit drop\")\n                    self._credits_available -= 1\n\n                await self.comms.push(\n                    topic=Topic.CREDIT_DROP,\n                    message=CreditDropMessage(\n                        service_id=self.service_id,\n                        amount=1,\n                        credit_drop_ns=time.time_ns(),\n                    ),\n                )\n            except asyncio.CancelledError:\n                self.logger.debug(\"Credit drop task cancelled\")\n                break\n            except Exception as e:\n                self.logger.error(f\"Exception issuing credit drop: {e}\")\n                await asyncio.sleep(0.1)\n\n    async def _on_credit_return(self, message: CreditReturnMessage) -&gt; None:\n        \"\"\"Process a credit return message.\n\n        Args:\n            message: The credit return message received from the pull request\n        \"\"\"\n        self.logger.debug(f\"Processing credit return: {message}\")\n        async with self._credit_lock:\n            self._credits_available += message.amount\n</code></pre>"},{"location":"api/#aiperf.services.timing_manager.timing_manager.TimingManager.required_clients","title":"<code>required_clients</code>  <code>property</code>","text":"<p>The communication clients required by the service.</p>"},{"location":"api/#aiperf.services.timing_manager.timing_manager.TimingManager.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.timing_manager.timing_manager.main","title":"<code>main()</code>","text":"<p>Main entry point for the timing manager.</p> Source code in <code>aiperf/services/timing_manager/timing_manager.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the timing manager.\"\"\"\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(TimingManager)\n</code></pre>"},{"location":"api/#aiperfservicesworkerworker","title":"aiperf.services.worker.worker","text":""},{"location":"api/#aiperf.services.worker.worker.Worker","title":"<code>Worker</code>","text":"<p>               Bases: <code>BaseService</code></p> <p>Worker is primarily responsible for converting the data into the appropriate format for the interface being used by the server. Also responsible for managing the conversation between turns.</p> Source code in <code>aiperf/services/worker/worker.py</code> <pre><code>class Worker(BaseService):\n    \"\"\"Worker is primarily responsible for converting the data into the appropriate\n    format for the interface being used by the server. Also responsible for managing\n    the conversation between turns.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Initializing worker\")\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.WORKER\n\n    @property\n    def required_clients(self) -&gt; list[ClientType]:\n        \"\"\"The communication clients required by the service.\"\"\"\n        return [\n            *(super().required_clients or []),\n            PullClientType.CREDIT_DROP,\n            PushClientType.CREDIT_RETURN,\n        ]\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize worker-specific components.\"\"\"\n        self.logger.debug(\"Initializing worker\")\n\n    @on_run\n    async def _run(self) -&gt; None:\n        \"\"\"Automatically start the worker in the run method.\"\"\"\n        await self.start()\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the worker.\"\"\"\n        self.logger.debug(\"Starting worker\")\n        # Subscribe to the credit drop topic\n        await self.comms.register_pull_callback(\n            message_type=Topic.CREDIT_DROP,\n            callback=self._process_credit_drop,\n        )\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the worker.\"\"\"\n        self.logger.debug(\"Stopping worker\")\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up worker-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up worker\")\n\n    async def _process_credit_drop(self, message: CreditDropMessage) -&gt; None:\n        \"\"\"Process a credit drop response.\n\n        Args:\n            message: The message received from the credit drop\n        \"\"\"\n        self.logger.debug(f\"Processing credit drop: {message}\")\n        # TODO: Implement actual worker logic\n        await asyncio.sleep(1)  # Simulate some processing time\n\n        self.logger.debug(\"Returning credits\")\n        await self.comms.push(\n            topic=Topic.CREDIT_RETURN,\n            message=CreditReturnMessage(\n                service_id=self.service_id,\n                amount=1,\n            ),\n        )\n</code></pre>"},{"location":"api/#aiperf.services.worker.worker.Worker.required_clients","title":"<code>required_clients</code>  <code>property</code>","text":"<p>The communication clients required by the service.</p>"},{"location":"api/#aiperf.services.worker.worker.Worker.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.worker.worker.main","title":"<code>main()</code>","text":"<p>Main entry point for the worker.</p> Source code in <code>aiperf/services/worker/worker.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the worker.\"\"\"\n\n    import uvloop\n\n    from aiperf.common.config import load_service_config\n\n    # Load the service configuration\n    cfg = load_service_config()\n\n    # Create and run the worker\n    worker = Worker(cfg)\n    uvloop.run(worker.run_forever())\n</code></pre>"},{"location":"api/#aiperfservicesworker_managerworker_manager","title":"aiperf.services.worker_manager.worker_manager","text":""},{"location":"api/#aiperf.services.worker_manager.worker_manager.WorkerManager","title":"<code>WorkerManager</code>","text":"<p>               Bases: <code>BaseComponentService</code></p> <p>The WorkerManager service is primary responsibility is to pull data from the dataset manager after receiving the timing credit from the timing manager. It will then push the request data to the worker to issue to the request.</p> Source code in <code>aiperf/services/worker_manager/worker_manager.py</code> <pre><code>@ServiceFactory.register(ServiceType.WORKER_MANAGER)\nclass WorkerManager(BaseComponentService):\n    \"\"\"\n    The WorkerManager service is primary responsibility is to pull data from the dataset manager\n    after receiving the timing credit from the timing manager. It will then push the request data\n    to the worker to issue to the request.\n    \"\"\"\n\n    def __init__(\n        self, service_config: ServiceConfig, service_id: str | None = None\n    ) -&gt; None:\n        super().__init__(service_config=service_config, service_id=service_id)\n        self.logger.debug(\"Initializing worker manager\")\n        self.workers: dict[str, WorkerProcess] = {}\n        # TODO: Need to implement some sort of max workers\n        self.cpu_count = multiprocessing.cpu_count()\n        self.worker_count = self.cpu_count\n        self.logger.debug(\n            f\"Detected {self.cpu_count} CPU threads. Spawning {self.worker_count} workers\"\n        )\n\n    @property\n    def service_type(self) -&gt; ServiceType:\n        \"\"\"The type of service.\"\"\"\n        return ServiceType.WORKER_MANAGER\n\n    @on_init\n    async def _initialize(self) -&gt; None:\n        \"\"\"Initialize worker manager-specific components.\"\"\"\n        self.logger.debug(\"Initializing worker manager\")\n\n    @on_start\n    async def _start(self) -&gt; None:\n        \"\"\"Start the worker manager.\"\"\"\n        self.logger.debug(\"Starting worker manager\")\n\n        # Spawn workers based on CPU count\n        if self.service_config.service_run_type == ServiceRunType.MULTIPROCESSING:\n            await self._spawn_multiprocessing_workers()\n\n        elif self.service_config.service_run_type == ServiceRunType.KUBERNETES:\n            await self._spawn_kubernetes_workers()\n\n        else:\n            self.logger.warning(\n                f\"Unsupported run type: {self.service_config.service_run_type}\"\n            )\n            raise ConfigError(\n                f\"Unsupported run type: {self.service_config.service_run_type}\"\n            )\n\n    @on_stop\n    async def _stop(self) -&gt; None:\n        \"\"\"Stop the worker manager.\"\"\"\n        self.logger.debug(\"Stopping worker manager\")\n        # TODO: This needs to be investigated, as currently we handle the exit signal\n        #       by all workers already, so need to understand best way to handle this\n        # # Stop all workers\n        # if self.service_config.service_run_type == ServiceRunType.MULTIPROCESSING:\n        #     await self._stop_multiprocessing_workers()\n        # elif self.service_config.service_run_type == ServiceRunType.KUBERNETES:\n        #     await self._stop_kubernetes_workers()\n        # else:\n        #     self.logger.warning(\n        #         f\"Unsupported run type: {self.service_config.service_run_type}\"\n        #     )\n\n    @on_cleanup\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up worker manager-specific components.\"\"\"\n        self.logger.debug(\"Cleaning up worker manager\")\n        self.workers.clear()\n\n    async def _spawn_kubernetes_workers(self) -&gt; None:\n        \"\"\"Spawn worker processes using Kubernetes.\"\"\"\n        self.logger.debug(f\"Spawning {self.worker_count} worker processes\")\n\n        # TODO: Implement Kubernetes start\n        raise NotImplementedError(\"Kubernetes start not implemented\")\n\n    async def _stop_kubernetes_workers(self) -&gt; None:\n        \"\"\"Stop worker processes using Kubernetes.\"\"\"\n        self.logger.debug(\"Stopping all worker processes\")\n\n        # TODO: Implement Kubernetes stop\n        raise NotImplementedError(\"Kubernetes stop not implemented\")\n\n    async def _spawn_multiprocessing_workers(self) -&gt; None:\n        \"\"\"Spawn worker processes using multiprocessing.\"\"\"\n        self.logger.debug(f\"Spawning {self.worker_count} worker processes\")\n\n        for i in range(self.worker_count):\n            worker_id = f\"worker_{i}\"\n            process = multiprocessing.Process(\n                target=bootstrap_and_run_service,\n                name=f\"worker_{i}_process\",\n                args=(Worker, self.service_config),\n                daemon=True,\n            )\n            process.start()\n            self.workers[worker_id] = WorkerProcess(\n                worker_id=worker_id, process=process\n            )\n            self.logger.debug(\n                f\"Started worker process {worker_id} (pid: {process.pid})\"\n            )\n\n    async def _stop_multiprocessing_workers(self) -&gt; None:\n        \"\"\"Stop all multiprocessing worker processes.\"\"\"\n        self.logger.debug(\"Stopping all worker processes\")\n\n        # First terminate all processes\n        for worker_id, worker_info in self.workers.items():\n            self.logger.debug(f\"Stopping worker process {worker_id} {worker_info}\")\n            process = worker_info.process\n            if process and process.is_alive():\n                self.logger.debug(\n                    f\"Terminating worker process {worker_id} (pid: {process.pid})\"\n                )\n                process.terminate()\n\n        # Then wait for all to finish\n        await asyncio.gather(\n            *[\n                self._wait_for_process(worker_id, worker_info.process)\n                for worker_id, worker_info in self.workers.items()\n                if worker_info.process\n            ]\n        )\n\n        self.logger.debug(\"All worker processes stopped\")\n\n    async def _wait_for_process(\n        self, worker_id: str, process: multiprocessing.Process\n    ) -&gt; None:\n        \"\"\"Wait for a process to terminate with timeout handling.\"\"\"\n        try:\n            await asyncio.wait_for(\n                asyncio.to_thread(process.join, timeout=1.0),  # Add timeout to join\n                timeout=5.0,  # Overall timeout\n            )\n            self.logger.debug(\n                f\"Worker process {worker_id} (pid: {process.pid}) stopped\"\n            )\n        except asyncio.TimeoutError:\n            self.logger.warning(\n                f\"Worker process {worker_id} (pid: {process.pid}) did not \"\n                f\"terminate gracefully, killing\"\n            )\n            process.kill()\n\n    @on_configure\n    async def _configure(self, message: Message) -&gt; None:\n        \"\"\"Configure the worker manager.\"\"\"\n        self.logger.debug(f\"Configuring worker manager with message: {message}\")\n</code></pre>"},{"location":"api/#aiperf.services.worker_manager.worker_manager.WorkerManager.service_type","title":"<code>service_type</code>  <code>property</code>","text":"<p>The type of service.</p>"},{"location":"api/#aiperf.services.worker_manager.worker_manager.WorkerProcess","title":"<code>WorkerProcess</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about a worker process.</p> Source code in <code>aiperf/services/worker_manager/worker_manager.py</code> <pre><code>class WorkerProcess(BaseModel):\n    \"\"\"Information about a worker process.\"\"\"\n\n    worker_id: str = Field(..., description=\"ID of the worker process\")\n    process: Any = Field(None, description=\"Process object or task\")\n</code></pre>"},{"location":"api/#aiperf.services.worker_manager.worker_manager.main","title":"<code>main()</code>","text":"<p>Main entry point for the worker manager.</p> Source code in <code>aiperf/services/worker_manager/worker_manager.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the worker manager.\"\"\"\n\n    from aiperf.common.bootstrap import bootstrap_and_run_service\n\n    bootstrap_and_run_service(WorkerManager)\n</code></pre>"},{"location":"api/#aiperftestsbase_test_component_service","title":"aiperf.tests.base_test_component_service","text":"<p>Base test class for component services.</p>"},{"location":"api/#aiperf.tests.base_test_component_service.BaseTestComponentService","title":"<code>BaseTestComponentService</code>","text":"<p>               Bases: <code>BaseTestService</code></p> <p>Base class for testing component services.</p> <p>This extends BaseTestService with specific tests for the component service functionality such as heartbeat, registration, and status updates.</p> Source code in <code>aiperf/tests/base_test_component_service.py</code> <pre><code>class BaseTestComponentService(BaseTestService):\n    \"\"\"\n    Base class for testing component services.\n\n    This extends BaseTestService with specific tests for the component service\n    functionality such as heartbeat, registration, and status updates.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"\n        Return the service class to test.\n\n        Returns:\n            The BaseComponentService class for testing\n        \"\"\"\n        return BaseComponentService\n\n    async def test_service_heartbeat(\n        self, initialized_service: BaseComponentService, mock_communication: MagicMock\n    ) -&gt; None:\n        \"\"\"\n        Test that the service sends heartbeat messages correctly.\n\n        Verifies:\n        1. The service generates and sends a valid heartbeat message\n        2. The message contains the correct service information\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        # Directly send a heartbeat instead of waiting for the task\n        await service.send_heartbeat()\n\n        # Check that a heartbeat message was published\n        assert Topic.HEARTBEAT in mock_communication.mock_data.published_messages\n        assert len(mock_communication.mock_data.published_messages[Topic.HEARTBEAT]) &gt; 0\n\n        # Verify heartbeat message contents\n        heartbeat_msg = mock_communication.mock_data.published_messages[\n            Topic.HEARTBEAT\n        ][0]\n        assert heartbeat_msg.service_id == service.service_id\n        assert heartbeat_msg.service_type == service.service_type\n\n    async def test_service_registration(\n        self, initialized_service: BaseComponentService, mock_communication: MagicMock\n    ) -&gt; None:\n        \"\"\"\n        Test that the service registers with the system controller.\n\n        Verifies:\n        1. The service sends a registration message to the controller\n        2. The registration message contains the correct service information\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        # Register the service\n        await service.register()\n\n        # Check that a registration message was published\n        assert Topic.REGISTRATION in mock_communication.mock_data.published_messages\n\n        # Verify registration message contents\n        registration_msg = mock_communication.mock_data.published_messages[\n            Topic.REGISTRATION\n        ][0]\n        assert registration_msg.service_id == service.service_id\n        assert registration_msg.service_type == service.service_type\n\n    async def test_service_status_update(\n        self, initialized_service: BaseComponentService, mock_communication: MagicMock\n    ) -&gt; None:\n        \"\"\"\n        Test that the service updates its status correctly.\n\n        Verifies:\n        1. The service publishes status messages when state changes\n        2. The status message contains the correct state and service information\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        # Update the service status\n        await service.set_state(ServiceState.READY)\n\n        # Check that a status message was published\n        assert Topic.STATUS in mock_communication.mock_data.published_messages\n\n        # Verify status message contents\n        status_msg = mock_communication.mock_data.published_messages[Topic.STATUS][0]\n        assert status_msg.service_id == service.service_id\n        assert status_msg.service_type == service.service_type\n        assert status_msg.state == ServiceState.READY\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_component_service.BaseTestComponentService.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to test.</p> <p>Returns:</p> Type Description <code>type[BaseService]</code> <p>The BaseComponentService class for testing</p> Source code in <code>aiperf/tests/base_test_component_service.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"\n    Return the service class to test.\n\n    Returns:\n        The BaseComponentService class for testing\n    \"\"\"\n    return BaseComponentService\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_component_service.BaseTestComponentService.test_service_heartbeat","title":"<code>test_service_heartbeat(initialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Test that the service sends heartbeat messages correctly.</p> <p>Verifies: 1. The service generates and sends a valid heartbeat message 2. The message contains the correct service information</p> Source code in <code>aiperf/tests/base_test_component_service.py</code> <pre><code>async def test_service_heartbeat(\n    self, initialized_service: BaseComponentService, mock_communication: MagicMock\n) -&gt; None:\n    \"\"\"\n    Test that the service sends heartbeat messages correctly.\n\n    Verifies:\n    1. The service generates and sends a valid heartbeat message\n    2. The message contains the correct service information\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    # Directly send a heartbeat instead of waiting for the task\n    await service.send_heartbeat()\n\n    # Check that a heartbeat message was published\n    assert Topic.HEARTBEAT in mock_communication.mock_data.published_messages\n    assert len(mock_communication.mock_data.published_messages[Topic.HEARTBEAT]) &gt; 0\n\n    # Verify heartbeat message contents\n    heartbeat_msg = mock_communication.mock_data.published_messages[\n        Topic.HEARTBEAT\n    ][0]\n    assert heartbeat_msg.service_id == service.service_id\n    assert heartbeat_msg.service_type == service.service_type\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_component_service.BaseTestComponentService.test_service_registration","title":"<code>test_service_registration(initialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Test that the service registers with the system controller.</p> <p>Verifies: 1. The service sends a registration message to the controller 2. The registration message contains the correct service information</p> Source code in <code>aiperf/tests/base_test_component_service.py</code> <pre><code>async def test_service_registration(\n    self, initialized_service: BaseComponentService, mock_communication: MagicMock\n) -&gt; None:\n    \"\"\"\n    Test that the service registers with the system controller.\n\n    Verifies:\n    1. The service sends a registration message to the controller\n    2. The registration message contains the correct service information\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    # Register the service\n    await service.register()\n\n    # Check that a registration message was published\n    assert Topic.REGISTRATION in mock_communication.mock_data.published_messages\n\n    # Verify registration message contents\n    registration_msg = mock_communication.mock_data.published_messages[\n        Topic.REGISTRATION\n    ][0]\n    assert registration_msg.service_id == service.service_id\n    assert registration_msg.service_type == service.service_type\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_component_service.BaseTestComponentService.test_service_status_update","title":"<code>test_service_status_update(initialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Test that the service updates its status correctly.</p> <p>Verifies: 1. The service publishes status messages when state changes 2. The status message contains the correct state and service information</p> Source code in <code>aiperf/tests/base_test_component_service.py</code> <pre><code>async def test_service_status_update(\n    self, initialized_service: BaseComponentService, mock_communication: MagicMock\n) -&gt; None:\n    \"\"\"\n    Test that the service updates its status correctly.\n\n    Verifies:\n    1. The service publishes status messages when state changes\n    2. The status message contains the correct state and service information\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    # Update the service status\n    await service.set_state(ServiceState.READY)\n\n    # Check that a status message was published\n    assert Topic.STATUS in mock_communication.mock_data.published_messages\n\n    # Verify status message contents\n    status_msg = mock_communication.mock_data.published_messages[Topic.STATUS][0]\n    assert status_msg.service_id == service.service_id\n    assert status_msg.service_type == service.service_type\n    assert status_msg.state == ServiceState.READY\n</code></pre>"},{"location":"api/#aiperftestsbase_test_controller_service","title":"aiperf.tests.base_test_controller_service","text":"<p>Base test class for controller services.</p>"},{"location":"api/#aiperf.tests.base_test_controller_service.BaseTestControllerService","title":"<code>BaseTestControllerService</code>","text":"<p>               Bases: <code>BaseTestService</code></p> <p>Base class for testing controller services.</p> <p>This extends BaseTestService with specific tests for controller service functionality such as command sending, service registration handling, and monitoring of component services.</p> Source code in <code>aiperf/tests/base_test_controller_service.py</code> <pre><code>class BaseTestControllerService(BaseTestService):\n    \"\"\"\n    Base class for testing controller services.\n\n    This extends BaseTestService with specific tests for controller service\n    functionality such as command sending, service registration handling,\n    and monitoring of component services.\n    \"\"\"\n\n    async def test_controller_command_publishing(\n        self, initialized_service: BaseControllerService, mock_communication: MagicMock\n    ) -&gt; None:\n        \"\"\"\n        Test that the controller can publish command messages.\n\n        Verifies the controller can send properly formatted commands to components.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        # Create a test command message\n        test_service_id = \"test_service_123\"\n        command = CommandType.PROFILE_START\n\n        # Create a command message\n        command_message = service.create_command_message(\n            command=command,\n            target_service_id=test_service_id,\n        )\n\n        # Publish the command\n        await service.comms.publish(Topic.COMMAND, command_message)\n\n        # Check that the command was published\n        assert Topic.COMMAND in mock_communication.mock_data.published_messages\n        assert len(mock_communication.mock_data.published_messages[Topic.COMMAND]) == 1\n\n        # Verify command message\n        published_cmd = mock_communication.mock_data.published_messages[Topic.COMMAND][\n            0\n        ]\n        assert published_cmd.service_id == service.service_id\n        assert published_cmd.command == command\n        assert published_cmd.target_service_id == test_service_id\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_controller_service.BaseTestControllerService.test_controller_command_publishing","title":"<code>test_controller_command_publishing(initialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Test that the controller can publish command messages.</p> <p>Verifies the controller can send properly formatted commands to components.</p> Source code in <code>aiperf/tests/base_test_controller_service.py</code> <pre><code>async def test_controller_command_publishing(\n    self, initialized_service: BaseControllerService, mock_communication: MagicMock\n) -&gt; None:\n    \"\"\"\n    Test that the controller can publish command messages.\n\n    Verifies the controller can send properly formatted commands to components.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    # Create a test command message\n    test_service_id = \"test_service_123\"\n    command = CommandType.PROFILE_START\n\n    # Create a command message\n    command_message = service.create_command_message(\n        command=command,\n        target_service_id=test_service_id,\n    )\n\n    # Publish the command\n    await service.comms.publish(Topic.COMMAND, command_message)\n\n    # Check that the command was published\n    assert Topic.COMMAND in mock_communication.mock_data.published_messages\n    assert len(mock_communication.mock_data.published_messages[Topic.COMMAND]) == 1\n\n    # Verify command message\n    published_cmd = mock_communication.mock_data.published_messages[Topic.COMMAND][\n        0\n    ]\n    assert published_cmd.service_id == service.service_id\n    assert published_cmd.command == command\n    assert published_cmd.target_service_id == test_service_id\n</code></pre>"},{"location":"api/#aiperftestsbase_test_service","title":"aiperf.tests.base_test_service","text":"<p>Base test class for testing AIPerf services.</p>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService","title":"<code>BaseTestService</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base test class for all service tests.</p> <p>This class provides common test methods and fixtures for testing AIPerf services. Specific service test classes should inherit from this class and implement service-specific fixtures and tests.</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>class BaseTestService(ABC):\n    \"\"\"\n    Base test class for all service tests.\n\n    This class provides common test methods and fixtures for testing\n    AIPerf services. Specific service test classes should inherit from\n    this class and implement service-specific fixtures and tests.\n    \"\"\"\n\n    @pytest.fixture(autouse=True)\n    def no_sleep(self, monkeypatch) -&gt; None:\n        \"\"\"\n        Patch asyncio.sleep with a no-op to prevent test delays.\n\n        This ensures tests don't need to wait for real sleep calls.\n        \"\"\"\n        monkeypatch.setattr(asyncio, \"sleep\", async_noop)\n\n    @pytest.fixture(autouse=True)\n    def patch_communication_factory(\n        self, mock_communication: MagicMock\n    ) -&gt; Generator[None, None, None]:\n        \"\"\"\n        Patch the communication factory to always return our mock communication.\n\n        This ensures no real communication is attempted during tests.\n        \"\"\"\n        with patch(\n            \"aiperf.common.factories.CommunicationFactory.create_instance\",\n            return_value=mock_communication,\n        ):\n            yield\n\n    @abstractmethod\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"\n        Return the service class to test.\n\n        Must be implemented by subclasses to specify which service is being tested.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method\")\n\n    @pytest.fixture\n    def service_config(self) -&gt; ServiceConfig:\n        \"\"\"\n        Create a service configuration for testing.\n\n        Returns:\n            A ServiceConfig instance with test settings\n        \"\"\"\n        return ServiceConfig(\n            service_run_type=ServiceRunType.MULTIPROCESSING,\n            comm_backend=CommunicationBackend.ZMQ_TCP,\n        )\n\n    @pytest.fixture\n    async def uninitialized_service(\n        self,\n        service_class: type[BaseService],\n        service_config: ServiceConfig,\n    ) -&gt; AsyncGenerator[BaseService, None]:\n        \"\"\"\n        Create an uninitialized instance of the service under test.\n\n        This provides a service instance before initialize() has been called,\n        allowing tests to verify initialization behavior.\n\n        Returns:\n            An uninitialized instance of the service\n\n        Example usage:\n        ```python\n        async def test_service_initialization(uninitialized_service: BaseService):\n            service = await async_fixture(uninitialized_service)\n            await service.initialize()\n        ```\n        \"\"\"\n        # Patch the heartbeat task otherwise it will run forever\n        with patch(\n            \"aiperf.common.service.base_component_service.BaseComponentService._heartbeat_task\",\n            lambda: None,\n        ):\n            service = service_class(service_config=service_config)\n            yield service\n\n    @pytest.fixture\n    async def initialized_service(\n        self,\n        uninitialized_service: BaseService,\n        mock_communication: MagicMock,\n    ) -&gt; AsyncGenerator[BaseService, None]:\n        \"\"\"\n        Create and initialize the service under test.\n\n        This fixture sets up a complete service instance ready for testing,\n        with the communication layer mocked.\n\n        Returns:\n            An initialized instance of the service\n\n        Example usage:\n        ```python\n        async def test_service_foo(initialized_service: BaseService):\n            service = await async_fixture(initialized_service)\n            await service.foo()\n        ```\n        \"\"\"\n        service = await async_fixture(uninitialized_service)\n\n        await service.initialize()\n\n        yield service\n\n    @pytest.mark.asyncio\n    async def test_service_initialization(\n        self, uninitialized_service: BaseService, mock_communication: MagicMock\n    ) -&gt; None:\n        \"\"\"\n        Test that the service initializes correctly. This will be executed\n        for every service that inherits from BaseTestService.\n\n        This verifies:\n        1. The service has a valid ID and type\n        2. The service transitions to the correct state during initialization\n        3. The service's internal initialization method is called\n        \"\"\"\n        service = await async_fixture(uninitialized_service)\n\n        # Check that the service has an ID and type\n        assert service.service_id is not None\n        assert service.service_type is not None\n\n        # Check that the service is not initialized\n        assert service.state == ServiceState.UNKNOWN\n\n        # Initialize the service\n        await service.initialize()\n\n        # Check that the service is initialized and in the READY state\n        assert service.is_initialized\n        assert service.state == ServiceState.READY\n\n        await service.stop()\n\n    @pytest.mark.asyncio\n    async def test_service_start_stop(self, initialized_service: BaseService) -&gt; None:\n        \"\"\"\n        Test that the service can start and stop correctly. This will be executed\n        for every service that inherits from BaseTestService.\n\n        This verifies:\n        1. The service transitions to the `ServiceState.RUNNING` state when started\n        2. The service transitions to the `ServiceState.STOPPED` state when stopped\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        # Start the service\n        await service.start()\n        assert service.state == ServiceState.RUNNING\n\n        # Stop the service\n        await service.stop()\n        assert service.state == ServiceState.STOPPED\n\n    @pytest.mark.parametrize(\n        \"state\",\n        [state for state in ServiceState if state != ServiceState.UNKNOWN],\n    )\n    @pytest.mark.asyncio\n    async def test_service_state_transitions(\n        self, initialized_service: BaseService, state: ServiceState\n    ) -&gt; None:\n        \"\"\"\n        Test that the service can transition to all possible states. This will be executed\n        for every service that inherits from BaseTestService.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        # Update the service state\n        await service.set_state(state)\n\n        # Check that the service state was updated\n        assert service.state == state\n\n    @pytest.mark.asyncio\n    async def test_service_run_does_not_start(\n        self, initialized_service: BaseService\n    ) -&gt; None:\n        \"\"\"\n        Test that the service does not start when the run method is called (default behavior). This will be executed\n        for every service that inherits from BaseTestService.\n        \"\"\"\n        service = await async_fixture(MagicMock(wraps=initialized_service))\n\n        service._forever_loop.return_value = None\n        await service.run_forever()\n        assert not service.start.called\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.initialized_service","title":"<code>initialized_service(uninitialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Create and initialize the service under test.</p> <p>This fixture sets up a complete service instance ready for testing, with the communication layer mocked.</p> <p>Returns:</p> Type Description <code>AsyncGenerator[BaseService, None]</code> <p>An initialized instance of the service</p> <p>Example usage:</p> <pre><code>async def test_service_foo(initialized_service: BaseService):\n    service = await async_fixture(initialized_service)\n    await service.foo()\n</code></pre> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.fixture\nasync def initialized_service(\n    self,\n    uninitialized_service: BaseService,\n    mock_communication: MagicMock,\n) -&gt; AsyncGenerator[BaseService, None]:\n    \"\"\"\n    Create and initialize the service under test.\n\n    This fixture sets up a complete service instance ready for testing,\n    with the communication layer mocked.\n\n    Returns:\n        An initialized instance of the service\n\n    Example usage:\n    ```python\n    async def test_service_foo(initialized_service: BaseService):\n        service = await async_fixture(initialized_service)\n        await service.foo()\n    ```\n    \"\"\"\n    service = await async_fixture(uninitialized_service)\n\n    await service.initialize()\n\n    yield service\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.no_sleep","title":"<code>no_sleep(monkeypatch)</code>","text":"<p>Patch asyncio.sleep with a no-op to prevent test delays.</p> <p>This ensures tests don't need to wait for real sleep calls.</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.fixture(autouse=True)\ndef no_sleep(self, monkeypatch) -&gt; None:\n    \"\"\"\n    Patch asyncio.sleep with a no-op to prevent test delays.\n\n    This ensures tests don't need to wait for real sleep calls.\n    \"\"\"\n    monkeypatch.setattr(asyncio, \"sleep\", async_noop)\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.patch_communication_factory","title":"<code>patch_communication_factory(mock_communication)</code>","text":"<p>Patch the communication factory to always return our mock communication.</p> <p>This ensures no real communication is attempted during tests.</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.fixture(autouse=True)\ndef patch_communication_factory(\n    self, mock_communication: MagicMock\n) -&gt; Generator[None, None, None]:\n    \"\"\"\n    Patch the communication factory to always return our mock communication.\n\n    This ensures no real communication is attempted during tests.\n    \"\"\"\n    with patch(\n        \"aiperf.common.factories.CommunicationFactory.create_instance\",\n        return_value=mock_communication,\n    ):\n        yield\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.service_class","title":"<code>service_class()</code>  <code>abstractmethod</code>","text":"<p>Return the service class to test.</p> <p>Must be implemented by subclasses to specify which service is being tested.</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@abstractmethod\n@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"\n    Return the service class to test.\n\n    Must be implemented by subclasses to specify which service is being tested.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement this method\")\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.service_config","title":"<code>service_config()</code>","text":"<p>Create a service configuration for testing.</p> <p>Returns:</p> Type Description <code>ServiceConfig</code> <p>A ServiceConfig instance with test settings</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.fixture\ndef service_config(self) -&gt; ServiceConfig:\n    \"\"\"\n    Create a service configuration for testing.\n\n    Returns:\n        A ServiceConfig instance with test settings\n    \"\"\"\n    return ServiceConfig(\n        service_run_type=ServiceRunType.MULTIPROCESSING,\n        comm_backend=CommunicationBackend.ZMQ_TCP,\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.test_service_initialization","title":"<code>test_service_initialization(uninitialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Test that the service initializes correctly. This will be executed for every service that inherits from BaseTestService.</p> <p>This verifies: 1. The service has a valid ID and type 2. The service transitions to the correct state during initialization 3. The service's internal initialization method is called</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_service_initialization(\n    self, uninitialized_service: BaseService, mock_communication: MagicMock\n) -&gt; None:\n    \"\"\"\n    Test that the service initializes correctly. This will be executed\n    for every service that inherits from BaseTestService.\n\n    This verifies:\n    1. The service has a valid ID and type\n    2. The service transitions to the correct state during initialization\n    3. The service's internal initialization method is called\n    \"\"\"\n    service = await async_fixture(uninitialized_service)\n\n    # Check that the service has an ID and type\n    assert service.service_id is not None\n    assert service.service_type is not None\n\n    # Check that the service is not initialized\n    assert service.state == ServiceState.UNKNOWN\n\n    # Initialize the service\n    await service.initialize()\n\n    # Check that the service is initialized and in the READY state\n    assert service.is_initialized\n    assert service.state == ServiceState.READY\n\n    await service.stop()\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.test_service_run_does_not_start","title":"<code>test_service_run_does_not_start(initialized_service)</code>  <code>async</code>","text":"<p>Test that the service does not start when the run method is called (default behavior). This will be executed for every service that inherits from BaseTestService.</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_service_run_does_not_start(\n    self, initialized_service: BaseService\n) -&gt; None:\n    \"\"\"\n    Test that the service does not start when the run method is called (default behavior). This will be executed\n    for every service that inherits from BaseTestService.\n    \"\"\"\n    service = await async_fixture(MagicMock(wraps=initialized_service))\n\n    service._forever_loop.return_value = None\n    await service.run_forever()\n    assert not service.start.called\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.test_service_start_stop","title":"<code>test_service_start_stop(initialized_service)</code>  <code>async</code>","text":"<p>Test that the service can start and stop correctly. This will be executed for every service that inherits from BaseTestService.</p> <p>This verifies: 1. The service transitions to the <code>ServiceState.RUNNING</code> state when started 2. The service transitions to the <code>ServiceState.STOPPED</code> state when stopped</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_service_start_stop(self, initialized_service: BaseService) -&gt; None:\n    \"\"\"\n    Test that the service can start and stop correctly. This will be executed\n    for every service that inherits from BaseTestService.\n\n    This verifies:\n    1. The service transitions to the `ServiceState.RUNNING` state when started\n    2. The service transitions to the `ServiceState.STOPPED` state when stopped\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    # Start the service\n    await service.start()\n    assert service.state == ServiceState.RUNNING\n\n    # Stop the service\n    await service.stop()\n    assert service.state == ServiceState.STOPPED\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.test_service_state_transitions","title":"<code>test_service_state_transitions(initialized_service, state)</code>  <code>async</code>","text":"<p>Test that the service can transition to all possible states. This will be executed for every service that inherits from BaseTestService.</p> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.mark.parametrize(\n    \"state\",\n    [state for state in ServiceState if state != ServiceState.UNKNOWN],\n)\n@pytest.mark.asyncio\nasync def test_service_state_transitions(\n    self, initialized_service: BaseService, state: ServiceState\n) -&gt; None:\n    \"\"\"\n    Test that the service can transition to all possible states. This will be executed\n    for every service that inherits from BaseTestService.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    # Update the service state\n    await service.set_state(state)\n\n    # Check that the service state was updated\n    assert service.state == state\n</code></pre>"},{"location":"api/#aiperf.tests.base_test_service.BaseTestService.uninitialized_service","title":"<code>uninitialized_service(service_class, service_config)</code>  <code>async</code>","text":"<p>Create an uninitialized instance of the service under test.</p> <p>This provides a service instance before initialize() has been called, allowing tests to verify initialization behavior.</p> <p>Returns:</p> Type Description <code>AsyncGenerator[BaseService, None]</code> <p>An uninitialized instance of the service</p> <p>Example usage:</p> <pre><code>async def test_service_initialization(uninitialized_service: BaseService):\n    service = await async_fixture(uninitialized_service)\n    await service.initialize()\n</code></pre> Source code in <code>aiperf/tests/base_test_service.py</code> <pre><code>@pytest.fixture\nasync def uninitialized_service(\n    self,\n    service_class: type[BaseService],\n    service_config: ServiceConfig,\n) -&gt; AsyncGenerator[BaseService, None]:\n    \"\"\"\n    Create an uninitialized instance of the service under test.\n\n    This provides a service instance before initialize() has been called,\n    allowing tests to verify initialization behavior.\n\n    Returns:\n        An uninitialized instance of the service\n\n    Example usage:\n    ```python\n    async def test_service_initialization(uninitialized_service: BaseService):\n        service = await async_fixture(uninitialized_service)\n        await service.initialize()\n    ```\n    \"\"\"\n    # Patch the heartbeat task otherwise it will run forever\n    with patch(\n        \"aiperf.common.service.base_component_service.BaseComponentService._heartbeat_task\",\n        lambda: None,\n    ):\n        service = service_class(service_config=service_config)\n        yield service\n</code></pre>"},{"location":"api/#aiperftestscommsmock_zmq","title":"aiperf.tests.comms.mock_zmq","text":""},{"location":"api/#aiperf.tests.comms.mock_zmq.MockCommunicationData","title":"<code>MockCommunicationData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Data structure to hold state information for mock communication objects.</p> Source code in <code>aiperf/tests/comms/mock_zmq.py</code> <pre><code>class MockCommunicationData(BaseModel):\n    \"\"\"Data structure to hold state information for mock communication objects.\"\"\"\n\n    published_messages: dict[Topic, list[Message]] = Field(default_factory=dict)\n    subscriptions: dict[str, Callable[[Message], Coroutine[Any, Any, None]]] = Field(\n        default_factory=dict\n    )\n    pull_callbacks: dict[Topic, Callable[[Message], None]] = Field(default_factory=dict)\n    push_messages: dict[Topic, Message] = Field(default_factory=dict)\n    requests: dict[str, Message] = Field(default_factory=dict)\n    responses: dict[str, Message] = Field(default_factory=dict)\n\n    def clear(self) -&gt; None:\n        self.published_messages.clear()\n        self.subscriptions.clear()\n        self.pull_callbacks.clear()\n        self.push_messages.clear()\n        self.requests.clear()\n        self.responses.clear()\n</code></pre>"},{"location":"api/#aiperf.tests.comms.mock_zmq.mock_zmq_communication","title":"<code>mock_zmq_communication()</code>","text":"<p>Create a mock communication object for testing service communication.</p> <p>This mock tracks published messages, subscriptions, pull callbacks, push messages, and requests and responses for verification in tests.</p> <p>Returns:</p> Type Description <code>MagicMock</code> <p>A MagicMock configured to behave like ZMQCommunication</p> Source code in <code>aiperf/tests/comms/mock_zmq.py</code> <pre><code>@pytest.fixture\ndef mock_zmq_communication() -&gt; MagicMock:\n    \"\"\"\n    Create a mock communication object for testing service communication.\n\n    This mock tracks published messages, subscriptions, pull callbacks,\n    push messages, and requests and responses for verification in tests.\n\n    Returns:\n        A MagicMock configured to behave like ZMQCommunication\n    \"\"\"\n    mock_comm = MagicMock(spec=BaseZMQCommunication)\n\n    # Configure basic behavior\n    mock_comm.initialize.return_value = None\n    mock_comm.shutdown.return_value = None\n    mock_comm.create_clients.return_value = None\n\n    mock_comm.mock_data = MockCommunicationData()\n\n    async def mock_publish(topic: Topic, message: Message) -&gt; None:\n        \"\"\"Mock implementation of publish that stores messages by topic.\"\"\"\n        if topic not in mock_comm.mock_data.published_messages:\n            mock_comm.mock_data.published_messages[topic] = []\n\n        mock_comm.mock_data.published_messages[topic].append(message)\n\n    mock_comm.publish.side_effect = mock_publish\n\n    async def mock_subscribe(\n        topic: str, callback: Callable[[Message], Coroutine[Any, Any, None]]\n    ) -&gt; None:\n        \"\"\"Mock implementation of subscribe that stores callbacks by topic.\"\"\"\n        mock_comm.mock_data.subscriptions[topic] = callback\n\n    mock_comm.subscribe.side_effect = mock_subscribe\n\n    async def mock_pull(\n        message_type: MessageType, callback: Callable[[Message], None]\n    ) -&gt; None:\n        \"\"\"Mock implementation of pull that stores callbacks by topic.\"\"\"\n        mock_comm.mock_data.pull_callbacks[message_type] = callback\n\n    mock_comm.register_pull_callback.side_effect = mock_pull\n\n    async def mock_push(topic: Topic, message: Message) -&gt; None:\n        \"\"\"Mock implementation of push that stores messages by topic.\"\"\"\n        mock_comm.mock_data.push_messages[topic] = message\n\n    mock_comm.push.side_effect = mock_push\n\n    async def mock_request(target: str, request_data: Message) -&gt; Message:\n        \"\"\"Mock implementation of request that stores requests by target.\"\"\"\n        mock_comm.mock_data.requests[target] = request_data\n\n        # Return a fake mock response\n        return StatusMessage(\n            service_id=\"mock_service_id\",\n            service_type=ServiceType.TEST,\n            state=ServiceState.READY,\n        )\n\n    mock_comm.request.side_effect = mock_request\n\n    return mock_comm\n</code></pre>"},{"location":"api/#aiperftestscommstest_zmq_communication","title":"aiperf.tests.comms.test_zmq_communication","text":"<p>Tests for the ZMQ communication module.</p>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication","title":"<code>TestZMQCommunication</code>","text":"<p>Tests for the ZMQ communication class.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nclass TestZMQCommunication:\n    \"\"\"Tests for the ZMQ communication class.\"\"\"\n\n    @pytest.fixture\n    def mock_config(self):\n        \"\"\"Return a mock configuration for ZMQCommunication.\"\"\"\n        return ZMQInprocConfig(name=\"test-client\")\n\n    @pytest.fixture\n    def zmq_communication(self, mock_config):\n        \"\"\"Return a ZMQCommunication instance for testing.\"\"\"\n        with patch(\"zmq.asyncio.Context\", MagicMock()) as mock_context:\n            # Set up the context mock to return properly\n            mock_context.return_value = MagicMock()\n            comm = BaseZMQCommunication(config=mock_config)\n            comm._context = mock_context\n            return comm\n\n    @pytest.fixture\n    def test_message(self):\n        \"\"\"Create a test message for communication tests.\"\"\"\n        return StatusMessage(\n            service_id=\"test-service\",\n            service_type=ServiceType.TEST,\n            state=ServiceState.READY,\n        )\n\n    @pytest.mark.asyncio\n    async def test_initialization(self, zmq_communication):\n        \"\"\"Test that the ZMQ communication initializes correctly.\"\"\"\n        result = await zmq_communication.initialize()\n        assert result is None\n        assert zmq_communication.is_initialized is True\n\n    @pytest.mark.asyncio\n    async def test_initialization_failure(self, zmq_communication):\n        \"\"\"Test initialization failure handling.\"\"\"\n        # Temporarily clear initialized_event to test error path\n        zmq_communication.initialized_event.clear()\n\n        # Create a mock implementation that raises an exception\n        async def mock_init_with_error():\n            raise CommunicationError(\n                CommunicationErrorReason.INITIALIZATION_ERROR, \"Test connection error\"\n            )\n\n        # Replace the original method and call to test error handling\n        original_init = zmq_communication.initialize\n        zmq_communication.initialize = mock_init_with_error\n\n        try:\n            with pytest.raises(\n                CommunicationError,\n                match=\"Communication Error INITIALIZATION_ERROR: Test connection error\",\n            ):\n                await zmq_communication.initialize()\n        finally:\n            # Restore the original method\n            zmq_communication.initialize = original_init\n\n    @pytest.mark.asyncio\n    async def test_create_clients(self, zmq_communication):\n        \"\"\"Test creating clients for different communication patterns.\"\"\"\n        # Mock the client socket creation\n        mock_client = AsyncMock()\n\n        # Patch the specific client classes and ensure they return our mock\n        with (\n            patch(\n                \"aiperf.common.comms.zmq.clients.ZMQPubClient\",\n                return_value=mock_client,\n            ),\n            patch(\n                \"aiperf.common.comms.zmq.clients.ZMQSubClient\",\n                return_value=mock_client,\n            ),\n        ):\n            # Call create_clients\n            await zmq_communication.create_clients(\n                PubClientType.COMPONENT, SubClientType.COMPONENT\n            )\n\n            # Verify clients were added to the dictionary\n            assert PubClientType.COMPONENT in zmq_communication.clients\n            assert SubClientType.COMPONENT in zmq_communication.clients\n\n            # Verify initialize was called for each client\n            assert len(zmq_communication.clients) == 2\n\n    @pytest.mark.asyncio\n    async def test_publish_message(self, zmq_communication, test_message):\n        \"\"\"Test publishing messages.\"\"\"\n        # Mock the socket publish method\n        mock_client = AsyncMock()\n        mock_client.publish.return_value = None\n\n        # Set up the client in the clients dictionary\n        zmq_communication.clients = {PubClientType.COMPONENT: mock_client}\n        zmq_communication.initialized_event.set()\n\n        # Publish a message\n        result = await zmq_communication.publish(Topic.STATUS, test_message)\n\n        # Verify the message was published\n        assert result is None\n        mock_client.publish.assert_called_once_with(Topic.STATUS, test_message)\n\n    @pytest.mark.asyncio\n    async def test_subscribe_to_topic(self, zmq_communication):\n        \"\"\"Test subscribing to a topic.\"\"\"\n        # Mock the client socket\n        mock_client = AsyncMock()\n        mock_client.subscribe.return_value = None\n\n        # Set up the client in the clients dictionary\n        zmq_communication.clients = {SubClientType.COMPONENT: mock_client}\n        zmq_communication.initialized_event.set()\n\n        # Create a callback function\n        async def callback(message: Message):\n            pass\n\n        # Subscribe to a topic\n        result = await zmq_communication.subscribe(Topic.STATUS, callback)\n\n        # Verify subscription was set up\n        assert result is None\n        mock_client.subscribe.assert_called_once_with(Topic.STATUS, callback)\n\n    @pytest.mark.asyncio\n    async def test_shutdown(self, zmq_communication):\n        \"\"\"Test graceful shutdown of communication.\"\"\"\n        # Mock the client socket\n        mock_client1 = AsyncMock()\n        mock_client1.shutdown.return_value = None\n        mock_client2 = AsyncMock()\n        mock_client2.shutdown.return_value = None\n\n        # Set up clients\n        zmq_communication.clients = {\n            PubClientType.COMPONENT: mock_client1,\n            SubClientType.COMPONENT: mock_client2,\n        }\n        zmq_communication.initialized_event.set()\n        zmq_communication.stop_event.clear()\n\n        # Mock the context with a patched shutdown method to avoid setting\n        # context to None\n        context_mock = MagicMock()\n        zmq_communication._context = context_mock\n\n        # Create a patched version of shutdown that doesn't set context to None\n        original_shutdown = zmq_communication.shutdown\n\n        async def patched_shutdown():\n            # Calls original gather but patch term() to prevent context from\n            # becoming None\n            with patch.object(zmq_communication, \"_context\", context_mock):\n                return await original_shutdown()\n\n        zmq_communication.shutdown = patched_shutdown\n\n        try:\n            # Shutdown the communication\n            result = await zmq_communication.shutdown()\n\n            # Verify both clients were shutdown\n            assert result is None\n            assert mock_client1.shutdown.called\n            assert mock_client2.shutdown.called\n            assert context_mock.term.called\n            assert zmq_communication.stop_event.is_set()\n        finally:\n            # Restore the original method\n            zmq_communication.shutdown = original_shutdown\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.mock_config","title":"<code>mock_config()</code>","text":"<p>Return a mock configuration for ZMQCommunication.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.fixture\ndef mock_config(self):\n    \"\"\"Return a mock configuration for ZMQCommunication.\"\"\"\n    return ZMQInprocConfig(name=\"test-client\")\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_create_clients","title":"<code>test_create_clients(zmq_communication)</code>  <code>async</code>","text":"<p>Test creating clients for different communication patterns.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_create_clients(self, zmq_communication):\n    \"\"\"Test creating clients for different communication patterns.\"\"\"\n    # Mock the client socket creation\n    mock_client = AsyncMock()\n\n    # Patch the specific client classes and ensure they return our mock\n    with (\n        patch(\n            \"aiperf.common.comms.zmq.clients.ZMQPubClient\",\n            return_value=mock_client,\n        ),\n        patch(\n            \"aiperf.common.comms.zmq.clients.ZMQSubClient\",\n            return_value=mock_client,\n        ),\n    ):\n        # Call create_clients\n        await zmq_communication.create_clients(\n            PubClientType.COMPONENT, SubClientType.COMPONENT\n        )\n\n        # Verify clients were added to the dictionary\n        assert PubClientType.COMPONENT in zmq_communication.clients\n        assert SubClientType.COMPONENT in zmq_communication.clients\n\n        # Verify initialize was called for each client\n        assert len(zmq_communication.clients) == 2\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_initialization","title":"<code>test_initialization(zmq_communication)</code>  <code>async</code>","text":"<p>Test that the ZMQ communication initializes correctly.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_initialization(self, zmq_communication):\n    \"\"\"Test that the ZMQ communication initializes correctly.\"\"\"\n    result = await zmq_communication.initialize()\n    assert result is None\n    assert zmq_communication.is_initialized is True\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_initialization_failure","title":"<code>test_initialization_failure(zmq_communication)</code>  <code>async</code>","text":"<p>Test initialization failure handling.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_initialization_failure(self, zmq_communication):\n    \"\"\"Test initialization failure handling.\"\"\"\n    # Temporarily clear initialized_event to test error path\n    zmq_communication.initialized_event.clear()\n\n    # Create a mock implementation that raises an exception\n    async def mock_init_with_error():\n        raise CommunicationError(\n            CommunicationErrorReason.INITIALIZATION_ERROR, \"Test connection error\"\n        )\n\n    # Replace the original method and call to test error handling\n    original_init = zmq_communication.initialize\n    zmq_communication.initialize = mock_init_with_error\n\n    try:\n        with pytest.raises(\n            CommunicationError,\n            match=\"Communication Error INITIALIZATION_ERROR: Test connection error\",\n        ):\n            await zmq_communication.initialize()\n    finally:\n        # Restore the original method\n        zmq_communication.initialize = original_init\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_message","title":"<code>test_message()</code>","text":"<p>Create a test message for communication tests.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.fixture\ndef test_message(self):\n    \"\"\"Create a test message for communication tests.\"\"\"\n    return StatusMessage(\n        service_id=\"test-service\",\n        service_type=ServiceType.TEST,\n        state=ServiceState.READY,\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_publish_message","title":"<code>test_publish_message(zmq_communication, test_message)</code>  <code>async</code>","text":"<p>Test publishing messages.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_publish_message(self, zmq_communication, test_message):\n    \"\"\"Test publishing messages.\"\"\"\n    # Mock the socket publish method\n    mock_client = AsyncMock()\n    mock_client.publish.return_value = None\n\n    # Set up the client in the clients dictionary\n    zmq_communication.clients = {PubClientType.COMPONENT: mock_client}\n    zmq_communication.initialized_event.set()\n\n    # Publish a message\n    result = await zmq_communication.publish(Topic.STATUS, test_message)\n\n    # Verify the message was published\n    assert result is None\n    mock_client.publish.assert_called_once_with(Topic.STATUS, test_message)\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_shutdown","title":"<code>test_shutdown(zmq_communication)</code>  <code>async</code>","text":"<p>Test graceful shutdown of communication.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_shutdown(self, zmq_communication):\n    \"\"\"Test graceful shutdown of communication.\"\"\"\n    # Mock the client socket\n    mock_client1 = AsyncMock()\n    mock_client1.shutdown.return_value = None\n    mock_client2 = AsyncMock()\n    mock_client2.shutdown.return_value = None\n\n    # Set up clients\n    zmq_communication.clients = {\n        PubClientType.COMPONENT: mock_client1,\n        SubClientType.COMPONENT: mock_client2,\n    }\n    zmq_communication.initialized_event.set()\n    zmq_communication.stop_event.clear()\n\n    # Mock the context with a patched shutdown method to avoid setting\n    # context to None\n    context_mock = MagicMock()\n    zmq_communication._context = context_mock\n\n    # Create a patched version of shutdown that doesn't set context to None\n    original_shutdown = zmq_communication.shutdown\n\n    async def patched_shutdown():\n        # Calls original gather but patch term() to prevent context from\n        # becoming None\n        with patch.object(zmq_communication, \"_context\", context_mock):\n            return await original_shutdown()\n\n    zmq_communication.shutdown = patched_shutdown\n\n    try:\n        # Shutdown the communication\n        result = await zmq_communication.shutdown()\n\n        # Verify both clients were shutdown\n        assert result is None\n        assert mock_client1.shutdown.called\n        assert mock_client2.shutdown.called\n        assert context_mock.term.called\n        assert zmq_communication.stop_event.is_set()\n    finally:\n        # Restore the original method\n        zmq_communication.shutdown = original_shutdown\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.test_subscribe_to_topic","title":"<code>test_subscribe_to_topic(zmq_communication)</code>  <code>async</code>","text":"<p>Test subscribing to a topic.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_subscribe_to_topic(self, zmq_communication):\n    \"\"\"Test subscribing to a topic.\"\"\"\n    # Mock the client socket\n    mock_client = AsyncMock()\n    mock_client.subscribe.return_value = None\n\n    # Set up the client in the clients dictionary\n    zmq_communication.clients = {SubClientType.COMPONENT: mock_client}\n    zmq_communication.initialized_event.set()\n\n    # Create a callback function\n    async def callback(message: Message):\n        pass\n\n    # Subscribe to a topic\n    result = await zmq_communication.subscribe(Topic.STATUS, callback)\n\n    # Verify subscription was set up\n    assert result is None\n    mock_client.subscribe.assert_called_once_with(Topic.STATUS, callback)\n</code></pre>"},{"location":"api/#aiperf.tests.comms.test_zmq_communication.TestZMQCommunication.zmq_communication","title":"<code>zmq_communication(mock_config)</code>","text":"<p>Return a ZMQCommunication instance for testing.</p> Source code in <code>aiperf/tests/comms/test_zmq_communication.py</code> <pre><code>@pytest.fixture\ndef zmq_communication(self, mock_config):\n    \"\"\"Return a ZMQCommunication instance for testing.\"\"\"\n    with patch(\"zmq.asyncio.Context\", MagicMock()) as mock_context:\n        # Set up the context mock to return properly\n        mock_context.return_value = MagicMock()\n        comm = BaseZMQCommunication(config=mock_config)\n        comm._context = mock_context\n        return comm\n</code></pre>"},{"location":"api/#aiperftestsconfigtest_audio_config","title":"aiperf.tests.config.test_audio_config","text":""},{"location":"api/#aiperf.tests.config.test_audio_config.test_audio_config_custom_values","title":"<code>test_audio_config_custom_values()</code>","text":"<p>This test ensures that the AudioConfig object is properly initialized when provided with custom input values. It verifies that the attributes of the object match the expected values specified in the test.</p> <p>Assertions: - Each attribute of the AudioConfig object matches the corresponding     value in the custom_values dictionary.</p> Source code in <code>aiperf/tests/config/test_audio_config.py</code> <pre><code>def test_audio_config_custom_values():\n    \"\"\"\n    This test ensures that the AudioConfig object is properly initialized\n    when provided with custom input values. It verifies that the attributes\n    of the object match the expected values specified in the test.\n\n    Assertions:\n    - Each attribute of the AudioConfig object matches the corresponding\n        value in the custom_values dictionary.\n    \"\"\"\n\n    custom_values = {\n        \"batch_size\": 32,\n        \"length\": AudioLengthConfig(mean=5.0, stddev=1.0),\n        \"format\": AudioFormat.WAV,\n        \"depths\": [16, 24],\n        \"sample_rates\": [44, 48],\n        \"num_channels\": 2,\n    }\n    config = AudioConfig(**custom_values)\n\n    for key, value in custom_values.items():\n        assert getattr(config, key) == value\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_audio_config.test_audio_config_defaults","title":"<code>test_audio_config_defaults()</code>","text":"<p>Test the default values of the AudioConfig class.</p> <p>This test verifies that the AudioConfig object is initialized with the correct default values as defined in the AudioDefaults class.</p> Source code in <code>aiperf/tests/config/test_audio_config.py</code> <pre><code>def test_audio_config_defaults():\n    \"\"\"\n    Test the default values of the AudioConfig class.\n\n    This test verifies that the AudioConfig object is initialized with the correct\n    default values as defined in the AudioDefaults class.\n    \"\"\"\n    config = AudioConfig()\n    assert config.batch_size == AudioDefaults.BATCH_SIZE\n    assert config.length.mean == AudioDefaults.LENGTH_MEAN\n    assert config.length.stddev == AudioDefaults.LENGTH_STDDEV\n    assert config.format == AudioDefaults.FORMAT\n    assert config.depths == AudioDefaults.DEPTHS\n    assert config.sample_rates == AudioDefaults.SAMPLE_RATES\n    assert config.num_channels == AudioDefaults.NUM_CHANNELS\n</code></pre>"},{"location":"api/#aiperftestsconfigtest_base_config","title":"aiperf.tests.config.test_base_config","text":""},{"location":"api/#aiperf.tests.config.test_base_config.test_attach_comments_with_verbose","title":"<code>test_attach_comments_with_verbose()</code>","text":"<p>Test the <code>serialize_to_yaml</code> method of <code>BaseTestConfig</code> when the <code>verbose</code> flag is set to <code>True</code>.</p> <p>This test ensures that: - Comments (e.g., descriptions) are not attached to the YAML output when <code>verbose</code> is <code>True</code>. - The serialized YAML output contains the expected structure, such as the presence of the \"nested\" key.</p> <p>Assertions: - Verify that the description comment for <code>field1</code> is not present in the YAML output. - Verify that the \"nested:\" key is included in the YAML output.</p> Source code in <code>aiperf/tests/config/test_base_config.py</code> <pre><code>def test_attach_comments_with_verbose():\n    \"\"\"\n    Test the `serialize_to_yaml` method of `BaseTestConfig` when the `verbose` flag is set to `True`.\n\n    This test ensures that:\n    - Comments (e.g., descriptions) are not attached to the YAML output when `verbose` is `True`.\n    - The serialized YAML output contains the expected structure, such as the presence of the \"nested\" key.\n\n    Assertions:\n    - Verify that the description comment for `field1` is not present in the YAML output.\n    - Verify that the \"nested:\" key is included in the YAML output.\n    \"\"\"\n    config = BaseTestConfig(\n        nested=NestedConfig(field1=\"value1\", field2=42),\n        verbose=True,\n    )\n\n    yaml_output = config.serialize_to_yaml(verbose=config.verbose, indent=2)\n\n    # Check if comments are attached when verbose is True\n    assert (\n        \"# field1 description\" not in yaml_output\n    )  # No description provided in this example\n    assert \"nested:\" in yaml_output\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_base_config.test_is_a_nested_config","title":"<code>test_is_a_nested_config()</code>","text":"<p>Test the <code>_is_a_nested_config</code> method of the <code>BaseConfig</code> class.</p> <p>This test verifies the behavior of the <code>_is_a_nested_config</code> method when: 1. A valid nested configuration object is passed. 2. An invalid input (not a dictionary) is passed.</p> <p>Assertions: - The method should return <code>True</code> when a valid nested configuration object is passed. - The method should return <code>False</code> when an invalid input is passed.</p> Source code in <code>aiperf/tests/config/test_base_config.py</code> <pre><code>def test_is_a_nested_config():\n    \"\"\"\n    Test the `_is_a_nested_config` method of the `BaseConfig` class.\n\n    This test verifies the behavior of the `_is_a_nested_config` method when:\n    1. A valid nested configuration object is passed.\n    2. An invalid input (not a dictionary) is passed.\n\n    Assertions:\n    - The method should return `True` when a valid nested configuration object is passed.\n    - The method should return `False` when an invalid input is passed.\n    \"\"\"\n    nested_model = NestedConfig(field1=\"value1\", field2=42)\n    field = BaseTestConfig.model_fields.get(\"nested\")\n\n    assert BaseConfig._is_a_nested_config(field, nested_model.model_dump())\n    assert not BaseConfig._is_a_nested_config(field, \"not a dict\")\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_base_config.test_preprocess_value_enum","title":"<code>test_preprocess_value_enum()</code>","text":"<p>Test the <code>_preprocess_value</code> method of the <code>BaseConfig</code> class when handling an enumeration value.</p> <p>This test defines a sample enumeration <code>SampleEnum</code> with two options, <code>OPTION_A</code> and <code>OPTION_B</code>. It verifies that when an enumeration value (<code>SampleEnum.OPTION_A</code>) is passed to <code>_preprocess_value</code>, the method correctly processes it into a lowercase string representation of the enumeration value's name.</p> Assertions <ul> <li>The processed value of <code>SampleEnum.OPTION_A</code> should be \"optiona\".</li> </ul> Source code in <code>aiperf/tests/config/test_base_config.py</code> <pre><code>def test_preprocess_value_enum():\n    \"\"\"\n    Test the `_preprocess_value` method of the `BaseConfig` class when handling\n    an enumeration value.\n\n    This test defines a sample enumeration `SampleEnum` with two options,\n    `OPTION_A` and `OPTION_B`. It verifies that when an enumeration value\n    (`SampleEnum.OPTION_A`) is passed to `_preprocess_value`, the method\n    correctly processes it into a lowercase string representation of the\n    enumeration value's name.\n\n    Assertions:\n        - The processed value of `SampleEnum.OPTION_A` should be \"optiona\".\n    \"\"\"\n\n    class SampleEnum(Enum):\n        OPTION_A = \"OptionA\"\n        OPTION_B = \"OptionB\"\n\n    value = SampleEnum.OPTION_A\n    processed_value = BaseConfig._preprocess_value(value)\n\n    assert processed_value == \"optiona\"\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_base_config.test_serialize_to_yaml","title":"<code>test_serialize_to_yaml()</code>","text":"<p>Tests the <code>serialize_to_yaml</code> method of the <code>BaseTestConfig</code> class.</p> <p>This test verifies that the YAML serialization of a <code>BaseTestConfig</code> object correctly includes all nested fields and their values, as well as other attributes of the configuration.</p> Assertions <ul> <li>The serialized YAML output contains the \"nested\" key.</li> <li>The serialized YAML output includes the \"field1\" and \"field2\" values   from the <code>NestedConfig</code> object.</li> <li>The serialized YAML output includes the \"verbose\" attribute with the   correct value.</li> </ul> Source code in <code>aiperf/tests/config/test_base_config.py</code> <pre><code>def test_serialize_to_yaml():\n    \"\"\"\n    Tests the `serialize_to_yaml` method of the `BaseTestConfig` class.\n\n    This test verifies that the YAML serialization of a `BaseTestConfig` object\n    correctly includes all nested fields and their values, as well as other\n    attributes of the configuration.\n\n    Assertions:\n        - The serialized YAML output contains the \"nested\" key.\n        - The serialized YAML output includes the \"field1\" and \"field2\" values\n          from the `NestedConfig` object.\n        - The serialized YAML output includes the \"verbose\" attribute with the\n          correct value.\n    \"\"\"\n    config = BaseTestConfig(\n        nested=NestedConfig(field1=\"value1\", field2=42),\n        verbose=True,\n    )\n\n    yaml_output = config.serialize_to_yaml(verbose=config.verbose, indent=2)\n\n    assert \"nested:\" in yaml_output\n    assert \"field1: value1\" in yaml_output\n    assert \"field2: 42\" in yaml_output\n    assert \"verbose: true\" in yaml_output\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_base_config.test_should_add_field_to_template","title":"<code>test_should_add_field_to_template()</code>","text":"<p>Test the <code>_should_add_field_to_template</code> method of the <code>BaseConfig</code> class.</p> <p>This test verifies the behavior of <code>_should_add_field_to_template</code> when handling fields with different <code>json_schema_extra</code> configurations.</p> Assertions <ul> <li>Fields with <code>add_to_template</code> set to <code>False</code> should not be added to the template.</li> <li>Fields with <code>add_to_template</code> set to <code>True</code> should be added to the template.</li> <li>Fields without <code>json_schema_extra</code> should be added to the template by default.</li> <li>Fields with <code>json_schema_extra</code> set to <code>None</code> should be added to the template by default.</li> <li>Fields with unexpected keys in <code>json_schema_extra</code> should be added to the template by default.</li> </ul> Source code in <code>aiperf/tests/config/test_base_config.py</code> <pre><code>def test_should_add_field_to_template():\n    \"\"\"\n    Test the `_should_add_field_to_template` method of the `BaseConfig` class.\n\n    This test verifies the behavior of `_should_add_field_to_template` when handling\n    fields with different `json_schema_extra` configurations.\n\n    Assertions:\n        - Fields with `add_to_template` set to `False` should not be added to the template.\n        - Fields with `add_to_template` set to `True` should be added to the template.\n        - Fields without `json_schema_extra` should be added to the template by default.\n        - Fields with `json_schema_extra` set to `None` should be added to the template by default.\n        - Fields with unexpected keys in `json_schema_extra` should be added to the template by default.\n    \"\"\"\n\n    field_with_flag = FieldInfo(json_schema_extra={\"add_to_template\": False})\n    field_with_add_to_template_true = FieldInfo(\n        json_schema_extra={\"add_to_template\": True}\n    )\n    field_no_extra = FieldInfo()\n    field_with_none_extra = FieldInfo(json_schema_extra=None)\n    field_with_unexpected_keys = FieldInfo(json_schema_extra={\"unexpected_key\": True})\n\n    assert not BaseConfig._should_add_field_to_template(field_with_flag)\n    assert BaseConfig._should_add_field_to_template(field_with_add_to_template_true)\n    assert BaseConfig._should_add_field_to_template(field_no_extra)\n    assert BaseConfig._should_add_field_to_template(field_with_none_extra)\n    assert BaseConfig._should_add_field_to_template(field_with_unexpected_keys)\n</code></pre>"},{"location":"api/#aiperftestsconfigtest_endpoint_config","title":"aiperf.tests.config.test_endpoint_config","text":""},{"location":"api/#aiperf.tests.config.test_endpoint_config.test_endpoint_config_custom_values","title":"<code>test_endpoint_config_custom_values()</code>","text":"<p>Test the <code>EndPointConfig</code> class with custom values. This test verifies that the <code>EndPointConfig</code> object correctly initializes its attributes when provided with a dictionary of custom values. It ensures that each attribute in the configuration matches the corresponding value from the input dictionary.</p> <p>Raises: - AssertionError: If any attribute value does not match the expected value.</p> Source code in <code>aiperf/tests/config/test_endpoint_config.py</code> <pre><code>def test_endpoint_config_custom_values():\n    \"\"\"\n    Test the `EndPointConfig` class with custom values.\n    This test verifies that the `EndPointConfig` object correctly initializes\n    its attributes when provided with a dictionary of custom values. It ensures\n    that each attribute in the configuration matches the corresponding value\n    from the input dictionary.\n\n    Raises:\n    - AssertionError: If any attribute value does not match the expected value.\n    \"\"\"\n\n    custom_values = {\n        \"model_selection_strategy\": \"round_robin\",\n        \"backend\": \"vllm\",\n        \"custom\": \"custom_endpoint\",\n        \"type\": \"custom_type\",\n        \"streaming\": True,\n        \"server_metrics_urls\": [\"http://custom-metrics-url\"],\n        \"url\": \"http://custom-url\",\n        \"grpc_method\": \"custom.package.Service/Method\",\n    }\n    config = EndPointConfig(**custom_values)\n    for key, value in custom_values.items():\n        config_value = getattr(config, key)\n        if isinstance(config_value, Enum):\n            config_value = config_value.value.lower()\n\n        assert config_value == value\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_endpoint_config.test_endpoint_config_defaults","title":"<code>test_endpoint_config_defaults()</code>","text":"<p>Test the default values of the EndPointConfig class.</p> <p>This test verifies that the default attributes of an EndPointConfig instance match the predefined constants in the EndPointDefaults class. It ensures that the configuration is initialized correctly with expected default values.</p> Source code in <code>aiperf/tests/config/test_endpoint_config.py</code> <pre><code>def test_endpoint_config_defaults():\n    \"\"\"\n    Test the default values of the EndPointConfig class.\n\n    This test verifies that the default attributes of an EndPointConfig instance\n    match the predefined constants in the EndPointDefaults class. It ensures that\n    the configuration is initialized correctly with expected default values.\n    \"\"\"\n\n    config = EndPointConfig()\n    assert config.model_selection_strategy == EndPointDefaults.MODEL_SELECTION_STRATEGY\n    assert config.backend == EndPointDefaults.BACKEND\n    assert config.custom == EndPointDefaults.CUSTOM\n    assert config.type == EndPointDefaults.TYPE\n    assert config.streaming == EndPointDefaults.STREAMING\n    assert config.server_metrics_urls == EndPointDefaults.SERVER_METRICS_URLS\n    assert config.url == EndPointDefaults.URL\n    assert config.grpc_method == EndPointDefaults.GRPC_METHOD\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_endpoint_config.test_server_metrics_urls_validator","title":"<code>test_server_metrics_urls_validator()</code>","text":"<p>Test the validation and assignment of the <code>server_metrics_urls</code> attribute in the <code>EndPointConfig</code> class. This test verifies the following scenarios: 1. When a single URL string is provided, it is correctly converted into a list containing that URL. 2. When a list of URL strings is provided, it is correctly assigned without modification. Assertions: - Ensure that <code>server_metrics_urls</code> is correctly set as a list in both cases.</p> Source code in <code>aiperf/tests/config/test_endpoint_config.py</code> <pre><code>def test_server_metrics_urls_validator():\n    \"\"\"\n    Test the validation and assignment of the `server_metrics_urls` attribute\n    in the `EndPointConfig` class.\n    This test verifies the following scenarios:\n    1. When a single URL string is provided, it is correctly converted into a list\n    containing that URL.\n    2. When a list of URL strings is provided, it is correctly assigned without modification.\n    Assertions:\n    - Ensure that `server_metrics_urls` is correctly set as a list in both cases.\n    \"\"\"\n\n    config = EndPointConfig(server_metrics_urls=\"http://metrics-url\")\n    assert config.server_metrics_urls == [\"http://metrics-url\"]\n\n    config = EndPointConfig(\n        server_metrics_urls=[\"http://metrics-url1\", \"http://metrics-url2\"]\n    )\n    assert config.server_metrics_urls == [\"http://metrics-url1\", \"http://metrics-url2\"]\n</code></pre>"},{"location":"api/#aiperftestsconfigtest_image_config","title":"aiperf.tests.config.test_image_config","text":""},{"location":"api/#aiperf.tests.config.test_image_config.test_image_config_custom_values","title":"<code>test_image_config_custom_values()</code>","text":"<p>Test the InputConfig class with custom values.</p> <p>This test verifies that the InputConfig class correctly initializes its attributes when provided with a dictionary of custom values.</p> Source code in <code>aiperf/tests/config/test_image_config.py</code> <pre><code>def test_image_config_custom_values():\n    \"\"\"\n    Test the InputConfig class with custom values.\n\n    This test verifies that the InputConfig class correctly initializes its attributes\n    when provided with a dictionary of custom values.\n    \"\"\"\n    custom_values = {\n        \"width\": ImageWidthConfig(mean=640.0, stddev=80.0),\n        \"height\": ImageHeightConfig(mean=480.0, stddev=60.0),\n        \"batch_size\": 16,\n        \"format\": ImageFormat.JPEG,\n    }\n    config = ImageConfig(**custom_values)\n\n    for key, value in custom_values.items():\n        assert getattr(config, key) == value\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_image_config.test_image_config_defaults","title":"<code>test_image_config_defaults()</code>","text":"<p>Test the default values of the ImageConfig class.</p> <p>This test verifies that the ImageConfig object is initialized with the correct default values as defined in the ImageDefaults class.</p> Source code in <code>aiperf/tests/config/test_image_config.py</code> <pre><code>def test_image_config_defaults():\n    \"\"\"\n    Test the default values of the ImageConfig class.\n\n    This test verifies that the ImageConfig object is initialized with the correct\n    default values as defined in the ImageDefaults class.\n    \"\"\"\n    config = ImageConfig()\n    assert config.width.mean == ImageDefaults.WIDTH_MEAN\n    assert config.width.stddev == ImageDefaults.WIDTH_STDDEV\n    assert config.height.mean == ImageDefaults.HEIGHT_MEAN\n    assert config.height.stddev == ImageDefaults.HEIGHT_STDDEV\n    assert config.batch_size == ImageDefaults.BATCH_SIZE\n    assert config.format == ImageDefaults.FORMAT\n</code></pre>"},{"location":"api/#aiperftestsconfigtest_input_config","title":"aiperf.tests.config.test_input_config","text":""},{"location":"api/#aiperf.tests.config.test_input_config.test_input_config_custom_values","title":"<code>test_input_config_custom_values()</code>","text":"<p>Test the InputConfig class with custom values.</p> <p>This test verifies that the InputConfig class correctly initializes its attributes when provided with a dictionary of custom values.</p> Source code in <code>aiperf/tests/config/test_input_config.py</code> <pre><code>def test_input_config_custom_values():\n    \"\"\"\n    Test the InputConfig class with custom values.\n\n    This test verifies that the InputConfig class correctly initializes its attributes\n    when provided with a dictionary of custom values.\n    \"\"\"\n    config = InputConfig(\n        batch_size=64,\n        extra={\"key\": \"value\"},\n        goodput={\"request_latency\": 200},\n        header={\"Authorization\": \"Bearer token\"},\n        file=\"synthetic:queries,passages\",\n        num_dataset_entries=10,\n        random_seed=42,\n    )\n\n    assert config.batch_size == 64\n    assert config.extra == {\"key\": \"value\"}\n    assert config.goodput == {\"request_latency\": 200}\n    assert config.header == {\"Authorization\": \"Bearer token\"}\n    assert config.file == PosixPath(\"synthetic:queries,passages\")\n    assert config.num_dataset_entries == 10\n    assert config.random_seed == 42\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_input_config.test_input_config_defaults","title":"<code>test_input_config_defaults()</code>","text":"<p>Test the default values of the InputConfig class.</p> <p>This test verifies that an instance of InputConfig is initialized with the expected default values as defined in the InputDefaults class. Additionally, it checks that the <code>audio</code> attribute is an instance of the AudioConfig class.</p> Source code in <code>aiperf/tests/config/test_input_config.py</code> <pre><code>def test_input_config_defaults():\n    \"\"\"\n    Test the default values of the InputConfig class.\n\n    This test verifies that an instance of InputConfig is initialized with the\n    expected default values as defined in the InputDefaults class. Additionally,\n    it checks that the `audio` attribute is an instance of the AudioConfig class.\n    \"\"\"\n\n    config = InputConfig()\n    assert config.batch_size == InputDefaults.BATCH_SIZE\n    assert config.extra == InputDefaults.EXTRA\n    assert config.goodput == InputDefaults.GOODPUT\n    assert config.header == InputDefaults.HEADER\n    assert config.file == InputDefaults.FILE\n    assert config.num_dataset_entries == InputDefaults.NUM_DATASET_ENTRIES\n    assert config.random_seed == InputDefaults.RANDOM_SEED\n    assert isinstance(config.audio, AudioConfig)\n    assert isinstance(config.image, ImageConfig)\n    assert isinstance(config.prompt, PromptConfig)\n    assert isinstance(config.sessions, SessionsConfig)\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_input_config.test_input_config_file_validation","title":"<code>test_input_config_file_validation()</code>","text":"<p>Test InputConfig file field with valid and invalid values.</p> Source code in <code>aiperf/tests/config/test_input_config.py</code> <pre><code>def test_input_config_file_validation():\n    \"\"\"\n    Test InputConfig file field with valid and invalid values.\n    \"\"\"\n    valid_file = \"synthetic:queries,passages\"\n    config = InputConfig(file=valid_file)\n    assert config.file == PosixPath(valid_file)\n\n    with pytest.raises(ValidationError):\n        InputConfig(file=12345)  # Invalid file (non-string value)\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_input_config.test_input_config_goodput_validation","title":"<code>test_input_config_goodput_validation()</code>","text":"<p>Test InputConfig goodput field with valid and invalid values.</p> Source code in <code>aiperf/tests/config/test_input_config.py</code> <pre><code>def test_input_config_goodput_validation():\n    \"\"\"\n    Test InputConfig goodput field with valid and invalid values.\n    \"\"\"\n    valid_goodput = {\"request_latency\": 300, \"output_token_throughput_per_user\": 600}\n    config = InputConfig(goodput=valid_goodput)\n    assert config.goodput == valid_goodput\n\n    with pytest.raises(ValidationError):\n        InputConfig(goodput={\"invalid_metric\": \"not_a_number\"})  # Invalid goodput\n</code></pre>"},{"location":"api/#aiperftestsconfigtest_output_config","title":"aiperf.tests.config.test_output_config","text":""},{"location":"api/#aiperf.tests.config.test_output_config.test_output_config_custom_values","title":"<code>test_output_config_custom_values()</code>","text":"<p>Test the OutputConfig class with custom values.</p> <p>This test verifies that the OutputConfig class correctly initializes its attributes when provided with a dictionary of custom values.</p> Source code in <code>aiperf/tests/config/test_output_config.py</code> <pre><code>def test_output_config_custom_values():\n    \"\"\"\n    Test the OutputConfig class with custom values.\n\n    This test verifies that the OutputConfig class correctly initializes its attributes\n    when provided with a dictionary of custom values.\n    \"\"\"\n    custom_values = {\n        \"artifact_directory\": Path(\"/custom/artifact/directory\"),\n    }\n    config = OutputConfig(**custom_values)\n\n    for key, value in custom_values.items():\n        assert getattr(config, key) == value\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_output_config.test_output_config_defaults","title":"<code>test_output_config_defaults()</code>","text":"<p>Test the default values of the OutputConfig class.</p> <p>This test verifies that the OutputConfig object is initialized with the correct default values as defined in the OutputDefaults class.</p> Source code in <code>aiperf/tests/config/test_output_config.py</code> <pre><code>def test_output_config_defaults():\n    \"\"\"\n    Test the default values of the OutputConfig class.\n\n    This test verifies that the OutputConfig object is initialized with the correct\n    default values as defined in the OutputDefaults class.\n    \"\"\"\n    config = OutputConfig()\n    assert config.artifact_directory == OutputDefaults.ARTIFACT_DIRECTORY\n</code></pre>"},{"location":"api/#aiperftestsconfigtest_prompt_config","title":"aiperf.tests.config.test_prompt_config","text":""},{"location":"api/#aiperf.tests.config.test_prompt_config.test_input_tokens_config_custom_values","title":"<code>test_input_tokens_config_custom_values()</code>","text":"<p>Test the InputTokensConfig class with custom values.</p> <p>This test verifies that the InputTokensConfig class correctly initializes its attributes when provided with a dictionary of custom values.</p> Source code in <code>aiperf/tests/config/test_prompt_config.py</code> <pre><code>def test_input_tokens_config_custom_values():\n    \"\"\"\n    Test the InputTokensConfig class with custom values.\n\n    This test verifies that the InputTokensConfig class correctly initializes its attributes\n    when provided with a dictionary of custom values.\n    \"\"\"\n    custom_values = {\n        \"mean\": 100,\n        \"stddev\": 10.0,\n    }\n    config = InputTokensConfig(**custom_values)\n\n    for key, value in custom_values.items():\n        assert getattr(config, key) == value\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_prompt_config.test_input_tokens_config_defaults","title":"<code>test_input_tokens_config_defaults()</code>","text":"<p>Test the default values of the InputTokensConfig class.</p> <p>This test verifies that the InputTokensConfig object is initialized with the correct default values as defined in the SyntheticTokensDefaults class.</p> Source code in <code>aiperf/tests/config/test_prompt_config.py</code> <pre><code>def test_input_tokens_config_defaults():\n    \"\"\"\n    Test the default values of the InputTokensConfig class.\n\n    This test verifies that the InputTokensConfig object is initialized with the correct\n    default values as defined in the SyntheticTokensDefaults class.\n    \"\"\"\n    config = InputTokensConfig()\n    assert config.mean == InputTokensDefaults.MEAN\n    assert config.stddev == InputTokensDefaults.STDDEV\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_prompt_config.test_output_tokens_config_custom_values","title":"<code>test_output_tokens_config_custom_values()</code>","text":"<p>Test the OutputTokensConfig class with custom values.</p> <p>This test verifies that the OutputTokensConfig class correctly initializes its attributes when provided with a dictionary of custom values.</p> Source code in <code>aiperf/tests/config/test_prompt_config.py</code> <pre><code>def test_output_tokens_config_custom_values():\n    \"\"\"\n    Test the OutputTokensConfig class with custom values.\n\n    This test verifies that the OutputTokensConfig class correctly initializes its attributes\n    when provided with a dictionary of custom values.\n    \"\"\"\n    custom_values = {\n        \"mean\": 100,\n        \"deterministic\": True,\n        \"stddev\": 10.0,\n    }\n    config = OutputTokensConfig(**custom_values)\n\n    for key, value in custom_values.items():\n        assert getattr(config, key) == value\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_prompt_config.test_output_tokens_config_defaults","title":"<code>test_output_tokens_config_defaults()</code>","text":"<p>Test the default values of the OutputTokensConfig class.</p> <p>This test verifies that the OutputTokensConfig object is initialized with the correct default values as defined in the OutputTokensDefaults class.</p> Source code in <code>aiperf/tests/config/test_prompt_config.py</code> <pre><code>def test_output_tokens_config_defaults():\n    \"\"\"\n    Test the default values of the OutputTokensConfig class.\n\n    This test verifies that the OutputTokensConfig object is initialized with the correct\n    default values as defined in the OutputTokensDefaults class.\n    \"\"\"\n    config = OutputTokensConfig()\n    assert config.mean == OutputTokensDefaults.MEAN\n    assert config.deterministic == OutputTokensDefaults.DETERMINISTIC\n    assert config.stddev == OutputTokensDefaults.STDDEV\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_prompt_config.test_prefix_prompt_config_custom_values","title":"<code>test_prefix_prompt_config_custom_values()</code>","text":"<p>Test the PrefixPromptConfig class with custom values.</p> <p>This test verifies that the PrefixPromptConfig class correctly initializes its attributes when provided with a dictionary of custom values.</p> Source code in <code>aiperf/tests/config/test_prompt_config.py</code> <pre><code>def test_prefix_prompt_config_custom_values():\n    \"\"\"\n    Test the PrefixPromptConfig class with custom values.\n\n    This test verifies that the PrefixPromptConfig class correctly initializes its attributes\n    when provided with a dictionary of custom values.\n    \"\"\"\n    custom_values = {\n        \"pool_size\": 100,\n        \"length\": 10,\n    }\n    config = PrefixPromptConfig(**custom_values)\n\n    for key, value in custom_values.items():\n        assert getattr(config, key) == value\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_prompt_config.test_prefix_prompt_config_defaults","title":"<code>test_prefix_prompt_config_defaults()</code>","text":"<p>Test the default values of the PrefixPromptConfig class.</p> <p>This test verifies that the PrefixPromptConfig object is initialized with the correct default values as defined in the PrefixPromptDefaults class.</p> Source code in <code>aiperf/tests/config/test_prompt_config.py</code> <pre><code>def test_prefix_prompt_config_defaults():\n    \"\"\"\n    Test the default values of the PrefixPromptConfig class.\n\n    This test verifies that the PrefixPromptConfig object is initialized with the correct\n    default values as defined in the PrefixPromptDefaults class.\n    \"\"\"\n    config = PrefixPromptConfig()\n    assert config.pool_size == PrefixPromptDefaults.POOL_SIZE\n    assert config.length == PrefixPromptDefaults.LENGTH\n</code></pre>"},{"location":"api/#aiperftestsconfigtest_sessions_config","title":"aiperf.tests.config.test_sessions_config","text":""},{"location":"api/#aiperf.tests.config.test_sessions_config.test_sessions_config_custom_values","title":"<code>test_sessions_config_custom_values()</code>","text":"<p>Test the SessionsConfig class with custom values.</p> <p>This test verifies that the SessionsConfig class correctly initializes its attributes when provided with a dictionary of custom values.</p> Source code in <code>aiperf/tests/config/test_sessions_config.py</code> <pre><code>def test_sessions_config_custom_values():\n    \"\"\"\n    Test the SessionsConfig class with custom values.\n\n    This test verifies that the SessionsConfig class correctly initializes its attributes\n    when provided with a dictionary of custom values.\n    \"\"\"\n    custom_values = {\n        \"num\": 100,\n        \"turns\": SessionTurnsConfig(mean=5.0, stddev=1.0),\n        \"turn_delay\": SessionTurnDelayConfig(mean=10.0, stddev=2.0, ratio=1.5),\n    }\n    config = SessionsConfig(**custom_values)\n\n    for key, value in custom_values.items():\n        assert getattr(config, key) == value\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_sessions_config.test_sessions_config_defaults","title":"<code>test_sessions_config_defaults()</code>","text":"<p>Test the default values of the SessionsConfig class.</p> <p>This test verifies that the SessionsConfig object is initialized with the correct default values as defined in the SessionsDefaults class.</p> Source code in <code>aiperf/tests/config/test_sessions_config.py</code> <pre><code>def test_sessions_config_defaults():\n    \"\"\"\n    Test the default values of the SessionsConfig class.\n\n    This test verifies that the SessionsConfig object is initialized with the correct\n    default values as defined in the SessionsDefaults class.\n    \"\"\"\n    config = SessionsConfig()\n    assert config.num == SessionsDefaults.NUM\n    assert config.turns.mean == SessionTurnsDefaults.MEAN\n    assert config.turns.stddev == SessionTurnsDefaults.STDDEV\n    assert config.turn_delay.mean == SessionTurnDelayDefaults.MEAN\n    assert config.turn_delay.stddev == SessionTurnDelayDefaults.STDDEV\n    assert config.turn_delay.ratio == SessionTurnDelayDefaults.RATIO\n</code></pre>"},{"location":"api/#aiperftestsconfigtest_tokenizer_config","title":"aiperf.tests.config.test_tokenizer_config","text":""},{"location":"api/#aiperf.tests.config.test_tokenizer_config.test_output_config_custom_values","title":"<code>test_output_config_custom_values()</code>","text":"<p>Test the OutputConfig class with custom values.</p> <p>This test verifies that the OutputConfig class correctly initializes its attributes when provided with a dictionary of custom values.</p> Source code in <code>aiperf/tests/config/test_tokenizer_config.py</code> <pre><code>def test_output_config_custom_values():\n    \"\"\"\n    Test the OutputConfig class with custom values.\n\n    This test verifies that the OutputConfig class correctly initializes its attributes\n    when provided with a dictionary of custom values.\n    \"\"\"\n    custom_values = {\n        \"name\": \"custom_tokenizer\",\n        \"revision\": \"v1.0.0\",\n        \"trust_remote_code\": True,\n    }\n    config = TokenizerConfig(**custom_values)\n\n    for key, value in custom_values.items():\n        assert getattr(config, key) == value\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_tokenizer_config.test_tokenizer_config_defaults","title":"<code>test_tokenizer_config_defaults()</code>","text":"<p>Test the default values of the TokenizerConfig class.</p> <p>This test verifies that the TokenizerConfig object is initialized with the correct default values as defined in the TokenizerDefaults class.</p> Source code in <code>aiperf/tests/config/test_tokenizer_config.py</code> <pre><code>def test_tokenizer_config_defaults():\n    \"\"\"\n    Test the default values of the TokenizerConfig class.\n\n    This test verifies that the TokenizerConfig object is initialized with the correct\n    default values as defined in the TokenizerDefaults class.\n    \"\"\"\n    config = TokenizerConfig()\n    assert config.name == TokenizerDefaults.NAME\n    assert config.revision == TokenizerDefaults.REVISION\n    assert config.trust_remote_code == TokenizerDefaults.TRUST_REMOTE_CODE\n</code></pre>"},{"location":"api/#aiperftestsconfigtest_user_config","title":"aiperf.tests.config.test_user_config","text":""},{"location":"api/#aiperf.tests.config.test_user_config.test_user_config_custom_values","title":"<code>test_user_config_custom_values()</code>","text":"<p>Test the UserConfig class with custom values. This test verifies that the UserConfig instance correctly initializes with the provided custom values and that its attributes match the expected values. Assertions:     - Checks that the <code>model_names</code> attribute is correctly set to \"model1, model2\".     - Verifies that the <code>verbose</code> attribute is set to True.     - Ensures that the <code>template_filename</code> attribute is set to \"custom_template.yaml\".</p> Source code in <code>aiperf/tests/config/test_user_config.py</code> <pre><code>def test_user_config_custom_values():\n    \"\"\"\n    Test the UserConfig class with custom values.\n    This test verifies that the UserConfig instance correctly initializes\n    with the provided custom values and that its attributes match the expected\n    values.\n    Assertions:\n        - Checks that the `model_names` attribute is correctly set to \"model1, model2\".\n        - Verifies that the `verbose` attribute is set to True.\n        - Ensures that the `template_filename` attribute is set to \"custom_template.yaml\".\n    \"\"\"\n\n    custom_values = {\n        \"model_names\": [\"model1\", \"model2\"],\n        \"verbose\": True,\n        \"template_filename\": \"custom_template.yaml\",\n    }\n    config = UserConfig(**custom_values)\n    assert config.model_names == [\"model1\", \"model2\"]\n    assert config.verbose is True\n    assert config.template_filename == \"custom_template.yaml\"\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_user_config.test_user_config_defaults","title":"<code>test_user_config_defaults()</code>","text":"<p>Test the default values of the UserConfig class. This test verifies that the UserConfig instance is initialized with the expected default values as defined in the UserDefaults class. Additionally, it checks that the <code>endpoint</code> and <code>input</code> attributes are instances of their respective configuration classes. Assertions: - <code>model_names</code> matches <code>UserDefaults.MODEL_NAMES</code>. - <code>verbose</code> matches <code>UserDefaults.VERBOSE</code>. - <code>template_filename</code> matches <code>UserDefaults.TEMPLATE_FILENAME</code>. - <code>endpoint</code> is an instance of <code>EndPointConfig</code>. - <code>input</code> is an instance of <code>InputConfig</code>. - <code>output</code> is an instance of <code>OutputConfig</code> - <code>tokenizer</code> is an instance of <code>TokenizerConfig</code>.</p> Source code in <code>aiperf/tests/config/test_user_config.py</code> <pre><code>def test_user_config_defaults():\n    \"\"\"\n    Test the default values of the UserConfig class.\n    This test verifies that the UserConfig instance is initialized with the expected\n    default values as defined in the UserDefaults class. Additionally, it checks that\n    the `endpoint` and `input` attributes are instances of their respective configuration\n    classes.\n    Assertions:\n    - `model_names` matches `UserDefaults.MODEL_NAMES`.\n    - `verbose` matches `UserDefaults.VERBOSE`.\n    - `template_filename` matches `UserDefaults.TEMPLATE_FILENAME`.\n    - `endpoint` is an instance of `EndPointConfig`.\n    - `input` is an instance of `InputConfig`.\n    - `output` is an instance of `OutputConfig`\n    - `tokenizer` is an instance of `TokenizerConfig`.\n    \"\"\"\n\n    config = UserConfig()\n    assert config.model_names == UserDefaults.MODEL_NAMES\n    assert config.verbose == UserDefaults.VERBOSE\n    assert config.template_filename == UserDefaults.TEMPLATE_FILENAME\n    assert isinstance(config.endpoint, EndPointConfig)\n    assert isinstance(config.input, InputConfig)\n    assert isinstance(config.output, OutputConfig)\n    assert isinstance(config.tokenizer, TokenizerConfig)\n</code></pre>"},{"location":"api/#aiperf.tests.config.test_user_config.test_user_config_serialization_to_file","title":"<code>test_user_config_serialization_to_file()</code>","text":"<p>Test the serialization and deserialization of a UserConfig object to and from a file.</p> <p>This test verifies that a UserConfig instance can be serialized to JSON format, written to a file, and then accurately deserialized back into a UserConfig object. It ensures that the original configuration and the loaded configuration are identical.</p> <p>Steps: 1. Create a UserConfig instance with predefined attributes. 2. Serialize the UserConfig instance to JSON and write it to a mocked file. 3. Read the JSON data from the mocked file and deserialize it back into a UserConfig instance. 4. Assert that the original UserConfig instance matches the deserialized instance.</p> <p>Mocks: - <code>pathlib.Path.open</code> is mocked to simulate file operations without actual file I/O.</p> Source code in <code>aiperf/tests/config/test_user_config.py</code> <pre><code>def test_user_config_serialization_to_file():\n    \"\"\"\n    Test the serialization and deserialization of a UserConfig object to and from a file.\n\n    This test verifies that a UserConfig instance can be serialized to JSON format,\n    written to a file, and then accurately deserialized back into a UserConfig object.\n    It ensures that the original configuration and the loaded configuration are identical.\n\n    Steps:\n    1. Create a UserConfig instance with predefined attributes.\n    2. Serialize the UserConfig instance to JSON and write it to a mocked file.\n    3. Read the JSON data from the mocked file and deserialize it back into a UserConfig instance.\n    4. Assert that the original UserConfig instance matches the deserialized instance.\n\n    Mocks:\n    - `pathlib.Path.open` is mocked to simulate file operations without actual file I/O.\n    \"\"\"\n    config = UserConfig(\n        model_names=[\"model1\", \"model2\"],\n        verbose=True,\n        template_filename=\"custom_template.yaml\",\n    )\n\n    # Serialize to JSON and write to a mocked file\n    mocked_file = mock_open()\n    with patch(\"pathlib.Path.open\", mocked_file):\n        mocked_file().write(config.model_dump_json(indent=4))\n\n    # Read the mocked file and deserialize back to UserConfig\n    with patch(\"pathlib.Path.open\", mocked_file):\n        mocked_file().read.return_value = config.model_dump_json(indent=4)\n        loaded_config = UserConfig.model_validate_json(mocked_file().read())\n\n    # Ensure the original and loaded configs are identical\n    assert config == loaded_config\n</code></pre>"},{"location":"api/#aiperftestsconftest","title":"aiperf.tests.conftest","text":"<p>Shared fixtures for testing AIPerf services.</p> <p>This file contains fixtures that are automatically discovered by pytest and made available to test functions in the same directory and subdirectories.</p>"},{"location":"api/#aiperf.tests.conftest.mock_communication","title":"<code>mock_communication(mock_zmq_communication)</code>","text":"<p>Create a mock communication object for testing service communication.</p> <p>This mock tracks published messages and subscriptions for verification in tests.</p> <p>Returns:</p> Type Description <code>MagicMock</code> <p>An MagicMock configured to behave like ZMQCommunication</p> Source code in <code>aiperf/tests/conftest.py</code> <pre><code>@pytest.fixture\ndef mock_communication(mock_zmq_communication: MagicMock) -&gt; MagicMock:  # noqa: F811 : used as a fixture\n    \"\"\"\n    Create a mock communication object for testing service communication.\n\n    This mock tracks published messages and subscriptions for verification in tests.\n\n    Returns:\n        An MagicMock configured to behave like ZMQCommunication\n    \"\"\"\n    return mock_zmq_communication\n</code></pre>"},{"location":"api/#aiperf.tests.conftest.mock_hf_tokenizer","title":"<code>mock_hf_tokenizer()</code>","text":"<p>Mock Hugging Face tokenizer to avoid HTTP requests during testing.</p> <p>This fixture patches AutoTokenizer.from_pretrained and provides a realistic mock tokenizer that can encode, decode, and handle special tokens.</p> Usage in tests <p>def test_something(mock_hf_tokenizer):     tokenizer = Tokenizer.from_pretrained(\"any-model-name\")     # tokenizer is now mocked and won't make HTTP requests</p> Source code in <code>aiperf/tests/conftest.py</code> <pre><code>@pytest.fixture\ndef mock_hf_tokenizer() -&gt; Generator[MagicMock, None, None]:\n    \"\"\"Mock Hugging Face tokenizer to avoid HTTP requests during testing.\n\n    This fixture patches AutoTokenizer.from_pretrained and provides a realistic\n    mock tokenizer that can encode, decode, and handle special tokens.\n\n    Usage in tests:\n        def test_something(mock_hf_tokenizer):\n            tokenizer = Tokenizer.from_pretrained(\"any-model-name\")\n            # tokenizer is now mocked and won't make HTTP requests\n    \"\"\"\n    # Create a mock tokenizer with realistic behavior\n    mock_tokenizer = MagicMock()\n    mock_tokenizer.bos_token_id = 1\n\n    def mock_call(text, **kwargs):\n        base_tokens = list(range(10, 10 + len(text.split())))\n        return {\"input_ids\": base_tokens}\n\n    def mock_encode(text, **kwargs):\n        return mock_call(text, **kwargs)[\"input_ids\"]\n\n    def mock_decode(token_ids, **kwargs):\n        return \" \".join([str(t) for t in token_ids])\n\n    mock_tokenizer.side_effect = mock_call\n    mock_tokenizer.encode = mock_encode\n    mock_tokenizer.decode = mock_decode\n\n    with patch(\n        \"aiperf.common.tokenizer.AutoTokenizer.from_pretrained\",\n        return_value=mock_tokenizer,\n    ):\n        yield mock_tokenizer\n</code></pre>"},{"location":"api/#aiperf.tests.conftest.mock_zmq_context","title":"<code>mock_zmq_context()</code>","text":"<p>Fixture to provide a mock ZMQ context.</p> Source code in <code>aiperf/tests/conftest.py</code> <pre><code>@pytest.fixture\ndef mock_zmq_context() -&gt; Generator[MagicMock, None, None]:\n    \"\"\"Fixture to provide a mock ZMQ context.\"\"\"\n    zmq_context = MagicMock()\n    zmq_context.socket.return_value = mock_zmq_socket()\n\n    with patch(\"zmq.Context\", new_callable=zmq_context):\n        yield zmq_context\n</code></pre>"},{"location":"api/#aiperf.tests.conftest.mock_zmq_socket","title":"<code>mock_zmq_socket()</code>","text":"<p>Fixture to provide a mock ZMQ socket.</p> Source code in <code>aiperf/tests/conftest.py</code> <pre><code>@pytest.fixture\ndef mock_zmq_socket() -&gt; Generator[MagicMock, None, None]:\n    \"\"\"Fixture to provide a mock ZMQ socket.\"\"\"\n    zmq_socket = MagicMock()\n    with patch(\"zmq.Socket\", new_callable=zmq_socket):\n        yield zmq_socket\n</code></pre>"},{"location":"api/#aiperftestsdata_exporterstest_console_exporter","title":"aiperf.tests.data_exporters.test_console_exporter","text":""},{"location":"api/#aiperftestsdata_exporterstest_exporter_manager","title":"aiperf.tests.data_exporters.test_exporter_manager","text":""},{"location":"api/#aiperftestsservicestest_dataset_manager","title":"aiperf.tests.services.test_dataset_manager","text":"<p>Tests for the dataset manager service.</p>"},{"location":"api/#aiperf.tests.services.test_dataset_manager.DatasetManagerTestConfig","title":"<code>DatasetManagerTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for dataset manager tests.</p> Source code in <code>aiperf/tests/services/test_dataset_manager.py</code> <pre><code>class DatasetManagerTestConfig(BaseModel):\n    \"\"\"Configuration model for dataset manager tests.\"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_dataset_manager.TestDatasetManager","title":"<code>TestDatasetManager</code>","text":"<p>               Bases: <code>BaseTestComponentService</code></p> <p>Tests for the dataset manager service.</p> <p>This test class extends BaseTestComponentService to leverage common component service tests while adding dataset manager specific tests.</p> Source code in <code>aiperf/tests/services/test_dataset_manager.py</code> <pre><code>@pytest.mark.asyncio\nclass TestDatasetManager(BaseTestComponentService):\n    \"\"\"\n    Tests for the dataset manager service.\n\n    This test class extends BaseTestComponentService to leverage common\n    component service tests while adding dataset manager specific tests.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the service class to be tested.\"\"\"\n        return DatasetManager\n\n    @pytest.fixture\n    def dataset_config(self) -&gt; DatasetManagerTestConfig:\n        \"\"\"\n        Return a test configuration for the dataset manager.\n        \"\"\"\n        return DatasetManagerTestConfig()\n\n    async def test_dataset_manager_initialization(\n        self, initialized_service: DatasetManager\n    ) -&gt; None:\n        \"\"\"\n        Test that the dataset manager initializes with the correct service type.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n        assert service.service_type == ServiceType.DATASET_MANAGER\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_dataset_manager.TestDatasetManager.dataset_config","title":"<code>dataset_config()</code>","text":"<p>Return a test configuration for the dataset manager.</p> Source code in <code>aiperf/tests/services/test_dataset_manager.py</code> <pre><code>@pytest.fixture\ndef dataset_config(self) -&gt; DatasetManagerTestConfig:\n    \"\"\"\n    Return a test configuration for the dataset manager.\n    \"\"\"\n    return DatasetManagerTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_dataset_manager.TestDatasetManager.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to be tested.</p> Source code in <code>aiperf/tests/services/test_dataset_manager.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the service class to be tested.\"\"\"\n    return DatasetManager\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_dataset_manager.TestDatasetManager.test_dataset_manager_initialization","title":"<code>test_dataset_manager_initialization(initialized_service)</code>  <code>async</code>","text":"<p>Test that the dataset manager initializes with the correct service type.</p> Source code in <code>aiperf/tests/services/test_dataset_manager.py</code> <pre><code>async def test_dataset_manager_initialization(\n    self, initialized_service: DatasetManager\n) -&gt; None:\n    \"\"\"\n    Test that the dataset manager initializes with the correct service type.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n    assert service.service_type == ServiceType.DATASET_MANAGER\n</code></pre>"},{"location":"api/#aiperftestsservicestest_post_processor_manager","title":"aiperf.tests.services.test_post_processor_manager","text":"<p>Tests for the post processor manager service.</p>"},{"location":"api/#aiperf.tests.services.test_post_processor_manager.PostProcessorTestConfig","title":"<code>PostProcessorTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for post processor manager tests.</p> Source code in <code>aiperf/tests/services/test_post_processor_manager.py</code> <pre><code>class PostProcessorTestConfig(BaseModel):\n    \"\"\"Configuration model for post processor manager tests.\"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_post_processor_manager.TestPostProcessorManager","title":"<code>TestPostProcessorManager</code>","text":"<p>               Bases: <code>BaseTestComponentService</code></p> <p>Tests for the post processor manager service.</p> <p>This test class extends BaseTestComponentService to leverage common component service tests while adding post processor manager specific tests.</p> Source code in <code>aiperf/tests/services/test_post_processor_manager.py</code> <pre><code>@pytest.mark.asyncio\nclass TestPostProcessorManager(BaseTestComponentService):\n    \"\"\"\n    Tests for the post processor manager service.\n\n    This test class extends BaseTestComponentService to leverage common\n    component service tests while adding post processor manager specific tests.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the service class to be tested.\"\"\"\n        return PostProcessorManager\n\n    @pytest.fixture\n    def processor_config(self) -&gt; PostProcessorTestConfig:\n        \"\"\"\n        Return a test configuration for the post processor manager.\n        \"\"\"\n        return PostProcessorTestConfig()\n\n    async def test_post_processor_manager_initialization(\n        self, initialized_service: PostProcessorManager\n    ) -&gt; None:\n        \"\"\"\n        Test that the post processor manager initializes with the correct service type.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n        assert service.service_type == ServiceType.POST_PROCESSOR_MANAGER\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_post_processor_manager.TestPostProcessorManager.processor_config","title":"<code>processor_config()</code>","text":"<p>Return a test configuration for the post processor manager.</p> Source code in <code>aiperf/tests/services/test_post_processor_manager.py</code> <pre><code>@pytest.fixture\ndef processor_config(self) -&gt; PostProcessorTestConfig:\n    \"\"\"\n    Return a test configuration for the post processor manager.\n    \"\"\"\n    return PostProcessorTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_post_processor_manager.TestPostProcessorManager.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to be tested.</p> Source code in <code>aiperf/tests/services/test_post_processor_manager.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the service class to be tested.\"\"\"\n    return PostProcessorManager\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_post_processor_manager.TestPostProcessorManager.test_post_processor_manager_initialization","title":"<code>test_post_processor_manager_initialization(initialized_service)</code>  <code>async</code>","text":"<p>Test that the post processor manager initializes with the correct service type.</p> Source code in <code>aiperf/tests/services/test_post_processor_manager.py</code> <pre><code>async def test_post_processor_manager_initialization(\n    self, initialized_service: PostProcessorManager\n) -&gt; None:\n    \"\"\"\n    Test that the post processor manager initializes with the correct service type.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n    assert service.service_type == ServiceType.POST_PROCESSOR_MANAGER\n</code></pre>"},{"location":"api/#aiperftestsservicestest_records_manager","title":"aiperf.tests.services.test_records_manager","text":"<p>Tests for the records manager service.</p>"},{"location":"api/#aiperf.tests.services.test_records_manager.RecordsManagerTestConfig","title":"<code>RecordsManagerTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for records manager tests.</p> Source code in <code>aiperf/tests/services/test_records_manager.py</code> <pre><code>class RecordsManagerTestConfig(BaseModel):\n    \"\"\"Configuration model for records manager tests.\"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_records_manager.TestRecordsManager","title":"<code>TestRecordsManager</code>","text":"<p>               Bases: <code>BaseTestComponentService</code></p> <p>Tests for the records manager service.</p> <p>This test class extends BaseTestComponentService to leverage common component service tests while adding records manager specific tests.</p> Source code in <code>aiperf/tests/services/test_records_manager.py</code> <pre><code>@pytest.mark.asyncio\nclass TestRecordsManager(BaseTestComponentService):\n    \"\"\"\n    Tests for the records manager service.\n\n    This test class extends BaseTestComponentService to leverage common\n    component service tests while adding records manager specific tests.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the service class to be tested.\"\"\"\n        return RecordsManager\n\n    @pytest.fixture\n    def records_config(self) -&gt; RecordsManagerTestConfig:\n        \"\"\"\n        Return a test configuration for the records manager.\n        \"\"\"\n        return RecordsManagerTestConfig()\n\n    async def test_records_manager_initialization(\n        self, initialized_service: RecordsManager\n    ) -&gt; None:\n        \"\"\"\n        Test that the records manager initializes with the correct service type.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n        assert service.service_type == ServiceType.RECORDS_MANAGER\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_records_manager.TestRecordsManager.records_config","title":"<code>records_config()</code>","text":"<p>Return a test configuration for the records manager.</p> Source code in <code>aiperf/tests/services/test_records_manager.py</code> <pre><code>@pytest.fixture\ndef records_config(self) -&gt; RecordsManagerTestConfig:\n    \"\"\"\n    Return a test configuration for the records manager.\n    \"\"\"\n    return RecordsManagerTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_records_manager.TestRecordsManager.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to be tested.</p> Source code in <code>aiperf/tests/services/test_records_manager.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the service class to be tested.\"\"\"\n    return RecordsManager\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_records_manager.TestRecordsManager.test_records_manager_initialization","title":"<code>test_records_manager_initialization(initialized_service)</code>  <code>async</code>","text":"<p>Test that the records manager initializes with the correct service type.</p> Source code in <code>aiperf/tests/services/test_records_manager.py</code> <pre><code>async def test_records_manager_initialization(\n    self, initialized_service: RecordsManager\n) -&gt; None:\n    \"\"\"\n    Test that the records manager initializes with the correct service type.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n    assert service.service_type == ServiceType.RECORDS_MANAGER\n</code></pre>"},{"location":"api/#aiperftestsservicestest_system_controller","title":"aiperf.tests.services.test_system_controller","text":"<p>Tests for the system controller service.</p>"},{"location":"api/#aiperf.tests.services.test_system_controller.SystemControllerTestConfig","title":"<code>SystemControllerTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for system controller tests.</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>class SystemControllerTestConfig(BaseModel):\n    \"\"\"Configuration model for system controller tests.\"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_system_controller.TestSystemController","title":"<code>TestSystemController</code>","text":"<p>               Bases: <code>BaseTestControllerService</code></p> <p>Tests for the system controller service.</p> <p>This test class extends BaseTestControllerService to leverage common controller service tests while adding system controller specific tests. Tests include service lifecycle management, message handling, and coordination.</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>@pytest.mark.asyncio\nclass TestSystemController(BaseTestControllerService):\n    \"\"\"\n    Tests for the system controller service.\n\n    This test class extends BaseTestControllerService to leverage common\n    controller service tests while adding system controller specific tests.\n    Tests include service lifecycle management, message handling, and coordination.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the class to test.\"\"\"\n        return SystemController\n\n    @pytest.fixture\n    def controller_config(self) -&gt; SystemControllerTestConfig:\n        \"\"\"Return a test configuration for the system controller.\"\"\"\n        return SystemControllerTestConfig()\n\n    async def test_controller_subscriptions(\n        self, initialized_service: SystemController, mock_communication: MagicMock\n    ) -&gt; None:\n        \"\"\"Verifies the controller sets up subscriptions to receive messages from components.\"\"\"\n\n        await async_fixture(initialized_service)\n\n        # A SystemController should subscribe to registration, status, and heartbeat topics\n        expected_topics = [Topic.REGISTRATION, Topic.STATUS, Topic.HEARTBEAT]\n\n        for topic in expected_topics:\n            assert topic in mock_communication.mock_data.subscriptions\n            assert callable(mock_communication.mock_data.subscriptions[topic])\n\n    @pytest.fixture(autouse=True)\n    def service_manager_with_multiprocess(\n        self, monkeypatch, service_config\n    ) -&gt; MultiProcessServiceManager:\n        \"\"\"\n        Return a test service manager with multiprocess support.\n\n        This fixture mocks the initialization methods to avoid actual process creation.\n\n        Args:\n            monkeypatch: Pytest monkeypatch fixture for patching functions\n\n        Returns:\n            A MultiProcessServiceManager instance configured for testing\n        \"\"\"\n        # Create a proper async mock for the service methods\n        async_mock = AsyncMock(return_value=None)\n\n        monkeypatch.setattr(\n            MultiProcessServiceManager, \"wait_for_all_services_registration\", async_mock\n        )\n\n        multiprocess_manager = MultiProcessServiceManager(\n            required_service_types=[ServiceType.TEST],\n            config=service_config,\n        )\n\n        return multiprocess_manager\n\n    async def test_service_run_does_start(\n        self, initialized_service: SystemController\n    ) -&gt; None:\n        \"\"\"\n        Test that the service run method starts the service (added by BaseControllerService using @on_run).\n        \"\"\"\n        service = await async_fixture(initialized_service)\n\n        with (\n            patch(\n                \"aiperf.services.system_controller.system_controller.SystemController._forever_loop\",\n                return_value=None,\n            ) as mock_forever_loop,\n            patch(\n                \"aiperf.services.system_controller.system_controller.SystemController.start\",\n                return_value=None,\n            ) as mock_start,\n        ):\n            await service.run_forever()\n            mock_forever_loop.assert_called_once()\n            mock_start.assert_called_once()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_system_controller.TestSystemController.controller_config","title":"<code>controller_config()</code>","text":"<p>Return a test configuration for the system controller.</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>@pytest.fixture\ndef controller_config(self) -&gt; SystemControllerTestConfig:\n    \"\"\"Return a test configuration for the system controller.\"\"\"\n    return SystemControllerTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_system_controller.TestSystemController.service_class","title":"<code>service_class()</code>","text":"<p>Return the class to test.</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the class to test.\"\"\"\n    return SystemController\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_system_controller.TestSystemController.service_manager_with_multiprocess","title":"<code>service_manager_with_multiprocess(monkeypatch, service_config)</code>","text":"<p>Return a test service manager with multiprocess support.</p> <p>This fixture mocks the initialization methods to avoid actual process creation.</p> <p>Parameters:</p> Name Type Description Default <code>monkeypatch</code> <p>Pytest monkeypatch fixture for patching functions</p> required <p>Returns:</p> Type Description <code>MultiProcessServiceManager</code> <p>A MultiProcessServiceManager instance configured for testing</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>@pytest.fixture(autouse=True)\ndef service_manager_with_multiprocess(\n    self, monkeypatch, service_config\n) -&gt; MultiProcessServiceManager:\n    \"\"\"\n    Return a test service manager with multiprocess support.\n\n    This fixture mocks the initialization methods to avoid actual process creation.\n\n    Args:\n        monkeypatch: Pytest monkeypatch fixture for patching functions\n\n    Returns:\n        A MultiProcessServiceManager instance configured for testing\n    \"\"\"\n    # Create a proper async mock for the service methods\n    async_mock = AsyncMock(return_value=None)\n\n    monkeypatch.setattr(\n        MultiProcessServiceManager, \"wait_for_all_services_registration\", async_mock\n    )\n\n    multiprocess_manager = MultiProcessServiceManager(\n        required_service_types=[ServiceType.TEST],\n        config=service_config,\n    )\n\n    return multiprocess_manager\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_system_controller.TestSystemController.test_controller_subscriptions","title":"<code>test_controller_subscriptions(initialized_service, mock_communication)</code>  <code>async</code>","text":"<p>Verifies the controller sets up subscriptions to receive messages from components.</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>async def test_controller_subscriptions(\n    self, initialized_service: SystemController, mock_communication: MagicMock\n) -&gt; None:\n    \"\"\"Verifies the controller sets up subscriptions to receive messages from components.\"\"\"\n\n    await async_fixture(initialized_service)\n\n    # A SystemController should subscribe to registration, status, and heartbeat topics\n    expected_topics = [Topic.REGISTRATION, Topic.STATUS, Topic.HEARTBEAT]\n\n    for topic in expected_topics:\n        assert topic in mock_communication.mock_data.subscriptions\n        assert callable(mock_communication.mock_data.subscriptions[topic])\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_system_controller.TestSystemController.test_service_run_does_start","title":"<code>test_service_run_does_start(initialized_service)</code>  <code>async</code>","text":"<p>Test that the service run method starts the service (added by BaseControllerService using @on_run).</p> Source code in <code>aiperf/tests/services/test_system_controller.py</code> <pre><code>async def test_service_run_does_start(\n    self, initialized_service: SystemController\n) -&gt; None:\n    \"\"\"\n    Test that the service run method starts the service (added by BaseControllerService using @on_run).\n    \"\"\"\n    service = await async_fixture(initialized_service)\n\n    with (\n        patch(\n            \"aiperf.services.system_controller.system_controller.SystemController._forever_loop\",\n            return_value=None,\n        ) as mock_forever_loop,\n        patch(\n            \"aiperf.services.system_controller.system_controller.SystemController.start\",\n            return_value=None,\n        ) as mock_start,\n    ):\n        await service.run_forever()\n        mock_forever_loop.assert_called_once()\n        mock_start.assert_called_once()\n</code></pre>"},{"location":"api/#aiperftestsservicestest_timing_manager","title":"aiperf.tests.services.test_timing_manager","text":"<p>Tests for the timing manager service.</p>"},{"location":"api/#aiperf.tests.services.test_timing_manager.TestTimingManager","title":"<code>TestTimingManager</code>","text":"<p>               Bases: <code>BaseTestComponentService</code></p> <p>Tests for the timing manager service.</p> <p>This test class extends BaseTestComponentService to leverage common component service tests while adding timing manager specific tests.</p> Source code in <code>aiperf/tests/services/test_timing_manager.py</code> <pre><code>@pytest.mark.asyncio\nclass TestTimingManager(BaseTestComponentService):\n    \"\"\"\n    Tests for the timing manager service.\n\n    This test class extends BaseTestComponentService to leverage common\n    component service tests while adding timing manager specific tests.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the service class to be tested.\"\"\"\n        return TimingManager\n\n    @pytest.fixture\n    def timing_config(self) -&gt; TimingManagerTestConfig:\n        \"\"\"\n        Return a test configuration for the timing manager.\n        \"\"\"\n        return TimingManagerTestConfig()\n\n    async def test_timing_manager_initialization(\n        self, initialized_service: TimingManager\n    ) -&gt; None:\n        \"\"\"\n        Test that the timing manager initializes with the correct service type.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n        assert service.service_type == ServiceType.TIMING_MANAGER\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_timing_manager.TestTimingManager.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to be tested.</p> Source code in <code>aiperf/tests/services/test_timing_manager.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the service class to be tested.\"\"\"\n    return TimingManager\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_timing_manager.TestTimingManager.test_timing_manager_initialization","title":"<code>test_timing_manager_initialization(initialized_service)</code>  <code>async</code>","text":"<p>Test that the timing manager initializes with the correct service type.</p> Source code in <code>aiperf/tests/services/test_timing_manager.py</code> <pre><code>async def test_timing_manager_initialization(\n    self, initialized_service: TimingManager\n) -&gt; None:\n    \"\"\"\n    Test that the timing manager initializes with the correct service type.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n    assert service.service_type == ServiceType.TIMING_MANAGER\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_timing_manager.TestTimingManager.timing_config","title":"<code>timing_config()</code>","text":"<p>Return a test configuration for the timing manager.</p> Source code in <code>aiperf/tests/services/test_timing_manager.py</code> <pre><code>@pytest.fixture\ndef timing_config(self) -&gt; TimingManagerTestConfig:\n    \"\"\"\n    Return a test configuration for the timing manager.\n    \"\"\"\n    return TimingManagerTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_timing_manager.TimingManagerTestConfig","title":"<code>TimingManagerTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for timing manager tests.</p> Source code in <code>aiperf/tests/services/test_timing_manager.py</code> <pre><code>class TimingManagerTestConfig(BaseModel):\n    \"\"\"Configuration model for timing manager tests.\"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperftestsservicestest_worker","title":"aiperf.tests.services.test_worker","text":"<p>Tests for the worker service.</p>"},{"location":"api/#aiperf.tests.services.test_worker.TestWorker","title":"<code>TestWorker</code>","text":"<p>               Bases: <code>BaseTestService</code></p> <p>Tests for the worker service.</p> <p>This test class extends BaseTestService since Worker is a direct subclass of BaseService, not a BaseComponentService.</p> Source code in <code>aiperf/tests/services/test_worker.py</code> <pre><code>@pytest.mark.asyncio\nclass TestWorker(BaseTestService):\n    \"\"\"\n    Tests for the worker service.\n\n    This test class extends BaseTestService since Worker is a direct subclass\n    of BaseService, not a BaseComponentService.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the service class to be tested.\"\"\"\n        return Worker\n\n    @pytest.fixture\n    def worker_config(self) -&gt; WorkerTestConfig:\n        \"\"\"\n        Return a test configuration for the worker.\n        \"\"\"\n        return WorkerTestConfig()\n\n    async def test_worker_initialization(self, initialized_service: Worker) -&gt; None:\n        \"\"\"\n        Test that the worker initializes with the correct configuration.\n\n        Verifies the worker service is properly instantiated with its configuration.\n        \"\"\"\n        # Basic existence checks\n        service = await async_fixture(initialized_service)\n        assert service is not None\n        assert service.service_config is not None\n        assert service.service_type == ServiceType.WORKER\n\n        # Initialize the worker\n        await service.initialize()\n\n        # Check the worker is properly initialized\n        assert service.is_initialized\n        assert service.state == ServiceState.READY\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker.TestWorker.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to be tested.</p> Source code in <code>aiperf/tests/services/test_worker.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the service class to be tested.\"\"\"\n    return Worker\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker.TestWorker.test_worker_initialization","title":"<code>test_worker_initialization(initialized_service)</code>  <code>async</code>","text":"<p>Test that the worker initializes with the correct configuration.</p> <p>Verifies the worker service is properly instantiated with its configuration.</p> Source code in <code>aiperf/tests/services/test_worker.py</code> <pre><code>async def test_worker_initialization(self, initialized_service: Worker) -&gt; None:\n    \"\"\"\n    Test that the worker initializes with the correct configuration.\n\n    Verifies the worker service is properly instantiated with its configuration.\n    \"\"\"\n    # Basic existence checks\n    service = await async_fixture(initialized_service)\n    assert service is not None\n    assert service.service_config is not None\n    assert service.service_type == ServiceType.WORKER\n\n    # Initialize the worker\n    await service.initialize()\n\n    # Check the worker is properly initialized\n    assert service.is_initialized\n    assert service.state == ServiceState.READY\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker.TestWorker.worker_config","title":"<code>worker_config()</code>","text":"<p>Return a test configuration for the worker.</p> Source code in <code>aiperf/tests/services/test_worker.py</code> <pre><code>@pytest.fixture\ndef worker_config(self) -&gt; WorkerTestConfig:\n    \"\"\"\n    Return a test configuration for the worker.\n    \"\"\"\n    return WorkerTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker.WorkerTestConfig","title":"<code>WorkerTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Test configuration for the workers.</p> Source code in <code>aiperf/tests/services/test_worker.py</code> <pre><code>class WorkerTestConfig(BaseModel):\n    \"\"\"\n    Test configuration for the workers.\n    \"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperftestsservicestest_worker_manager","title":"aiperf.tests.services.test_worker_manager","text":"<p>Tests for the worker manager service.</p>"},{"location":"api/#aiperf.tests.services.test_worker_manager.TestWorkerManager","title":"<code>TestWorkerManager</code>","text":"<p>               Bases: <code>BaseTestComponentService</code></p> <p>Tests for the worker manager service.</p> <p>This test class extends BaseTestComponentService to leverage common component service tests while adding worker manager specific tests.</p> Source code in <code>aiperf/tests/services/test_worker_manager.py</code> <pre><code>@pytest.mark.asyncio\nclass TestWorkerManager(BaseTestComponentService):\n    \"\"\"\n    Tests for the worker manager service.\n\n    This test class extends BaseTestComponentService to leverage common\n    component service tests while adding worker manager specific tests.\n    \"\"\"\n\n    @pytest.fixture\n    def service_class(self) -&gt; type[BaseService]:\n        \"\"\"Return the service class to be tested.\"\"\"\n        return WorkerManager\n\n    @pytest.fixture\n    def worker_manager_config(self) -&gt; WorkerManagerTestConfig:\n        \"\"\"\n        Return a test configuration for the worker manager.\n        \"\"\"\n        return WorkerManagerTestConfig()\n\n    async def test_worker_manager_initialization(\n        self, initialized_service: WorkerManager\n    ) -&gt; None:\n        \"\"\"\n        Test that the worker manager initializes with the correct attributes.\n        \"\"\"\n        service = await async_fixture(initialized_service)\n        assert service.service_type == ServiceType.WORKER_MANAGER\n        assert hasattr(service, \"workers\")\n        assert hasattr(service, \"cpu_count\")\n        assert service.cpu_count == multiprocessing.cpu_count()\n        assert service.worker_count == service.cpu_count\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker_manager.TestWorkerManager.service_class","title":"<code>service_class()</code>","text":"<p>Return the service class to be tested.</p> Source code in <code>aiperf/tests/services/test_worker_manager.py</code> <pre><code>@pytest.fixture\ndef service_class(self) -&gt; type[BaseService]:\n    \"\"\"Return the service class to be tested.\"\"\"\n    return WorkerManager\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker_manager.TestWorkerManager.test_worker_manager_initialization","title":"<code>test_worker_manager_initialization(initialized_service)</code>  <code>async</code>","text":"<p>Test that the worker manager initializes with the correct attributes.</p> Source code in <code>aiperf/tests/services/test_worker_manager.py</code> <pre><code>async def test_worker_manager_initialization(\n    self, initialized_service: WorkerManager\n) -&gt; None:\n    \"\"\"\n    Test that the worker manager initializes with the correct attributes.\n    \"\"\"\n    service = await async_fixture(initialized_service)\n    assert service.service_type == ServiceType.WORKER_MANAGER\n    assert hasattr(service, \"workers\")\n    assert hasattr(service, \"cpu_count\")\n    assert service.cpu_count == multiprocessing.cpu_count()\n    assert service.worker_count == service.cpu_count\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker_manager.TestWorkerManager.worker_manager_config","title":"<code>worker_manager_config()</code>","text":"<p>Return a test configuration for the worker manager.</p> Source code in <code>aiperf/tests/services/test_worker_manager.py</code> <pre><code>@pytest.fixture\ndef worker_manager_config(self) -&gt; WorkerManagerTestConfig:\n    \"\"\"\n    Return a test configuration for the worker manager.\n    \"\"\"\n    return WorkerManagerTestConfig()\n</code></pre>"},{"location":"api/#aiperf.tests.services.test_worker_manager.WorkerManagerTestConfig","title":"<code>WorkerManagerTestConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for worker manager tests.</p> Source code in <code>aiperf/tests/services/test_worker_manager.py</code> <pre><code>class WorkerManagerTestConfig(BaseModel):\n    \"\"\"Configuration model for worker manager tests.\"\"\"\n\n    # TODO: Replace this with the actual configuration model once available\n    pass\n</code></pre>"},{"location":"api/#aiperfteststest_aiperf_task","title":"aiperf.tests.test_aiperf_task","text":""},{"location":"api/#aiperfteststest_audio_generator","title":"aiperf.tests.test_audio_generator","text":""},{"location":"api/#aiperf.tests.test_audio_generator.decode_audio","title":"<code>decode_audio(data_uri)</code>","text":"<p>Helper function to decode audio from data URI format.</p> <p>Parameters:</p> Name Type Description Default <code>data_uri</code> <code>str</code> <p>Data URI string in format \"format,b64_data\"</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, int]</code> <p>Tuple of (audio_data: np.ndarray, sample_rate: int)</p> Source code in <code>aiperf/tests/test_audio_generator.py</code> <pre><code>def decode_audio(data_uri: str) -&gt; tuple[np.ndarray, int]:\n    \"\"\"Helper function to decode audio from data URI format.\n\n    Args:\n        data_uri: Data URI string in format \"format,b64_data\"\n\n    Returns:\n        Tuple of (audio_data: np.ndarray, sample_rate: int)\n    \"\"\"\n    # Parse data URI\n    _, b64_data = data_uri.split(\",\")\n    decoded_data = base64.b64decode(b64_data)\n\n    # Load audio using soundfile - format is auto-detected from content\n    audio_data, sample_rate = sf.read(io.BytesIO(decoded_data))\n    return audio_data, sample_rate\n</code></pre>"},{"location":"api/#aiperfteststest_benchmark_duration_metric","title":"aiperf.tests.test_benchmark_duration_metric","text":""},{"location":"api/#aiperfteststest_hooks","title":"aiperf.tests.test_hooks","text":""},{"location":"api/#aiperf.tests.test_hooks.test_hook_decorators","title":"<code>test_hook_decorators()</code>","text":"<p>Test the hook decorators.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>def test_hook_decorators():\n    \"\"\"Test the hook decorators.\"\"\"\n    test_hooks = MockHooks()\n\n    assert test_hooks.get_hooks(AIPerfHook.ON_INIT) == [\n        test_hooks.on_init_3,\n        test_hooks.on_init_2,\n        test_hooks.on_init_1,\n    ], \"Init hooks should be registered in the order they are defined\"\n    assert test_hooks.get_hooks(AIPerfHook.ON_CLEANUP) == [test_hooks.on_cleanup_1], (\n        \"Cleanup hooks should be registered\"\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_hook_inheritance","title":"<code>test_hook_inheritance()</code>","text":"<p>Test the hook inheritance.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>def test_hook_inheritance():\n    \"\"\"Test the hook inheritance.\"\"\"\n    test_hooks_inheritance = MockHooksInheritance()\n\n    assert test_hooks_inheritance.get_hooks(AIPerfHook.ON_INIT) == [\n        test_hooks_inheritance.on_init_3,\n        test_hooks_inheritance.on_init_2,\n        test_hooks_inheritance.on_init_1,\n        test_hooks_inheritance.on_init_4,\n    ], \"Init hooks should be registered in the order they are defined\"\n\n    assert test_hooks_inheritance.get_hooks(AIPerfHook.ON_CLEANUP) == [\n        test_hooks_inheritance.on_cleanup_1,\n        test_hooks_inheritance.on_cleanup_2,\n    ], \"Cleanup hooks should be registered in the order they are defined\"\n\n    assert test_hooks_inheritance.get_hooks(AIPerfHook.ON_START) == [\n        test_hooks_inheritance.on_start_1\n    ], \"Start hook should be registered\"\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_hook_ordering","title":"<code>test_hook_ordering()</code>","text":"<p>Test that the hook ordering is correct.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>def test_hook_ordering():\n    \"\"\"Test that the hook ordering is correct.\"\"\"\n\n    @supports_hooks(AIPerfHook.ON_INIT)\n    class Hooks(HooksMixin):\n        @on_init\n        async def on_init_2(self):\n            pass\n\n        @on_init\n        async def on_init_3(self):\n            pass\n\n        @on_init\n        async def on_init_1(self):\n            pass\n\n    hooks = Hooks()\n\n    # Ensure the hooks are added in the order they are defined\n    assert hooks.get_hooks(AIPerfHook.ON_INIT) == [\n        hooks.on_init_2,\n        hooks.on_init_3,\n        hooks.on_init_1,\n    ], \"Hooks should be registered in the order they are defined\"\n\n    class Hooks2(Hooks):\n        @on_init\n        async def on_init_0(self):\n            pass\n\n    hooks2 = Hooks2()\n\n    # Ensure that base hooks are registered before the subclass hooks\n    assert hooks2.get_hooks(AIPerfHook.ON_INIT) == [\n        # Base hooks\n        hooks2.on_init_2,\n        hooks2.on_init_3,\n        hooks2.on_init_1,\n        # Subclass hooks\n        hooks2.on_init_0,\n    ], \"Base hooks should be registered before subclass hooks\"\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_inheritance_hook_order","title":"<code>test_inheritance_hook_order()</code>  <code>async</code>","text":"<p>Test that the hook order is correct when using inheritance.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_inheritance_hook_order():\n    \"\"\"Test that the hook order is correct when using inheritance.\"\"\"\n\n    class MockHooksInheritance2(MockHooks):\n        @on_init\n        async def on_init_99(self):\n            assert self.on_init_1 in self.called_hooks\n            self.add_called_hook(self.on_init_99)\n\n        @on_init\n        async def on_init_0(self):\n            assert self.on_init_1 in self.called_hooks\n            self.add_called_hook(self.on_init_0)\n\n    test_hooks = MockHooksInheritance2()\n\n    await test_hooks.initialize()\n\n    assert test_hooks.on_init_0 in test_hooks.called_hooks, (\n        \"Subclass hook should be called\"\n    )\n    assert test_hooks.on_init_1 in test_hooks.called_hooks, \"Base hook should be called\"\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_inheritance_hook_override","title":"<code>test_inheritance_hook_override()</code>  <code>async</code>","text":"<p>Test that a hook that is overridden in a subclass does not call the base class hook.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_inheritance_hook_override():\n    \"\"\"Test that a hook that is overridden in a subclass does not call the base class hook.\"\"\"\n\n    class MockHooksInheritance3(MockHooks):\n        @on_init\n        async def on_init_1(self):\n            assert MockHooks.on_init_1 not in self.called_hooks\n            self.add_called_hook(self.on_init_1)\n\n    test_hooks = MockHooksInheritance3()\n\n    await test_hooks.initialize()\n\n    assert test_hooks.on_init_1 in test_hooks.called_hooks, (\n        \"Subclass hook should be called\"\n    )\n    assert MockHooks.on_init_1 not in test_hooks.called_hooks, (\n        \"Base hook should not be called\"\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_instance_additional_hooks","title":"<code>test_instance_additional_hooks()</code>  <code>async</code>","text":"<p>Test that additional hooks can be added to a class that supports hooks.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_instance_additional_hooks():\n    \"\"\"Test that additional hooks can be added to a class that supports hooks.\"\"\"\n    test_hooks = MockHooksInheritance()\n\n    async def custom_start_hook():\n        test_hooks.add_called_hook(custom_start_hook)\n\n    test_hooks.register_hook(AIPerfHook.ON_START, custom_start_hook)\n\n    assert test_hooks.get_hooks(AIPerfHook.ON_START) == [\n        test_hooks.on_start_1,\n        custom_start_hook,\n    ]\n\n    await test_hooks.start()\n\n    assert custom_start_hook in test_hooks.called_hooks, (\n        \"Custom start hook should be called\"\n    )\n    assert test_hooks.on_start_1 in test_hooks.called_hooks, (\n        \"Base start hook should be called\"\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_instance_additional_supported_hooks","title":"<code>test_instance_additional_supported_hooks()</code>  <code>async</code>","text":"<p>Test that additional hook types can be supported by a class</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>@pytest.mark.asyncio\nasync def test_instance_additional_supported_hooks():\n    \"\"\"Test that additional hook types can be supported by a class\"\"\"\n    test_hooks = MockHooks()\n\n    async def custom_stop_hook():\n        test_hooks.add_called_hook(custom_stop_hook)\n\n    # this should raise an UnsupportedHookError because the hook type is not supported\n    with pytest.raises(UnsupportedHookError):\n        test_hooks.register_hook(AIPerfHook.ON_STOP, custom_stop_hook)\n\n    # Now we add the hook type to the supported hooks\n    test_hooks.supported_hooks.add(AIPerfHook.ON_STOP)\n\n    # Now we can register the hook and it will not raise an UnsupportedHookError\n    test_hooks.register_hook(AIPerfHook.ON_STOP, custom_stop_hook)\n\n    # Expect the hook to be in the list of hooks\n    assert test_hooks.get_hooks(AIPerfHook.ON_STOP) == [custom_stop_hook]\n\n    async def custom_init_hook():\n        test_hooks.called_hooks.add(custom_init_hook)\n        # Hack to allow the hook to run the newly added ON_STOP hook\n        await test_hooks.run_hooks_async(AIPerfHook.ON_STOP)\n\n    test_hooks.register_hook(\n        AIPerfHook.ON_INIT, custom_init_hook\n    )  # this should not raise an UnsupportedHookError\n\n    await test_hooks.initialize()\n\n    # Expect the custom init and stop hooks to have been called\n    assert custom_init_hook in test_hooks.called_hooks, (\n        \"Custom init hook should be called\"\n    )\n    assert custom_stop_hook in test_hooks.called_hooks, (\n        \"Custom stop hook should be called\"\n    )\n</code></pre>"},{"location":"api/#aiperf.tests.test_hooks.test_unsupported_hook_decorator","title":"<code>test_unsupported_hook_decorator()</code>","text":"<p>Test that an UnsupportedHookError is raised when a hook is defined on a class that does not support it.</p> Source code in <code>aiperf/tests/test_hooks.py</code> <pre><code>def test_unsupported_hook_decorator():\n    \"\"\"Test that an UnsupportedHookError is raised when a hook is defined on a class\n    that does not support it.\n    \"\"\"\n\n    @supports_hooks(AIPerfHook.ON_CLEANUP)\n    class TestHooksUnsupported(MockHooks):\n        @on_start\n        async def _on_start_1(self):\n            self.add_called_hook(self._on_start_1)\n\n    with pytest.raises(UnsupportedHookError):\n        TestHooksUnsupported()  # this should raise an UnsupportedHookError\n</code></pre>"},{"location":"api/#aiperfteststest_image_generator","title":"aiperf.tests.test_image_generator","text":""},{"location":"api/#aiperfteststest_max_response_metric","title":"aiperf.tests.test_max_response_metric","text":""},{"location":"api/#aiperfteststest_messages","title":"aiperf.tests.test_messages","text":""},{"location":"api/#aiperfteststest_metric_summary","title":"aiperf.tests.test_metric_summary","text":""},{"location":"api/#aiperfteststest_min_request_metric","title":"aiperf.tests.test_min_request_metric","text":""},{"location":"api/#aiperfteststest_prompt_generator","title":"aiperf.tests.test_prompt_generator","text":""},{"location":"api/#aiperfteststest_records","title":"aiperf.tests.test_records","text":""},{"location":"api/#aiperf.tests.test_records.test_record_dataclass","title":"<code>test_record_dataclass()</code>","text":"<p>Test the initialization and attribute assignment of the Record dataclass.</p> <p>This test creates two transaction objects and a Record object containing them. It asserts that the Record's 'request' attribute and 'transactions' list are set correctly.</p> Source code in <code>aiperf/tests/test_records.py</code> <pre><code>def test_record_dataclass():\n    \"\"\"\n    Test the initialization and attribute assignment of the Record dataclass.\n\n    This test creates two transaction objects and a Record object containing them.\n    It asserts that the Record's 'request' attribute and 'transactions' list are set correctly.\n    \"\"\"\n    req = Transaction(timestamp=100, payload=None)\n    resp1 = Transaction(timestamp=1, payload=\"foo\")\n    resp2 = Transaction(timestamp=2, payload=\"bar\")\n    record = Record(request=req, responses=[resp1, resp2])\n    assert record.request == req\n    assert record.responses == [resp1, resp2]\n</code></pre>"},{"location":"api/#aiperf.tests.test_records.test_records_add_and_get_records","title":"<code>test_records_add_and_get_records()</code>","text":"<p>Test the functionality of adding a record to the Records object and retrieving it.</p> <p>This test verifies that: - A record can be added to the Records instance with a specified request and a list of transaction objects. - The added record contains the correct request value and associated transactions.</p> Source code in <code>aiperf/tests/test_records.py</code> <pre><code>def test_records_add_and_get_records():\n    \"\"\"\n    Test the functionality of adding a record to the Records object and retrieving it.\n\n    This test verifies that:\n    - A record can be added to the Records instance with a specified request and a list of transaction objects.\n    - The added record contains the correct request value and associated transactions.\n    \"\"\"\n    records = Records()\n    req = Transaction(timestamp=5, payload=None)\n    resp1 = Transaction(timestamp=10, payload=\"payload1\")\n    resp2 = Transaction(timestamp=20, payload=\"payload2\")\n\n    records.add_record(request=req, responses=[resp1, resp2])\n    all_records = records.records\n    assert len(all_records) == 1\n    assert all_records[0].request == req\n    assert all_records[0].responses == [resp1, resp2]\n    assert all_records[0].responses == [resp1, resp2]\n</code></pre>"},{"location":"api/#aiperf.tests.test_records.test_records_multiple_adds","title":"<code>test_records_multiple_adds()</code>","text":"<p>Test that multiple records can be added to the Records object and retrieved in order.</p> <p>This test creates two transaction objects with different timestamps and payloads, adds them as records with distinct request values, and verifies: - The total number of records is correct. - The order of records is preserved. - The request and transaction payloads are correctly associated with each record.</p> Source code in <code>aiperf/tests/test_records.py</code> <pre><code>def test_records_multiple_adds():\n    \"\"\"\n    Test that multiple records can be added to the Records object and retrieved in order.\n\n    This test creates two transaction objects with different timestamps and payloads,\n    adds them as records with distinct request values, and verifies:\n    - The total number of records is correct.\n    - The order of records is preserved.\n    - The request and transaction payloads are correctly associated with each record.\n    \"\"\"\n    records = Records()\n    req1 = Transaction(timestamp=100, payload=None)\n    req2 = Transaction(timestamp=200, payload=None)\n    resp1 = Transaction(timestamp=150, payload=\"a\")\n    resp2 = Transaction(timestamp=250, payload=\"b\")\n    records.add_record(request=req1, responses=[resp1])\n    records.add_record(request=req2, responses=[resp2])\n    all_records = records.records\n    assert len(all_records) == 2\n    assert all_records[0].request == req1\n    assert all_records[1].request == req2\n    assert all_records[0].responses[0].payload == \"a\"\n    assert all_records[1].responses[0].payload == \"b\"\n</code></pre>"},{"location":"api/#aiperf.tests.test_records.test_records_serialization_and_deserialization","title":"<code>test_records_serialization_and_deserialization()</code>","text":"<p>Test the serialization and deserialization of the Records model using Pydantic's model_dump and model_validate methods. This test creates a Records instance, adds a record with two transaction objects, serializes the Records instance to a dictionary, and then deserializes it back to a Records object. It asserts that the deserialized object retains the correct structure and data, including the request value and the details of each transaction.</p> Source code in <code>aiperf/tests/test_records.py</code> <pre><code>def test_records_serialization_and_deserialization():\n    \"\"\"\n    Test the serialization and deserialization of the Records model using Pydantic's model_dump and model_validate methods.\n    This test creates a Records instance, adds a record with two transaction objects, serializes the Records instance to a dictionary,\n    and then deserializes it back to a Records object. It asserts that the deserialized object retains the correct structure and data,\n    including the request value and the details of each transaction.\n    \"\"\"\n\n    records = Records()\n    req = Transaction(timestamp=1000, payload=\"request_payload\")\n    resp1 = Transaction(timestamp=42, payload={\"foo\": \"bar\"})\n    resp2 = Transaction(timestamp=43, payload=[1, 2, 3])\n    records.add_record(request=req, responses=[resp1, resp2])\n\n    # Serialize to dict using Pydantic's model_dump\n    data = records.model_dump()\n\n    # Deserialize back using model_validate\n    loaded_records = Records.model_validate(data)\n\n    assert len(loaded_records.records) == 1\n    assert loaded_records.records[0].request.timestamp == req.timestamp\n    assert loaded_records.records[0].request.payload == req.payload\n    assert loaded_records.records[0].responses[0].timestamp == 42\n    assert loaded_records.records[0].responses[0].payload == {\"foo\": \"bar\"}\n    assert loaded_records.records[0].responses[1].timestamp == 43\n    assert loaded_records.records[0].responses[1].payload == [1, 2, 3]\n</code></pre>"},{"location":"api/#aiperf.tests.test_records.test_transaction_dataclass","title":"<code>test_transaction_dataclass()</code>","text":"<p>Test the initialization and attribute assignment of the Transaction dataclass.</p> <p>This test verifies that a transaction object can be created with a specific timestamp and payload, and that its attributes are correctly set and accessible.</p> Source code in <code>aiperf/tests/test_records.py</code> <pre><code>def test_transaction_dataclass():\n    \"\"\"\n    Test the initialization and attribute assignment of the Transaction dataclass.\n\n    This test verifies that a transaction object can be created with a specific timestamp and payload,\n    and that its attributes are correctly set and accessible.\n    \"\"\"\n    resp = Transaction(timestamp=1234567890, payload={\"result\": \"ok\"})\n    assert resp.timestamp == 1234567890\n    assert resp.payload == {\"result\": \"ok\"}\n</code></pre>"},{"location":"api/#aiperfteststest_request_latency_metric","title":"aiperf.tests.test_request_latency_metric","text":""},{"location":"api/#aiperfteststest_tokenizer","title":"aiperf.tests.test_tokenizer","text":""},{"location":"api/#aiperfteststest_ttft_metric","title":"aiperf.tests.test_ttft_metric","text":""},{"location":"api/#aiperfteststest_ttst_metric","title":"aiperf.tests.test_ttst_metric","text":""},{"location":"api/#aiperftestsutilsasync_test_utils","title":"aiperf.tests.utils.async_test_utils","text":"<p>Utilities for testing asynchronous code.</p>"},{"location":"api/#aiperf.tests.utils.async_test_utils.async_fixture","title":"<code>async_fixture(fixture)</code>  <code>async</code>","text":"<p>Manually await an async pytest fixture.</p> <p>This is necessary because pytest fixtures are not awaited by default in test methods. If the fixture is an async generator, this will get the first yielded value.</p> <p>Parameters:</p> Name Type Description Default <code>fixture</code> <code>T</code> <p>The fixture to await</p> required <p>Returns:</p> Type Description <code>T</code> <p>The awaited fixture value</p> Source code in <code>aiperf/tests/utils/async_test_utils.py</code> <pre><code>async def async_fixture(fixture: T) -&gt; T:\n    \"\"\"\n    Manually await an async pytest fixture.\n\n    This is necessary because pytest fixtures are not awaited by default in test methods.\n    If the fixture is an async generator, this will get the first yielded value.\n\n    Args:\n        fixture: The fixture to await\n\n    Returns:\n        The awaited fixture value\n    \"\"\"\n    if hasattr(fixture, \"__aiter__\"):\n        # If it's an async generator, get the first yielded value\n        with contextlib.suppress(StopAsyncIteration):\n            async_gen = cast(AsyncIterator[Any], fixture)\n            value = await anext(async_gen)\n            return cast(T, value)\n\n    # Otherwise return the fixture as is\n    return fixture\n</code></pre>"},{"location":"api/#aiperf.tests.utils.async_test_utils.async_noop","title":"<code>async_noop(*args, **kwargs)</code>  <code>async</code>","text":"<p>A no-op async function for testing purposes.</p> <p>Can be used to replace asyncio.sleep, asyncio.wait_for, or other async calls in tests. Accepts any arguments but performs no operation and returns immediately.</p> Source code in <code>aiperf/tests/utils/async_test_utils.py</code> <pre><code>async def async_noop(*args, **kwargs) -&gt; None:\n    \"\"\"\n    A no-op async function for testing purposes.\n\n    Can be used to replace asyncio.sleep, asyncio.wait_for, or other async calls in tests.\n    Accepts any arguments but performs no operation and returns immediately.\n    \"\"\"\n    return\n</code></pre>"},{"location":"api/#aiperftestsutilsmetric_test_utils","title":"aiperf.tests.utils.metric_test_utils","text":""},{"location":"hook-system/","title":"Hook system","text":""},{"location":"hook-system/#aiperf-hook-system","title":"AIPerf Hook System","text":"<p>TODO: Once we create a Mixin for self.stop_event, we can avoid having the user to call <code>while not self.stop_event.is_set()</code></p> <p>The AIPerf Hook System provides a powerful, extensible mechanism for implementing lifecycle management and event-driven programming patterns. It enables clean separation of concerns by allowing components to register callbacks that execute at specific points during service execution.</p>"},{"location":"hook-system/#core-components","title":"Core Components","text":""},{"location":"hook-system/#1-hook-types-aiperfhook","title":"1. Hook Types (<code>AIPerfHook</code>)","text":"<p>The system defines standard lifecycle hooks:</p> <ul> <li><code>ON_INIT</code>: Initialization phase</li> <li><code>ON_RUN</code>: Main execution phase</li> <li><code>ON_CONFIGURE</code>: Configuration updates</li> <li><code>ON_START</code>: Service startup</li> <li><code>ON_STOP</code>: Service shutdown</li> <li><code>ON_CLEANUP</code>: Resource cleanup</li> </ul> <p>And additional usability hooks:</p> <ul> <li><code>ON_SET_STATE</code>: State transitions</li> <li><code>AIPERF_TASK</code>: Background task registration</li> </ul>"},{"location":"hook-system/#2-hook-system-hooksystem","title":"2. Hook System (<code>HookSystem</code>)","text":"<p>Manages hook registration and execution:</p> <pre><code>class HookSystem:\n    def __init__(self, supported_hooks: set[HookType]):\n        self.supported_hooks = supported_hooks\n        self._hooks: dict[HookType, list[Callable]] = {}\n</code></pre>"},{"location":"hook-system/#3-hooks-mixin-hooksmixin","title":"3. Hooks Mixin (<code>HooksMixin</code>)","text":"<p>Provides the interface for hook-enabled classes:</p> <pre><code>class HooksMixin:\n    supported_hooks: set[HookType] = set()\n\n    def __init__(self):\n        self._hook_system = HookSystem(self.supported_hooks)\n        # Auto-register decorated methods\n</code></pre>"},{"location":"hook-system/#usage-patterns","title":"Usage Patterns","text":""},{"location":"hook-system/#basic-implementation-self-contained","title":"Basic Implementation - Self Contained","text":"<p>Hooks can be defined and used by the same class</p> <pre><code>import asyncio\nfrom aiperf.common.hooks import HooksMixin, supports_hooks, on_init, on_cleanup, AIPerfHook\n\n@supports_hooks(AIPerfHook.ON_INIT, AIPerfHook.ON_CLEANUP)\nclass MyService(HooksMixin):\n    def __init__(self):\n        self.resources = []\n        # Make sure to call __init__ on the HooksMixin\n        super().__init__()\n\n    # Hook definitions\n\n    @on_init\n    async def _setup_database(self):\n        \"\"\"Initialize database connection.\"\"\"\n        self.db = await connect_to_database()\n        self.resources.append(self.db)\n\n    @on_init\n    async def _setup_cache(self):\n        \"\"\"Initialize cache system.\"\"\"\n        self.cache = await setup_redis_cache()\n        self.resources.append(self.cache)\n\n    @on_cleanup\n    async def _cleanup_resources(self):\n        \"\"\"Clean up all resources.\"\"\"\n        await asyncio.gather(*[\n            resource.close() for resource in self.resources\n        ])\n\n    # Top-level functions that will call the hooks\n\n    async def initialize(self):\n        await self.run_hooks_async(AIPerfHook.ON_INIT)\n\n    async def cleanup(self):\n        await self.run_hooks_async(AIPerfHook.ON_CLEANUP)\n</code></pre>"},{"location":"hook-system/#basic-implementation-inheritance","title":"Basic Implementation - Inheritance","text":"<p>Hooks can also be used to call additional functionality defined in subclasses. By calling <code>await self.run_hooks_async(AIPerfHook.ON_INIT)</code>, the base class is able to call all registered init functions no matter the subclass that defined it.</p> <pre><code>from aiperf.common.hooks import HooksMixin, supports_hooks, on_init, on_cleanup, AIPerfHook\n\n@supports_hooks(AIPerfHook.ON_INIT, AIPerfHook.ON_CLEANUP)\nclass MyHookService(HooksMixin):\n    \"\"\"Defines the top-level functionality that will call the registered hooks.\"\"\"\n    def __init__(self):\n        # Make sure to call __init__ on the HooksMixin\n        super().__init__()\n\n    async def initialize(self):\n        \"\"\"Runs all of the registered ON_INIT hooks\"\"\"\n        # Note: Using run_hooks without the _async will run them serially\n        await self.run_hooks(AIPerfHook.ON_INIT)\n\n    async def cleanup(self):\n        \"\"\"Runs all of the registered ON_CLEANUP hooks\"\"\"\n        await self.run_hooks_async(AIPerfHook.ON_CLEANUP)\n\n\nclass CustomService(MyHookService):\n    \"\"\"Defines functions that will be called by the lifecycle hooks\"\"\"\n    @on_init\n    async def _setup_database(self):\n        \"\"\"Initialize database connection.\"\"\"\n        self.db = await connect_to_database()\n        self.resources.append(self.db)\n\n    @on_init\n    async def _setup_cache(self):\n        \"\"\"Initialize cache system.\"\"\"\n        self.cache = await setup_redis_cache()\n        self.resources.append(self.cache)\n\n    @on_cleanup\n    async def _cleanup_cache(self):\n        await self.cache.close()\n\n    @on_cleanup\n    async def _cleanup_database(self):\n        await self.db.close()\n</code></pre>"},{"location":"hook-system/#hook-execution-flow","title":"Hook Execution Flow","text":"<pre><code>sequenceDiagram\n    participant C as \ud83d\udcf1 Client\n    participant CS as \ud83d\udd27 CustomService\n    participant MHS as \u2699\ufe0f MyHookService\n    participant HM as \ud83c\udfaf HooksMixin\n\n    Note over C, HM: Hook System Setup &amp; Registration\n    MHS--&gt;&gt;HM: \ud83d\udccb @supports_hooks(AIPerfHook.ON_INIT, ...)\n    CS--&gt;&gt;HM: \ud83d\udd17 @on_init (registration)\n\n    Note over C, HM: Hook Execution Flow\n    C-&gt;&gt;+MHS: \ud83d\ude80 initialize()\n    MHS-&gt;&gt;+HM: \u26a1 run_hooks_async(ON_INIT)\n\n    Note over HM: Parallel Hook Execution\n    loop \ud83d\udd04 For each registered hook\n        HM-&gt;&gt;+CS: \ud83c\udfac Execute hook function\n        CS--&gt;&gt;-HM: \u2705 Hook completed\n    end\n\n    HM--&gt;&gt;-MHS: \ud83c\udfc1 All hooks completed\n    MHS--&gt;&gt;-C: \u2728 Initialization complete\n\n    %% Custom styling for better visibility\n    %%{init: {\n        'theme': 'dark',\n        'themeVariables': {\n            'primaryColor': '#2196f3',\n            'primaryTextColor': '#ffffff',\n            'primaryBorderColor': '#1976d2',\n            'lineColor': '#90a4ae',\n            'secondaryColor': '#9c27b0',\n            'tertiaryColor': '#4caf50',\n            'background': '#263238',\n            'noteTextColor': '#ffffff',\n            'noteBkgColor': '#37474f',\n            'noteBorderColor': '#546e7a'\n        }\n    }}%%\n</code></pre>"},{"location":"hook-system/#inheritance-and-hook-composition","title":"Inheritance and Hook Composition","text":"<pre><code>@supports_hooks(AIPerfHook.ON_INIT, AIPerfHook.ON_CLEANUP)\nclass BaseService(HooksMixin):\n    @on_init\n    async def base_init(self):\n        self.logger.info(\"Base service initializing\")\n\n@supports_hooks(AIPerfHook.ON_START)  # Adds ON_START to inherited hooks\nclass WebService(BaseService):\n    @on_init\n    async def web_init(self):\n        self.logger.info(\"Web service initializing\")\n\n    @on_start\n    async def start_server(self):\n        self.server = await start_web_server()\n</code></pre> <p>Hook inheritance flow:</p> <pre><code>graph TD\n    A[\"**BaseService**\"] --&gt; B[\"*WebService*\"]\n    A --&gt; C[\"&lt;b&gt;Hooks:&lt;/b&gt;&lt;br/&gt;\u2022 ON_INIT&lt;br/&gt;\u2022 ON_CLEANUP\"]\n    B --&gt; D[\"&lt;b&gt;Inherited Hooks:&lt;/b&gt;&lt;br/&gt;\u2022 ON_INIT&lt;br/&gt;\u2022 ON_CLEANUP&lt;br/&gt;&lt;br/&gt;&lt;b&gt;Added Hook:&lt;/b&gt;&lt;br/&gt;\u2022 ON_START\"]\n\n    E[\"Hook Execution&lt;br/&gt;Order\"] --&gt; F[\"base_init()\"]\n    F --&gt; G[\"web_init()\"]\n\n    %% Styling for better visibility\n    style A fill:#bbdefb,stroke:#1976d2,stroke-width:2px,color:#000\n    style B fill:#c8e6c9,stroke:#388e3c,stroke-width:2px,color:#000\n    style C fill:#e1f5fe,stroke:#0277bd,stroke-width:2px,color:#000\n    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000\n    style E fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000\n    style F fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000\n    style G fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000\n\n    %% Better arrow styling\n    linkStyle 0 stroke:#666,stroke-width:2px\n    linkStyle 1 stroke:#666,stroke-width:2px\n    linkStyle 2 stroke:#666,stroke-width:2px\n    linkStyle 3 stroke:#666,stroke-width:2px\n    linkStyle 4 stroke:#666,stroke-width:2px\n</code></pre>"},{"location":"hook-system/#hook-registration-and-execution-order","title":"Hook Registration and Execution Order","text":"<p>Hooks are registered in a predictable, deterministic order that ensures proper initialization flow:</p>"},{"location":"hook-system/#1-across-classes-base-derived","title":"1. Across Classes: Base \u2192 Derived","text":"<pre><code>class BaseService(HooksMixin):\n    @on_init\n    async def base_setup(self):        # Registered 1st\n        pass\n\nclass MyService(BaseService):\n    @on_init\n    async def service_setup(self):     # Registered 2nd\n        pass\n</code></pre>"},{"location":"hook-system/#2-within-classes-definition-order","title":"2. Within Classes: Definition Order","text":"<pre><code>class MyService(BaseService):\n    @on_init\n    async def setup_database(self):    # Registered 1st\n        pass\n\n    @on_init\n    async def setup_cache(self):       # Registered 2nd\n        pass\n\n    @on_init\n    async def setup_metrics(self):     # Registered 3rd\n        pass\n</code></pre> <p>\ud83d\udca1 Key Point: Base class hooks always run before derived class hooks, ensuring that foundational components (communication, signals) are initialized before service-specific functionality.</p> <p>\u26a0\ufe0f Important: To maintain this execution order, you must use <code>run_hooks()</code> (serial execution). Using <code>run_hooks_async()</code> runs hooks concurrently and does not guarantee execution order, even though registration order is still deterministic.</p> <pre><code># \u2705 Preserves execution order (serial)\nawait self.run_hooks(AIPerfHook.ON_INIT)\n\n# \u274c No execution order guarantee (concurrent)\nawait self.run_hooks_async(AIPerfHook.ON_INIT)\n</code></pre>"},{"location":"hook-system/#advanced-features","title":"Advanced Features","text":""},{"location":"hook-system/#runtime-hook-registration","title":"Runtime Hook Registration","text":"<pre><code>service = MyService()\n\nasync def custom_monitoring_hook():\n    await send_metrics_to_monitoring_system()\n\n# Register hook at runtime using class instance\nservice.register_hook(AIPerfHook.ON_START, custom_monitoring_hook)\n</code></pre>"},{"location":"hook-system/#serial-vs-concurrent-execution","title":"Serial vs Concurrent Execution","text":"<pre><code># Serial execution (hooks run one after another). Each one is awaited individually.\nawait self.run_hooks(AIPerfHook.ON_INIT)\n\n# Concurrent execution (all hooks run simultaneously and are gathered at the end)\nawait self.run_hooks_async(AIPerfHook.ON_INIT)\n</code></pre>"},{"location":"hook-system/#error-handling","title":"Error Handling","text":""},{"location":"hook-system/#unsupported-hook-error","title":"Unsupported Hook Error","text":"<p>When a hook decorator is defined on a function within a class that does not support that hook type, an exception is raised. The reason for this is to cause traceability and prevent users from trying to hook into a functionality that is not implemented.</p> <pre><code>@supports_hooks(AIPerfHook.ON_INIT)\nclass LimitedService(HooksMixin):\n    @on_start  # This will raise UnsupportedHookError\n    async def invalid_hook(self):\n        pass\n</code></pre>"},{"location":"hook-system/#multi-error-handling","title":"Multi-Error Handling","text":"<p>When multiple hooks fail, the system collects all errors:</p> <pre><code>try:\n    await self.run_hooks(AIPerfHook.ON_INIT)\nexcept AIPerfMultiError as e:\n    for error in e.errors:\n        self.logger.error(f\"Hook failed: {error}\")\n</code></pre>"},{"location":"hook-system/#best-practices","title":"Best Practices","text":""},{"location":"hook-system/#1-hook-naming-convention","title":"1. Hook Naming Convention","text":"<pre><code>class MyService(BaseService):\n    @on_init\n    async def _initialize_database(self):  # Prefix with underscore\n        pass\n\n    @on_cleanup\n    async def _cleanup_connections(self):  # Descriptive names\n        pass\n</code></pre>"},{"location":"hook-system/#2-resource-management","title":"2. Resource Management","text":"<pre><code>@on_init\nasync def _setup_resources(self):\n    self.resources = []\n\n@on_cleanup\nasync def _cleanup_resources(self):\n    for resource in reversed(self.resources):  # LIFO cleanup\n        await resource.close()\n</code></pre>"},{"location":"hook-system/#3-error-isolation","title":"3. Error Isolation","text":"<pre><code>@on_init\nasync def _safe_initialization(self):\n    try:\n        await risky_operation()\n    except Exception as e:\n        self.logger.error(f\"Non-critical init failed: {e}\")\n        # Don't re-raise if operation is optional\n</code></pre>"},{"location":"hook-system/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Concurrent execution: Use <code>run_hooks_async()</code> for independent hooks</li> <li>Serial execution: Use <code>run_hooks()</code> when hooks have dependencies (ie. base class hooks must be called before subclass hooks)</li> <li>Hook registration: Happens once during <code>__init__</code>, minimal overhead</li> <li>Memory usage: Hooks are stored as method references bound to self, not duplicated</li> </ul> <p>The AIPerf Hook System provides a robust foundation for building extensible, maintainable services with clear lifecycle management and event-driven architecture patterns.</p>"},{"location":"hook-system/#the-special-aiperf_task-decorator","title":"The Special <code>@aiperf_task</code> Decorator","text":"<p>The <code>@aiperf_task</code> decorator is unique among the AIPerf hooks because it doesn't follow the typical hook execution pattern. Instead of being executed at specific lifecycle moments like other hooks, functions decorated with <code>@aiperf_task</code> are automatically registered as long-running background tasks that start when the service initializes and run continuously until the service shuts down.</p>"},{"location":"hook-system/#how-aiperf_task-works","title":"How <code>@aiperf_task</code> Works","text":"<p>The <code>@aiperf_task</code> decorator works through the <code>AIPerfTaskMixin</code> class, which provides automatic task lifecycle management:</p> <ol> <li>Discovery: All methods decorated with <code>@aiperf_task</code> are discovered during class initialization</li> <li>Automatic Startup: Tasks are automatically started during the <code>ON_INIT</code> hook phase</li> <li>Registration: Each task is created using <code>asyncio.create_task()</code> and stored in <code>registered_tasks</code></li> <li>Automatic Shutdown: Tasks are cancelled and cleaned up during the <code>ON_STOP</code> hook phase</li> </ol>"},{"location":"hook-system/#using-aiperftaskmixin","title":"Using <code>AIPerfTaskMixin</code>","text":"<p>To use <code>@aiperf_task</code> decorated methods, your class must inherit from <code>AIPerfTaskMixin</code>:</p> <pre><code>from aiperf.common.hooks import AIPerfTaskMixin, aiperf_task\nimport asyncio\n\nclass BackgroundService(AIPerfTaskMixin):\n    def __init__(self):\n        self.stop_event = asyncio.Event()\n        self.metrics = {}\n        super().__init__()  # Important: call super().__init__()\n\n    @aiperf_task\n    async def _monitor_system_health(self):\n        \"\"\"Continuously monitor system health metrics.\"\"\"\n        while not self.stop_event.is_set():\n            try:\n                # Collect system metrics\n                cpu_usage = await get_cpu_usage()\n                memory_usage = await get_memory_usage()\n\n                self.metrics.update({\n                    'cpu': cpu_usage,\n                    'memory': memory_usage,\n                    'timestamp': time.time()\n                })\n\n                # Check if metrics exceed thresholds\n                if cpu_usage &gt; 90:\n                    self.logger.warning(f\"High CPU usage: {cpu_usage}%\")\n\n                await asyncio.sleep(5)  # Poll every 5 seconds\n\n            except asyncio.CancelledError:\n                self.logger.info(\"Health monitoring task cancelled\")\n                break\n            except Exception as e:\n                self.logger.error(f\"Error in health monitoring: {e}\")\n                await asyncio.sleep(1)\n\n    # Manual lifecycle control\n    async def start_service(self):\n        \"\"\"Start the service and all background tasks.\"\"\"\n        await self.run_hooks(AIPerfHook.ON_INIT)  # This starts all @aiperf_task methods\n\n    async def stop_service(self):\n        \"\"\"Stop the service and all background tasks.\"\"\"\n        self.stop_event.set()  # Signal tasks to stop\n        await self.run_hooks(AIPerfHook.ON_STOP)   # This cancels and waits for all tasks\n</code></pre>"},{"location":"hook-system/#key-differences-from-other-hooks","title":"Key Differences from Other Hooks","text":"Aspect Regular Hooks (<code>@on_init</code>, <code>@on_start</code>, etc.) <code>@aiperf_task</code> Execution Called once at specific lifecycle events Run continuously as background tasks Lifecycle Short-lived, return after completion Long-lived, run until service shutdown Cancellation Not applicable Automatically cancelled on service stop Purpose Setup, teardown, event handling Background processing, monitoring, polling Mixin Required <code>HooksMixin</code> <code>AIPerfTaskMixin</code>"},{"location":"hook-system/#task-lifecycle-management","title":"Task Lifecycle Management","text":"<p>The <code>AIPerfTaskMixin</code> handles the complete lifecycle of <code>@aiperf_task</code> decorated methods:</p> <pre><code>class AIPerfTaskMixin(HooksMixin):\n    def __init__(self):\n        super().__init__()\n        self.registered_tasks: dict[str, asyncio.Task] = {}\n\n    @on_init\n    async def _start_tasks(self):\n        \"\"\"Start all the registered tasks.\"\"\"\n        for hook in self.get_hooks(AIPerfHook.AIPERF_TASK):\n            self.registered_tasks[hook.__name__] = asyncio.create_task(hook())\n\n    @on_stop\n    async def _stop_tasks(self):\n        \"\"\"Stop all the registered tasks.\"\"\"\n        for task in self.registered_tasks.values():\n            task.cancel()\n\n        # Wait for all tasks to complete\n        with contextlib.suppress(asyncio.CancelledError):\n            await asyncio.gather(*self.registered_tasks.values())\n</code></pre>"},{"location":"hook-system/#best-practices-for-aiperf_task","title":"Best Practices for <code>@aiperf_task</code>","text":""},{"location":"hook-system/#1-always-handle-cancellation","title":"1. Always Handle Cancellation","text":"<pre><code>@aiperf_task\nasync def _background_worker(self):\n    try:\n        while not self.stop_event.is_set():\n            await do_work()\n            await asyncio.sleep(1)\n    except asyncio.CancelledError:\n        # Perform cleanup if necessary\n        await cleanup_resources()\n        raise  # Re-raise to properly cancel the task\n</code></pre>"},{"location":"hook-system/#2-use-stop-events-for-graceful-shutdown","title":"2. Use Stop Events for Graceful Shutdown","text":"<pre><code>@aiperf_task\nasync def _poller(self):\n    while not self.stop_event.is_set():\n        try:\n            await poll_external_service()\n            await asyncio.sleep(10)\n        except asyncio.CancelledError:\n            break\n</code></pre>"},{"location":"hook-system/#3-include-error-handling-and-recovery","title":"3. Include Error Handling and Recovery","text":"<pre><code>@aiperf_task\nasync def _resilient_worker(self):\n    retry_count = 0\n    max_retries = 3\n\n    while not self.stop_event.is_set():\n        try:\n            await potentially_failing_operation()\n            retry_count = 0  # Reset on success\n\n        except asyncio.CancelledError:\n            break\n        except Exception as e:\n            retry_count += 1\n            if retry_count &gt; max_retries:\n                self.logger.error(f\"Task failed {max_retries} times, stopping\")\n                break\n\n            backoff_time = min(2 ** retry_count, 60)  # Exponential backoff\n            await asyncio.sleep(backoff_time)\n</code></pre>"},{"location":"hook-system/#4-avoid-blocking-operations","title":"4. Avoid Blocking Operations","text":"<pre><code>@aiperf_task\nasync def _file_processor(self):\n    while not self.stop_event.is_set():\n        try:\n            # Use asyncio.to_thread for blocking I/O\n            result = await asyncio.to_thread(cpu_intensive_operation)\n            await process_result(result)\n\n        except asyncio.CancelledError:\n            break\n</code></pre>"},{"location":"hook-system/#real-world-use-cases","title":"Real-World Use Cases","text":""},{"location":"hook-system/#network-communication-tasks","title":"Network Communication Tasks","text":"<pre><code>@aiperf_task\nasync def _message_receiver(self):\n    \"\"\"Continuously receive messages from ZMQ socket.\"\"\"\n    while not self.is_shutdown:\n        try:\n            message = await self.socket.recv_string()\n            await self.handle_message(message)\n        except asyncio.CancelledError:\n            break\n</code></pre>"},{"location":"hook-system/#periodic-maintenance-tasks","title":"Periodic Maintenance Tasks","text":"<pre><code>@aiperf_task\nasync def _cleanup_old_files(self):\n    \"\"\"Clean up old log files every hour.\"\"\"\n    while not self.stop_event.is_set():\n        try:\n            await cleanup_logs_older_than(days=7)\n            await asyncio.sleep(3600)  # Wait 1 hour\n        except asyncio.CancelledError:\n            break\n</code></pre>"},{"location":"hook-system/#health-check-and-heartbeat-tasks","title":"Health Check and Heartbeat Tasks","text":"<pre><code>@aiperf_task\nasync def _send_heartbeat(self):\n    \"\"\"Send periodic heartbeat messages.\"\"\"\n    while not self.stop_event.is_set():\n        try:\n            heartbeat = HeartbeatMessage(\n                service_id=self.service_id,\n                timestamp=time.time(),\n                status=\"healthy\"\n            )\n            await self.publish_heartbeat(heartbeat)\n            await asyncio.sleep(self.heartbeat_interval)\n        except asyncio.CancelledError:\n            break\n</code></pre>"},{"location":"hook-system/#task-registry-and-debugging","title":"Task Registry and Debugging","text":"<p>All <code>@aiperf_task</code> decorated methods are stored in <code>self.registered_tasks</code> with their function name as the key:</p> <pre><code># Access running tasks programmatically\nfor task_name, task in self.registered_tasks.items():\n    print(f\"Task {task_name}: {'running' if not task.done() else 'finished'}\")\n\n# Check if a specific task is running\nif '_monitor_system_health' in self.registered_tasks:\n    task = self.registered_tasks['_monitor_system_health']\n    if not task.done():\n        print(\"Health monitoring is active\")\n</code></pre>"},{"location":"hook-system/#integration-with-services","title":"Integration with Services","text":"<p>When using with AIPerf services that inherit from <code>BaseService</code>, the lifecycle is automatically managed:</p> <pre><code>from aiperf.common.service.base_service import BaseService\n\nclass MyService(BaseService):  # BaseService inherits from AIPerfTaskMixin\n    @aiperf_task\n    async def _background_processor(self):\n        while not self.stop_event.is_set():\n            await self.process_work()\n            await asyncio.sleep(1)\n\n    # Tasks will automatically start when service initializes\n    # Tasks will automatically stop when service shuts down\n</code></pre>"},{"location":"diagrams/Service%20Class%20Diagram/","title":"Service Class Diagram","text":"<pre><code>classDiagram\n    direction LR\n\n    %% Abstract classes\n    class AbstractBaseService {\n        &lt;&lt;abstract&gt;&gt;\n    }\n\n    %% Concrete base classes\n    class BaseService {\n        &lt;&lt;abstract&gt;&gt;\n    }\n\n    %% Specialized service types\n    class BaseComponentService {\n        &lt;&lt;abstract&gt;&gt;\n    }\n\n    class BaseControllerService {\n        &lt;&lt;abstract&gt;&gt;\n    }\n\n    %% Concrete service implementations\n    class SystemController {\n    }\n\n    class Worker {\n    }\n\n    class WorkerManager {\n    }\n\n    class DatasetManager {\n    }\n\n    class RecordsManager {\n    }\n\n    class TimingManager {\n    }\n\n    class PostProcessorManager {\n    }\n\n    %% Service management classes\n    class BaseServiceManager {\n        &lt;&lt;abstract&gt;&gt;\n    }\n\n    class MultiProcessServiceManager {\n    }\n\n    class KubernetesServiceManager {\n    }\n\n    %% Relationships\n    AbstractBaseService &lt;|-- BaseService\n    BaseService &lt;|-- BaseComponentService\n    BaseService &lt;|-- BaseControllerService\n    BaseService &lt;|-- Worker\n    BaseControllerService &lt;|-- SystemController\n    BaseComponentService &lt;|-- WorkerManager\n    BaseComponentService &lt;|-- DatasetManager\n    BaseComponentService &lt;|-- RecordsManager\n    BaseComponentService &lt;|-- TimingManager\n    BaseComponentService &lt;|-- PostProcessorManager\n\n\n    SystemController ..&gt; BaseServiceManager: uses\n    BaseServiceManager &lt;|-- MultiProcessServiceManager\n    BaseServiceManager &lt;|-- KubernetesServiceManager\n    WorkerManager --|&gt; Worker: spawns\n</code></pre>"}]}